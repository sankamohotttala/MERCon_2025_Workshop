"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Welcome","",,2024 IEEE International Conference on Pervasive Computing and Communications (PerCom),"11 Apr 2024","2024","","","1","2","On behalf of the Steering and Organizing Committees, we are delighted to welcome you to the 22nd IEEE International Conference on Pervasive Computing and Communications (PerCom 2024), to be held in Biarritz, France, from March 11-15, 2024. IEEE PerCom is a flagship annual conference that provides a forum for researchers and practitioners to present new discoveries and discuss future developments in pervasive computing and communications research and technologies.","2474-249X","979-8-3503-2603-1","10.1109/PerCom59722.2024.10494501","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10494501","","","","","","","IEEE","11 Apr 2024","","","IEEE","IEEE Conferences"
"Welcome From the TPC Chairs","",,2024 IEEE International Conference on Pervasive Computing and Communications (PerCom),"11 Apr 2024","2024","","","3","3","","2474-249X","979-8-3503-2603-1","10.1109/PerCom59722.2024.10494425","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10494425","","","","","","0","IEEE","11 Apr 2024","","","IEEE","IEEE Conferences"
"Committees","",,2024 IEEE International Conference on Pervasive Computing and Communications (PerCom),"11 Apr 2024","2024","","","4","10","Committees.","2474-249X","979-8-3503-2603-1","10.1109/PerCom59722.2024.10494491","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10494491","","","","","","","IEEE","11 Apr 2024","","","IEEE","IEEE Conferences"
"Keynotes","",,2024 IEEE International Conference on Pervasive Computing and Communications (PerCom),"11 Apr 2024","2024","","","11","12","","2474-249X","979-8-3503-2603-1","10.1109/PerCom59722.2024.10494433","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10494433","","","","","","","IEEE","11 Apr 2024","","","IEEE","IEEE Conferences"
"Technical Program","",,2024 IEEE International Conference on Pervasive Computing and Communications (PerCom),"11 Apr 2024","2024","","","13","17","Technical Program.","2474-249X","979-8-3503-2603-1","10.1109/PerCom59722.2024.10494484","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10494484","","","","","","","IEEE","11 Apr 2024","","","IEEE","IEEE Conferences"
"About IEEE PerCom 2024","",,2024 IEEE International Conference on Pervasive Computing and Communications (PerCom),"11 Apr 2024","2024","","","18","18","","2474-249X","979-8-3503-2603-1","10.1109/PerCom59722.2024.10494469","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10494469","","","","","","0","IEEE","11 Apr 2024","","","IEEE","IEEE Conferences"
"2024 IEEE International Conference on Pervasive Computing and Communications (PerCom)","",,2024 IEEE International Conference on Pervasive Computing and Communications (PerCom),"11 Apr 2024","2024","","","19","19","2024 IEEE International Conference on Pervasive Computing and Communications (PerCom).","2474-249X","979-8-3503-2603-1","10.1109/PerCom59722.2024.10494478","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10494478","","","","","","","IEEE","11 Apr 2024","","","IEEE","IEEE Conferences"
"UR2M: Uncertainty and Resource-Aware Event Detection on Microcontrollers","H. Jia; Y. D. Kwon; D. Mat; N. Pham; L. Qendro; T. Vu; C. Mascolo","University of Cambridge, Cambridge, UK; University of Cambridge, Cambridge, UK; Singapore Management University, Singapore; Cardiff University, Cardiff, UK; Nokia Bell Labs, Cambridge, UK; University of Colorado Boulder, Colorado, US; University of Cambridge, Cambridge, UK",2024 IEEE International Conference on Pervasive Computing and Communications (PerCom),"11 Apr 2024","2024","","","1","10","Traditional machine learning techniques are prone to generating inaccurate predictions when confronted with shifts in the distribution of data between the training and testing phases. This vulnerability can lead to severe consequences, especially in applications such as mobile healthcare. Uncertainty estimation has the potential to mitigate this issue by assessing the reliability of a model's output. However, existing uncertainty estimation techniques often require substantial computational resources and memory, making them impractical for implementation on microcontrollers (MCUs). This limitation hinders the feasibility of many important on-device wearable event detection (WED) applications, such as heart attack detection. In this paper, we present UR2M, a novel Uncertainty and Resource-aware event detection framework for MCUs. Specifically, we (i) develop an uncertainty-aware WED based on evidential theory for accurate event detection and reliable uncertainty estimation; (ii) introduce a cascade ML framework to achieve efficient model inference via early exits, by sharing shallower model layers among different event models; (iii) optimize the deployment of the model and MCU library for system efficiency. We conducted extensive experiments and compared UR2M to traditional uncertainty baselines using three wearable datasets. Our results demonstrate that UR2M achieves up to 864% faster inference speed, 857% energy-saving for uncertainty estimation, 55% memory saving on two popular MCUs, and a 22% improvement in uncertainty quantification performance. UR2M can be deployed on a wide range of MCUs, significantly expanding real-time and reliable WED applications.","2474-249X","979-8-3503-2603-1","10.1109/PerCom59722.2024.10494467","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10494467","Uncertainty;Event Detection;Efficiency;Microcontrollers","Training;Pervasive computing;Uncertainty;Event detection;Microcontrollers;Memory management;Reliability theory","","","","37","IEEE","11 Apr 2024","","","IEEE","IEEE Conferences"
"Leveraging On-Board UAV Motion Estimation for Lightweight Macroscopic Crowd Identification","K. Anjum; T. Chowdhury; S. Mandava; B. Piccoli; D. Pompili","Dept. of Electrical and Computer Engineering; Dept. of Electrical and Computer Engineering; Dept. of Electrical and Computer Engineering; Dept. of of Mathematical Sciences, Rutgers University, NJ, USA; Dept. of Electrical and Computer Engineering",2024 IEEE International Conference on Pervasive Computing and Communications (PerCom),"11 Apr 2024","2024","","","11","17","This paper introduces a novel, lightweight, on-board approach to crowd pattern identification, ingeniously using the processes of existing video compression standards, particularly H.264 or MPEG-4. Piggy-backing on the H.264 video-encoding algorithm, we propose real-time crowd pattern recognition and identification methodologies that can identify macroscopic patterns in as low as 2 milliseconds on NVIDIA TX2, resulting in around 45 x execution time reduction compared to existing approaches. Furthermore, we introduce a temporally aware approach to pinpoint and adapt to crowd movement patterns, continuously recalibrating as a drone's Point Of View (POV) varies or observed motions diverge. Evaluating our method against publicly available datasets, we emphasize our system's performance and computational advantages, especially when faced with real-time observational shifts. In conclusion, our approach elegantly bridges the gap between crowd safety imperatives and the challenges of UAV monitoring, heralding a new era of real-time drone-centric crowd management intelligence.","2474-249X","979-8-3503-2603-1","10.1109/PerCom59722.2024.10494446","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10494446","Crowd Pattern Recognition;Crowd Surveillance;On-board Computation;Video Encoding","Pervasive computing;System performance;Motion estimation;Transform coding;Video compression;Autonomous aerial vehicles;Real-time systems","","","","21","IEEE","11 Apr 2024","","","IEEE","IEEE Conferences"
"End-to-End Multi-Modal Tiny-CNN for Cardiovascular Monitoring on Sensor Patches","M. F. Rifet Ibrahim; T. Alkanat; M. Meijer; A. Schlaefer; P. Stelldinger","NXP Semiconductors, Eindhoven, The Netherlands; NXP Semiconductors, Eindhoven, The Netherlands; NXP Semiconductors, Eindhoven, The Netherlands; Institute of Medical Technology and Intelligent Systems, Hamburg University of Technology, Hamburg, Germany; Department of Computer Science, Hamburg University of Applied Sciences, Hamburg, Germany",2024 IEEE International Conference on Pervasive Computing and Communications (PerCom),"11 Apr 2024","2024","","","18","24","The vast majority of cardiovascular diseases are avoidable or treatable by preventive measures and early de-tection. To efficiently detect early signs and risk factors, car-diovascular parameters can be monitored continuously with small sensor patches, which improve the comfort of patients. However, processing the sensor data is a challenging task with the demanding needs of robustness, reliability, performance and efficiency. The field of deep learning has tremendous potential to provide a way to analyze cardiovascular sensor data to detect anomalies which alleviates the workload of doctors for more effective data interpretation. In this work, we show the feasibility of applying deep learning for the classification of synchronized electrocardiogram and phonocardiogram recordings under very tight resource constraints. Our model employs an early fusion of data and uses convolutional layers to solve the problem of binary classification of anomalies. Our experiments show that our model matches the accuracy of the current state-of-the-art model on the “training-a” dataset of the Physionet Challenge 2016 database while being more than two orders of magnitude more efficient in memory footprint and compute cost. Further, we demonstrate the applicability of our model on edge devices, such as sensor patches, by estimating processor performance, power consumption, and silicon area.","2474-249X","979-8-3503-2603-1","10.1109/PerCom59722.2024.10494450","Bundesministerium für Bildung und Forschung (BMBF)(grant numbers:16KISK221); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10494450","patient monitoring;edge computing;tiny-ml;smart sensing;sensor patches","Deep learning;Performance evaluation;Databases;Computational modeling;Medical services;Silicon;Synchronization","","1","","30","IEEE","11 Apr 2024","","","IEEE","IEEE Conferences"
"Co-zyBench: Using Co-Simulation and Digital Twins to Benchmark Thermal Comfort Provision in Smart Buildings","J. Ma; D. Panic; R. Yus; G. Bouloukakis","Télécom SudParis, Institut Poly technique de Paris, France; Télécom SudParis, Institut Poly technique de Paris, France; Dept. of Computer Science and Electrical Engineering, University of Maryland, Baltimore County, USA; Télécom SudParis, Institut Poly technique de Paris, France",2024 IEEE International Conference on Pervasive Computing and Communications (PerCom),"11 Apr 2024","2024","","","25","35","Heating, Ventilation, and Air Conditioning (HVAC) systems account for 40% to 50% of energy usage in commercial buildings. Thus, innovative ways to control and manage HVAC systems while preserving occupants' comfort are required. State-of-the-art solutions employ pervasive systems with sensors or smart devices to gauge individual thermal sensations, yet assessing these methods is challenging. Real-world experiments are expensive, limited in access, and often overlook occupant and regional diversity. To address this, we introduce Co-zyBench, a benchmark tool using a Digital Twin (DT) approach for evaluating personalized thermal comfort systems. It employs a co-simulation middleware interfacing between a DT of the smart building and its HVAC system and another DT representing occupants' dynamic thermal preferences in various spaces. The DTs that support Co-zyBench are generated based on information, including data captured by sensors, of the space in which the thermal comfort system has to be evaluated. Co-zyBench incorporates metrics for energy consumption, thermal comfort, and occupant equality. It also features reference DTs based on standard buildings, HVAC systems, and occupants with diverse thermal preferences.","2474-249X","979-8-3503-2603-1","10.1109/PerCom59722.2024.10494430","China Scholarship Council (CSC); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10494430","personalized thermal comfort;benchmarking;energy consumption;digital twin","Pervasive computing;Energy consumption;HVAC;Smart buildings;Thermal sensors;Benchmark testing;Sensor systems","","3","","46","IEEE","11 Apr 2024","","","IEEE","IEEE Conferences"
"Adopting User-Space Networking for DDS Message-Oriented Middleware","V. Bode; C. Trinitis; M. Schulz; D. Buettner; T. Preclik","Department of Informatics, Technical University of Munich, Garching, Germany; Department of Informatics, Technical University of Munich, Garching, Germany; Department of Informatics, Technical University of Munich, Garching, Germany; Siemens AG, T CED SES-DE, Munich and Erlangen, Germany; Siemens AG, T CED SES-DE, Munich and Erlangen, Germany",2024 IEEE International Conference on Pervasive Computing and Communications (PerCom),"11 Apr 2024","2024","","","36","46","Due to the flexibility it offers, publish-subscribe messaging middleware is a popular choice in Industrial IoT (IIoT) applications. The Data Distribution Service (DDS) is a widely used industry standard for these systems with a focus on versatility and extensibility, implemented by multiple vendors and present in myriad deployments across industries like aerospace, healthcare and industrial automation. However, many IoT scenarios require real-time capabilities for deployments with rigid timing, reliability and resource constraints, while publish-subscribe mechanisms currently rely on components that are not strictly real-time capable, such as the Linux networking stack, making it hard to provide robust performance guarantees without large safety margins. In order to make publish-subscribe approaches viable and efficient also in such real-time scenarios, we introduce userspace DDS networking transport extensions, allowing us to fasttrack the communication hot path by bypassing the Linux kernel. For this purpose, we extend the best-performing vendor implementation from a previous study, CycloneDDS, to include modules for two widespread user-space networking technologies, the Data Plane Development Kit (DPDK) and the eXpress Data Path (XDP), and we evaluate their performance benefits against four existing DDS implementations (OpenDDS, RTI Connext, FastDDS and CycloneDDS). The CycloneDDS-DPDK and CycloneDDS-XDP extensions offer a performance benefit of 31% and 18% reduced mean latency, respectively, as well as an increase in bandwidth and sample rate throughput of up to 59%, while reducing the latency bound by at least 94%, demonstrating the performance and dependability advantages of circumventing the kernel for real-time communications.","2474-249X","979-8-3503-2603-1","10.1109/PerCom59722.2024.10494460","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10494460","","Industries;Linux;Publish-subscribe;Bandwidth;Throughput;Real-time systems;Safety","","1","","26","IEEE","11 Apr 2024","","","IEEE","IEEE Conferences"
"Furcifer: a Context Adaptive Middleware for Real-world Object Detection Exploiting Local, Edge, and Split Computing in the Cloud Continuum","M. Mendula; P. Bellavista; M. Levorato; S. L. de Guevara Contreras","Department of Computer Science and Engineering, University of Bologna, Italy; Department of Computer Science and Engineering, University of Bologna, Italy; Department of Computer Science and Engineering, University of Bologna, Italy; Donald Bren School of Information and Computer Sciences, University of California at Irvine, United States",2024 IEEE International Conference on Pervasive Computing and Communications (PerCom),"11 Apr 2024","2024","","","47","56","Modern real-time applications widely embed compute intense neural algorithms at their core. Current solutions to support such algorithms either deploy highly-optimized Deep Neural Networks at mobile devices or offload the execution of possibly larger higher-performance neural models to edge servers. While the former solution typically maps to higher energy consumption and lower performance, the latter necessitates the low-latency wireless transfer of high volumes of data. Time-varying variables describing the state of these systems, such as connection quality and system load, determine the optimality of the different computing configurations in terms of energy consumption, task performance, and latency. Herein, we propose Furcifer, a framework capable of dynamically adapting the cloud continuum computing configuration in response to the perceived state of the system. Our container-based approach incorporates low-complexity predictors that generalize well across operating environments. In addition, we develop a highly optimized split Deep Neural Network model, which achieves in-model supervised compression and enhances task offloading. Experimental results for object detection across diverse conditions, environments, and wireless technologies, show Furcifer's remarkable outcomes, including a 2x energy reduction, 30% higher mean Average Precision score than pure local computing, and a notable three-fold increase in frame per second rate compared to static offloading.","2474-249X","979-8-3503-2603-1","10.1109/PerCom59722.2024.10494426","National Science Foundation(grant numbers:CCF 2140154,CNS 2134567); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10494426","Edge Computing;Machine Learning;Object Detection;Mobile agents;Image compression","Wireless communication;Energy consumption;Image edge detection;Computational modeling;Object detection;Artificial neural networks;Real-time systems","","1","","44","IEEE","11 Apr 2024","","","IEEE","IEEE Conferences"
"Practical Latency-Aware Scheduling for Low-Latency Elephant VR Flows in Wi-Fi Networks","S. -J. Lu; W. -X. Chen; Y. -S. Su; Y. -S. Chang; Y. -W. Liu; C. -Y. Li; G. -H. Tu","Computer Science, National Yang Ming Chiao Tung University, Hsinchu City, Taiwan, ROC; Computer Science, National Yang Ming Chiao Tung University, Hsinchu City, Taiwan, ROC; Computer Science, National Yang Ming Chiao Tung University, Hsinchu City, Taiwan, ROC; Computer Science, National Yang Ming Chiao Tung University, Hsinchu City, Taiwan, ROC; Computer Science, National Yang Ming Chiao Tung University, Hsinchu City, Taiwan, ROC; Computer Science, National Yang Ming Chiao Tung University, Hsinchu City, Taiwan, ROC; Computer Science and Engineering, Michigan State University, East Lansing, MI, USA",2024 IEEE International Conference on Pervasive Computing and Communications (PerCom),"11 Apr 2024","2024","","","57","68","Virtual reality (VR) applications are increasingly popular. With high-quality video streams and interactive content, they require both low-latency and high-bandwidth performance demands on the communication from the edge-based VR server to the VR headsets. Although most VR headsets are equipped with dedicated wired or wireless modules connected to the VR server, using common Wi-Fi networks to support them can be a promising trend due to convenience and low cost. However, current Wi-Fi Access Points (APs) cannot meet latency demands of low-latency elephant VR flows, especially in traffic congestion cases. We thus design a practical Wi-Fi scheduling solution, designated as LAST-PQ (Latency-Aware Scheduler with Two-level Priority Queueing), to support VR flows at the Wi-Fi AP. It monitors the runtime latency performance of VR flows while prioritizing scheduling for urgent flows, whose latency demands are at risk of violation. We implement LAST-PQ in Linux on a commodity Wi-Fi platform using an open-source Wi-Fi driver; it is compliant to the current Wi-Fi scheduling framework. The evaluation result shows that it can reduce latency by up to 79.89% in various congested scenarios; moreover, it consistently meets the latency demands of VR flows in cases of mobility at runtime.","2474-249X","979-8-3503-2603-1","10.1109/PerCom59722.2024.10494496","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10494496","Wi-Fi;low latency;VR;scheduling","Headphones;Wireless communication;Runtime;Virtual reality;Streaming media;Servers;Low latency communication","","","","39","IEEE","11 Apr 2024","","","IEEE","IEEE Conferences"
"DiTMoS: Delving into Diverse Tiny-Model Selection on Microcontrollers","X. Ma; S. He; H. Qiao; D. Ma","School of Computing and Information Systems, Singapore Management University, Singapore; School of Computing and Information Systems, Singapore Management University, Singapore; School of Computing and Information Systems, Singapore Management University, Singapore; School of Computing and Information Systems, Singapore Management University, Singapore",2024 IEEE International Conference on Pervasive Computing and Communications (PerCom),"11 Apr 2024","2024","","","69","79","Enabling efficient and accurate deep neural network (DNN) inference on microcontrollers is non-trivial due to the constrained on-chip resources. Current methodologies primarily focus on compressing larger models yet at the expense of model accuracy. In this paper, we rethink the problem from the inverse perspective by constructing small/weak models directly and improving their accuracy. Thus, we introduce DiTMoS, a novel DNN training and inference framework with a selector-classifiers architecture, where the selector routes each input sample to the appropriate classifier for classification. DiTMoS is grounded on a key insight: a composition of weak models can exhibit high diversity and the union of them can significantly boost the accuracy upper bound. To approach the upper bound, DiT-MoS introduces three strategies including diverse training data splitting to increase the classifiers' diversity, adversarial selector-classifiers training to ensure synergistic interactions thereby maximizing their complementarity, and heterogeneous feature aggregation to improve the capacity of classifiers. We further propose a network slicing technique to alleviate the extra memory overhead incurred by feature aggregation. We deploy DiTMoS on the Neucleo STM32F767ZI board and evaluate it based on three time-series datasets for human activity recognition, keywords spotting, and emotion recognition, respectively. The experiment results manifest that: (a) DiTMoS achieves up to 13.4% accuracy improvement compared to the best baseline; (b) network slicing almost completely eliminates the memory overhead incurred by feature aggregation with a marginal increase of latency. Code is released at https//github.com/TheMaXiao/DiTMoS","2474-249X","979-8-3503-2603-1","10.1109/PerCom59722.2024.10494422","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10494422","embedded machine learning;model diversity;model selection;adversarial training","Training;Pervasive computing;Upper bound;Microcontrollers;Network slicing;Time series analysis;Training data","","1","","42","IEEE","11 Apr 2024","","","IEEE","IEEE Conferences"
"Stitching Satellites to the Edge: Pervasive and Efficient Federated LEO Satellite Learning","M. Elmahallawy; T. Luo","Department of Computer Science, Missouri University of Science and Technology, Rolla, MO, USA; Department of Computer Science, Missouri University of Science and Technology, Rolla, MO, USA",2024 IEEE International Conference on Pervasive Computing and Communications (PerCom),"11 Apr 2024","2024","","","80","89","In the ambitious realm of space AI, the integration of federated learning (FL) with low Earth orbit (LEO) satellite constellations holds immense promise. However, many challenges persist in terms of feasibility, learning efficiency, and convergence. These hurdles stem from the bottleneck in communication, characterized by sporadic and irregular connectivity between LEO satellites and ground stations, coupled with the limited computation capability of satellite edge computing (SEC). This paper proposes a novel FL-SEC framework that empowers LEO satellites to execute large-scale machine learning (ML) tasks onboard efficiently. Its key components include i) personalized learning via divide-and-conquer, which identifies and eliminates redundant satellite images and converts complex multi-class classification problems to simple binary classification, enabling rapid and energy-efficient training of lightweight ML models suitable for IoT/edge devices on satellites; ii) orbital model retraining, which generates an aggregated “orbital model” per orbit and retrains it before sending to the ground station, significantly reducing the required communication rounds. We conducted experiments using Jetson Nano, an edge device closely mimicking the limited compute on LEO satellites, and a real satellite dataset. The results underscore the effectiveness of our approach, highlighting SEC's ability to run lightweight ML models on real and high-resolution satellite imagery. Our approach dramatically reduces FL convergence time by nearly 30 times, and satellite energy consumption down to as low as 1.38 watts, all while maintaining an exceptional accuracy of up to 96%.","2474-249X","979-8-3503-2603-1","10.1109/PerCom59722.2024.10494442","National Science Foundation(grant numbers:2008878); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10494442","Low Earth orbit (LEO) satellite;satellite edge computing (SEC);federated Learning (FL)","Training;Space vehicles;Energy consumption;Satellites;Computational modeling;Image edge detection;Low earth orbit satellites","","1","","25","IEEE","11 Apr 2024","","","IEEE","IEEE Conferences"
"OpenPack: A Large-Scale Dataset for Recognizing Packaging Works in IoT-Enabled Logistic Environments","N. Yoshimura; J. Morales; T. Maekawa; T. Hara","Graduate School of Information Science and Technology, Osaka University, Japan; Graduate School of Information Science and Technology, Osaka University, Japan; Graduate School of Information Science and Technology, Osaka University, Japan; Graduate School of Information Science and Technology, Osaka University, Japan",2024 IEEE International Conference on Pervasive Computing and Communications (PerCom),"11 Apr 2024","2024","","","90","97","Unlike human daily activities, existing publicly available sensor datasets for work activity recognition in industrial domains are limited by difficulties in collecting realistic data as close collaboration with industrial sites is required. This also limits research on and development of methods for industrial applications. To address these challenges and contribute to research on machine recognition of work activities in industrial domains, in this study, we introduce a new large-scale dataset for packaging work recognition called OpenPack. OpenPack contains 53.8 hours of multimodal sensor data, including acceleration data, keypoints, depth images, and readings from IoT-enabled devices (e.g., handheld barcode scanners), collected from 16 distinct subjects with different levels of packaging work experience. We apply state-of-the-art human activity recognition techniques to the dataset and provide future directions of complex work activity recognition studies in the pervasive computing community based on the results. We believe that OpenPack will contribute to the sensor-based action/activity recognition community by providing challenging tasks. The OpenPack dataset is available at https://open-pack.github.io.","2474-249X","979-8-3503-2603-1","10.1109/PerCom59722.2024.10494448","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10494448","datasets;work activity;activity recognition","Pervasive computing;Multimodal sensors;Collaboration;Packaging;Benchmark testing;Human activity recognition;Task analysis","","5","","33","IEEE","11 Apr 2024","","","IEEE","IEEE Conferences"
"Semi-Automated Framework for Digitalizing Multi-Product Warehouses with Large Scale Camera Arrays","K. Higashiura; K. Yokoyama; Y. Asai; H. Shimosato; K. Kano; S. Katayama; K. Urano; T. Yonezawa; N. Kawaguchi","Graduate School of Engineering, Nagoya University, Japan; Graduate School of Engineering, Nagoya University, Japan; Graduate School of Engineering, Nagoya University, Japan; Graduate School of Engineering, Nagoya University, Japan; Graduate School of Engineering, Nagoya University, Japan; Graduate School of Engineering, Nagoya University, Japan; Graduate School of Engineering, Nagoya University, Japan; Graduate School of Engineering, Nagoya University, Japan; Graduate School of Engineering, Nagoya University, Japan",2024 IEEE International Conference on Pervasive Computing and Communications (PerCom),"11 Apr 2024","2024","","","98","105","As global demand for logistics continues to grow, optimizing the automation and efficiency of distribution warehouse operations is of paramount importance. Digitalizing warehouse environments, which refers to the process of sensing the physical space and extracting meaningful information from the obtained data, offers a promising solution to this challenge. However, converting raw warehouse data, such as video footage captured inside the warehouse, into actionable metadata (e.g., tracking the movement paths of workers and products or analyzing the usage patterns of different warehouse locations) often necessitates significant human intervention. The rise of machine learning further complicates this, as it requires the manual preparation of extensive training datasets. In this paper, we introduce a framework that semi-automates the digitalization process in complex warehouse settings. This framework employs dense optical flow and representation learning to autonomously segment warehouse objects and cluster similar objects, thereby substantially cutting down on annotation costs. To evaluate our approach, we constructed a large-scale data collection platform with over 60 fixed cameras in a real-world logistics warehouse, and the video data from this platform was then applied to our framework. Our evaluations indicate that our method markedly reduces both the time and resources required for warehouse digitalization using the captured video data.","2474-249X","979-8-3503-2603-1","10.1109/PerCom59722.2024.10494498","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10494498","smart warehouse;data digitalization;digital twin","Representation learning;Training;Annotations;Tracking;Computational modeling;Data collection;Cameras","","3","","30","IEEE","11 Apr 2024","","","IEEE","IEEE Conferences"
"SmartEx: A Framework for Generating User-Centric Explanations in Smart Environments","M. Sadeghi; L. Herbold; M. Unterbusch; A. Vogelsang","University of Cologne, Cologne, Germany; University of Cologne, Cologne, Germany; University of Cologne, Cologne, Germany; University of Cologne, Cologne, Germany",2024 IEEE International Conference on Pervasive Computing and Communications (PerCom),"11 Apr 2024","2024","","","106","113","Explainability is crucial for complex systems like pervasive smart environments, as they collect and analyze data from various sensors, follow multiple rules, and control different devices resulting in behavior that is not trivial and, thus, should be explained to the users. The current approaches, however, offer flat, static, and algorithm-focused explanations. User-centric explanations, on the other hand, consider the recipient and context, providing personalized and context-aware explanations. To address this gap, we propose an approach to incorporate user-centric explanations into smart environments. We introduce a conceptual model and a reference architecture for characterizing and generating such explanations. Our work is the first technical solution for generating context-aware and granular explanations in smart environments. Our architecture implementation demonstrates the feasibility of our approach through various scenarios.","2474-249X","979-8-3503-2603-1","10.1109/PerCom59722.2024.10494449","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10494449","","Pervasive computing;Computer architecture;Sensor systems;Service-oriented architecture;Intelligent systems;Complex systems;Recommender systems","","3","","53","IEEE","11 Apr 2024","","","IEEE","IEEE Conferences"
"Is Your Kettle Smarter Than a Hacker? A Scalable Tool for Assessing Replay Attack Vulnerabilities on Consumer IoT Devices","S. Lazzaro; V. De Angelis; A. M. Mandalari; F. Buccafurri","Mediterranea University of Reggio Calabria University of Calabria; Mediterranea University of Reggio Calabria University of Calabria; University College, London; Mediterranea University of Reggio, Calabria",2024 IEEE International Conference on Pervasive Computing and Communications (PerCom),"11 Apr 2024","2024","","","114","124","Consumer Internet of Things (IoT) devices often leverage the local network to communicate with the corresponding companion app or other devices. This has benefits in terms of efficiency since it offloads the cloud. ENISA and NIST security guidelines underscore the importance of enabling default local communication for safety and reliability. Indeed, an IoT device should continue to function in case the cloud connection is not available. While the security of cloud-device connections is typically strengthened through the usage of standard protocols, local connectivity security is frequently overlooked. Neglecting the security of local communication opens doors to various threats, including replay attacks. In this paper, we investigate this class of attacks by designing a systematic methodology for automatically testing IoT devices vulnerability to replay attacks. Specifically, we propose a tool, named REPLIoT, able to test whether a replay attack is successful or not, without prior knowledge of the target devices. We perform thousands of automated experiments using popular commercial devices spanning various vendors and categories. Notably, our study reveals that among these devices, 51% of them do not support local connectivity, thus they are not compliant with the reliability and safety requirements of the ENISA/NIST guidelines. We find that 75% of the remaining devices are vulnerable to replay attacks with REPLIoT having a detection accuracy of 0.98-1. Finally, we investigate the possible causes of this vulnerability, discussing possible mitigation strategies.","2474-249X","979-8-3503-2603-1","10.1109/PerCom59722.2024.10494466","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10494466","Internet of Things;replay attack;security;privacy;IoT device","Performance evaluation;Cloud computing;Systematics;Natural language processing;Internet of Things;Security;Reliability","","7","","44","IEEE","11 Apr 2024","","","IEEE","IEEE Conferences"
"AnchorLoc: Large-Scale, Real-Time Visual Localisation Through Anchor Extraction and Detection","C. H. Park; A. Alhilal; T. Braud; P. Hui","Hong Kong University of Science and Technology, Hong Kong; Hong Kong University of Science and Technology, Hong Kong; Hong Kong University of Science and Technology, Hong Kong; Hong Kong University of Science and Technology, Hong Kong",2024 IEEE International Conference on Pervasive Computing and Communications (PerCom),"11 Apr 2024","2024","","","125","134","Pervasive Augmented Reality (AR) requires accurate pose registration of the device in real-time at a neighbourhood-to-city scale. At such a scale, most pose registration techniques suffer from exponential computational and storage costs and a significant data collection burden. This paper introduces AnchorLoc, a framework that relies on visual anchors (stable and highly recognisable visual elements in a scene) to perform fast and accurate pose registration. Anchorloc automatically identifies these anchors from large image sequences to optimise the search space in later image retrieval and pose registration. As such, it significantly improves the computational efficiency of existing hierarchical localisation pipelines without compromising accuracy. We collect a large-scale localisation dataset consisting of image sequences and 3D reconstruction of a university campus. AnchorLoc reduces localisation runtime by 83% on our campus dataset and 69% on the Cambridge Landmarks dataset without significantly increasing mean pose estimation errors. It is also more accurate and faster than SLD, a localisation algorithm that takes a comparable approach at the keypoint level. This work informs the development of more efficient pervasive AR applications that rely on both absolute and relative camera pose tracking on image sequences.","2474-249X","979-8-3503-2603-1","10.1109/PerCom59722.2024.10494441","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10494441","Camera relocalisation;Visual-Inertial Odometry;Augmented Reality","Visualization;Three-dimensional displays;Runtime;Scalability;Pipelines;Cameras;Superluminescent diodes","","","","46","IEEE","11 Apr 2024","","","IEEE","IEEE Conferences"
"Early Detection of Driving Maneuvers for Proactive Congestion Prevention","D. Das; S. Bhattacharjee; S. Chakraborty; B. Mitra; S. K. Das","Indian Institute of Technology Kharagpur, Kharagpur, India; Western Michigan University, MI, USA; Indian Institute of Technology Kharagpur, Kharagpur, India; Indian Institute of Technology Kharagpur, Kharagpur, India; Missouri University of Science and Technology, MO, USA",2024 IEEE International Conference on Pervasive Computing and Communications (PerCom),"11 Apr 2024","2024","","","135","142","Road traffic congestion affects not only the commute delay but also a city's overall social, economic, and environmental growth. Existing approaches for road congestion mitigation primarily adopt a reactive approach by detecting congestion after it occurs and recommending alternate routes to the vehicles, which fails to prevent congestion cascading. In contrast, we propose a pervasive platform called ProCon that proactively infers the driving micro-behaviors that can contribute to congestion formation and assist the drivers in avoiding such maneuvers in real-time during the navigation. Thorough evaluations over multiple real-life and simulated datasets indicate that ProCon can reduce congestion for more than 60% of the scenarios on average while significantly reducing the travel time of the vehicles.","2474-249X","979-8-3503-2603-1","10.1109/PerCom59722.2024.10494436","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10494436","Road congestion;Proactive mitigation;Driving behavior;Pervasive recommendation","Navigation;Social networking (online);Roads;Urban areas;Power system protection;Predictive models;Road traffic","","","","26","IEEE","11 Apr 2024","","","IEEE","IEEE Conferences"
"Decentralized Landslide Disaster Prediction for Imbalanced and Distributed Data","R. Ozeki; H. Yonekura; H. Rizk; H. Yamaguchi","Osaka University, Japan; Osaka University, Osaka, Japan; Osaka University, Osaka, Japan; Osaka University, Osaka, Japan",2024 IEEE International Conference on Pervasive Computing and Communications (PerCom),"11 Apr 2024","2024","","","143","150","Precise disaster prediction plays a critical role in saving lives. Traditional landslide prediction methods have predominantly relied on deep neural networks such as CNNs and LSTMs. However, these methods face two main challenges. The first is the class imbalance issue, as landslides are rare, disrupting the training process. The second challenge stems from decentralized data management, with variations in volume and characteristics across regions. Typically, local municipalities manage disaster data within their regions, and sharing or migrating this data is not straightforward. This paper presents SlideSafe: a novel landslide prediction system that combines spatio-temporal contrastive learning and collaborative learning11Our implementation is available here (https://github.com/mclab-osaka/slidesafe). It begins by training a contrastive learning model to extract meaningful representations of land characteristics in each region. Subsequently, these trained models are merged among regions with similar characteristics, leveraging federated learning. The federated models are then fine-tuned and customized for the landslide event prediction using the data specific to each region. Experimental results indicate that the proposed system achieves higher precision under 100% recall compared to state-of-the-art federated learning methods, which are often adversely affected by non-iid data and data scarcity.","2474-249X","979-8-3503-2603-1","10.1109/PerCom59722.2024.10494417","JST; CREST(grant numbers:JPMJCR21M5); NVIDIA; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10494417","Decentralized Landslide Prediction;Class imbalance;Contrastive Learning;Selective Federated Learning","Training;Pervasive computing;Federated learning;Disasters;Self-supervised learning;Predictive models;Reliability engineering","","","","32","IEEE","11 Apr 2024","","","IEEE","IEEE Conferences"
"Panel: AI for Pervasive Computing: Curse or Blessing?","D. Nicklas","University of Bamberg, Bamberg, Germany",2024 IEEE International Conference on Pervasive Computing and Communications (PerCom),"11 Apr 2024","2024","","","151","153","In the past years, we have witnessed a remarkable surge in the integration of machine learning within pervasive computing, revolutionizing how we interact with technology daily and build pervasive systems.","2474-249X","979-8-3503-2603-1","10.1109/PerCom59722.2024.10494461","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10494461","","Pervasive computing;Machine learning;Surges","","","","0","IEEE","11 Apr 2024","","","IEEE","IEEE Conferences"
"PA2BLO: Low-Power, Personalized Audio Badge","H. Sabbella; D. S. Weerakoon; M. Gulati; A. Misra","School of Computing and Information Systems, Singapore Management University; School of Computing and Information Systems, Singapore Management University; School of Computing, National University of Singapore; School of Computing and Information Systems, Singapore Management University",2024 IEEE International Conference on Pervasive Computing and Communications (PerCom),"11 Apr 2024","2024","","","154","163","We present the hardware design and software pipeline for an ultra-low power device, in the form factor of a wearable badge, that supports energy efficient sensing, processing and wireless transfer of human voice commands and interactions. The proposed system, called PA2BLO, is envisioned to support both: (a) real-time, scalable, authorized voice based interaction and control of devices and appliances, and (b) longitudinal, low-power logging of natural voice interactions. PA2BLO in-troduces two key novel capabilities. First, it includes a low power, low-complexity voice authentication module that is able to reliably authenticate an authorized user only using low sampling rate (500 Hz) audio data. Second, to reduce concerns around inadvertent leakage of voice biometrics to less secure voice-driven services, PA2BLO uses a power-efficient, randomized pitch shifting technique that dramatically lowers the ability to perform speaker recognition while preserving instruction/speech comprehensibility. We describe PA2BLO's Cortex M4F-based micro-controller based hardware implementation, which is care-fully designed to eliminate redundant processing and consumes less than 50J of energy per hour of active voice capture and processing. Through both controlled and naturalistic studies, we show that the PA2BLO prototype is capable of authenticating user voice segments reliably (accuracy> 89.8%) and can operate for well over a day (using a supercapacitor charged within just one minute) while capturing 2+ hours of active speaker data.","2474-249X","979-8-3503-2603-1","10.1109/PerCom59722.2024.10494427","National Research Foundation, Singapore under its NRF Investigatorship(grant numbers:NRFNRFI05-2019-0007); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10494427","Sub-kHz Speaker Authentication;Speech Anonymization;Ultra-low Power Wearable Badge","Wireless communication;Wireless sensor networks;Pipelines;Authentication;Supercapacitors;Hardware;Speaker recognition","","1","","33","IEEE","11 Apr 2024","","","IEEE","IEEE Conferences"
"BLEAR: Practical Wireless Earphone Tracking under BLE protocol","L. Ge; W. Xie; J. Zhang; Q. Zhang","RITAS, CSE Dept., Southern University of Science and Technology, Shenzhen, China; RITAS, CSE Dept., Southern University of Science and Technology, Shenzhen, China; RITAS, CSE Dept., Southern University of Science and Technology, Shenzhen, China; CSE Dept., The Hong Kong University of Science and Technology, Hong Kong, China",2024 IEEE International Conference on Pervasive Computing and Communications (PerCom),"11 Apr 2024","2024","","","164","173","Motion tracking is an important aspect of human-computer interaction (HCI) and recent research focuses on motion tracking using earphones' embedded acoustic sensors. However, these solutions can only be deployed on wired ear-phones, while most of the commercial earphones are wireless ones. This limitation arises because wireless earphones utilize the Bluetooth Low Energy (BLE) protocol for handling audio data, which blocks the usage of existing acoustic sensing solutions. Firstly, the low sampling rate of BLE prevents the system from processing high-frequency ultrasounds. However, the sensing signal for earphones must be ultrasonic to prevent disturbance to the user. Secondly, BLE employs an audio compression process that is applied with different compression rates with different bandwidths. This will break the structure of wideband signals usually used for acoustic sensing. To overcome these challenges, we present BLEAR, the first earphone-tracking system compatible with the BLE audio recording protocol. To let BLE earphones receive ultrasounds, BLEAR utilizes a specially designed bandwidth conversion scheme that uses a mask signal to trigger a non-linear effect that converts high-frequency components to low-frequency ones, thereby overcoming the low audio sampling rate restriction of BLE. Additionally, by strategically designing beacon signals to align with BLE's subband compression pattern, BLEAR mitigates the influence of audio compression and achieves accurate wireless earphone tracking. We implement a wireless earphone prototype for BLEAR and conduct extensive experiments involving 8 subjects to demonstrate its feasibility. The experimental results show that BLEAR achieves a mean distance tracking error of 3.37 cm, an angle tracking error of 5.3 degrees, and an accuracy of 97.14% in recognizing 7 common user activities. This work not only introduces a BLE-compatible earphone tracking solution but also establishes a foundation for broader BLE device tracking applications.","2474-249X","979-8-3503-2603-1","10.1109/PerCom59722.2024.10494424","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10494424","Human-computer interaction;earphone;motion tracking;BLE","Headphones;Wireless communication;Wireless sensor networks;Protocols;Ultrasonic imaging;Tracking;Prototypes","","","","32","IEEE","11 Apr 2024","","","IEEE","IEEE Conferences"
"Ultra Write: A Lightweight Continuous Gesture Input System with Ultrasonic Signals on COTS Devices","W. Chen; C. Zheng; W. He; Y. Zou; K. Wu","College of Computer Science and Software engineering, Shenzhen University, Shenzhen, China; College of Computer Science and Software engineering, Shenzhen University, Shenzhen, China; College of Computer Science and Software engineering, Shenzhen University, Shenzhen, China; College of Computer Science and Software engineering, Shenzhen University, Shenzhen, China; Information Hub, The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China",2024 IEEE International Conference on Pervasive Computing and Communications (PerCom),"11 Apr 2024","2024","","","174","183","Due to the advantages of acoustic sensing such as device ubiquity, hands-free interaction and privacy security, acoustic-based gesture input techniques have gained extensive at-tention and many excellent works have been proposed. However, these works have the following shortcomings: high cost of system construction, non-continuous input, and degraded performance in cross-user scenarios. To overcome the above shortcomings, we propose UltraWrite, a continuous gesture input system that needs rather low system construction cost, supports continuous input, and achieves high cross-user recognition performance. The key idea of our solution is to synthesize the data of continuous gestures from isolated ones, and build an end-to-end continuous gesture recognition model by introducing the connectionist temporal classification (CTC) mechanism widely used in natural language processing. We have implemented the system on a commercial tablet and conducted comprehensive experiments to evaluate its performance. The results demonstrate that UltraWrite achieves an average word accuracy of 99.3% and word error rate of 0.34% when considering only the first output candidate word. In addition, we have also evaluated the system's robustness to background noise, sensing distance and angle. The results reveal that UltraWrite displays strong robustness to these factors.","2474-249X","979-8-3503-2603-1","10.1109/PerCom59722.2024.10494485","China NSFC(grant numbers:62172286,U2001207); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10494485","Acoustic Sensing;Gesture Input;Cross-Domain Learning","Performance evaluation;Pervasive computing;Privacy;Costs;Acoustics;Robustness;Natural language processing","","","","39","IEEE","11 Apr 2024","","","IEEE","IEEE Conferences"
"Affective- NLI: Towards Accurate and Interpretable Personality Recognition in Conversation","Z. Wen; J. Cao; Y. Yang; R. Yang; S. Liu","Department of Computing, The Hong Kong Polytechnic University, Hong Kong, China; Department of Computing, The Hong Kong Polytechnic University, Hong Kong, China; Department of Computing, The Hong Kong Polytechnic University, Hong Kong, China; Department of Computing, The Hong Kong Polytechnic University, Hong Kong, China; Department of Computing, The Hong Kong Polytechnic University, Hong Kong, China",2024 IEEE International Conference on Pervasive Computing and Communications (PerCom),"11 Apr 2024","2024","","","184","193","Personality Recognition in Conversation (PRC) aims to identify the personality traits of speakers through textual dialogue content. It is essential for providing personalized services in various applications of Human-Computer Interaction (HCI), such as AI-based mental therapy and companion robots for the elderly. Most recent studies analyze the dialog content for personality classification yet overlook two major concerns that hinder their performance. First, crucial implicit factors contained in conversation, such as emotions that reflect the speakers' personalities are ignored. Second, only focusing on the input dialog content disregards the semantic understanding of personality itself, which reduces the interpretability of the results. In this paper, we propose Affective Natural Language Inference (Affective-NLI) for accurate and interpretable PRC. To utilize affectivity within dialog content for accurate person-ality recognition, we fine-tuned a pre-trained language model specifically for emotion recognition in conversations, facilitating real-time affective annotations for utterances. For interpretability of recognition results, we formulate personality recognition as an NLI problem by determining whether the textual description of personality labels is entailed by the dialog content. Extensive experiments on two daily conversation datasets suggest that Affective-NLI significantly outperforms (by 6%-7%) state-of-the-art approaches. Additionally, our Flow experiment demonstrates that Affective-NLI can accurately recognize the speaker's personality in the early stages of conversations by surpassing state-of-the-art methods with 22% −34% 11Our source code and data is at https://github.com/preke/Affective-NLI..","2474-249X","979-8-3503-2603-1","10.1109/PerCom59722.2024.10494487","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10494487","human-computer interaction;personality recognition","Pervasive computing;Emotion recognition;Source coding;Semantics;Natural languages;Medical treatment;Oral communication","","","","47","IEEE","11 Apr 2024","","","IEEE","IEEE Conferences"
"iMove: Exploring Bio-Impedance Sensing for Fitness Activity Recognition","M. Liu; V. F. Rey; Y. Zhang; L. S. Swarup Ray; B. Zhou; P. Lukowicz","German Research Center for Artificial Intelligence (DFKI), Kaiserslautern, Germany; German Research Center for Artificial Intelligence (DFKI), Kaiserslautern, Germany; German Research Center for Artificial Intelligence (DFKI), Kaiserslautern, Germany; German Research Center for Artificial Intelligence (DFKI), Kaiserslautern, Germany; German Research Center for Artificial Intelligence (DFKI), Kaiserslautern, Germany; German Research Center for Artificial Intelligence (DFKI), Kaiserslautern, Germany",2024 IEEE International Conference on Pervasive Computing and Communications (PerCom),"11 Apr 2024","2024","","","194","205","Automatic and precise fitness activity recognition can be beneficial in aspects from promoting a healthy lifestyle to personalized preventative healthcare. While IMUs are currently the prominent fitness tracking modality, through iMove, we show bio-impedence can help improve IMU-based fitness tracking through sensor fusion and contrastive learning. To evaluate our methods, we conducted an experiment including six upper body fitness activities performed by ten subjects over five days to collect synchronized data from bio-impedance across two wrists and IMU on the left wrist. The contrastive learning framework uses the two modalities to train a better IMU-only classification model, where bio-impedance is only required at the training phase, by which the average Macro F1 score with the input of a single IMU was improved by 3.22 % reaching 84.71 % compared to the 81.49 % of the IMU baseline model. We have also shown how bio-impedance can improve human activity recognition (HAR) directly through sensor fusion, reaching an average Macro F1 score of 89.57 % (two modalities required for both training and inference) even if Bio-impedance alone has an average macro F1 score of 75.36 %, which is outperformed by IMU alone. In addition, similar results were obtained in an extended study on lower body fitness activity classification, demonstrating the generalisability of our approach.Our findings underscore the potential of sensor fusion and contrastive learning as valuable tools for advancing fitness activity recognition, with bio-impedance playing a pivotal role in augmenting the capabilities of IMU-based systems.","2474-249X","979-8-3503-2603-1","10.1109/PerCom59722.2024.10494489","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10494489","bio-impedance sensing;human activity recognition;contrastive learning;sensor fusion","Training;Wrist;Target tracking;Target recognition;Biological system modeling;Self-supervised learning;Sensor fusion","","1","","37","IEEE","11 Apr 2024","","","IEEE","IEEE Conferences"
"DeepApnea: Deep Learning Based Sleep Apnea Detection Using Smartwatches","Z. Liu; X. Chen; F. Ma; J. Fernandez-Mendoza; G. Cao",The Pennsylvania State University; The Pennsylvania State University; The Pennsylvania State University; The Pennsylvania State University; The Pennsylvania State University,2024 IEEE International Conference on Pervasive Computing and Communications (PerCom),"11 Apr 2024","2024","","","206","216","Sleep apnea is a serious sleep disorder where patients have multiple extended pauses in breath during sleep. Although some portable or contactless sleep apnea detection systems have been proposed, none of them can achieve fine-grained sleep apnea detection without strict requirements on the device or environmental settings. To address this problem, we present DeepApnea, a deep learning based sleep apnea detection system that leverages patients' wrist movement data collected by smartwatches to identify different types of sleep apnea events (i.e., central apneas, obstructive apneas, and hypopneas). Through a clinical study, we identify some special characteristics associated with different types of sleep apnea captured by smartwatch. However, there are many technical challenges such as how to extract informative apnea features from the noisy data and how to leverage features extracted from the multi-axis sensing data. To address these challenges, we first propose signal pre-processing methods to filter the raw accelerometer (ACC) data, smoothing away noise while preserving the respiratory signal and potential features for identifying sleep apnea. Then, we design a deep learning architecture to extract features from three ACC axes collaboratively, where self attention and cross-axis correlation techniques are leveraged to improve the classification accuracy. We have implemented DeepApnea on smartwatches and performed a clinical study. Evaluation results demonstrate that DeepApnea can significantly outperform existing work on identifying different types of sleep apnea.","2474-249X","979-8-3503-2603-1","10.1109/PerCom59722.2024.10494473","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10494473","Apnea Detection;Deep Learning;SmartWatch","Deep learning;Wrist;Correlation;Smoothing methods;Noise;Feature extraction;Sleep apnea","","","","31","IEEE","11 Apr 2024","","","IEEE","IEEE Conferences"
