"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Cover Page","",,2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","1","1",": Presents the front cover or splash screen of the proceedings record.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869906","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869906","","","","","","","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Front Page","",,2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","1","35","Presents the front cover or splash screen of the proceedings record.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869900","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869900","","","","","","","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Table of Contents","",,2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","36","59","Presents the table of contents for this issue of the publication.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9870021","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9870021","","","","","","","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Copyright Page","",,2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","1","1","Presents the copyright information for the conference. May include reprint permission information.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869985","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869985","","","","","","","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Memristor-Based In-Circuit Computation for Trace-Based STDP","D. Wang; J. Xu; F. Li; L. Zhang; Y. Wang; A. Lansner; A. Hemani; L. -R. Zheng; Z. Zou","State Key Laboratory of ASIC and System, School of Information Science and Technology, Fudan University, Shanghai, China; State Key Laboratory of ASIC and System, School of Information Science and Technology, Fudan University, Shanghai, China; State Key Laboratory of ASIC and System, School of Information Science and Technology, Fudan University, Shanghai, China; Department of Electrical Engineering, Technical University of Denmark, Kongens Lyngby, Denmark; Department of Future Technologies, University of Turku, Turku, Finland; KTH Royal Institution of Technology, Stockholm, Sweden; KTH Royal Institution of Technology, Stockholm, Sweden; State Key Laboratory of ASIC and System, School of Information Science and Technology, Fudan University, Shanghai, China; State Key Laboratory of ASIC and System, School of Information Science and Technology, Fudan University, Shanghai, China",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","1","4","Recently, memristors have been widely used to implement Spiking Neural Networks (SNNs), which is promising in edge computing scenarios. However, most memristor-based SNN implementations adopt simplified spike-timing-dependent plasticity (STDP) for the online learning process. It is challenging for memristor-based implementations to support the trace-based STDP learning rules that have been widely used in neuromorphic applications. This paper proposed a versatile memristor-based architecture to implement the synaptic-level trace-based STDP learning rules. Especially, the similarity between synaptic trace dynamics and the memristor nonlinearity is explored and exploited to emulate the trace variables of trace-based STDP. As two typical trace-based STDP learning rules, the pairwise STDP and the triplet STDP, are simulated on two typical nonlinear bipolar memristor devices. The simulation results show that the behavior of physical memristor devices can be well estimated (below 6% in terms of the relative root-mean-square error), and the memristor-based in-circuit computation for trace-based STDP learning rules can achieve a high correlation coefficient over 98%.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9870015","National Natural Science Foundation of China(grant numbers:61876039,17DZ2260900,92164301); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9870015","Memristor;trace;spike-timing-dependent plasticity (STDP);online learning;spiking neural network (SNN);neuromorphic computation","Correlation coefficient;Neuromorphics;Circuits and systems;Simulation;Neural networks;Memristors;Computer architecture","","6","","13","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Energy-Efficient High-Accuracy Spiking Neural Network Inference Using Time-Domain Neurons","J. Song; J. Shirn; H. Kim; W. -S. Choi","Department of ECE, ISRC, Seoul National University, Seoul, South Korea; Department of ECE, ISRC, Seoul National University, Seoul, South Korea; Department of ECE, ISRC, Seoul National University, Seoul, South Korea; Department of ECE, ISRC, Seoul National University, Seoul, South Korea",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","5","8","Due to the limitations of realizing artificial neural networks on prevalent von Neumann architectures, recent studies have presented neuromorphic systems based on spiking neural networks (SNNs) to reduce power and computational cost. However, conventional analog voltage-domain integrate-and-fire (I&F) neuron circuits, based on either current mirrors or op-amps, pose serious issues such as nonlinearity or high power consumption, thereby degrading either inference accuracy or energy efficiency of the SNN. To achieve excellent energy efficiency and high accuracy simultaneously, this paper presents a low-power highly linear time-domain I&F neuron circuit. Designed and simulated in a 28nm CMOS process, the proposed neuron leads to more than 4.3x lower error rate on the MNIST inference over the conventional current-mirror-based neurons. In addition, the power consumed by the proposed neuron circuit is simulated to be $0.230\mu \mathrm{W}$ per neuron, which is orders of magnitude lower than the existing voltage-domain neurons.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9870009","National Research Foundation of Korea(grant numbers:2020M3H2A1078119); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9870009","artificial neural network;spiking neural network;ANN-to-SNN conversion;integrate-and-fire neuron;time-domain signal processing","Power demand;Error analysis;Neuromorphics;Simulation;Neurons;Signal processing;CMOS process","","8","","15","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Analog-Domain Time-Series Moment Extraction for Low Power Predictive Maintenance Analytics","A. Shylendra; P. Shukla; S. Bhunia; A. R. Trivedi",NA; NA; NA; NA,2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","9","12","This work presents a novel low-power CMOS implementation for fast statistical feature extraction from time series. Machine learning (ML) models have become standard for time series processing, however, need to rely on a statistical feature extraction stage. Low power statistical feature extraction from time series has received limited attention despite its central role. Addressing this gap, we present a CMOS-based nonparametric statistical feature extraction. We exploit hardware-level opportunities in the analog domain, such as eliminating additions by current outputs and simplifying kernel cells. We also leverage algorithmic opportunities to utilize continuous-domain sample integration to downsample time series without affecting accuracy. Our propositions are experimentally verified using TSMC 65nm test chip and show 17–75 × lower energy than an advanced digital design on various statistical features. While analog processing is susceptible to non-idealities, co-designing the downstream ML model against such non-idealities can retain accuracy to benefit from the analog domain's area/energy efficiency.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869914","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869914","Anomaly detection;statistical feature extraction","Semiconductor device modeling;Interpolation;Circuits and systems;Time series analysis;Machine learning;Feature extraction;Kernel","","3","","7","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Effect of ReRAM Neuromorphic Circuit Array Variation and Fault on Inference Accuracy","P. Quibuyen; T. Jiao; H. Y. Wong","Dept. of Electrical Engineering, San Jose State University, San Jose, USA; Dept. of Electrical Engineering, San Jose State University, San Jose, USA; Dept. of Electrical Engineering, San Jose State University, San Jose, USA",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","13","16","In this paper, we study the inference accuracy of Resistive Random Access Memory (ReRAM) based neuromorphic circuit under various array faults using fully analog SPICE simulations. The ReRAM Verilog-A model is calibrated to the experiment and a 45nm realistic Process Design Kit (PDK) is used. A handwritten dataset is used for the demonstration with a neural network containing 3 hidden layers. The faults studied include the random variations of ReRAM gap size due to gap size drifting and the “stuck-off” faults with various spatial shapes in the ReRAM arrays. We also study how the faulty array location in the neural network affects circuit fault tolerance. Finally, we propose fault-aware processing and layout guidelines for extending the lifetime of ReRAM neuromorphic circuits for Internet-of-Things (IoT) applications.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869936","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869936","Fault;Inference Accuracy;Internet-of-Things (IoTs);Neuromorphic;ReRAM;SPICE simulation","Process design;Neuromorphics;Shape;Neural networks;Resistive RAM;Layout;SPICE","","1","","21","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Low-current, highly linear synaptic memory device based on MoS2 transistors for online training and inference","M. Farronato; M. Melegari; S. Ricci; S. Hashemkani; C. M. Compagnoni; D. Ielmini","Dipartimento di Elettronica, Informazione e Bioingegneria (DEIB), Politecnico di Milano and IUNET, Milano, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria (DEIB), Politecnico di Milano and IUNET, Milano, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria (DEIB), Politecnico di Milano and IUNET, Milano, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria (DEIB), Politecnico di Milano and IUNET, Milano, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria (DEIB), Politecnico di Milano and IUNET, Milano, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria (DEIB), Politecnico di Milano and IUNET, Milano, Italy",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","1","4","In-memory computing (IMC) is attracting a strong interest for hardware accelerators of neural networks for artificial intelligence (AI) applications. To that aim, high density memory arrays are used as artificial synaptic arrays, storing the weights of the neural network and performing the matrix-vector multiplication (MVM) involved in the network operation. Within these implementations, in-situ update of the weights can be achieved during network training, thus avoiding power-hungry data movement. For training applications, a key requirement for synaptic devices is the capability to operate at low current to avoid large area of the peripheral circuitry and excessive current-resistance (IR) drop. Also, high linearity of weight update is necessary for accelerating the outer product for online training by backpropagation. To meet all these demands, in this work we present a novel synaptic memory device based on interface-state trapping in MOS transistors with a 2D MoS2 channel. By operating the device in the deep subthreshold regime, a very low (few nS) and linearly updatable conductance with pulses of equal amplitude is demonstrated. Simulations of neural network training show an accuracy of 96.8% for MNIST, close to the floating-point accuracy of 97.8%.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869854","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869854","MoS2;synaptic device;in-memory computing;neural networks;deep learning","Training;Backpropagation;Performance evaluation;MOSFET;Linearity;Logic gates;Sulfur","","3","","25","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Class Attention Transfer for Semantic Segmentation","Y. Cho; S. Kang","Department of Artificial Intelligence, Sogang University, Seoul, South Korea; Department of Electronic Engineering, Sogang University, Seoul, South Korea",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","41","45","This paper proposes a knowledge transfer method using class attention maps (CAM) that are class-discriminative for training lightweight semantic segmentation networks. Since semantic segmentation classifies for each pixel, it is difficult to focus on the discriminative regions for each class in a single channel attention map. Thus, we generate attention maps for each class by using weights obtained from feature maps and class masks for squeezing the channels of the feature maps and then forcing a student network to generate the CAM that mimic the CAM of a teacher network. Our proposed method improves the state-of-the-art HRNetV2-W18+OCR by 4.78% in mIoU on the Cityscapes dataset.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869901","Korea Creative Content Agency(grant numbers:R2020040058); Korea Agency for Infrastructure Technology Advancement (KAIA); Ministry of the Interior and Safety(grant numbers:22PQWO-C153369-04); National Research Foundation of Korea (NRF); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869901","Knowledge Distillation;Semantic Segmentation;Attention Maps","Training;Image segmentation;Circuits and systems;Semantics;Integrated circuit modeling;Task analysis;Artificial intelligence","","3","","19","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Lightweight and Efficient Neural Network Using Progressively Greedy Search","J. -Y. Chang; C. -T. Chiu; P. -H. Chen","Institute of Communications Engineering, National Tsing Hua University, HsinChu, Taiwan, R.O.C.; Department of Computer Science, National Tsing Hua University, HsinChu, Taiwan, R.O.C.; Institute of Communications Engineering, National Tsing Hua University, HsinChu, Taiwan, R.O.C.",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","46","49","In this paper, we propose a progressively greedy search (PGS) method for lightweight and efficient neural networks. We search neural network architectures in a restricted design space to reduce the search cost without sampling models. The searched models have regular weights which is similar to structural pruning. Our search strategy can automatically find a suitable channel number in each layer without manual setting. We pay more attention to the architecture, not the model weights, which is different from the pruning methods. Compared to RegNetX-200MF [1], our searched model, PGS 178MF, reduces 21.65MFLOPs and increases 0.93% accuracy in the same training cost. Compared to conventional width scaling, the architecture we have searched on MobileNet-V3-large improves accuracy by 0.72% under a similar model size.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869968","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869968","Efficient Neural Network;Neural Architecture Search;Restricted Design Space;Progressively Greedy Search","Training;Costs;Circuits and systems;Neural networks;Manuals;Search problems;Artificial intelligence","","","","20","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Deep Learning Toolkit-Driven Equivalence Checking of Flow-Based Computing Systems","S. Singireddy; R. Ewetz; S. Jha","University of Texas at San Antonio, San Antonio, USA; University of Central Florida, Orlando, USA; University of Texas at San Antonio, San Antonio, USA",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","50","53","The processor-memory bottleneck inherent to von Neumann architectures has encouraged the development of alternative computing paradigms. One such paradigm is flow-based in-memory computing using nanoscale crossbars. Recent improvements to design automation tools has scaled the crossbar designs to over one million memristors and over one hundred input variables. However, the state-of-the-art verification method using graph reachability cannot verify the correctness of crossbar designs with more than twenty input variables. In this paper, we propose an equivalence checking technique that natively leverages existing deep learning infrastructure. We achieve this by observing an analogy between a memristor crossbar and recurrent neural networks (RNNs), which allows equivalence checking to be efficiently performed using neural network inference. Using benchmark circuits from the RevLib and MCNC suites, we show that our proposed method can, on average, verify the correctness of a design 166x faster than the state-of-the-art method.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869979","National Science Foundation(grant numbers:2113307,1755825,1908471,2008339); ONR(grant numbers:N000142112332); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869979","flow-based;in-memory;memristor;crossbar","Deep learning;Recurrent neural networks;Design automation;Circuits and systems;Input variables;Memristors;Computer architecture","","1","","15","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"GaN Distributed RF Power Amplifer Automation Design with Deep Reinforcement Learning","Y. Sun; M. Benosman; R. Ma","Mtsubishi Electric Research Laboratories (MERL), Cambridge, MA, USA; Mtsubishi Electric Research Laboratories (MERL), Cambridge, MA, USA; Mtsubishi Electric Research Laboratories (MERL), Cambridge, MA, USA",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","54","57","Radio frequency (RF) circuit design demands rich experience of practical know-how and extensive simulation. Complicated interactions among different building components must be considered. This becomes more challenging at higher frequency and for sophisticated circuits. In this study, we proposed a novel design automation methodology based on deep reinforcement learning (RL). For the first time, we applied RL to design a wideband non-uniform distributed RF power amplifier known for its high dimensional design challenges. Our results show that the design principles can be learned effectively and the agent can generate the optimal circuit parameters to meet the design specifications including operating frequency range (2-18GHz), output power (>37dBm), gain flatness (<4dB) and average return loss (>5.8 dB) with GaN technology. Notably, our well-trained RL agent outperforms human expert given the same design task, with 78% accuracy and offers generalizability, which is lacked in the conventional optimization approach to shorten the time-to-market.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869961","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869961","RF circuits;deep reinforcement learning;automation design","Radio frequency;Automation;Power amplifiers;Reinforcement learning;Radiofrequency integrated circuits;Task analysis;Wideband","","","","13","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Real-time prediction of cardiovascular diseases using reservoir-computing and fusion with electronic medical record","S. Sadasivuni; V. Damodaran; I. Banerjee; A. Sanyal","Electrical Engineering Department, University at Buffalo, Buffalo, NY, USA; School of Electrical, Computer and Energy Engineering, Arizona State University, Tempe, Arizona, USA; Mayo Clinic Phoenix, Arizona, USA; School of Electrical, Computer and Energy Engineering, Arizona State University, Tempe, Arizona, USA",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","58","61","Cardiovascular diseases (CVDs) are a leading cause of death in USA and globally, but many people suffering from CVDs are asymptomatic in the early stages leading to reduced awareness, and less chances of managing the disease. This work presents a potential solution for at-home monitoring by leveraging predictive power of artificial intelligence (AI) for developing a fusion framework that combines patient electrocardiogram (ECG) and electronic medical record (EMR) for predicting risk of CVDs at an early stage. To improve energy-efficiency of wearable ECG sensor, in-sensor analog reservoir-computing is proposed that precludes need for front-end digitization and transmission of raw sensor data. The fusion framework predicts ischemic heart disease (I20–I25 ICD codes) with area under the receiver operating characteristic (AUROC) of 0.91, and other heart diseases (I30–I52 ICD codes) with AUROC of 0.95 which is better than state-of-the-art while not requiring laboratory test results.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869980","National Science Foundation(grant numbers:CCF-194833I); Air Force Research Laboratory(grant numbers:FA8650-18-2-5402); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869980","cardiovascular disease;artificial intelligence;in-memory computing;data fusion;artificial neural network;reservoir-computer","Heart;Codes;Transforms;Receivers;Electrocardiography;Real-time systems;Cardiovascular diseases","","4","","21","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Towards On-device Domain Adaptation for Noise-Robust Keyword Spotting","C. Cioflan; L. Cavigelli; M. Rusci; M. De Prado; L. Benini","Integrated Systems Laboratory, ETH Zurich; Zurich Research Center, Huawei Technologies; DEI, University of Bologna; Bonseyes Community Association; Integrated Systems Laboratory, ETH Zurich",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","82","85","The accuracy of a keyword spotting model deployed on embedded devices often degrades when the system is exposed to real environments with significant noise. In this paper, we explore a methodology for tailoring a model to on-site noises through on-device domain adaptation, while accounting for the edge computing-associated costs. We show that accuracy improvements by up to 18 % can be obtained by specialising on difficult, previously unseen noise types, on embedded devices with a power budget in the Watt range, with a storage requirement of 1.1 GB. We also demonstrate an accuracy improvement of 1.43% on an ultra-low power platform consuming few-10mW, requiring only 1.47 MB of memory for the adaptation stage, at a one-time energy cost of 5.81 J.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869990","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869990","","Training;Adaptation models;Costs;Computational modeling;Memory management;Random access memory;Noise robustness","","5","","19","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Temporal Redundancy-Based Computation Reduction for 3D Convolutional Neural Networks","U. De Alwis; M. Alioto","ECE Dept., National University of Singapore, Singapore; ECE Dept., National University of Singapore, Singapore",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","86","89","Making sense of human actions in video sequences has become an essential task in video surveillance applications. In such applications, 3D CNNs have become a prime choice due to their excellent performance. However, the performance advantage offered by these networks comes at a higher computational and memory cost. In this paper, a novel method is introduced to enhance temporal similarity at minimal accuracy degradation in input video sequences for 3D CNNs, as demonstrated through video benchmarks focusing on human action recognition. The proposed Temporal Similarity Tunnels (TST) method enhances temporal similarity in the feature maps of the initial and the subsequent frames, reducing computations in the convolutional layer of 3D CNNs. The proposed method achieves 46.5% (45%) computation reduction in the C3D network evaluated under the UCF101 (HMDB51) dataset, while maintaining an accuracy drop of <1 %. Similarly, the computation reduction in 3D-MobileNets v1 and v2 is 48% (38%) at an accuracy drop of 1 % (1.4%) for UCF10l dataset.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869903","Singapore National Research Foundation(grant numbers:NRF-CRP20-2017-0003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869903","video action recognition;3D convolutional neural networks;computational efficiency;temporal similarity","Degradation;Three-dimensional displays;Costs;Circuits and systems;Video sequences;Focusing;Benchmark testing","","3","","13","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"MOGNET: A Mux-residual quantized Network leveraging Online-Generated weights","V. T. Nguyen; W. Guicquero; G. Sicard","CEA-LETI, Grenoble, France; CEA-LETI, Grenoble, France; CEA-LETI, Grenoble, France",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","90","93","This paper presents a compact model architecture called MOGNET, compatible with a resource-limited hardware. MOGNET uses a streamlined Convolutional factorization block based on a combination of 2 point-wise (1×1) convolutions with a group-wise convolution in-between. To further limit the overall model size and reduce the on-chip required memory, the second point-wise convolution's parameters are on-line generated by a Cellular Automaton structure. In addition, MOGNET enables the use of low-precision weights and activations, by taking advantage of a Multiplexer mechanism with a proper Bitshift rescaling for integrating residual paths without increasing the hardware- related complexity. To efficiently train this model we also introduce a novel weight ternarization method favoring the balance between quantized levels. Experimental results show that given tiny memory budget (sub-2Mb), MOGNET can achieve higher accuracy with a clear gap up to 1% at a similar or even lower model size compared to recent state-of-the-art methods.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869933","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869933","CNN;quantized neural networks;skip connections;channel attention;logic-gated CNN;Cellular Automaton","Multiplexing;Limiting;Circuits and systems;Memory management;Automata;Dynamic range;Hardware","","1","","28","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Survey and Comparison of Milliwatts Micro controllers for Tiny Machine Learning at the Edge","M. Giordano; L. Piccinelli; M. Magno","Center for Project Based Learning - ETH, Zürich; Center for Project Based Learning - ETH, Zürich; Center for Project Based Learning - ETH, Zürich",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","94","97","Low power Internet of Things devices are growing in number and computational capabilities, pushing to ubiquitous deployment of smart sensors that embed on board both the sensing and the processing. Thus, one of the most emerging requirements of such devices is to provide intelligence in resource-constrained processors that consume few milliwatts of power. This work focuses on surveying, comparing and evaluating seven different recent and popular microcontrollers with a power envelope from a few up to hundreds of milliwatts against a Convolutional Neural Networks workload for a non trivial task such as face recognition. The evaluation reports key points of tiny machine learning performance of the target microcontrollers in terms of inference time, power consumption, energy per inference and computational efficiency. Experimental results highlight best-in-class power consumption for Ambiq Apollo3 and Sony Spresense at 41.3 μW/MHz and 128.2 μW/MHz respectively. The computational efficiency primacy goes instead to the MAX78000 and then to xCORE.ai at 117 MAC/cycle and 7.69 MAC/cycle respectively, achieving the fastest inference at 1.4 ms and 1.5 ms respectively. The platforms that required the least energy per inference were the MAX78000 and GAP8, at 0.09 mJ/inference and 0.52 mJ/inference respectively. The benchmarked tinyML network will be released openly to allow other researchers to run future comparisons on novel low power microprocessors.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9870017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9870017","Survey;Comparison;TinyML;CNN;Low-power;Benchmark","Performance evaluation;Power demand;Program processors;Microcontrollers;Multicore processing;Computer architecture;Parallel processing","","20","","12","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Optimizing Exponent Bias for Sub-8bit Floating-Point Inference of Fine-tuned Transformers","J. Lee; J. Choi","Department of Electronic Engineering, Hanyang University, Seoul, Korea; Department of Electronic Engineering, Hanyang University, Seoul, Korea",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","98","101","The Transformer-based fine-tuned neural networks have demonstrated remarkable success in natural language processing (NLP) at the cost of a substantial computational burden. Post-training quantization (PTQ) is a promising technique to reduce the computational cost without expensive re-training. But prior works either demand complex calibration or suffer noticeable accuracy degradation. This paper proposes a practical method for sub-8bit floating-point (FP) PTQ. The proposed method optimizes the exponent bias to minimize quantization error in terms of signal-to-quantization noise ratio (SQNR) progressively like stochastic gradient descent. We evaluate that the proposed method achieves close to full-precision model accuracy for 6 to 8 bit FP PTQ of fine-tuned BERT on GLUE and SQuAD tasks with negligible run-time overhead.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869965","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869965","Transformer;reduced-precision;floating-point;SQNR;exponent bias;post-training quantization;BERT","Quantization (signal);Bit error rate;Neural networks;Stochastic processes;Transformers;Natural language processing;Inference algorithms","","","","15","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"AutoDeepHLS: Deep Neural Network High-level Synthesis using fixed-point precision","M. Riazati; M. Daneshtalab; M. Sjödin; B. Lisper","Heterogeneous Systems Research Group, Mälardalen University, Västeras, Sweden; Heterogeneous Systems Research Group, Mälardalen University, Västeras, Sweden; Heterogeneous Systems Research Group, Mälardalen University, Västeras, Sweden; Heterogeneous Systems Research Group, Mälardalen University, Västeras, Sweden",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","122","125","Deep Neural Networks (DNN) have received much attention in various applications such as visual recognition, self-driving cars, health care, etc. Hardware implementation, specifically using FPGA and ASIC due to their high performance and low power consumption, is considered an efficient method. However, implementation on these platforms is difficult for neural network designers since they usually have limited knowledge of hardware. High-Level Synthesis (HLS) tools can act as a bridge between high-level DNN designs and hardware implementation. Nevertheless, these tools usually need implementation at the C level, whereas the design of neural networks is usually performed at a higher level (such as Keras or TensorFlow). In this paper, we propose a fully automated flow for creating a C-level implementation that is synthesizable with HLS Tools. Various aspects such as performance, minimal access to memory elements, data type knobs, and design verification are considered. Our results show that the generated C implementation is much more HLS friendly than previous works. Furthermore, a complete flow is proposed to determine different fixed-point precisions for network elements. We show that our method results in 25% and 34% reduction in bit-width for LeNet and VGG, respectively, without any accuracy loss.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869907","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869907","Deep Neural Network;Accelerator;High-Level Synthesis;Fixed-Point;Quantization","Deep learning;Knowledge engineering;Visualization;Power demand;Circuits and systems;Neural networks;Bridge circuits","","3","","25","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Intrinsic Sparse LSTM using Structured Targeted Dropout for Efficient Hardware Inference","J. H. Lindmar; C. Gao; S. -C. Liu","Institute of Neuroinformatics, University of Zürich and ETH Zürich, Zurich, Switzerland; Institute of Neuroinformatics, University of Zürich and ETH Zürich, Zurich, Switzerland; Institute of Neuroinformatics, University of Zürich and ETH Zürich, Zurich, Switzerland",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","126","129","Recurrent Neural Networks (RNNs) are useful for speech recognition but their fully-connected structure leads to a large memory footprint, making it difficult to deploy them on resource-constrained embedded systems. Previous structured RNN pruning methods can effectively reduce RNN size; however, it is difficult to find a good balance between high sparsity and high task accuracy or the pruned models only lead to moderate speedup on custom hardware accelerators. This work proposes a novel structured pruning method called Structure Targeted Dropout (STD)-Intrinsic Sparse Structures (ISS) that stochastically drops grouped rows and columns of the weight matrices during training. The compressed networks are equivalent to a smaller dense network, which can be efficiently processed by Graphics Processing Units (GPUs). STD-ISS is evaluated on the TIMIT phone recognition task using Long Short-Term Memory (LSTM) RNNs. It outperforms previous state-of-the-art hardware-friendly methods on both accuracy and compression ratio. STD-ISS achieves a size compression ratio of up to 50× with <1 % accuracy loss, leading to a 19.1× speedup on the embedded Jetson Xavier NX GPU platform.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869988","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869988","recurrent neural networks;long short-term memory;structured pruning;model compression","Training;Recurrent neural networks;Embedded systems;Circuits and systems;Graphics processing units;Speech recognition;Sparse matrices","","1","","13","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"DC-MPQ: Distributional Clipping-based Mixed-Precision Quantization for Convolutional Neural Networks","S. Lee; H. Kim","Department of Electrical and Information Engineering, Research Center for Electrical and Information Technology, Seoul National University of Science and Technology, Seoul, Korea; Department of Electrical and Information Engineering, Research Center for Electrical and Information Technology, Seoul National University of Science and Technology, Seoul, Korea",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","130","133","Quantization is a representative network compression technique that reduces the number of computational operations and memory accesses in the computation process of convolutional neural networks (CNNs). The existing naïve quantization method has a problem in that the quantization point corresponding to the near-zero value decreases as the precision decreases; as a result, the quantization error increases. Recent quantization-related studies have suggested various solutions to this problem. Nevertheless, studies that suggest a method to solve this problem by considering the characteristics of hardware accelerator implementation have not been actively conducted. To address this problem, this study proposes a method of using standard deviation values, which are simple statistical values of distribution for each layer, as clipping points and setting a scale factor with a clipping point as the base to quantize the weights into a mixed-precision integer format of 4-bit/8-bit. The proposed technique can be applied to any network without additional training, and only biasing and mapping are performed based on the pre-stored standard deviation values; thus, the computational complexity is low, rendering it hardware-friendly. Experimental results indicate that the proposed mixed-precision quantization of the weights of ResNet-18 on ImageNet achieved an effect of reducing the weight capacity by 84% with a 0.34% Top-1 accuracy drop compared to full precision. In YOLACT, an instance segmentation model using a ResNet-50 backbone, on MS COCO, a weight capacity reduction of 81.7% was achieved with only 0.27% and 0.19% drops in box mean average precision (mAP) and mask mAP, respectively.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869959","Ministry of Education(grant numbers:NRF-2019R1A6A1A03032119); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869959","mixed-precision quantization;hardware-aware quantization;distributional clipping;convolutional neural network;segmentation","Training;Degradation;Image segmentation;Quantization (signal);Rendering (computer graphics);Mobile handsets;Convolutional neural networks","","1","","19","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"An Energy-Efficient Spiking Neural Network for Finger Velocity Decoding for Implantable Brain-Machine Interface","J. Liao; L. Widmer; X. Wang; A. Di Mauro; S. R. Nason-Tomaszewski; C. A. Chestek; L. Benini; T. Jang","ETH Zurich, Switzerland; ETH Zurich, Switzerland; ETH Zurich, Switzerland; ETH Zurich, Switzerland; University of Michigan, USA; University of Michigan, USA; ETH Zurich, Switzerland; ETH Zurich, Switzerland",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","134","137","Brain-machine interfaces (BMIs) are promising for motor rehabilitation and mobility augmentation. High-accuracy and low-power algorithms are required to achieve implantable BMI systems. In this paper, we propose a novel spiking neural network (SNN) decoder for implantable BMI regression tasks. The SNN is trained with enhanced spatio-temporal backpropagation to fully leverage its ability in handling temporal problems. The proposed SNN decoder achieves the same level of correlation coefficient as the state-of-the-art ANN decoder in offline finger velocity decoding tasks, while it requires only 6.8% of the computation operations and 9.4% of the memory access.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869846","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869846","Brain-machine interface;motor decoding;spiking neural network;spatio-temporal backpropagation","Backpropagation;Correlation coefficient;Training;Memory management;Brain-computer interfaces;Energy efficiency;Decoding","","13","","23","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"A Full-Neuron Memory Model Designed for Neuromorphic Systems","K. Liu; X. Cui; C. Zou; Y. Kuang; Y. Zhong; K. Xiao; Y. Wang","Key Laboratory of Microelectronic Devices and Circuits Ministry of Education, School of Integrated Circuits, Peking University; Key Laboratory of Microelectronic Devices and Circuits Ministry of Education, School of Integrated Circuits, Peking University; Key Laboratory of Microelectronic Devices and Circuits Ministry of Education, School of Integrated Circuits, Peking University; Key Laboratory of Microelectronic Devices and Circuits Ministry of Education, School of Integrated Circuits, Peking University; Key Laboratory of Microelectronic Devices and Circuits Ministry of Education, School of Integrated Circuits, Peking University; Key Laboratory of Microelectronic Devices and Circuits Ministry of Education, School of Integrated Circuits, Peking University; Key Laboratory of Microelectronic Devices and Circuits Ministry of Education, School of Integrated Circuits, Peking University",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","138","141","Neuromorphic computing is considered to be a promising approach to developing general artificial intelligence. Like a human brain, the neuromorphic system uses neurons as the basic unit for information computing and storage. Neural networks have made great progress in some intelligent tasks by borrowing from the way the brain computes. Another important part of forming artificial intelligence is memory storage in neuromorphic systems. However, there is a lack of effective and practical methods for information storing in neuromorphic systems. In this paper, we propose a brain-like full-neuron memory (FNM) model to store memories in neuromorphic systems. We successfully stored ten numbers and letters in the FNM model. Memory objects are learned through Hebbian synaptic plasticity in an unsupervised manner and stored as neural activations in FNM. FNM works in a content-addressed way, which means the stored numbers and letters can be recalled by associative either visual or auditory stimuli. Memories are hierarchically structured in FNM. The numbers and letters can be recalled in full by incomplete input stimuli benefiting from the hierarchical structure. Some experiments are designed to verify the memory ability of the FNM model. With FNM model, the complete information processing and storage can be done in neuromorphic systems without taking the intermediate results out and processing or storing them on other computing platforms.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869902","National Key Research and Development Program of China(grant numbers:2018YFE0203801); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869902","full-neuron memory;associative memory;hebb plasticity;neuromorphic computing;neuromorphic system","Visualization;Neuromorphics;Neuromorphic engineering;Computational modeling;Neurons;Information processing;Brain modeling","","1","","14","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"A probability-inspired normalization for fixed-precision Hyper-Dimensional Computing","S. Datta; J. M. Rabaey","Electrical Engineering and Computer Sciences, University of California Berkeley, Berkeley, CA; Electrical Engineering and Computer Sciences, University of California Berkeley, Berkeley, CA",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","21","24","Hyper-Dimensional Computing (HDC), a promising nano-scalable paradigm for low-energy predictions and lightweight learned models, has seen a surge of interest from the hardware accelerator community. However, the classical single-bit per vector element approach for HDC seldom achieves higher classification accuracy than multi-bit alternatives, and is inadequate to support the rapidly growing application space. A great challenge for multi-bit HDC hardware is to negotiate the enormous increase in logic vis-a-vis the single-bit hardware. Key to minimizing this cost is to limit bits per vector element, which is potentially unbounded without transformation, and can be very large for some applications. This work proposes a hardware. friendly numerical transformation on a HDC vector where the result has fixed bits per element. Under a reasonable assumption on the vector's distribution, it is proven that the transformation guarantees at most a small, known error in associative search. Verification experiments indicate the theoretical guarantee is very pessimistic; the actual error is less than 18% of the theoretical upper bound. Estimates predict 3.8X hardware savings with a 0.04% accuracy drop. We believe emerging stochastic approaches like HDC offer exciting new opportunities of employing high-dimensional probability theory for accelerator design.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869986","TSMC; DARPA; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869986","Hyper-dimensional computing;energy efficiency;Internet-of-Things;probability;machine learning","Upper bound;Costs;Limiting;Stochastic processes;Tail;Learning (artificial intelligence);Predictive models","","","","14","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Enabling Energy-Efficient Inference for Self-Attention Mechanisms in Neural Networks","Q. Chen; C. Sun; Z. Lu; C. Gao","Institute of Photonic Chips, University of Shanghai for Science and Technology, Shanghai, China; School of Electronic Science and Engineering, Nanjing University, Nanjing, China; KTH-Royal Institute of Technology, Stockholm, Sweden; Institute of Neuroinformatics, University of Zürich and ETH Zürich, Zurich, Switzerland",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","25","28","The study of specialized accelerators tailored for neural networks is becoming a promising topic in recent years. Such existing neural network accelerators are usually designed for convolutional neural networks (CNNs) or recurrent neural networks have been (RNNs), however, less attention has been paid to the attention mechanisms, which is an emerging neural network primitive with the ability to identify the relations within input entities. The self-attention-oriented models such as Transformer have achieved great performance on natural language processing, computer vision and machine translation. However, the self-attention mechanism has intrinsically expensive computational workloads, which increase quadratically with the number of input entities. Therefore, in this work, we propose an software-hardware co-design solution for energy-efficient self-attention inference. A prediction-based approximate self-attention mechanism is introduced to substantially reduce the runtime as well as power consumption, and then a specialized hardware architecture is designed to further increase the speedup. The design is implemented on a Xilinx XC7Z035 FPGA, and the results show that the energy efficiency is improved by 5.7x with less than 1% accuracy loss.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869924","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869924","Self-attention;approximate computing;VLSI","Runtime;Recurrent neural networks;Power demand;Computer architecture;Transformers;Energy efficiency;Machine translation","","4","","13","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Temporal Frame Filtering with Near-Pixel Compute for Autonomous Driving","W. Li; Q. Wu; J. Sharda; S. Chang; S. Yu","Georgia Institute of Technology, Atlanta, USA; University of California Santa Barbara, Santa Barbara, USA; Georgia Institute of Technology, Atlanta, USA; University of California Santa Barbara, Santa Barbara, USA; Georgia Institute of Technology, Atlanta, USA",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","29","32","As the computer vision techniques behind the advances in autonomous driving become more complex, the on-vehicle processors experience increased burden due to the need to compute on the received images in real-time. Near-pixel compute is an emerging paradigm that brings part of the critical compute tasks very close to the image sensors, and the transmitted data is reduced in dimensionality or partially processed to alleviate the backend compute stress. In this work, we present a near-pixel compute architecture targeting a temporal frame filtering network which drops redundant image frames for the autonomous driving BDD100K dataset. Several circuit optimizations to the compute units are introduced, including using NOR gate array as data buffers, front-end demosaicing, sparsity-aware adder tree, and indirect calculation of image frame difference. The proposed design is synthesized at 40 nm, a node compatible with CMOS image sensor (CIS) technology, which completes the filtering algorithm in 2.2 ms with an energy efficiency of 15.7 TOPS/W and compute density of 380.1 GOPS/mm2.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9870011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9870011","near-pixel compute;autonomous driving;hardware accelerator;convolutional network networks","Target tracking;Program processors;Filtering;Computer architecture;Logic gates;Energy efficiency;Real-time systems","","5","","12","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"A General-Purpose and Configurable Planar Data Processor for Energy-Efficient Pooling Computation","L. Pan; P. Xue; H. Li; L. Sun; M. Huang","SEU-FEI Nano-Pico Center, Key Laboratory of MEMS of Ministry of Education, School of Electronic Science and Engineering, Southeast University, Nanjing, People's Republic of China; Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China, Shenzhen, China; SEU-FEI Nano-Pico Center, Key Laboratory of MEMS of Ministry of Education, School of Electronic Science and Engineering, Southeast University, Nanjing, People's Republic of China; SEU-FEI Nano-Pico Center, Key Laboratory of MEMS of Ministry of Education, School of Electronic Science and Engineering, Southeast University, Nanjing, People's Republic of China; Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China, Shenzhen, China",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","33","36","Convolutional Neural Networks (CNN) have been widely used in artificial intelligence applications. A typical CNN contains both convolution and pooling layer, in which the convolution is to detect local conjunctions of features and the pooling is to merge similar patterns into one. It is necessary to make pooling operation, which plays a great role in CNN. Up to now, there have been numerous researches on CNN accelerators, however, most of the previous works are only focused on the acceleration of convolution layers, and the specific studies on pooling units are still lacking. Besides, the existing pooling designs are usually constrained by either the poor flexibility or the low energy/area efficiency. In this work, we propose a general purpose and energy-efficient planar data processor to support the pooling operation from different CNN structure. By using the configurable data path control method, the processor is able to support universal pooling operation with arbitrary input feature shape and arbitrary pooling kernel/stride/padding size. Besides, the processor exhibits high efficiency with hardware utilization ratio near 100% during operation, indicating good performance of the design. Most importantly, it is energy-efficient that exhibits 86%-off on power consumption and 62%-off on area utilization when compared with the separate pooling module of NVDLA (NVIDIA Deep Learning Accelerator), thus is particularly suitable for the resource-limited edge intelligent devices.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869992","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869992","Energy-Efficient;CNN accelerator;Pooling","Power demand;Convolution;Shape;Process control;Energy efficiency;Hardware;System-on-chip","","1","","6","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"A 0.95 mJ/frame DNN Training Processor for Robust Object Detection with Real-World Environmental Adaptation","D. Han; D. Im; G. Park; Y. Kim; S. Song; J. Lee; H. -J. Yoo","School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","37","40","A DNN training processor with a maximum of 332 TOPS/W is proposed for efficient and robust object detection. The proposed processor is able to support both quantization and pruning-based personalization to make a user-optimized lightweight network. In addition to personalization, it supports real-time adaptation to compensate for accuracy degradation caused by environmental changes or unpredictable situations. It maintains conventional input slice skipping architecture and stochastic rounding-based computing for the efficient acceleration of the DNN training. It further improves efficiency by removing pseudo-RNGs during the stochastic rounding and adding blocks to pruning-aware training. Moreover, it suggests an LT-flag-based reconfigurable accumulation network and enables multi-learning-task-allocation for low-latency DNN training with the backward unlocking solution. Fabricated in 28-nm technology, the proposed processor demonstrates 46.6 FPS object detection with 0.95 mJ/frame energy consumption which is the state-of-the-art performance compared with the previous processors.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869960","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869960","Deep Neural Network;Back-propagation;Object Detection;Quantization;Pruning;Backward Locking","Training;Degradation;Energy consumption;Quantization (signal);Object detection;Computer architecture;Throughput","","5","","13","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Optimizing Accelerator Configurability for Mobile Transformer Networks","S. Colleman; P. Zhu; W. Sun; M. Verhelst","Department of Electrical Engineering, MICAS-ESAT, KULeuven, Belgium; OPPO Electronics; OPPO Electronics; Department of Electrical Engineering, MICAS-ESAT, KULeuven, Belgium",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","142","145","Transformers are increasingly used to process time series data. Their deployment in mobile devices is however challenging due to their large computational requirements. Hardware acceleration through custom neural network processors can reduce the resulting latency and energy footprint of the network. Yet, the large variety of different layer types in mobile transformers troubles the selection of the best accelerator architecture and hardware mapping. Specifically, the layer performance strongly depends on the spatial unrolling dimensions, i.e. the layer loop dimensions along which hardware parallelization is enabled. This paper will therefore research the best datapath organization, and required datapath flexibility to efficiently support mobile transformers. The Mobile ViTS network is selected as the reference network for its wide variety in layer types. Results are explored across a wide range of accelerator area (datapath dimensions, memory size) and bandwidth constraints.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869945","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869945","CNN;transformer;cross-layer;configurability;hardware modelling and optimization","Program processors;Codes;Time series analysis;Neural networks;Organizations;Transformers;Mobile handsets","","3","","5","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Configurable CNN Accelerator in Speech Processing based on Vector Convolution","L. Hui; S. Cao; Z. Chen; S. Li; S. Xu","School of Communication and Information Engineering, Shanghai University; School of Communication and Information Engineering, Shanghai University; School of Communication and Information Engineering, Shanghai University; School of Communication and Information Engineering, Shanghai University; School of Communication and Information Engineering, Shanghai University",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","146","149","In speech applications, both input feature maps (IFMs) and kernels of neural networks are greatly diverse in shapes and sizes, which poses significant challenges to hardware acceleration. In this paper, a configurable CNN accelerator is introduced to make a good balance between the flexibility and efficiency for various neural network models in speech processing. The vector convolution scheme is first proposed by re-arrangement of IFM rows and weight values in vectors, by which the element convolution is converted into vector operations to break the limit of kernel-centric processing. The structure of vector processing element (VPE) is introduced to fit the continuous scaling down of IFMs with little control overheads, and the architecture of the CNN accelerator is proposed accordingly. FPGA implementation results demonstrate that the throughput is increased by 86% by the proposed architecture compared to state-of-the-art FPGA accelerators for the VGG16 network, while high DSP utilization is guaranteed for both 1D and 2D CNNs with various input sizes.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869904","National Natural Science Foundation of China(grant numbers:61904101); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869904","Accelerator;CNN;speech processing;FPGA implementation","Convolution;Shape;Neural networks;Process control;Throughput;Convolutional neural networks;Speech processing","","4","","13","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"M3FPU: Multiformat Matrix Multiplication FPU Architectures for Neural Network Computations","W. Jeon; Y. C. P. Cho; H. M. Kim; H. Kim; J. Chung; J. Kim; M. Lee; C. -G. Lyuh; J. Han; Y. Kwon","AI SoC Research Department, AI Processor Research Team, Electronics and Telecommunications Research Institute, Daejeon, Republic of Korea; AI SoC Research Department, AI Processor Research Team, Electronics and Telecommunications Research Institute, Daejeon, Republic of Korea; AI SoC Research Department, AI Processor Research Team, Electronics and Telecommunications Research Institute, Daejeon, Republic of Korea; AI SoC Research Department, AI Processor Research Team, Electronics and Telecommunications Research Institute, Daejeon, Republic of Korea; AI SoC Research Department, AI Processor Research Team, Electronics and Telecommunications Research Institute, Daejeon, Republic of Korea; AI SoC Research Department, AI Processor Research Team, Electronics and Telecommunications Research Institute, Daejeon, Republic of Korea; AI SoC Research Department, AI Processor Research Team, Electronics and Telecommunications Research Institute, Daejeon, Republic of Korea; AI SoC Research Department, AI Processor Research Team, Electronics and Telecommunications Research Institute, Daejeon, Republic of Korea; AI SoC Research Department, AI Processor Research Team, Electronics and Telecommunications Research Institute, Daejeon, Republic of Korea; AI SoC Research Department, AI Processor Research Team, Electronics and Telecommunications Research Institute, Daejeon, Republic of Korea",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","150","153","Parallel computing performance on floating-point numbers is one of the most important factors in modern computer systems. The hardware components of floating-point units have the potential to improve parallel performance and resource utilization, however, the existing vector-type multiformat parallel floating-point units cannot take advantage of them. We propose M3FPU, a new matrix-type multiformat floating-point unit that applies an outer product matrix multiplication method to a multiplier tree of floating-point units to increase parallelism and resource utilization by the square. M3FPU utilizes the unused part of the multiplier tree of the existing floating-point unit that is filled with zeros. The proposed M3FPU is implemented on a 12nm silicon process and achieves a 44.17% smaller area compared to the state-of-the-art multiformat floating-point unit architecture when supporting the same number of 8-bit floating-point number parallel operations.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869984","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869984","floating-point unit;multiformat arithmetic;matrix multiplication;machine learning","Circuits and systems;Scalability;Neural networks;Merging;Computer architecture;Learning (artificial intelligence);Parallel processing","","3","","10","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Quantized ID-CNN for a Low-power PDM-to-PCM Conversion in TinyML KWS Applications","P. Vitolo; G. D. Licciardo; A. C. Amendola; L. Di Benedetto; R. Liguori; A. Rubino; D. Pau","Department of Industrial Engineering, University of Salerno, Fisciano, SA, Italy; Department of Industrial Engineering, University of Salerno, Fisciano, SA, Italy; Department of Industrial Engineering, University of Salerno, Fisciano, SA, Italy; Department of Industrial Engineering, University of Salerno, Fisciano, SA, Italy; Department of Industrial Engineering, University of Salerno, Fisciano, SA, Italy; Department of Industrial Engineering, University of Salerno, Fisciano, SA, Italy; System Research and Applications, STMicroelectronics, Agrate Brianza, MI, Italy",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","154","157","This paper proposes a novel low-power HW accelerator for audio PDM-to-PCM conversion based on artificial neural network. The system processes samples from a digital MEMS microphone and converts them in PCM format by using a 1-Dimensional Convolutional Neural Network (1D-CNN). The model has been quantized to reduce the computational complexity while preserving its Signal-to-Noise Ratio (SNR) and the HW accelerator has been designed to minimize the physical resources. The SNR achieved is 41.56 dB while the prototyping of the design on a Xilinx Artix-7 FPGA shows a dynamic power consumption of 1 mW and a utilization of 606 LUTs and 410 FFs. These results enable the proposed system to be the first step of a tiny low-power end-to-end neural network-based Keyword Spotting (KWS) system.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869909","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869909","PDM-to-PCM conversion;neural network;keywork spotting;FPGA;low power","Micromechanical devices;Power demand;Filtering;Table lookup;Iterative methods;Convolutional neural networks;Pulse modulation","","9","","25","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"A Real-time Super-resolution Accelerator Using a big. LITTLE Core Architecture","X. T. Nguyen; T. N. Nguyen; H. -J. Lee; K. Lee","Department of Electrical and Computer Engineering, Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering, Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering, Seoul National University, Seoul, Korea; School of AI Convergence, Sungshin Women's University, Seoul, Korea",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","158","161","Image super-resolution (SR) networks have shown a remarkable restoration performance but come with a huge memory bandwidth requirement due to a large-size input and lack of a pooling layer. As a result, SR accelerators usually adopted a streaming-like scheme to fit a highly customized and small SR network to available resources, which causes a large accuracy drop. To address this problem, this work proposes an SR accelerator using a big.LITTLE core architecture which is able to execute various networks in real-time. The proposed SR processor achieves an inference speed of 36.63 frames per second and a throughput of 221.79 GOPs at 200MHz for ×2 SR (from 960×540 to 1920×1080) while using only 1,280 eight-bit multipliers and 330 KB on-chip SRAM.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869926","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869926","Image super-resolution;SR accelerator;SRNPU","PSNR;Superresolution;Memory management;Random access memory;Streaming media;Throughput;Real-time systems","","3","","17","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Stain-free Holographic Detection of Circulating Tumor Cells Using A Deep Feature Fusion Neural Network","M. Wei; X. Huang; W. Han; Z. Tian; G. Wu; S. Wang; L. Sun","Key Laboratory of RF Circuits and Systems, Ministry of Education, Hangzhou Dianzi University, China; Key Laboratory of RF Circuits and Systems, Ministry of Education, Hangzhou Dianzi University, China; Key Laboratory of RF Circuits and Systems, Ministry of Education, Hangzhou Dianzi University, China; Key Laboratory of RF Circuits and Systems, Ministry of Education, Hangzhou Dianzi University, China; Institute for Translational Medicine, Zhejiang University, China; Institute for Translational Medicine, Zhejiang University, China; Key Laboratory of RF Circuits and Systems, Ministry of Education, Hangzhou Dianzi University, China",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","102","105","Circulating tumor cells (CTCs) have important reference value in cancer diagnostics. As the existing fluorescence-based CTC detection method faces the limitation of tedious staining steps and photobleaching, it's necessary to develop a stain-free identification method. This work demonstrated a stain-free holographic detection of CTCs using a deep feature fusion neural network. By utilizing the subtle difference between CTCs internal structures captured by the holographic microscope, the proposed neural network fuses low-level features extracted by the shallow layers with high-level features extracted by deep layers into fused features for CTCs identification, and reached an accuracy of 94%. Compared with the previous fluorescent stain-based method, this work provides a potential solution for high accuracy stain-free CTC detections.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869981","National Natural Science Foundation of China(grant numbers:61827806); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869981","stain-free;CTC identification;holographic detection;feature fusion;deep neural network","Deep learning;Fuses;Circuits and systems;Microscopy;Neural networks;Fluorescence;Feature extraction","","","","12","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Energy Efficient Text Spotting Technique for Mobile Edge Computing","S. Jeong; Y. Kwon","Computer Science Department, The State University of New York, Korea, Incheon, Korea; Computer Science Department, The State University of New York, Korea, Incheon, Korea",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","106","109","We propose a new scene text spotting system which aims at minimizing the power consumption in mobile edge devices. We focused on preprocessing methods and changes in the processing pipeline. Overall, we removed non-text images from the processing pipeline to reduce power consumption and positioned texts at the center of the images to improve accuracy. Moreover, we were able to achieve a substantial power saving and increased text recognition accuracy. Compared to the baseline method, our proposed method shows an 80% higher performance score. The accuracy score was increased by 17% and the power consumption was reduced by 30% because we could reduce the execution count of the neural network by 40%.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869940","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869940","Edge computing;Mobile computing;Computational efficiency;Computer vision;Text spotting","Power demand;Multi-access edge computing;Text recognition;Circuits and systems;Image edge detection;Pipelines;Neural networks","","1","","13","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"A Study On Reliable High-Speed HBC Enhanced by ECC for Wearable Neural Interfaces","S. Moon; J. Ko; B. Kim; Y. Lee","Electrical Engineering, Pohang University of Science and Technology (POSTECH), Pohang, South Korea; Electrical Engineering, Pohang University of Science and Technology (POSTECH), Pohang, South Korea; Electrical Engineering, Pohang University of Science and Technology (POSTECH), Pohang, South Korea; Electrical Engineering, Pohang University of Science and Technology (POSTECH), Pohang, South Korea",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","110","113","This work reports the first quantitative study about reliable high-speed human body communication (HBC) enhanced by error correction code (ECC) for wearable neural interfaces. For the first time, Bose-Chaudhuri-Hocqunghem (BCH) code was applied to the measured raw data of an HBC transceiver (TRX) that operated at about 100 Mb/s or faster to quantitatively assess the reliability improvement and the additional power and area cost associated with the BCH code. In our assessments, the (136, 128, 1) BCH code very efficiently improved the reliability of the HBC as it improved the eye height by up to about 95 % at costs of only 5-7% additional power and 46% additional silicon area. With slightly more power consumption up to 21% and 90% chip area, the (160, 128, 4) BCH code greatly improved the reliability of the HBC as it increased the eye height by up to 200%.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869999","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869999","BCH code;error coding;human body communication;decision feedback equalization;eye diagram","Costs;Power demand;Power measurement;Costing;Transceivers;Time measurement;Silicon","","","","6","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Deep Learning aided BP-Flip Decoding of Polar Codes","Y. Lee; U. Lee; H. H. Fisseha; M. H. Sunwoo","Department of Electrical and Computer Engineering, Ajou University, Suwon, Republic of Korea; Department of Electrical and Computer Engineering, Ajou University, Suwon, Republic of Korea; Department of Electrical and Computer Engineering, Ajou University, Suwon, Republic of Korea; Department of Electrical and Computer Engineering, Ajou University, Suwon, Republic of Korea",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","114","117","This paper proposes the deep neural network (DNN) based on a belief propagation flip (BPF) decoding algorithm. The conventional BPF decoding does not determine which bits to flip and exhaustively flips the bits of a critical set (CS). This paper uses a DNN to decide which bits to flip. In addition, to reduce the training complexity of DNN, the codeword segmentation and the classes consisting of CS were used. As a result, the proposed BP-DNN-Flip algorithm shows a performance gain of 0.3dB at frame error rate (FER) 10−4 compared to the conventional BPF decoding algorithm. In addition, it has a lower average time complexity of at least 55% compared to traditional BPF decoding algorithms at a signal-to-noise ratio (SNR) of 1.5dB.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869917","National Research and Development program through the National Research Foundation of Korea (NRF); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869917","deep learning;polar code;belief propagation;flip","Band-pass filters;Training;Deep learning;Simulation;Neural networks;Performance gain;Decoding","","1","","17","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Improving Deep-Learning-based Optical Music Recognition for Camera-based Inputs","W. Ng; X. T. Nguyen","Department of Composition; Department of Electrical and Computer Engineering, Seoul National University, Seoul, Korea",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","118","121","Recently, convolutional neural networks (CNNs) have demonstrated promising performance in optical music recognition (OMR). However, the recognition accuracy of an OMR is significantly degraded for a noisy image input given by a camera. To address the problem, this study investigates the use of well-known preprocessed techniques and a state-of-the-art deep learning OMR method. The proposed framework is, then, trained with the Camera-PrIMuS dataset. The experimental results demonstrate that the proposed approach improves the accuracy by 11.1% on average. We conclude that developing OMR algorithms to read camera-based input music scores is plausible and should be further explored.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869934","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869934","Optical Music Recognition;Camera-based inputs","Deep learning;Image recognition;Circuits and systems;Optical computing;Optical fiber networks;Optical imaging;Cameras","","","","16","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"AIWareK: Compiling PyTorch Model for AI Processor Using MLIR Framework","H. Kwon; H. M. Kim; C. -G. Lyuh; J. -K. Kim; J. Han; Y. Kwon","AI SoC Research Division, ETRI, Daejeon, Republic of Korea; AI SoC Research Division, ETRI, Daejeon, Republic of Korea; AI SoC Research Division, ETRI, Daejeon, Republic of Korea; AI SoC Research Division, ETRI, Daejeon, Republic of Korea; AI SoC Research Division, ETRI, Daejeon, Republic of Korea; AI SoC Research Division, ETRI, Daejeon, Republic of Korea",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","463","465","Deep learning compiler becomes necessary with the active research on AI hardware. This work compiles PyTorch models into target hardware codes using MLIR framework. The compiler first constructs a graph from the PyTorch model using TorchScript tracing. To construct the graph, our domain-specific parser generates an abstract syntax tree using tokens generated from the lexer. Then, the graph IR (GIR) is built and lowered into the kernel IR (KIR) and the processor IR (PIR) in MLIR framework. PIR becomes the input of the backed compiler that generates target machine codes. Experimental result shows that AIWareK compiled ResNet18 in 7.67 seconds, yielding 1.16e-03 mean absolute error.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869913","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869913","MLIR;compiler;deep learning;AI hardware","Deep learning;Codes;Circuits and systems;Syntactics;Hardware;Artificial intelligence;Kernel","","2","","13","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"ArtBrain-K: AI Processor based-on 5-PetaFLOPS AI Server System","J. Han; C. -G. Lyuh; K. Shin; H. M. Kim; H. Kwon; J. Chung; C. P. Cho; J. Kim; J. Suk; C. Kim; M. Choi; Y. Kwon","AI SoC Research Division, ETRI, Daejeon, Republic of Korea; AI SoC Research Division, ETRI, Daejeon, Republic of Korea; AI SoC Research Division, ETRI, Daejeon, Republic of Korea; AI SoC Research Division, ETRI, Daejeon, Republic of Korea; AI SoC Research Division, ETRI, Daejeon, Republic of Korea; AI SoC Research Division, ETRI, Daejeon, Republic of Korea; AI SoC Research Division, ETRI, Daejeon, Republic of Korea; AI SoC Research Division, ETRI, Daejeon, Republic of Korea; AI SoC Research Division, ETRI, Daejeon, Republic of Korea; AI SoC Research Division, ETRI, Daejeon, Republic of Korea; AI SoC Research Division, ETRI, Daejeon, Republic of Korea; AI SoC Research Division, ETRI, Daejeon, Republic of Korea",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","466","468","We developed ArtBrain-K, an artificial intelligence server system with a performance of 5 PetaFLOPS per rack that can have a small form factor with low power, 2400W based on a proprietary artificial intelligence processor with 40 TeraFLOPS performance, and 15W power consumption. It consists of 8 artificial intelligence compute nodes with a performance of 590 TeraFLOPS and 300W power consumption which loaded with 20 ABrain-S NPU boards based on the artificial intelligence processor. Also, we developed AIWareRT, a software development environment for independent artificial intelligence processor. Compared to the existing GPU system, the performance is 3 times higher and the power efficiency is 7 times higher. It has been applied to the next-generation airport automatic immigration system and image recognition-based security system, and it can be used in fields that require enormous computing resources for data processing and learning, such as a huge neural network such as a transformer-based artificial intelligence algorithm.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869983","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869983","AI Processor;AI Server System;Huge neural Network","Power demand;Software algorithms;Graphics processing units;Learning (artificial intelligence);Transformers;Data processing;Software","","1","","7","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Implementing Binarized Neural Network Processor on FPGA-Based Platform","J. Lee; H. Kim; B. -S. Kim; S. Jeon; J. C. Lee; D. S. Kim","SoC Platform Research Center, Korea Electronics Technology Institute, Seongnam-si, Korea; SoC Platform Research Center, Korea Electronics Technology Institute, Seongnam-si, Korea; SoC Platform Research Center, Korea Electronics Technology Institute, Seongnam-si, Korea; SoC Platform Research Center, Korea Electronics Technology Institute, Seongnam-si, Korea; SoC Platform Research Center, Korea Electronics Technology Institute, Seongnam-si, Korea; SoC Platform Research Center, Korea Electronics Technology Institute, Seongnam-si, Korea",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","469","471","Binarized neural networks (BNNs) have 1-bit weights and activations, which are well suited for FPGAs. The BNNs suffer from accuracy loss compared with conventional neural networks. Shortcut connections are introduced to address the performance degradation. This work proposes a BNN processor supporting the shortcut connects. To evaluate the performance of the processor, we implement the system on an FPGA (Xilinx Kintex UltraScale). Our experiments show that the proposed processor achieves state-of-the-art energy efficiency.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869997","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869997","Deep Learning;Binarized Neural Network;Neural Network Processor;FPGA Accelerator","Degradation;Circuits and systems;Neural networks;Energy efficiency;Artificial intelligence;Field programmable gate arrays","","1","","16","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Implementation of an Quantum Circuit Simulator using Classical Bits","Y. Hong; S. Jeon; S. Park; B. -S. Kim","Korea Electronics Technology Institute, SoC Platform Research Center, Seongnam-si, Korea; Korea Electronics Technology Institute, SoC Platform Research Center, Seongnam-si, Korea; Korea Electronics Technology Institute, SoC Platform Research Center, Seongnam-si, Korea; Korea Electronics Technology Institute, SoC Platform Research Center, Seongnam-si, Korea",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","472","474","The quantum computer has attracted much attention since it can reduce running time of many tasks such as factorization and search compared to classical computers. However, the actual quantum computer is difficult to get access, and the classical computer has a problem of calculation time and computation cost grows exponentially with increasing the number of qubits. In this paper, we address an efficient quantum circuit simulator including quantum circuit emulation hardware and its software framework using classical bit. Also, the proposed quantum circuit simulator operates the same as the conventional quantum software framework and shows a fast operation speed.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9870019","MOTIE; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9870019","quantum circuit;quantum simulator;quantum computer;FPGA","Costs;Circuits and systems;Qubit;Emulation;Software;Hardware;Quantum circuit","","4","","7","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Weighted Decoupling: An Effective Image Resizing Method for Binarized Neural Network","S. -W. Im; S. Jeon; B. -S. Kim; T. -H. Hwang","SoC Platform Research Center, Korea Electronics Technology Institute, Seongnam-si, Korea; SoC Platform Research Center, Korea Electronics Technology Institute, Seongnam-si, Korea; SoC Platform Research Center, Korea Electronics Technology Institute, Seongnam-si, Korea; SoC Platform Research Center, Korea Electronics Technology Institute, Seongnam-si, Korea",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","475","478","Many neuromorphic hardware uses a micro controller unit that has low computing power and small memory size. To process deep neural network applications on hardware-restricted conditions and to alleviate computational latency, binarized neural networks have been developed. Moreover, we can reduce required multiply-accumulate operation by shrinking resolution of input images. In this paper, we compare various image resizing method and propose weighted decoupling, a new resizing method for the best accuracy of ResNetB18 model, an additionally binarized version of ResNetE18. A ResNetB18 model with proposed resizing method shows the better accuracy performance than that of a same model trained with 12.25× large images.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869964","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869964","Neuromorphic Hardware;ResNet;ResNetE18;ResNetB18;Binarized Neural Network;Image resizing","Deep learning;Performance evaluation;Image resolution;Neuromorphics;Simulation;Image edge detection;Computational modeling","","2","","9","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Characteristic Comparison of Korean Unstructured Dialogue Corpora by Morphological Analysis","S. Moon; S. Shin; S. Kim; M. Jung; J. Y. Jang","Artificial Intelligence Research Center, Korea Electronics Technology Institute, Seongnam-si, Republic of Korea; Artificial Intelligence Research Center, Korea Electronics Technology Institute, Seongnam-si, Republic of Korea; Artificial Intelligence Research Center, Korea Electronics Technology Institute, Seongnam-si, Republic of Korea; Artificial Intelligence Research Center, Korea Electronics Technology Institute, Seongnam-si, Republic of Korea; Artificial Intelligence Research Center, Korea Electronics Technology Institute, Seongnam-si, Republic of Korea",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","1","4","Natural language processing (NLP) has globally attracted researchers' attention. Many unstructured dialogue corpora in other languages as well as English and Chinese have been collected for NLP research. Those corpora show various characteristics depending on the relationship between speakers, the dialogue topic, how dialogues are gathered, etc. Analyzing their characteristics is therefore mandatory to comprehend the corpora for studying natural language dialogue. In this paper, we choose six different Korean unstructured dialogue corpora for their characteristic comparison, and identify the average numbers of utterances, proper nouns and pronouns per dialogue using MeCab-ko, a Korean morpheme analyzer.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869853","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869853","natural language dialogue;Korean unstructured dialogue corpora;morphological analysis","Circuits and systems;Natural language processing;Task analysis;Artificial intelligence","","1","","12","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"AI Accelerator Embedded Computational Storage for Large-Scale DNN Models","B. Ahn; J. Jang; H. Na; M. Seo; H. Son; Y. H. Song","Memory Business Division, Samsung Electronics, Co., Ltd., Hwaseong, Republic of Korea; Memory Business Division, Samsung Electronics, Co., Ltd., Hwaseong, Republic of Korea; Memory Business Division, Samsung Electronics, Co., Ltd., Hwaseong, Republic of Korea; Memory Business Division, Samsung Electronics, Co., Ltd., Hwaseong, Republic of Korea; Memory Business Division, Samsung Electronics, Co., Ltd., Hwaseong, Republic of Korea; Memory Business Division, Samsung Electronics, Co., Ltd., Hwaseong, Republic of Korea",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","483","486","As the model size of Deep Neural Networks (DNN) is extremely expanding, especially in Natural Language Processing (NLP) field, it is not suitable for performing AI application on conventional DRAM-based systems that lack capacity. For such a reason, we propose a new computational storage by integrating a Neural Processing Unit (NPU) that could perform the DNN inference to the NAND Flash Memory Controller (FMC). Our NPU is able to use weight scheduling to efficiently load data from multiple NAND channels, and the optimal number of MAC units in NPU Core module is derived. We evaluate our proposed NPU architecture when using a very large size of DNN model. In contrast to DRAM-based memory system, ours show an equal inference performance, and total memory access power and latency are reduced by 22.6% and 36.3%, respectively. Also, by using the data buffer of NAND flash memory as shared SRAM, the area overhead could be reduced by 82% compared to when NPU using dedicated SRAM.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869991","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869991","deep neural networks;neural processing unit;computational storage;near-storage computing;NAND flash memory;data-intensive network","Processor scheduling;Computational modeling;Neural networks;Random access memory;Process control;Computer architecture;Natural language processing","","5","","15","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"An Architecture of Sparse Length Sum Accelerator in AxDIMM","S. -h. Kang; B. Kim; S. Lee; K. Sohn","DRAM Design Team1, Samsung Electronics, Hwasung, South Korea; DRAM Design Team1, Samsung Electronics, Hwasung, South Korea; DRAM Design Team1, Samsung Electronics, Hwasung, South Korea; DRAM Design Team1, Samsung Electronics, Hwasung, South Korea",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","1","4","In this paper, we have implemented high-efficient near-memory sparse-length sum hardware accelerator which is parallelized over each channel or rank to support Meta's deep learning recommendation model (DLRM). In addition, we described high-level architecture and efforts to enable on the conventional x86 server system. From our suggested near-memory accelerator, we got 1.94 × performance gain on two rank system which are physically multiplied.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869896","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869896","Near-memory processing;neural network accelerator;FPGA","Deep learning;Circuits and systems;Memory management;Bandwidth;Performance gain;Generators;Servers","","3","","8","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"CMS: A Computational Memory Solution for High-Performance and Power-Efficient Recommendation System","M. Ha; J. Sim; D. Moon; M. Rhee; J. Choi; B. Koh; E. Lim; K. Park","Memory Systems R&D, SK hynix, Icheon, South Korea; Memory Systems R&D, SK hynix, Icheon, South Korea; Memory Systems R&D, SK hynix, Icheon, South Korea; Memory Systems R&D, SK hynix, Icheon, South Korea; Memory Systems R&D, SK hynix, Icheon, South Korea; Memory Systems R&D, SK hynix, Icheon, South Korea; Memory Solution Product Development, SK hynix, Icheon, South Korea; Memory Systems R&D, SK hynix, Icheon, South Korea",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","491","494","This paper proposes a cost-effective and scalable memory solution for high-performance and power-efficient recommendation systems, called computational memory solution (CMS). To address the memory bandwidth challenges of the deep learning-based recommendation system, CMS offloads memory-intensive embedding operations to near-data processors equipped with large capacity and high bandwidth memory. In contrast to the other state-of-the-art near-memory processing accelerators that only support inference and have scalability restrictions, CMS supports training and scales as much as the high-speed serial interface allows. Our evaluation results show that CMS achieves up to $7.5\times$ higher throughput and $12.2\times$ higher power efficiency for training than state-of-the-art accelerators.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869851","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869851","deep learning;heterogeneous system;memory solution;near data processing;recommendation system","Training;Program processors;Circuits and systems;Scalability;Memory architecture;Bandwidth;Throughput","","4","","12","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Al Engine Structures in LG TV Processor","H. Shin; S. Kim; J. Lim; K. Rhee; J. Yang; J. Kim","SIC R&D Center LG Electronics Seoul, Korea, hyunchul; SIC R&D Center LG Electronics Seoul, Korea, hyunchul; SIC R&D Center LG Electronics Seoul, Korea, hyunchul; SIC R&D Center LG Electronics Seoul, Korea, hyunchul; SIC R&D Center LG Electronics Seoul, Korea, hyunchul; SIC R&D Center LG Electronics Seoul, Korea, hyunchul",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","495","498","Recently, artificial intelligence(AI) functions have been rapidly adopted to TV systems. We have developed two different kinds of AI picture processing engine structures. The first one is an optimized structure for pixel level processing, which requires large logic area in chip for highly complicated computations on huge amount of data. Specifically, the activation data can be transferred from the previous layer to the next layer without external data movement, which only requires minimum internal memory transactions. The second one is a more general structure which can be used for various applications. Most deep learning engines show lower MAC utilization ratio than expected, which may result from excessive external memory transactions. For high utilization, we adopted memory bandwidth reduction methods such as weight clustering, layer fusion, and multiple layer fusion. Our convolution engine with 8-bit integer precision also reduced both memory bandwidth and power consumption. In the result, LG TV processor can conduct both pixel level processing and recognition in a very efficient way and shows astonishing image quality.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9870004","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9870004","deep learning;AI picture quality;TV Chip;DDR memory bandwidth;power consumption;8-bit integer","Deep learning;TV;Power demand;Convolution;Memory management;Bandwidth;Hardware","","","","7","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"A low power neural network training processor with 8-bit floating point with a shared exponent bias and fused multiply add trees","J. Park; S. Lee; D. Jeon","Institute of Engineering Research, Seoul National University, Seoul; Department of Convergence Science and Technology, Seoul National University, Seoul; Department of Convergence Science and Technology, Seoul National University, Seoul",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","499","499","This demonstration showcases a neural network training processor implemented in silicon through 40nm LPCMOS technology. Based on custom 8-bit floating point and efficient tree-based processing schemes and dataflow, we achieve 2.48× higher energy efficiency than a prior low-power neural network training processor.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869947","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869947","DNN Training Accelerators;VLSI;Integrated","Training;Circuits and systems;Neural networks;Silicon;Energy efficiency;Artificial intelligence","","","","2","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Live Demonstration: Efficient Deep Learning Algorithm for Alzheimer's Disease Diagnosis using Retinal Images","D. Y. Kim; Y. J. Lim; J. H. Park; M. H. Sunwoo","Department of Electrical and Computer Engineering, Ajou University, Suwon, Republic of Korea; Department of Electrical and Computer Engineering, Ajou University, Suwon, Republic of Korea; Department of Electrical and Computer Engineering, Ajou University, Suwon, Republic of Korea; Department of Electrical and Computer Engineering, Ajou University, Suwon, Republic of Korea",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","508","508","This live demonstration presents Alzheimer's Disease (AD) detection using deep learning based smartphone application. The deep learning model is based on MobileNetV3 as a backbone, and an Attention mechanism is applied. However, we modified the backbone structure into U-Net-like architecture to perform better. Furthermore, we modified the conventional Attention mechanism to the Weighted Attention mechanism. The masking-adding process has been applied in the training method of the model.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869957","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869957","Deep Learning;Algorithm;Alzheimer's Disease;Diagnosis;Edge Devices;Neural Network","Deep learning;Training;Circuits and systems;Retina;Medical diagnosis;Alzheimer's disease;Integrated circuit modeling","","1","","4","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Spiking Neural Network based Real-time Radar Gesture Recognition Live Demonstration","J. Huang; P. Gerhards; F. Kreutz; B. Vogginger; F. Kelber; D. Scholz; K. Knobloch; C. G. Mayr",Infineon Technologies Dresden; Infineon Technologies Dresden; Infineon Technologies Dresden; Technische Universität Dresden; Technische Universität Dresden; Infineon Technologies Dresden; Infineon Technologies Dresden; Technische Universität Dresden,2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","500","500","This live demo aims at continuously real-time classifying radar gesture signals from the real world with the neuromorphic hardware SpiNNaker 2 prototype to play the game. With the 10 MHz operation frequency on SpiNNaker 2 FPGA, the closed-loop setup realizes around 35 ms delay from PC sending input data to receiving classification output, and there is nearly no feeling of apparent delay when testers are playing the game. The energy cost per frame is 3.29 µJ, and the operation cycle is less than 8 k. Even if our current middleware has not considered balanced work loading among different processing cores, the tightly couple memory usage on the heaviest loaded processing element is less than half of the total 128 kB available memory space based on the directly trained gesture recognition spiking neural network (SNN) model with 2048 input neurons, 5 hidden neurons, and 4 classification outputs.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869943","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869943","real-time;gesture recognition;SpiNNaker 2;spiking neural network;radar","Neuromorphics;Neurons;Memory management;Prototypes;Radar;Gesture recognition;Games","","1","","5","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"A DNN Training Processor for Robust Object Detection with Real-World Environmental Adaptation","D. Han; D. Im; G. Park; Y. Kim; S. Song; J. Lee; H. -J. Yoo","School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","501","501","This demonstration is related to the submitted paper, “A 0.95 mJ/frame DNN Training Processor for Robust Object Detection with Real-World Environmental Adaptation”, (Submission ID: 45). Lightweight DNN is essential for energy-efficient DNN execution in mobile/edge devices. However, it suffers from significant accuracy degradation when it is applied to the new environment. In other words, the lightweight DNN loses generality due to its low network capacity. In particular, the mobile-oriented DNNs do not work properly in unexpected situations such as camera malfunction as shown in Fig. 1. Therefore, accuracy compensation for unpredictable accidents is important to prevent critical system damage. Real-time online DNN tuning is a promising solution to compensate accuracy of the lightweight network while maintaining its hardware benefits. In this demonstration, we demonstrate online tuning-based lightweight object detection execution based on our proposed processor and systems. The proposed processor successfully demonstrates 46.6 FPS object detection with 0.95 mJ/frame energy consumption which is the state-of-the-art performance compared with the existing processors.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869954","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869954","","Training;Degradation;Energy consumption;Circuits and systems;Object detection;Cameras;Real-time systems","","2","","0","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"A 181µW Real-Time 3-D Hand-Gesture Recognition System for Edge Applications","Y. Lu; Z. Li; X. Zhang; T. T. -H. Kim","Centre for Integrated Circuits and Systems, School of Electrical and Electronic Engineering Nanyang Technological University, Singapore; Centre for Integrated Circuits and Systems, School of Electrical and Electronic Engineering Nanyang Technological University, Singapore; Centre for Integrated Circuits and Systems, School of Electrical and Electronic Engineering Nanyang Technological University, Singapore; Centre for Integrated Circuits and Systems, School of Electrical and Electronic Engineering Nanyang Technological University, Singapore",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","502","502","This demonstration presents an ultra-low-power real-time 3-D hand gesture recognition system for edge scenarios. The rotation-resistant features are extracted through bi-directional convolution, and the gestures are classified based on an iteration-free feature clustering scheme. The computing-intensive units for gesture recognition are adaptively gated according to the input data patterns for power saving. The proposed system can recognize 9 static and 20 dynamic hand gestures with an average accuracy of 94.4% and 98.6%, respectively. Besides, it can track the fingertips in real-time. The measurement result shows the prototype chip achieves the lowest power of 181 µW at 0.6 V and 25 MHz.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869899","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869899","low-power;high accuracy;3-D hand gesture recognition","Semiconductor device measurement;Power measurement;Convolution;Circuits and systems;Prototypes;Gesture recognition;Bidirectional control","","","","3","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Live Demonstration: Home Appliance Control System with Dynamic Hand Gesture Recognition base on 3D Hand Skeletons","T. -H. Tsai; Y. -J. Luo; W. -C. Wan","Department of Electrical Engineering National Central University City, Taoyuan, Taiwan; Department of Electrical Engineering National Central University City, Taoyuan, Taiwan; Department of Electrical Engineering National Central University City, Taoyuan, Taiwan",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","503","503","In this paper, we present a two-stage lightweight convolutional neural network architecture on hand gesture recognition for home appliance control system. At the first stage, we utilize DetNet to detect the hand and generate 3D hand skeleton locations. At the second stage, a skeleton-based dynamic hand gesture recognition model is developed. We have 99.4% accuracy by the trained CNN model with our testing dataset. Besides, we implement this system on the Nvidia Jetson AGX Xavier to control the on/off of the fan and the light and the overall system achieve 15 fps.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9870006","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9870006","dynamic hand gesture recognition;convolutional neural networks;skeleton;home appliance application","Home appliances;Fans;Three-dimensional displays;Circuits and systems;Gesture recognition;Control systems;Skeleton","","4","","1","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"An Edge-Optimized Incremental Learning Algorithm For Audio Classification","T. -H. Tsai; M. A. Hussain; C. -L. Lee","Department of Electrical Engineering, National Central University, Taoyuan City, Taiwan; Department of Electrical Engineering, National Central University, Taoyuan City, Taiwan; Department of Electrical Engineering, National Central University, Taoyuan City, Taiwan",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","504","504","In the proposed demo, we would like to show the incremental learning for audio classification using an embedded system. Figure 1 shows the overview of the data processing based on our proposed incremental learning algorithm. The proposed incremental learning algorithm can increase the capability of DNN model to classify new audio sounds which are not included in the base model. In the proposed system, the audio data is gathered at the edge device, and DNN model is trained using our proposed algorithm to learn about the new classes while retaining the knowledge about previous classes as well.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869939","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869939","","Embedded systems;Circuits and systems;Learning (artificial intelligence);Data processing;Data models;Classification algorithms;Integrated circuit modeling","","1","","0","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Deep Learning-based Real-time Segmentation for Edge Computing Devices","J. Kwak; H. Yu; Y. Cho; S. Kang; J. Cho; J. -Y. Park; J. -W. Lee","Department of Electronic Engineering, Sogang University, Seoul, Korea; Department of Electronic Engineering, Sogang University, Seoul, Korea; Department of Electronic Engineering, Sogang University, Seoul, Korea; Department of Electronic Engineering, Sogang University, Seoul, Korea; LX Semicon, Seoul, Korea; LX Semicon, Seoul, Korea; LX Semicon, Seoul, Korea",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","1","1","Recently, due to the rapid improvement of artificial intelligence technology, numerous studies are considered to solve various problems using deep learning. Typical deep neural networks for semantic segmentation require the high computation with a large capacity to extract abundant amounts of contextual information for accurate prediction. Our live demonstration will show real-time semantic segmentation operation on an NVIDIA Jetson-Xavier board with the BiSeNet-based method compressed using a novel knowledge distillation method.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869967","National Research Foundation of Korea (NRF); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869967","deep learning;semantic segmentation;real-time processing","Deep learning;Circuits and systems;Semantics;Neural networks;Real-time systems;Data mining;Artificial intelligence","","","","2","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Fast DNN-based Mechatronics Prototyping Platform on Robotic Arm Control","Y. -C. Chung; H. -H. Lian; Y. -L. Xiao; C. -T. Huang; J. -J. Liou","National Tsing Hua University, Hsinchu, Taiwan; National Tsing Hua University, Hsinchu, Taiwan; National Tsing Hua University, Hsinchu, Taiwan; National Tsing Hua University, Hsinchu, Taiwan; National Tsing Hua University, Hsinchu, Taiwan",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","506","506","In industrial applications, a robotic controller re-quires a low-latency computation process for real-time con-straints. In the meantime, more controllers are designed with DNN-based reinforcement learning, which needs increasing computation power. In this demo, we developed a fast prototyping infrastructure in AI -based mechatronics. Our software/hardware co-optimization incorporates a cyber-physical system (CPS), a host computer, and a DNN-based accelerator on an FPGA. The holistic accelerator is built upon the ESP SoC (System-on-Chip) platform with the high-level synthesis (HLS) technique and an improved interface. Our demonstration on an intelligent robotic arm showcases 101 times speedup over a CPU-based software implementation.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869932","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869932","","Mechatronics;Service robots;Process control;Reinforcement learning;Manipulators;Software;Real-time systems","","1","","2","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Live Demo: Memory-Efficient Hardware Design for a Real-Time Convolutional Encoder-Decoder Network","M. -W. Jeong; C. -Y. Shin; C. E. Rhee","Department of Electrical and Computer Engineering, Inha University, Incheon, Korea; Department of Electrical and Computer Engineering, Inha University, Incheon, Korea; Department of Electrical and Computer Engineering, Inha University, Incheon, Korea",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","507","507","This work presents a FPGA-based convolutional-neural-network (CNN)-based encoder-decoder accelerator for interpolation of high-resolution images. The baseline model is DVF [1]. The proposed system is demonstrated on Virtex UltraScale+ HBM VCU128 evaluation kit.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9870020","National Research Foundation of Korea; Ministry of Science, ICT & Future Planning(grant numbers:NRF-2021R1A2C2008946); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9870020","","Interpolation;Circuits and systems;Real-time systems;Hardware;Integrated circuit modeling;Artificial intelligence","","1","","1","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"MemSE: Fast MSE Prediction for Noisy Memristor-Based DNN Accelerators","J. Kern; S. Henwood; G. Mordido; E. Dupraz; A. Aïssa-El-Bey; Y. Savaria; F. Leduc-Primeau","Department of Electrical Engineering, Poly technique Montreal, Montreal, QC, Canada; Department of Electrical Engineering, Poly technique Montreal, Montreal, QC, Canada; Department of Electrical Engineering, Poly technique Montreal, Montreal, QC, Canada; Lab-STICC, IMT Atlantique, CNRS UMR 6285, Brest, France; Lab-STICC, IMT Atlantique, CNRS UMR 6285, Brest, France; Department of Electrical Engineering, Poly technique Montreal, Montreal, QC, Canada; Department of Electrical Engineering, Poly technique Montreal, Montreal, QC, Canada",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","62","65","Memristors enable the computation of matrix-vector multiplications (MVM) in memory and, therefore, show great potential in highly increasing the energy efficiency of deep neural network (DNN) inference accelerators. However, computations in memristors suffer from hardware non-idealities and are subject to different sources of noise that may negatively impact system performance. In this work, we theoretically analyze the mean squared error of DNNs that use memristor crossbars to compute MVM. We take into account both the quantization noise, due to the necessity of reducing the DNN model size, and the programming noise, stemming from the variability during the programming of the memristance value. Simulations on pre-trained DNN models showcase the accuracy of the analytical prediction. Furthermore the proposed method is almost two order of magnitude faster than Monte-Carlo simulation, thus making it possible to optimize the implementation parameters to achieve minimal error for a given power constraint.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869978","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869978","","Analytical models;Quantization (signal);Computational modeling;System performance;Memristors;Programming;Predictive models","","2","","14","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"TAC-RAM: A 65nm 4Kb SRAM Computing-in-Memory Design with 57.55 TOPS/W supporting Multibit Matrix-Vector Multiplication for Binarized Neural Network","X. Wang; X. Liu; X. Hu; X. Zhong; X. Chen; Y. Liu; P. Kong; F. Tian; C. Tsui",The Hong Kong University of Science and Technology; The AI Chip Center for Emerging Smart Systems; The AI Chip Center for Emerging Smart Systems; The Hong Kong University of Science and Technology; The Hong Kong University of Science and Technology; The AI Chip Center for Emerging Smart Systems; The AI Chip Center for Emerging Smart Systems; The Hong Kong University of Science and Technology; The Hong Kong University of Science and Technology,2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","66","69","In this paper, an energy-efficient computing-in-memory architecture using 10T-SRAM cells is proposed to resolve the design challenges of mixed-signal Computing-in-memory (CIM) schemes. A time-assisted current-based (TAC-based) MAC and ADC mechanism is developed to maintain good linearity throughout the multiplication and AD conversion process. A binary-search discharge-based ADC (DB-ADC) ensures high energy efficiency and throughput in high precision mixed-signal computations. A 4Kb SRAM array is fabricated in TSMC 65nm CMOS process and measurement results show that a throughput of 24.1 GOPS and a peak energy efficiency of 57.55 TOPS/W are achieved with multi-bit MAC operation for 4-bit input, 1-bit binarized weight, and 11-bit signed output.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869970","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869970","Analog computing;Energy-efficient SRAM;Convolutional neural networks (CNNs);Dot-product;Edge-computing;In-memory computation","Weight measurement;Semiconductor device measurement;Neural networks;Energy resolution;Random access memory;Linearity;Computer architecture","","2","","9","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"DualPIM: A Dual-Precision and Low-Power CNN Inference Engine Using SRAM- and eDRAM-based Processing-in-Memory Arrays","S. Jung; J. Lee; H. Noh; J. -H. Yoon; J. Kung","Department of EECS, DGIST, Daegu, Republic of Korea; Department of EECS, DGIST, Daegu, Republic of Korea; Department of EECS, DGIST, Daegu, Republic of Korea; Department of EECS, DGIST, Daegu, Republic of Korea; Department of EECS, DGIST, Daegu, Republic of Korea",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","70","73","Recently, machine learning community has focused on developing deep learning models that are not only accurate but also efficient to deploy them on resource-limited devices. One popular approach to improve the model efficiency is to aggressively quantize both features and weight parameters. However, the quantization generally entails accuracy degradation thus additional compensation techniques are required. In this work, we present a novel network architecture, named DualNet, that leverages two separate bit-precision paths to effectively achieve high accuracy and low model complexity. On top of this new network architecture, we propose to utilize both SRAM-and eDRAM-based processing-in-memory (PIM) arrays, named DualPIM, to run each computing path in a DualNet at a dedicated PIM array. As a result, the proposed DualNet significantly reduces the energy consumption by 81% on average compared to other quantized neural networks (i.e., 4-bit and ternary), while achieving 1.3 % higher accuracy on average.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869905","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869905","convolutional neural networks;deep learning;processing-in-memory;quantized neural networks","Energy consumption;Quantization (signal);Neural networks;Random access memory;Parallel processing;Network architecture;Energy efficiency","","3","","11","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"BiMDiM: Area efficient Bi-directional MRAM Digital in-Memory Computing","D. Kim; Y. Jang; T. Kim; J. Park","School of Electrical Engineering, Korea University, Seoul, Korea; School of Electrical Engineering, Korea University, Seoul, Korea; School of Electrical Engineering, Korea University, Seoul, Korea; School of Electrical Engineering, Korea University, Seoul, Korea",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","74","77","Spin transfer torque MRAM (STT-MRAM) based digital in-memory computing (IMC) has been recently proposed for energy efficient processing of convolutional neural network (CNN). The conventional MRAM based IMC architecture suffers from excessive storage area since a large number of intermediate sum and carry bits should be stored for the following successive additions during multiply-accumulate (MAC) operations. In this paper, we propose an area efficient bi-directional MRAM digital IMC (BiMDiM) scheme, where the size of memory cells storing the intermediate sums and carries can be efficiently reduced by repetitively using the same memory cells during MAC operations. In addition, to reduce the number of inefficient half-additions, which can process only two inputs with almost same hardware cost, the addition re-scheduling is also presented to further improve the energy and latency of BiMDiM. The proposed BiMDiM architecture has been simulated using 28nm CMOS process. When compared to the baseline architecture, the proposed BiMDiM improves area efficiency up to 53%.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869915","National R&D Program through the National Research Foundation of Korea; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869915","Convolutional neural network (CNN);Spin Transfer Torque magnetic random access memory (STT-MRAM);digital in memory computing (digital IMC);Memory area","Torque;Costs;Energy resolution;Random access memory;Bidirectional control;In-memory computing;Energy efficiency","","4","","7","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"T-EAP: Trainable Energy-Aware Pruning for NVM-based Computing-in-Memory Architecture","C. -Y. Chang; Y. -C. Chuang; K. -C. Chou; A. -Y. Wu","Graduate Institute of Electronics Engineering, National Taiwan University, Taipei, Taiwan; Graduate Institute of Electronics Engineering, National Taiwan University, Taipei, Taiwan; Graduate Institute of Electronics Engineering, National Taiwan University, Taipei, Taiwan; Graduate Institute of Electronics Engineering, National Taiwan University, Taipei, Taiwan",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","78","81","While convolutional neural networks (CNNs) are desired for outstanding performance in many applications, the energy consumption for inference becomes enormous. Computing-in-memory architecture based on embedded nonvolatile memory (NVM-CIM) has emerged to improve CNNs' energy efficiency. Recently, NVM crossbar-aware pruning has been extensively studied. However, directly incorporating energy estimation during sparse learning has not been well explored. In this paper, for the first time, we propose T-EAP, a trainable energy-aware pruning method to close the gap between pruning policy and energy optimization for NVM-CIM. Specifically, T-EAP improves the energy-accuracy trade-off by removing redundant weight groups that consume significant energy. Moreover, the trainable thresholds enable end-to-end sparse learning without a laborious train-prune-retrain process. Experimental results based on NeuroSim, which is a circuit-level simulator for CIM systems, show that compared with prior work, T-EAP maintains the accuracy while reducing energy consumption by up to 26.5% and 22.7% for VGG-8 and ResNet-20, respectively. We also provide a layer-wise analysis for energy savings to validate the effectiveness of T-EAP.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869849","Ministry of Science and Technology of Taiwan(grant numbers:110-2218-E-002-034-MBK); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869849","Computing-in-memory;embedded nonvolatile memory;deep learning accelerator;energy consumption;pruning","Energy consumption;Mars;Nonvolatile memory;Circuits and systems;Estimation;Computer architecture;Learning (artificial intelligence)","","4","","16","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"A Hybrid Spiking Recurrent Neural Network on Hardware for Efficient Emotion Recognition","C. Zou; X. Cui; Y. Kuang; Y. Wang; X. Wang","Key Laboratory of Microelectronics Devices and Circuits, School of Integrated Circuits, Peking University, Beijing, China; Key Laboratory of Microelectronics Devices and Circuits, School of Integrated Circuits, Peking University, Beijing, China; Key Laboratory of Microelectronics Devices and Circuits, School of Integrated Circuits, Peking University, Beijing, China; Key Laboratory of Microelectronics Devices and Circuits, School of Integrated Circuits, Peking University, Beijing, China; Key Laboratory of Integrated Microsystem, School of ECE, Peking University Shenzhen Graduate School, Shenzhen, China",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","332","335","In recent years, neuromorphic engineering based on spiking neural networks (SNNs) for real-time and low-power artificial intelligence (AI) tasks has attracted a lot of interest. However, most of the previous implementations on hardware of these algorithms concentrate on traditional feedforward fully-connected/convolutional neural network (CNNs) architectures which are used for vision image processing. Their applications in temporal text tasks using recurrent neural networks (RNNs) is less discussed. In this paper, we point out main difficulties of RNNs implementation on conventional neuromorphic systems and propose a hardware-oriented spiking RNN architecture for emotion recognition, which absorbs the external dynamics of traditional RNN and internal dynamics of SNN. Experimental results on two emotion recognition datasets show our spiking RNNs achieve comparable accuracies with other deep learning models and efficient run-time performance.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869950","111 Project(grant numbers:B18001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869950","AI;RNN;SNN;emotion recognition","Deep learning;Emotion recognition;Recurrent neural networks;Target recognition;Neuromorphic engineering;Hardware;Real-time systems","","3","","18","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"AI driven Wide Dynamic Range CMOS Image Sensor","W. Kisku; M. Bhushan; A. Kaur; D. Mishra","Department of Electrical Engineering, Indian Institute of Technology Jodhpur, Jodhpur, India; Department of Electrical Engineering, Indian Institute of Technology Jodhpur, Jodhpur, India; Department of Electrical Engineering, Indian Institute of Technology Jodhpur, Jodhpur, India; Department of Computer Science and Engineering, Indian Institute of Technology Jodhpur, Jodhpur, India",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","366","370","This work proposes the implementation of a wide dynamic range CMOS image sensors using on-chip DNN. A given pixel is read in the linear mode under low light illumination and in logarithmic mode under high light where the mode of operation of pixel is decided using comparator. The compressive nature of logarithmic pixel is leveraged using amplifier to enhance the dynamic range. To further enhance the dynamic range, three hardware efficient DNN models, SiDCNet, SiDCNet (inr.) and SiDCNet (fire), are implemented and compared. On an average, the PSNR and SSIM of 31.17 dB and 0.95, respectively, is observed on standard test images. A comparison between post DNN inference is drawn with the linear-logarithmic acquisition, resulting an increase in image quality of 8.5 dB and 0.14 in terms of PSNR and SSIM.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9870003","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9870003","Linear-Logarithmic (Lin-Log) Pixel;High Dy-namic Range;CMOS Image Sensor;Re-configurable Readout;Deep Learning;Convolutional Neural Networks","Image quality;Semiconductor device modeling;Neural networks;Dynamic range;CMOS image sensors;Hardware;System-on-chip","","","","19","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"SENeCA: Scalable Energy-efficient Neuromorphic Computer Architecture","A. Yousefzadeh; G. -J. van Schaik; M. Tahghighi; P. Detterer; S. Traferro; M. Hijdra; J. Stuijt; F. Corradi; M. Sifalakis; M. Konijnenburg","IMEC, Eindhoven, The Netherlands; IMEC, Eindhoven, The Netherlands; IMEC, Eindhoven, The Netherlands; IMEC, Eindhoven, The Netherlands; IMEC, Eindhoven, The Netherlands; IMEC, Eindhoven, The Netherlands; IMEC, Eindhoven, The Netherlands; IMEC, Eindhoven, The Netherlands; IMEC, Eindhoven, The Netherlands; IMEC, Eindhoven, The Netherlands",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","371","374","SENeCA is our first RISC-V-based digital neuromorphic processor to accelerate bio-inspired Spiking Neural Networks for extreme edge applications inside or near sensors where ultra-low power and adaptivity features are required. SENeCA is optimized to exploit unstructured spatio-temporal sparsity in computations and data transfer. It is a digital IP, contains interconnected Neuron Cluster Cores, with RISC-V-based instruction set, an optimized Neuromorphic Co-Processor, and event-based communication infrastructure. SENeCA improves state of the art by: Addressing the flexibility issue in neuromorphic processors by allowing a fully programmable neuron model and learning/adaptivity algorithms; Improving the area efficiency by employing a 3-level memory hierarchy which allows using novel embedded memory technologies; Efficient deployment of advanced learning mechanisms and optimization algorithms by accelerating neural operations in three data types: int4, int8 and BrainFloat16; Efficient event communication by using a new Network-on-Chip with multicasting, a compression mechanism, and source-based routing. The implemented digital IP can be tuned for different applications to have a flexible number of cores and Neural Processing Elements (NPEs) per core and optional use of off-chip memory. Next to the hardware, the SENeCA platform includes an SDK and a hardware-aware simulator for close-loop synthesis/mapping optimization11The SENeCA platform is freely accessible for the academic purposes. .","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9870025","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9870025","","Multicast algorithms;Neuromorphics;Memory management;Neurons;Neural networks;Network-on-chip;Sensor phenomena and characterization","","11","","12","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Analog LSTM for Keyword Spotting","K. Odame; M. Nyamukuru","Dartmouth College, Hanover, NH; Dartmouth College, Hanover, NH",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","375","378","In this paper, we present a novel analog application-specific integrated circuit (ASIC) architecture for edge artificial intelligence. Our novel architecture is a power efficient long short-term memory, which is a deep learning neural network that is especially suited for processing time-series sensor data. Evaluated on a 10-class keyword spotting machine learning task, our neural network achieves a classification accuracy of 91 %, with a model size of 2264 parameters and estimated power consumption of 0.76 µW","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869922","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869922","","Integrated circuits;Deep learning;Power demand;Circuits and systems;Neural networks;Memory management;Task analysis","","3","","19","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Neuromorphic Event-Based Spatio-temporal Attention using Adaptive Mechanisms","A. Gruel; A. Vitale; J. Martinet; M. Magno","I3S / CNRS, Université Côte d'Azur, Sophia Antipolis, France; PBL Center ETH Zürich, Zürich, Switzerland; I3S / CNRS, Université Côte d'Azur, Sophia Antipolis, France; PBL Center ETH Zürich, Zürich, Switzerland",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","379","382","Contrary to RGB cameras, Dynamic Vision Sensor (DVS) output visual data in the form of an asynchronous events stream by recording pixel-wise luminance changes at microsecond resolution. While conventional computer vision approaches utilise frame-based input data, thus failing to take full advantage of the high temporal resolution, novel approaches use spiking neural networks Spiking Neural Networks (SNNs) which are more compatible to handle event-based data since these bio-inspired neural models intrinsically encode information in a sparse manner using activation spikes trains. This paper presents an attentional mechanism which detects regions with higher event density by using inherent SNN dynamics combined with online weight and threshold adaptation. We implemented the network directly on Intel's research neuromorphic chip Loihi and evaluate our proposed method on the open DVS128 Gesture Dataset. Our system is able to process 1 ms of event-data in 6 ms and reject more than 50% of incoming unwanted events occurring only 20 ms after activity onset.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869977","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869977","Event-Based Vision;Online Adaptation;Neuro-morphic Hardware;Spiking Neural Networks","Adaptation models;Visualization;Neuromorphics;Neural networks;Vision sensors;Real-time systems;Recording","","11","","14","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"MARSv2: Multicore and Programmable Reconstruction Architecture SRAM CIM-Based Accelerator with Lightweight Network","C. -Y. Hsieh; S. -T. Lin; Z. Li; C. -C. Lu; M. -F. Chang; K. -T. Tang","Department of Electrical Engineering, National Tsing Hua University, Hsinchu, Taiwan; Department of Electrical Engineering, National Tsing Hua University, Hsinchu, Taiwan; Department of Electrical Engineering, National Tsing Hua University, Hsinchu, Taiwan; Information and Communication Labs Industrial Technology Research Institute, Hsinchu, Taiwan; Department of Electrical Engineering, National Tsing Hua University, Hsinchu, Taiwan; Department of Electrical Engineering, National Tsing Hua University, Hsinchu, Taiwan",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","383","386","Computing-in-memory (CIM) systems reduce the degree of large-scale data movement by performing computation on the memory; this avoids a von Neumann bottleneck. Because of its low-power characteristic, CIM has demonstrated great potential for increasing the energy efficiency of edge devices. This paper presents a multicore and programmable reconstruction architecture using static random-access memory (SRAM) CIM-based accelerator with lightweight network. The proposed architecture uses SRAM CIM macro as the processing element, supporting sparse convolutional neural network computing. This architecture achieves 15.16 TOPS/W system energy efficiency and 747.6 GOPS on the CIFAR10 data set.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9870005","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9870005","computing-in-memory;deep learning;sparsity;CNN accelerator","Performance evaluation;Multicore processing;Convolution;Circuits and systems;Pipelines;Random access memory;Computer architecture","","1","","8","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Efficient Hardware Implementation for Online Local Learning in Spiking Neural Networks","W. Guo; M. E. Fouda; A. M. Eltawil; K. N. Salama","Department of ECE, CEMSE Division, King Abdullah University of Science and Technology, Saudi Arabia; Center for Embedded & Cyber-physical Systems, University of California-Irvine, Irvine, CA, USA; Department of ECE, CEMSE Division, King Abdullah University of Science and Technology, Saudi Arabia; Department of ECE, CEMSE Division, King Abdullah University of Science and Technology, Saudi Arabia",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","387","390","Local learning schemes have shown promising performance in spiking neural networks and are considered as a step towards more biologically plausible learning. Despite many efforts to design high-performance neuromorphic systems, a fast and efficient neuromorphic hardware system is still missing. This work proposes a scalable, fast, and efficient spiking neuromorphic hardware system with on-chip local learning capability that can achieve competitive classification accuracy. We introduce an effective hardware-friendly local training algorithm that is compatible with sparse temporal input coding and binary random classification weights. The algorithm is demonstrated to deliver competitive accuracy. The proposed digital system explores spike sparsity in communication, parallelism in vector-matrix operations, and locality of training errors, which leads to low cost and fast training speed. Taking into consideration energy, speed, resource, and accuracy, our design shows 7.7× efficiency over a recent spiking direct feedback alignment method and 2.7× efficiency over the spike-timing-dependent plasticity method.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869946","King Abdullah University of Science and Technology (KAUST); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869946","Neuromorphic computing;spiking neural networks;local training;deep learning;backpropagation","Training;Neuromorphics;Digital systems;Neural networks;Learning (artificial intelligence);Parallel processing;Hardware","","2","","19","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"FPGA Accelerator for Radar-Based Human Activity Recognition","K. Long; C. Rao; X. Zhang; W. Ye; X. Lou","School of Information Science and Technology, ShanghaiTech University, Shanghai, China; School of Information Science and Technology, ShanghaiTech University, Shanghai, China; School of Information Science and Technology, ShanghaiTech University, Shanghai, China; College of Electrical Science and Technology, Shenzhen University, Shenzhen, China; School of Information Science and Technology, ShanghaiTech University, Shanghai, China",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","391","394","Deep learning is enabling radar-based human activity recognition (HAR) to be used in various application scenarios. In many applications, HAR systems need to be implemented in edge devices with the requirement of real-time processing. This paper presents a high-performance and energy efficient FPGA accelerator for radar-based HAR. The accelerator implements the state-of-the-art Mobile RadarNet algorithm to deliver high precision recognition of human activities. Specific architecture with optimized data is proposed to improve the overall computation efficiency. The accelerator is implemented in a field programmable gate array (FPGA)-based system on chip (SoC) platform. Experimental results show that the overall performance in terms of processing speed and energy efficiency is significantly improved without affecting the recognition accuracy.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869908","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869908","human activity recognition (HAR);radar;convolutional neural network (CNN);edge computing","Deep learning;Quantization (signal);Neural networks;Computer architecture;Logic gates;Energy efficiency;Real-time systems","","2","","15","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"A Winograd-Based Highly-Parallel Convolution Engine for 8-bit CNN Acceleration","Y. -T. Chen; Y. -F. Ou; C. -T. Huang","Department of Electrical Engineering, National Tsing Hua University, Hsinchu, Taiwan; Department of Electrical Engineering, National Tsing Hua University, Hsinchu, Taiwan; Department of Electrical Engineering, National Tsing Hua University, Hsinchu, Taiwan",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","395","398","Convolutional neural network (CNN) accelerators for computational imaging typically use 8-bit fixed-point models for efficient computation, but the convolution engine still dominates the chip area. Quantizing models in lower bitwidths can cut down resource demand effectively, but it results in a significant loss of output quality. Another approach to reducing computational complexity is through Winograd convolution which lessens the demand for logic gates without diminishing model quality. Nevertheless, the resource reduction ratio of Winograd convolution declines with input bitwidths, and it needs even more gates than direct convolution at 8-bit. In this paper, we realize an area-efficient convolution engine for 8-bit computational imaging models by considering Winograd convolution and quantization jointly. First, we elaborate hardware sharing techniques for highly-parallel Winograd convolution. Then we propose an un-even scheme for Winograd-domain quantization that yields only up to 0.16 dB of PSNR drop on computational imaging models. Finally, we implement a highly-parallel Winograd convolution engine for 8-bit CNN inference. Synthesized with TSMC 40nm technology, the engine uses 2.17M of logic gates for delivering 5.12 TOPS of inference capability, saving 29.5% and 41.1 % of logic gates compared to a direct convolution engine and a naïve Winograd implementation respectively. On modified FFDNet and EDSR baselines, it achieves up to Full HD 20 fps with merely 0.09 dB of PSNR drop on average.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869911","MOST(grant numbers:109-2622-8-007-022); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869911","Winograd convolution;highly-parallel;computational imaging;CNN;quantization","Quantization (signal);Convolution;Computational modeling;Imaging;Logic gates;Hardware;Computational efficiency","","3","","15","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Row-wise Accelerator for Vision Transformer","H. -Y. Wang; T. -S. Chang","Institute of Electronics, National Yang Ming Chiao Tung University, Hsinchu, Taiwan; Institute of Electronics, National Yang Ming Chiao Tung University, Hsinchu, Taiwan",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","399","402","Following the success of the natural language processing, the transformer for vision applications has attracted significant attention in recent years due to its excellent performance. However, existing deep learning hardware accelerators for vision cannot execute this structure efficiently due to significant model architecture differences. As a result, this paper proposes the hardware accelerator for vision transformers with row-wise scheduling, which decomposes major operations in vision transformers as a single dot product primitive for a unified and efficient execution. Furthermore, by sharing weights in columns, we can reuse the data and reduce the usage of memory. The implementation with TSMC 40nm CMOS technology only requires 262K gate count and 149KB SRAM buffer for 403.2 GOPS throughput at 600MHz clock frequency.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869928","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869928","vision transformer;hardware design;accelerators","Deep learning;Machine vision;Random access memory;Logic gates;Transformers;Throughput;Natural language processing","","13","","17","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"A Real-Time Sparsity-Aware 3D-CNN Processor for Mobile Hand Gesture Recognition","S. Kim; J. Jung; W. Jang; H. Jeong; K. Lee","Graduate School of Artificial Inteligence, UNIST, Ulsan, Repulic of Korea; Department of Electrical Engineering, UNIST, Ulsan, Repulic of Korea; Graduate School of Artificial Inteligence, UNIST, Ulsan, Repulic of Korea; Department of Electrical Engineering, UNIST, Ulsan, Repulic of Korea; Dept. of EE, Graduate School of AI, UNIST, Ulsan, Repulic of Korea",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","403","406","A sparsity-aware 3D convolution neural network (CNN) accelerator is proposed for the real-time mobile hand gesture recognition (HGR) system. The complex computation of 3D convolution with the video data makes it difficult for real-time operation, especially in the resource-constrained mobile platform. To facilitate real-time implementation of HGR, this paper proposes two key features: 1) the inter-frame differential aware input method and IDANet to reduce the MAC operation and the external bandwidth by 84 % and 95.2 %, respectively, and achieve 79.97% accuracy on NvGesture dataset; 2) a low-latency 3D-CNN accelerator that utilizes activation and weight sparsity, achieving 31× faster inference latency than the state-of-the-art. The proposed processor is designed in 65 nm CMOS technology. It consumes 262 mW of power and achieves 599 GOPS/W of energy efficiency. As a result, the system realized 1.584 ms inference latency for real-time HGR in a mobile platform.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869929","Samsung Electronics; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869929","3D-CNN;hand gesture recognition processor;VLSI","Three-dimensional displays;Convolution;Neural networks;Gesture recognition;Bandwidth;Streaming media;Real-time systems","","","","15","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"An Adaptive High-Performance Quantization Approach for Resource-Constrained CNN Inference","H. -H. Chin; R. -S. Tsay; H. -I. Wu","Department of Computer Science, National Tsing-Hua University, Hsinchu, Taiwan; Department of Computer Science, National Tsing-Hua University, Hsinchu, Taiwan; Department of Computer Science, National Tsing-Hua University, Hsinchu, Taiwan",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","336","339","Recent convolutional neural network (CNN) development continues to advance the state-of-the-art model accuracy for various applications. However, the enhanced accuracy comes at the cost of substantial memory bandwidth and storage requirements and demanding computational resources. Although in the past the quantization methods have effectively reduced the deployment cost for edge devices, it suffers from significant information loss when processing the biased activations of contemporary CNNs. In this paper, we hence introduce an adaptive high-performance quantization method to resolve the issue of biased activation by dynamically adjusting the scaling and shifting factors based on the task loss. Our proposed method has been extensively evaluated on image classification models (ResNet-18/34/50, MobileNet-V2, EfficientNet-B0) with ImageNet dataset and object detection model (YOLO-V4) with COCO dataset. The results show that our 4-bit integer (INT4) quantization models achieve better accuracy than the state-of-the-art 4-bit models, and in some cases, even surpass the golden full-precision models. The final designs have been successfully deployed onto extremely resource-constrained edge devices for many practical applications.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869850","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869850","deep neural network;low bit-width quantization","Adaptation models;Quantization (signal);Costs;Image resolution;Memory management;Object detection;Reduced order systems","","1","","19","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Bin-Specific Quantization in Spectral-Domain Convolutional Neural Network Accelerators","J. Park; J. Lee; G. Kim; H. -M. Bae","School of Electrical Engineering, KAIST, Daejeon, Korea; Department of Electrical Engineering and Computer Science, DGIST, Daegu, Korea; Department of Electrical Engineering and Computer Science, DGIST, Daegu, Korea; School of Electrical Engineering, KAIST, Daejeon, Korea",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","407","410","Spectral-domain convolution engines can effectively reduce the computational complexity of convolution operations. In these engines, however, element-wise multiplications of the spectral representations dominate the multiply and accumulate (MAC) operations. In light of this, we propose bin-specific quantization (BSQ), which is to judiciously allocate varying bit width to each spectral bin in overlap-save. This allows efficient computation of the Hadamard product since the magnitude of the high-frequency components in image features is significantly smaller than that of the low-frequency counterparts. Using the statistics from spectral representations of feature maps, we also delineate methods for properly allocating bit precision to those spectral bins. When BSQ is applied, the average bit precisions of the arithmetic operators in spectral-domain convolvers, without the requirement of network re-training, were lowered by 24 % (AlexNet), 20% (VGG-16), and 22% (ResNet-18) while having no significant reduction (< 1%) on classification accuracy on the ImageNet dataset.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869971","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869971","Acceleration;Approximate Computing;Convolutional Neural Networks;Quantization;Retrain-less","Quantization (signal);Circuits and systems;Convolvers;Computational efficiency;Convolutional neural networks;Computational complexity;Artificial intelligence","","","","7","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Efficient Nonlinear Autoregressive Neural Network Architecture for Real-Time Biomedical Applications","B. Olney; S. Mahmud; R. Karam",University of South Florida; University of South Florida; University of South Florida,2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","411","414","Medical devices, such as continuous glucose monitors (CGMs) and drug-delivery pumps, are often combined in closed-loop systems for treating chronic diseases. Generally, these systems consist of sensors and actuators whose operation is modulated based on sensed stimuli. Closed-loop systems may be susceptible to a number of different security and reliability issues which may result in incorrect operation which may endanger patients. Nonlinear autoregressive neural networks (NARNNs) may be used in such systems for error detection and correction due to their predictive capabilities; however, an efficient implementation is needed for use in wearables and biomedical implants. In this paper, we present an area-and energy-efficient, pipelined NARNN hardware architecture suitable for such constrained devices. The architecture was tested on FPGA to confirm functionality, then synthesized targeting the SAED 32nm EDK. This NARNN implementation requires an estimated area of $0.02 mm^{2},0.54\mu s$ and $0.76 nJ$ per inference.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869935","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869935","","Wearable computers;Computer architecture;Real-time systems;Energy efficiency;Software;Software reliability;Sensors","","4","","12","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Real-Time Low Power Audio Distortion Circuit Modeling: a TinyML Deep Learning Approach","D. Plozza; M. Giordano; M. Magno","Center for Project Based Learning, ETH Zürich, Zürich, Switzerland; Center for Project Based Learning, ETH Zürich, Zürich, Switzerland; Center for Project Based Learning, ETH Zürich, Zürich, Switzerland",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","415","418","This work proposes a combined approach using deep learning and standard signal conditioning to model analog audio distortion circuits in real-time. The proposed model targets low latency and low power resource-constrained processors, and it is based on a quantized neural network. Pre- and post-processing consisting in filtering and dithering has been applied to improve the performance of the proposed optimized model. The model has been compared with a real-time state-of-art model WaveNet3 running on a modern desktop computer, which we used as performance reference. Our proposed model achieves a parameter size reduction of 8.4x and a neural network multiply-accumulation operations reduction of 5.1x with respect to the WaveNet3, while maintaining comparable performance. The model has been optimized and deployed on the novel MAX78000 microcontroller which features an on-board convolutional neural network hardware accelerator. Experimental results show real-time operation with a total latency of less than 10 ms and a power consumption as low as 91.8 mW in active mode, making the system suited for live music performances. Experimental results also demonstrate the capability of the hardware accelerator of the MAX78000 to reach 53.2 multiply-accumulation operations per cycle.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9870024","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9870024","Audio systems;edge computing;artificial neural networks;hardware acceleration;low-power electronics;music","Deep learning;Microcontrollers;Computational modeling;Neural networks;Distortion;Real-time systems;Integrated circuit modeling","","1","","15","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Improving Embedded Target Tracking Systems Based on Siamese Networks with Infrared Images","S. -J. Horng; Y. -J. Zeng","Department of Computer Science and Information Engineering, National Taiwan University of Science and Technology, Taipei, Taiwan; Department of Computer Science and Information Engineering, National Taiwan University of Science and Technology, Taipei, Taiwan",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","419","422","Whether it is for hunting prey, or modern racing, games, or war, how to accurately track the target is the key to the victory. When we can have a machine to help us track the target, we can naturally solve more problems. Not only it can be used in military applications, such as warplane radar and missiles but it can be applied in civilian purposes including home security, event broadcasting, smart home. The target tracking is becoming increasingly mature. In this paper, we aim to develop a practical three-axis target tracking system by simulating the hunting ability of snakes in nature, and we add thermal infrared images to increase the model modality and optimize the ability of existing Siamese tracking network. Multi-Modal Machine Learning (MMML) is modified with the Siamese tracking network into a multi-modal fusion model, so as to improve the model's perception. At the same time, the Siamese networks models for training normal images and thermal infrared images are separated and a pseudo-Siamese network is used as the main framework to process the different the databases. This paper successfully improves the stability and accuracy of the model. With the embedded development version and three-axis servo motor, our system can be more flexible in tracking applications.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869937","Ministry of Science and Technology(grant numbers:110-2221-E-011-125-,110-2218-E-001-006-MBK,111-2218-E-011-011-MBK); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869937","Target tracking;Siamese tracking network;Multi-Modal Machine Learning","Training;Missiles;Target tracking;Machine learning;Smart homes;Radar tracking;Stability analysis","","1","","24","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Hand Gesture Recognition Using IR-UWB Radar with Spiking Neural Networks","S. Wang; Y. Yan; H. Chu; G. Hu; Z. Zhang; Z. Zou; L. Zheng","State Key Laboratory of ASIC and System, School of Information Science and Technology, Fudan University, Shanghai, China; State Key Laboratory of ASIC and System, School of Information Science and Technology, Fudan University, Shanghai, China; State Key Laboratory of ASIC and System, School of Information Science and Technology, Fudan University, Shanghai, China; State Key Laboratory of ASIC and System, School of Information Science and Technology, Fudan University, Shanghai, China; Z-Ai Hour Technology Co., LTD., Hangzhou, China; State Key Laboratory of ASIC and System, School of Information Science and Technology, Fudan University, Shanghai, China; State Key Laboratory of ASIC and System, School of Information Science and Technology, Fudan University, Shanghai, China",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","423","426","Hand gesture recognition has emerged in recent years as a robust method in non-contact human-computer interfaces, especially in the application scenario of the Internet of Things. This paper proposes a high-accuracy and low-power algorithm for hand gesture recognition. The hand gesture dataset was collected by Integrated Systems Lab at ETH Zurich using a low-cost impulse radio ultra-wideband (IR-UWB) radar. The signals are transformed into spikes sequence by time-event coding and level-crossing sampling. These spike arrays are processed by spiking neural networks (SNNs), which have more biological interpretability and are inherently suitable for processing time-series signals. The algorithm has achieved 95.44% accuracy in 5 hand gestures and 96.60% accuracy in 6 hand gestures. As for power consumption, the classification network operates 350 kFLOPs per data sequence on 5 hand gesture datasets, which is 90× smaller than the previous approach.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9870013","National Natural Science Foundation of China(grant numbers:62076066,61876039); Science and Technology Commission of Shanghai Municipality(grant numbers:19511132000,17DZ2260900); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9870013","IR-UWB;SNNs;neuromorphic processing;hand gesture recognition;internet of things;level-crossing sampling","Human computer interaction;Power demand;Neural networks;Gesture recognition;Radar;Parallel processing;Encoding","","","","16","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Real-time Biosignal Recording and Machine-Learning Analysis System","H. Li; J. Wang; S. Zhao; F. Tian; J. Yang; M. Sawan","School of Engineering, Westlake University, Hangzhou, China; School of Engineering, Westlake University, Hangzhou, China; School of Engineering, Westlake University, Hangzhou, China; School of Engineering, Westlake University, Hangzhou, China; School of Engineering, Westlake University, Hangzhou, China; School of Engineering, Westlake University, Hangzhou, China",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","427","430","Biosignal recording and processing systems (BRPSs) are in high demand for numerous applications such as brain-machine interfaces, healthcare, and other clinical applications. However, conventional BRPS can only perform simple operations, such as filtering and denoising, but cannot perform robust machine learning-based analyses in real time. This paper proposes an intelligent BRPS that consists of a signal recording front-end for biosignal acquisition, control and visualization hub, and FPGA board for machine learning acceleration. High-speed Ethernet and PCIe interfaces were used to increase the data transmission rate of the system. Moreover, the integrated accelerator in the FPGA is designed in a single-instruction-multiple-data (SIMD) mode to perform complex machine learning operations in parallel to speed up data-processing tasks. The proposed system is validated for various applications, including EEG-based seizure prediction with a convolutional neural network (CNN), EMG-based gesture recognition with a spiking neural network (SNN), and ECG-based arrhythmia detection with a binary neural network (BNN). Experimental results reveal that this system takes 13 ms to process one-second electrophysiological signals at 512 Hz and 32 channels, thus achieving real-time performance. The proposed BRPS is an open-source and expandable system, and different machine-learning approaches can be configured for diverse applications.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869982","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869982","Signal Processing System;Biosignal;Graphical User Interface;AI accelerator;FPGA;Neural Networks","Noise reduction;Process control;Machine learning;Medical services;Real-time systems;Recording;Convolutional neural networks","","6","","11","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"An Attention-based Neural Network on Multiple Speaker Diarization","S. W. Cheng; K. J. Hung; H. C. Chang; Y. C. Liao","National Yang Ming Chiao, Tung University, Hsinchu, Taiwan; National Yang Ming Chiao, Tung University, Hsinchu, Taiwan; National Yang Ming Chiao, Tung University, Hsinchu, Taiwan; National Yang Ming Chiao, Tung University, Hsinchu, Taiwan",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","431","434","Speaker diarization is a task to label audio or video recordings with classes that correspond to speaker identity for each point in time, which can be used in a multi-speaker conversation environment, such as a meeting or interview. Moreover, speaker diarization can be used to improve the performance of auto speech recognition. This paper presents an end-to-end diarization model based on an attention mechanism with data augmentation, several data pre-processing, and post-processing. In the CALLHOME data set, the case of two speakers reached a 9.12% diarization error rate. We combine the speaker diarization model, and auto speech recognition model and implement the transcript conversion system on an edge device. By using proposed speaker diarization as preprocessing to segment recording according to different speakers, then get the transcript of each segmented utterance by ASR model to fulfill the transcript conversion on the edge device. Experiment shows that our model also performs well in the scenario with two people on edge devices with both accuracy and inference time.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9870007","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9870007","Speaker Diarization;End-to-end Diarization Model;Attention Mechanism;Transcript Conversion","Training;Performance evaluation;Filter banks;Speech recognition;Oral communication;Feature extraction;Transformers","","1","","10","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Disparity Estimation using Light Ray Pair in Stacked 3D Light Field","H. Jung; H. -J. Lee; C. E. Rhee","Dept. of Electrical and Computer Engineering, Seoul National University, Seoul, Republic of Korea; Dept. of Electrical and Computer Engineering, Seoul National University, Seoul, Republic of Korea; Dept. of Information and Communication Engineering, Inha University, Incheon, Republic of Korea",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","435","438","Light field (LF) is a concept that defines a number of light rays passing through free space, and creates novel views and estimates three-dimensional (3D) information by combining some of the light rays. Among them, the stacked 3D LF is a structure made by stacking several 3D LFs, and it supports free viewpoint movements over a wide range. However, 3D LF is a relatively simple structure and its use is limited due to insufficient vertical light rays. This paper proposes an effective method for estimating vertical disparity between 3D LFs in a stacked 3D LF. This vertical disparity can be used as key information to release the limitation. The contribution of this paper is as follows. First, this paper defines light ray pair in a stacked 3D LF. Light rays corresponding to light ray pair share the same foreground and background, and there is only vertical disparity. Second, based on light ray pair, this paper proposes an effective image reconstruction for disparity estimation. This method reconstructs the reference image by connecting all light rays that are light ray pair with the target image from the neighboring 3D LF. Since this reference image has only vertical disparity, disparity estimation becomes relatively easy. Additionally, the image-based disparity estimation may damage the continuity of 3D LF, so post-processing is applied to compensate for this. In the experimental results, the proposed method shows a noticeable improvement in objects with large disparity that are close to the camera.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9870014","National Research Foundation of Korea(grant numbers:2021R1A6A3A01086703); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9870014","3D light field;disparity estimation;image-based rendering;epipolar plane image","Three-dimensional displays;Circuits and systems;Stacking;Estimation;Rendering (computer graphics);Cameras;Light fields","","1","","10","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Adversarially-Trained Tiny Autoencoders for Near-Sensor Continuous Structural Health Monitoring","A. Burrello; G. Sintoni; D. Brunelli; L. Benini","DEI, University of Bologna, Bologna, Italy; DEI, University of Bologna, Bologna, Italy; DII, University of Trento, Trento, Italy; DEI, University of Bologna, Bologna, Italy",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","439","442","Structural Health Monitoring (SHM) systems are increasingly employed in many civil structures such as buildings, tunnels and viaducts. Typical installations consist of sensors that gather information and send it to a central computing unit, which then periodically analyzes the incoming data and produces an assessment of the structure conditions. To avoid the transmission of a huge amount of raw data and reduce latency in the detection of structural anomalies, recent works focus on moving computation on the sensor nodes. This work shows that a small autoencoder, which fits the tiny 2 MB memory of a typical microcontroller used for SHM sensor nodes can achieve very competitive accuracy in detecting structural anomalies as well as vehicle passage on bridges by leveraging adversarial training based on generative adversarial networks (GANs). We improve accuracy over state-of-the-art algorithms in two use-cases on real-standing buildings: i) predicting anomalies on a bridge (+7.4%) and ii) detecting vehicles on a viaduct (2.30 ×).","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869952","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869952","","Training;Buildings;Bridge circuits;Transportation;Telecommunication traffic;Benchmark testing;Prediction algorithms","","1","","11","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"A machine learning enhanced approximate message passing massive MIMO accelerator","S. Brennsteiner; T. Arslan; J. S. Thompson; A. McCormick","School of Engineering, Institute of Integrated Micro and Nano Systems, University of Edinburgh, Edinburgh, United Kingdom; School of Engineering, Institute of Integrated Micro and Nano Systems, University of Edinburgh, Edinburgh, United Kingdom; School of Engineering, University of Edinburgh, Institute for Digital Communications, Edinburgh, United Kingdom; Alpha Data Parallel Systems Ltd, Edinburgh, United Kingdom",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","443","446","Machine learning in the physical layer of communication systems currently receives much attention due to its potential to improve performance over difficult or unknown channels. Model-driven machine learning combines well-established algorithms with machine learning enhancements to realize these performance gains while keeping computational complexity within practical limits. In this work, we present the first model-driven machine-learning accelerator based on Orthogonal Approximate Message Passing (OAMP) for massive MIMO. The accelerator is configurable to support various machine learning enhancements such as those used in the OAMPNet and MMNet algorithms. The accelerator architecture is implemented as a deep pipeline to maximize throughput and we explore a range of antenna, user, and modulation configurations. Our results show the feasibility of deploying machine learning enhanced algorithms in future physical layer processors.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869942","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869942","","Wireless communication;Machine learning algorithms;Computational modeling;Message passing;Machine learning;Massive MIMO;Approximation algorithms","","1","","14","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Irrelevant Pixels are Everywhere: Find and Exclude Them for More Efficient Computer Vision","C. Tung; A. Goel; X. Hu; N. Eliopoulos; E. S. Amobi; G. K. Thiruvathukal; V. Chaudhary; Y. -H. Lu","Purdue University; Purdue University; Purdue University; Purdue University; Loyola University, Chicago; Loyola University, Chicago; Case Western Reserve University; Purdue University",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","340","343","Computer vision is often performed using Convolutional Neural Networks (CNNs). CNNs are compute-intensive and challenging to deploy on power-contrained systems such as mobile and Internet-of-Things (IoT) devices. CNNs are computeintensive because they indiscriminately compute many features on all pixels of the input image. We observe that, given a computer vision task, images often contain pixels that are irrelevant to the task. For example, if the task is looking for cars, pixels in the sky are not very useful. Therefore, we propose that a CNN be modified to only operate on relevant pixels to save computation and energy. We propose a method to study three popular computer vision datasets, finding that 48% of pixels are irrelevant. We also propose the focused convolution to modify a CNN's convolutional layers to reject the pixels that are marked irrelevant. On an embedded device, we observe no loss in accuracy, while inference latency, energy consumption, and multiply-add count are all reduced by about 45%.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9870012","NSF(grant numbers:OAC-2104709,OAC-2107020); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9870012","computer vision;low-power devices;embedded systems;datasets","Performance evaluation;Computer vision;Energy consumption;Convolution;Economic indicators;Circuits and systems;Convolutional neural networks","","3","","17","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"ANOLUF: A Feature Selection and Channel Selection Methodology for Medical Event-Detection","R. Ranjandish",NA,2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","1","4","A feature selection and a channel selection methodology are presented in this paper to provide a reliable and flexible comparison between different features. Using the proposed method, the best feature extractor(s), as well as the best corresponding channel(s) for a medical event-detector are selected. In this paper, we focus on the seizure onset detection (SOD) in closed-loop stimulation systems for epilepsy control, as the target application. However, the target application can be any type of medical event-detector and is not limited to SODs. Detecting the onset of seizures with a minimum delay and maximum sensitivity and specificity (or minimum false alarm rate) is the major and the most important task of an implantable medical device (IMD) for epilepsy control. However, delay in seizure onset detection is not used to score models or features employed in the state-of-the-art SODs. Thanks to the proposed method, feature scoring is performed based on any set of target performance metrics such as detection delay (DD), false-positive rate (FPR), false-negative rate (FNR), sensitivity, power consumption, etc. The presented method is applied to the long-term dataset of the open-access SWECETHZ iEEG database. Ten top-score features are extracted from each patient's iEEG which include the feature extractor and the corresponding electrode number. This work and its results provide a reliable methodology for designing accurate and robust event detectors for IMDs.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869852","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869852","Feature selection;channel selection;medical event;event detection;seizure detection;iEEG;EEG;signal processing;machine learning;implantable medical device","Performance evaluation;Sensitivity;Medical devices;Power demand;Epilepsy;Sensitivity and specificity;Feature extraction","","","","5","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"CIM-based Robust Logic Accelerator using 28 nm STT-MRAM Characterization Chip Tape-out","A. Singh; M. Zahedi; T. Shahroodi; M. Gupta; A. Gebregiorgis; M. Komalan; R. V. Joshi; F. Catthoor; R. Bishnoi; S. Hamdioui","Computer Engineering Laboratory, TU Delft, The Netherlands; Computer Engineering Laboratory, TU Delft, The Netherlands; Computer Engineering Laboratory, TU Delft, The Netherlands; IMEC Leuven, Belgium; Computer Engineering Laboratory, TU Delft, The Netherlands; IMEC Leuven, Belgium; IBM Thomas J. Watson Research Centre, Yorktown, USA; IMEC Leuven, Belgium; Computer Engineering Laboratory, TU Delft, The Netherlands; Computer Engineering Laboratory, TU Delft, The Netherlands",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","451","454","Spin-transfer torque magnetic random access memory (STT-MRAM) based computation-in-memory (CIM) architectures have shown great prospects for an energy-efficient computing. However, device variations and non-idealities narrow down the sensing margin that severely impacts the computing accuracy. In this work, we propose an adaptive referencing mechanism to improve the sensing margin of a CIM architecture for boolean binary logic (BBL) operations. We generate reference signals using multiple STT-MRAM devices and place them strategically into the array such that these signals can address the variations and trace the wire parasitics effectively. We have demonstrated this behavior using an STT-MRAM model, which is calibrated using 1Mbit characterized array. Results show that our proposed architecture for binary neural networks (BNN) achieves up to 17.8 TOPS/W on the MNIST dataset and 130× performance improvement for the text encryption compared to the software implementation on Intel Haswell processor.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869993","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869993","STT-MRAM;computation-in-memory;binary logic;binary neural networks","Torque;Neural networks;Wires;Random access memory;Computer architecture;Software;Common Information Model (computing)","","10","","12","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"A 10T SRAM Compute-In-Memory Macro with Analog MAC Operation and Time Domain Conversion","H. Park; K. Lee; J. Park","School of Electrical Engineering, Korea University, Seoul, Korea; School of Electrical Engineering, Korea University, Seoul, Korea; School of Electrical Engineering, Korea University, Seoul, Korea",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","455","458","This paper presents a novel 10T SRAM Compute-In-Memory (CIM) architecture that efficiently combines current-domain computation with time-domain analog readout. In the analog multiply and accumulation (MAC) computations of the proposed CIM, by weakening the bit-line (BL) discharge current, the MAC results are linearly formed, thus efficiently processing the binarized inputs and weights. In addition, to reduce the hardware cost of analog readout circuit, a time-domain based analog MAC conversion scheme using the current mirror-based voltage to time converter circuits and the flip-flop based time-to-digital converter (TDC) are employed. The hardware implementation results with 28nm CMOS process technology show that the proposed 128×64 SRAM CIM macro achieves a 1788-TOPS/W with 3.75ns delay at 0.9V. It also shows an 86.01% of inference accuracy using CIFAR-10 dataset with VGG-7 model. Compared with the previous works, the proposed SRAM CIM shows up to 4.43× improvement in TOPS/W.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9870016","National Research Foundation of Korea; Institute of Information & communications Technology Planning & evaluation (IITP)(grant numbers:2021-0-00903-002); IC Design Education Center(IDEC), Korea; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9870016","memory;compute in memory;current domain compute;time to digital converter","Semiconductor device modeling;Costs;Computational modeling;Random access memory;Computer architecture;Voltage;Hardware","","3","","13","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"A Process and Data Variations Tolerant Capacitive Coupled 10T1C SRAM for In-Memory Compute (IMC) in Deep Neural Network Accelerators","B. Iqbal; A. Grover; H. Rawat","Indraprastha Institute of Information Technology Delhi, New Delhi, India; Indraprastha Institute of Information Technology Delhi, New Delhi, India; STMicroelectronics Greater Noida, New Delhi, India",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","459","462","Advanced processors suffer from Von-Neumann bottleneck and In-Memory Compute (IMC) based solutions are proposed to improve performance and reduce power consumption by bypassing this bottleneck. In this work, we present a 10T1C SRAM cell that enables process and data variation tolerant robust compute operation. The cell is 33% more linear than competing architectures and also enables much higher parallelism (higher throughput) due to 40X lesser variability. A sample IMC SRAM instance in 65nm Low Standby Power Technology with 4-bit flash ADC and digital adder operates at an energy efficiency of 350 TOPS/W.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9870026","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9870026","In memory compute;SRAM;Process Tolerant;Deep Neural Network(DNN)","Program processors;Power demand;Microprocessors;Neural networks;Computer architecture;Voltage;Parallel processing","","6","","11","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Power-Efficient Double-Cyclic Low-Precision Training for Convolutional Neural Networks","S. Kim; H. Kim","Department of Electrical and Information Engineering, Research Center for Electrical and Information Technology, Seoul National University of Science and Technology, Seoul, Korea; Department of Electrical and Information Engineering, Research Center for Electrical and Information Technology, Seoul National University of Science and Technology, Seoul, Korea",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","344","347","Owing to the rapid development of deep learning, there has been a remarkable growth in the field of computer vision, including image classification. However, because recent deep learning models require many parameters and calculations, it is essential to reduce power consumption through weight reduction for practical use in embedded platforms, such as mobile devices. In particular, recent attempts to train deep learning models on edge/mobiles have been increasing to obtain customized models with user environments and to solve privacy issues. However, because batteries and hardware resources are limited in the edge/mobile environment, the need for low-precision training has increased. In this study, we propose a power-efficient double-cyclic low-precision training method that uses two different precision cycles for weights and activations during training. The results of verifying the proposed method in various ResNet models indicate an average accuracy improvement of 0.25% compared with the existing low-precision training method and an approximately 25% power reduction effect. Consequently, a 92.8% reduction in hardware resources is achieved with negligible performance degradation compared to full-precision training.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869948","National Research Foundation of Korea(NRF)(grant numbers:2020M3H2A1078119); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869948","quantization;low-precision training;convolutional neural network;image classification;hardware implementation;low-power","Training;Deep learning;Performance evaluation;Privacy;Power demand;Computational modeling;Market research","","1","","24","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Hardware-Friendly Logarithmic Quantization with Mixed-Precision for MobileNetV2","D. Choi; H. Kim","Department of Electrical and Information Engineering, Research Center for Electrical and Information Technology Seoul National University of Science and Technology, Seoul, Korea; Department of Electrical and Information Engineering, Research Center for Electrical and Information Technology Seoul National University of Science and Technology, Seoul, Korea",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","348","351","In a variety of computer vision applications, convolutional neural networks (CNNs) have achieved excellent accuracy. However, in order for a CNN to operate on embedded platforms such as mobile devices, hardware resources and power consumption must be reduced. Accordingly, research involving the application of low-precision quantization to lightweight networks, such as MobileNet, has attracted considerable attention. In particular, compared to linear quantization, logarithmic quantization can significantly reduce hardware resources by processing multiplication operations as addition operations when implementing a hardware accelerator. In this study, we propose a novel logarithmic weight quantization considering the characteristics of MobileNetV2, which is known to be notoriously difficult to quantize, and a mixed-precision quantization that minimizes accuracy loss by training the distribution range using the trainable parameter $\alpha$, Experimental results show that the proposed method achieves accuracies greater than 1.47% and 2% on the CIFAR-10 and Tiny-ImageNet datasets, respectively, compared to the general log-scale quantization methods. As a result, the proposed method achieves a significant hardware resource reduction with only a slight degradation in performance when compared to the full precision (i.e., FP32), and achieves an additional power reduction effect of about 48% compared to linear scale quantization at the same precision.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869994","National Research Foundation of Korea(NRF); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869994","Deep learning;Convolutional Neural Network;logarithmic quantization;MobileNetV2","Degradation;Training;Performance evaluation;Computer vision;Quantization (signal);Power demand;Lightweight structures","","9","","27","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Navigating Local Minima in Quantized Spiking Neural Networks","J. K. Eshraghian; C. Lammie; M. R. Azghadi; W. D. Lu","Dept. of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI, USA; College of Science and Engineering, James Cook University, Queensland, Australia; College of Science and Engineering, James Cook University, Queensland, Australia; Dept. of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI, USA",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","352","355","Spiking and Quantized Neural Networks (NNs) are becoming exceedingly important for hyper-efficient implementations of Deep Learning (DL) algorithms. However, these networks face challenges when trained using error backpropagation, due to the absence of gradient signals when applying hard thresholds. The broadly accepted trick to overcoming this is through the use of biased gradient estimators: surrogate gradients which approximate thresholding in Spiking Neural Networks (SNNs), and Straight-Through Estimators (STEs), which completely by-pass thresholding in Quantized Neural Networks (QNNs). While noisy gradient feedback has enabled reasonable performance on simple supervised learning tasks, it is thought that such noise increases the difficulty of finding optima in loss landscapes, especially during the later stages of optimization. By periodically boosting the Learning Rate (LR) during training, we expect the network can navigate unexplored solution spaces that would otherwise be difficult to reach due to local minima, barriers, or flat surfaces. This paper presents a systematic evaluation of a cosine-annealed LR schedule coupled with weight-independent adaptive moment estimation as applied to Quantized SNNs (QSNNs). We provide a rigorous empirical evaluation of this technique on high precision and 4-bit quantized SNNs across three datasets, demonstrating state-of-the-art performance on the more complex datasets. Our source code is available at this link: https://github.com/jeshraghian/QSNNs.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869966","Korea Foundation; Semiconductor Research Corporation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869966","Deep learning;quantization;spiking neural networks;scheduling","Training;Deep learning;Schedules;Systematics;Navigation;Estimation;Noise measurement","","10","","20","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Tiny TCN model for Gesture Recognition With Multi-point Low power ToF-Sensors","S. Boner; C. Vogt; M. Magno","Department of Information technology and Electrical Engineering, ETH, Zurich; Department of Information technology and Electrical Engineering, ETH, Zurich; Department of Information technology and Electrical Engineering, ETH, Zurich",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","356","359","Gesture recognition is currently an important field of research, as it provides the basis for the next generation of Human Machine Interface. Especially recognizing gestures with touch-less technology has several advantages including, for example, the possibility of working with gloves either outside or in sterile environments. In this work, we present a tiny machine learning neural network model exploiting a novel, miniaturized and low power Time of flight (ToF)-sensor from STMicroelectronics. The algorithm is based on a combination of temporal convolutional networks and is optimized to work on an embedded small and low power ARM cortex-M4 processor with a few kilo Byte of RAM, as employed in every recent Bluetooth Low Energy module. A dataset has been collected with the ToF sensor for training and evaluation of the proposed algorithm. The model has been evaluated for accuracy and a trade-off between computational resources and accuracy is presented. The gesture recognition achieves a very high accuracy of over 96% over 6 different gestures.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869848","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869848","Low power Sensors;TinyML;EdgeAI;Wearable devices;TCN;CNN;Gesture recognition","Training;Machine learning algorithms;Microcontrollers;Computational modeling;Neural networks;Random access memory;Gesture recognition","","5","","16","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"A Lightweight Detector for Small Objects","A. K. Sharma; K. K. Kim","Deptartment of Electronic Engineering, Daegu University, Gyeongsan, South Korea; Deptartment of Electronic Engineering, Daegu University, Gyeongsan, South Korea",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","360","361","Object detection is one of the significant applications of computer vision, that combines the work of image classification and localization. It is being used in several areas nowadays like, Autonomous vehicles, face recognition, security cameras, e.t.c. There are some lightweight object detection algorithms based on You Only Look Once (YOLO) [1], and SSD (Single Shot MultiBox Detector) [2]. The drawback of these algorithms is that they consume a larger number of parameters for training, provide less mAP, and also lack detection of small objects. To overcome the above-mentioned issues, a computationally cheap lightweight object detector with a strong network and an enhancer block has been proposed in this paper, which helps in increasing the accuracy and improving the detection of small objects. The proposed object detector is trained from scratch without using any pre-trained image classifier weights. The object detector is trained on Udacity Annotated Driving Dataset, and the result shows that the model uses fewer number parameters (0.43M parameters for training), and is also better at detecting small objects than the conventional models at the time of inference, and provides 4.8% and 0.8% higher mAP than two different conventional models.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869898","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869898","object detection;lightweight DNN;CNN","Training;Location awareness;Computational modeling;Face recognition;Detectors;Object detection;Classification algorithms","","","","5","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Real-time Radar Gesture Classification with Spiking Neural Network on SpiNNaker 2 Prototype","J. Huang; B. Vogginger; P. Gerhards; F. Kreutz; F. Kelber; D. Scholz; K. Knobloch; C. G. Mayr",Infineon Technologies Dresden; Technische Universität Dresden; Infineon Technologies Dresden; Infineon Technologies Dresden; Technische Universität Dresden; Infineon Technologies Dresden; Infineon Technologies Dresden; Technische Universität Dresden,2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","362","365","Neuromorphic hardware has been emerging in recent years, seeking various applications to explore its uniqueness, limitations, and possibilities. As a representative application and research area, gesture recognition is gaining wider popularity, while the conflict of spiking neural network (SNN) size and available memory of neuromorphic edge-AI can be a thorny issue, which is even intensified by the demand for continuously processing input data stream from the sensor in the real-world scenario since a certain amount of memory is required to ensure that no data loss or overwrite happens. In this paper, an SNN-based real-time radar gesture recognition closed-loop system is proposed, with Infineon's 60 GHz radar continuously capturing motion and the multi-core neuromorphic hardware SpiNNaker 2 serving as the backend to classify gestures with an SNN. A PC is used to preprocess the data and manipulate an actuator. This system requires less than 8 k operation cycles per processor for each radar frame and achieves a classification accuracy of 98.83% with an 8-bit quantized model, with only 134.2 kB memory usage on three processing elements (PEs) and low energy cost. Besides, it performs well in the real-time closed-loop test with 35 ms latency.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869987","German Research Foundation (DFG, Deutsche Forschungsgemeinschaft)(grant numbers:2050/1-ProjectID390696704); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869987","SNN;real-time;neuromorphic hardware;radar;SpiNNaker 2;gesture recognition;multi-core processor","Quantization (signal);Neuromorphics;Memory management;Neural networks;Radar;Gesture recognition;Real-time systems","","2","","15","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Hybrid Binary-Stochastic Computing-based ANN Design with Binary-in-Series-out ReLU","K. -C. J. Chen; C. -T. Chen","Department of Computer Science and Engineering, National Sun Yat-sen University, Taiwan; Department of Computer Science and Engineering, National Sun Yat-sen University, Taiwan",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","162","165","Because of the remarkable performance on the problem of classification and recognition, Artificial Neural Networks (ANNs) have received much attention in recent years. However, due to the massive parameters and complicated interconnections between each neuron, ANN hardware architectures suffer from considerable area overhead and power consumption, which becomes the design challenge nowadays. To mitigate the design problem, the Stochastic Computing (SC)-based computing method has been proposed to use stochastic bit-stream for each kind of arithmetic operation in recent years. Besides, many SC-based ANN designs were proposed and showed their efficiency to save the computing power and area of the hardware. However, the conventional SC-based ANNs (SC-ANNs) suffer from low computing accuracy due to the applied stochastic bit-stream. To further improve the computing accuracy of the SC-ANN, we propose to replace the SC-based multiply-accumulator (MAC) with the parallel counter (PC) in this work. In addition, we further propose a binary-input-series-output (BISO) ReLU function to transfer the binary to the corresponding stochastic bit-stream efficiently. Compared with the conventional SC-ANN approach, the proposed SC-ANN design with PC-based MAC and BISO ReLU can improve computing accuracy by 86.6%. In addition, the proposed approach can reduce 95.3% area cost and 90% power consumption over than non-SC-ANN design, which achieves higher hardware efficiency.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869930","Ministry of Science and Technology(grant numbers:MOST 110-2221-E-110-026-MY3,MOST 110-2218-E-110-009); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869930","stochastic computing;artificial neural network;ReLU;parallel counter;machine learning","Power demand;Costs;Circuits and systems;Neurons;Artificial neural networks;Learning (artificial intelligence);Computer architecture","","","","12","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"A Behavior-Level Simulation Framework for RRAM-Based Deep Learning Accelerators with Flexible Architecture Configurations","H. -Y. Kao; S. -H. Huang","Department of Electronic Engineering, Chung Yuan Christian University, Taoyuan, Taiwan; Department of Electronic Engineering, Chung Yuan Christian University, Taoyuan, Taiwan",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","166","169","It is recognized that RRAM-based deep learning accelerators provide a promising solution to boost the energy efficiency of neural network algorithms. However, to precisely evaluate the model performance at the early design stage, there is a demand to integrate RRAM's physical properties, such as the lognormal distribution of resistance state, leakage current, and sneak path, to the neural network design framework (such as PyTorch). In this paper, we propose a behavior-level simulator, which considers RRAM's physical properties, for the development of RRAM-based deep learning accelerators. Especially, our simulator has the flexibility to allow users to configure their own hardware architectures. As a result, an accurate behavior-level hardware architecture exploration can be made at the early design stage. Benchmark data consistently show that the proposed approach works well in practice.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869956","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869956","Computing-in-memories;DNN accelerators;Non-linear effects;RRAM arrays;Simulator","Deep learning;Resistance;Computational modeling;Neural networks;Computer architecture;Hardware;Energy efficiency","","2","","12","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Scale up your In-Memory Accelerator: Leveraging Wireless-on-Chip Communication for AIMC-based CNN Inference","N. Bruschi; G. Tagliavini; F. Conti; S. Abadal; A. Cabellos-Aparicio; E. Alarcón; G. Karunaratne; I. Boybat; L. Benini; D. Rossi","University of Bologna, Bologna, Italy; University of Bologna, Bologna, Italy; University of Bologna, Bologna, Italy; Universitat Politècnica de Catalunya, Barcelona, Spain; Universitat Politècnica de Catalunya, Barcelona, Spain; Universitat Politècnica de Catalunya, Barcelona, Spain; IBM Research Europe; IBM Research Europe; University of Bologna, Bologna, Italy; University of Bologna, Bologna, Italy",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","170","173","Analog In-Memory Computing (AIMC) is emerging as a disruptive paradigm for heterogeneous computing, potentially delivering orders of magnitude better peak performance and efficiency over traditional digital signal processing architectures on Matrix-Vector multiplication. However, to sustain this throughput in real-world applications, AIMC tiles must be supplied with data at very high bandwidth and low latency; this poses an unprecedented pressure on the on-chip communication infrastructure, which becomes the system's performance and efficiency bottleneck. In this context, the performance and plasticity of emerging on-chip wireless communication paradigms provide the required breakthrough to up-scale on-chip communication in large AIMC devices. This work presents a many-tile AIMC architecture with inter-tile wireless communication that integrates multiple heterogeneous computing clusters, embedding a mix of parallel RISC-V cores and AIMC tiles. We perform an extensive design space exploration of the proposed architecture and discuss the benefits of exploiting emerging on-chip communication technologies such as wireless transceivers in the millimeter-wave and terahertz bands.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869996","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869996","In-Memory Computing;Heterogeneous Systems;Network-on-Chip;Wireless-based Communications","Performance evaluation;Wireless communication;System performance;Computer architecture;Bandwidth;Throughput;Heterogeneous networks","","4","","18","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"X-Fault: Impact of Faults on Binary Neural Networks in Memristor-Crossbar Arrays with Logic-in-Memory Computation","F. Staudigl; K. J. X. Sturm; M. Bartel; T. Fetz; D. Sisejkovic; J. M. Joseph; L. B. Pöhls; R. Leupers","Institute for Communication Technologies and Embedded Systems, RWTH Aachen University, Germany; Institute for Communication Technologies and Embedded Systems, RWTH Aachen University, Germany; Institute for Communication Technologies and Embedded Systems, RWTH Aachen University, Germany; Institute for Communication Technologies and Embedded Systems, RWTH Aachen University, Germany; Institute for Communication Technologies and Embedded Systems, RWTH Aachen University, Germany; Institute for Communication Technologies and Embedded Systems, RWTH Aachen University, Germany; Chair of Integrated Digital Systems and Circuit Design, RWTH Aachen University, Germany; Institute for Communication Technologies and Embedded Systems, RWTH Aachen University, Germany",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","174","177","Memristor-based crossbar arrays represent a promising emerging memory technology to replace conventional memories by offering a high density and enabling computing-in-memory (CIM) paradigms. While analog computing provides the best performance, non-idealities and ADC/DAC conversion limit memristor-based CIM. Logic-in-Memory (LIM) presents another flavor of CIM, in which the memristors are used in a binary manner to implement logic gates. Since binary neural networks (BNN s) use binary logic gates as the dominant operation, they can benefit from the massively parallel execution of binary operations and better resilience to variations of the memristors. Although conventional neural networks have been thoroughly investigated, the impact of faults on memristor-based BNNs remains unclear. Therefore, we analyze the impact of faults on logic gates in memristor-based crossbar arrays for BNNs. We propose a simulation framework that simulates different traditional faults to examine the accuracy loss of BNNs on memristive crossbar arrays. In addition, we compare different logic families based on the robustness and feasibility to accelerate AI applications.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869897","Federal Ministry of Education and Research(grant numbers:l6ME0398K,16ME0399); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869897","ReRAM;memristor;faults;reliability;logic-in-memory","Computational modeling;Neural networks;Memristors;Logic gates;Data models;Common Information Model (computing);Circuit faults","","5","","20","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"An Asynchronous Soft Macro for Ultra-Low Power Communication in Neuromorphic Computing","D. Bertozzi; K. Bhardwaj; S. M. Nowick","Engineering Department, University of Ferrara, Ferrara, Italy; Lawrence Livermore National Laboratory, Livermore, CA, USA; Department of Computer Science, Columbia University, New York, NY, USA",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","178","181","Asynchronous networks-on-chip (NoCs) playa fundamental role to materialize energy efficiency and scalability of spiking neural network-based neuromorphic systems. An unmistakable trend in this field consists of using bundled-data encoding for NoC design, showing promise in overall cost metrics while incorporating moderate timing constraints. To date, no framework exists for cost-effective and flexible NoC design with this approach. This paper aims at bridging this gap, by making bundled-data NoCs available to neuromorphic system designers through a highly-configurable and technology-independent soft macro. To our knowledge, this is the first paper to prove synchronous-equivalent design flexibility for an asynchronous NoC.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869944","National Science Foundation (NSF)(grant numbers:CCF-1527796); University of Ferrara; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869944","","Costs;Neuromorphic engineering;Scalability;Integrated circuit interconnections;Switches;Market research;Extraterrestrial measurements","","1","","30","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"A 62.45 TOPS/W Spike-Based Convolution Neural Network Accelerator with Spatiotemporal Parallel Data Flow and Sparsity Mechanism","C. -H. Hsu; Y. -H. Cheng; Z. Li; P. -L. Huang; K. -T. Tang","National Tsing Hua university, Hsinchu, Taiwan; National Tsing Hua university, Hsinchu, Taiwan; National Tsing Hua university, Hsinchu, Taiwan; National Tsing Hua university, Hsinchu, Taiwan; National Tsing Hua university, Hsinchu, Taiwan",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","182","185","Convolutional neural networks (CNNs) have been widely used for image recognition and classification in recent years. Low energy consumption is crucial in the circuit design of edge devices, and data reuse is one method of reducing energy consumption. In addition, spiking neural networks (SNNs) are receiving increasing attention due to their low power use. However, the temporal characteristic of SNNs causes repeated data access at different time steps, leading to high energy consumption. In this paper, a spiked-based CNN accelerator that can support various inference time steps and models is proposed. Spatiotemporal parallel data flows are employed to reuse data from different time steps and, convolution operations are used to reduce energy consumption. Furthermore, the accelerator is designed for high sparsity and event driven SNNs. The synthesis achieves power efficiency of 62.45 TOPS/W and area efficiency of 7.58 TOPS/kmm2.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9870018","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9870018","Spiking neural network;accelerator;sparsity;energy efficiency;area efficiency","Energy consumption;Convolution;Image edge detection;Computational modeling;Neurons;Energy efficiency;Data models","","2","","11","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"A Closed-Loop Brain-Machine Interface with One-Shot Learning and Online Tuning for Patient-Specific Neurological Disorder Treatment","C. -W. Tsai; M. Zhang; L. Zhang; J. Yoo","National University of Singapore, Singapore; Huawei Technologies, Chengdu, China; National University of Singapore, Singapore; National University of Singapore, Singapore",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","186","189","Treatment of neurological disorders such as epilepsy, Parkinson's tremor, and Alzheimer's disease require energy-efficient Machine-Learning (ML) on-the-edge with one-shot learning, particularly in wearable form factor for pervasiveness. In many cases, patient-to-patient variations on neurological biomarkers are huge. Thus, patient-specific training with one-shot learning and online tuning is crucial. This paper introduces a wearable closed-loop brain-machine interface system targeting one-shot learning low-power high-accuracy seizure detection classifiers, with a special focus on a low-power online-tuning scheme to effectively track each patient's symptoms.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9870001","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9870001","Brain-machine interface;machine learning;one-shot learning;online learning;online tuning;seizure detection;seizure suppression","Neurological diseases;Training;Target tracking;Power demand;Wearable computers;Machine learning;Brain-computer interfaces","","1","","18","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Challenges and Opportunities of Edge AI for Next-Generation Implantable BMIs","M. Shaeri; A. Afzal; M. Shoaran","Institute of Electrical and Micro Engineering, Center for Neuroprosthetics, Geneva, Switzerland; Institute of Electrical and Micro Engineering, Center for Neuroprosthetics, Geneva, Switzerland; Institute of Electrical and Micro Engineering, Center for Neuroprosthetics, Geneva, Switzerland",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","190","193","Neuroscience and neurotechnology are currently being revolutionized by artificial intelligence (AI) and machine learning. AI is widely used to study and interpret neural signals (analytical applications), assist people with disabilities (prosthetic applications), and treat underlying neurological symptoms (ther-apeutic applications). In this brief, we will review the emerging opportunities of on-chip AI for the next-generation implantable brain machine interfaces (BMIs), with a focus on state-of-the-art prosthetic BMIs. Major technological challenges for the effectiveness of AI models will be discussed. Finally, we will present algorithmic and IC design solutions to enable a new generation of AI-enhanced and high-channel-count BMIs.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9870008","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9870008","Artificial Intelligence (AI);Machine Learning (ML);Brain Machine Interface (BMI);hardware efficiency","Neuroscience;Machine learning;System-on-chip;Trajectory;Artificial intelligence;Integrated circuit modeling;Next generation networking","","12","","21","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Towards Intelligent Noninvasive Closed-loop Neuromodulation Systems","J. Yang; N. Li; Y. -H. Chen; M. Sawan","School of Engineering, Westlake University, Hangzhou, China; School of Engineering, Westlake University, Hangzhou, China; School of Engineering, Westlake University, Hangzhou, China; School of Engineering, Westlake University, Hangzhou, China",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","194","197","Neuromodulation is an effective method to treat various kinds of brain diseases. It has drawn significant attention in academic research and the medical market and has become a rapidly developing area of medicine. However, current neuromodulation technologies face bottlenecks such as high cost, bulky, and lack of intelligent closed-loop for patient-specific treatments. These bottlenecks further limit the widespread use of neuromodulation technologies. Fortunately, these challenges, in turn, drive the advancement in integrated circuits and systems designs for biomedical applications. This paper presents recent research on IC development that is relevant to addressing the abovementioned challenges, emphasizing closing the loop with on-chip artificial intelligence (AI). Our current research will be presented as a case study to demonstrate how dedicated IC designs and AI can benefit the development of an intelligent and miniaturized closed-loop neuromodulation system. The challenges and emerging directions for the development of circuits and systems for neuromodulation technologies are summarized in the concluding remarks.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9870022","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9870022","Closed-loop;neuromodulation;biomedical devices;artificial intelligence;integrated circuits","Integrated circuits;Costs;Circuits and systems;System-on-chip;Neuromodulation;Artificial intelligence;System analysis and design","","1","","16","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"A Wearable High Blood Pressure Classification Processor Using Photoplethysmogram Signals through Power Spectral Density Features","M. Sheeraz; A. R. Aslam; N. Hafeez; H. Heidari; M. A. B. Altaf","Lahore University of Management Sciences (LUMS), Pakistan; Lahore University of Management Sciences (LUMS), Pakistan; Kings College London, United Kingdom; University of Glasgow, United Kingdom; Lahore University of Management Sciences (LUMS), Pakistan",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","198","201","High blood pressure (BP) is a major source of health problems related to mental stress, cardiac issues, kidney problems, vision, and brain. High BP bursts can damage and rupture blood vessels and cause strokes. Therefore, it is quite important to continuously monitor it for high BP patients. Conventional BP monitoring devices a) can cause discomfort and b) not suitable for intermittent monitoring. The photoplethysmographic (PPG) signals measure the volume changes in the human blood through human skin. This work presents a high BP classification processor using PPG signals through an artificial intelligence (AI) based boosted circuit. A data set of 25 participants was collected. Ten out of the 25 participants were high blood pressure patients with systolic BP (SBP) and, diastolic BP (DBP) values higher than 140mmHg and 90mmHg, respectively. The AI boosted circuit calculates the power spectral densities, power spectral densities difference, and the sum of the consecutive difference between PPG signals. The features are forwarded to a small 3-level Decision Tree (DT) classifier. The decision tree classifier classifies the high SBP and DBP as high or normal/low with 96.2% classification accuracy. The SBP values $\geq$ 130mmHg and $<$ 130mmHg were classified as HIGH SBP or LOW/NORMAL SBP respectively. Similarly, the DBP values $\geq$ 80mmHg and $<$ 80mmHg were classified as HIGH DBP or LOW/NORMAL DBP, respectively. The system was implemented on an Artix-7 FPGA which consumes power of $\approx 18.23uW$ @ 50 MHz.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869847","LUMS; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869847","Photoplethysmographic (PPG);Blood Pressure (BP);Systolic Blood Pressure (SBP);Diastolic Blood Pressure (DBP);Decision Tree (DT)","Volume measurement;Particle measurements;Blood pressure;Skin;Real-time systems;System-on-chip;Decision trees","","5","","22","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Reconfigurable Acceleration of Graph Neural Networks for Jet Identification in Particle Physics","Z. Que; M. Loo; W. Luk","Imperial College, London, UK; Imperial College, London, UK; Imperial College, London, UK",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","202","205","This paper presents a novel reconfigurable architecture to accelerate Graph Neural Networks (GNNs) for JEDI-net, a jet identification algorithm in particle physics which achieves state-of-the-art accuracy. The challenge is to deploy JEDI-net for online selection targeting the Large Hadron Collider (LHC) experiments with low latency. This paper proposes custom strength reduction for matrix multiplication operations customised for the GNN-based JEDI-net, which avoids the costly multiplication of the adjacency matrix with the input feature matrix. It exploits sparsity patterns and binary adjacency matrices to increase hardware efficiency while reducing latency. The throughput is further enhanced by a coarse-grained pipeline enabled by adopting column-major order data layout. Evaluation results show that our FPGA implementation is 11 times faster and consumes 12 times lower power than a GPU implementation. Moreover, the throughput of our FPGA design is sufficiently high to enable deployment of JEDI-net in a sub-microsecond, real-time collider trigger system, enabling it to benefit from improved accuracy.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869941","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869941","","High energy physics;Large Hadron Collider;Pipelines;Layout;Throughput;Graph neural networks;Real-time systems","","2","","15","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"A Mapping Model of SNNs to Neuromorphic Hardware","X. Cui; X. Hao; Y. Liang; G. Sun; X. Cui; Y. Wang; R. Huang","Peking University, Beijing, China; Peking University, Beijing, China; Peking University, Beijing, China; Peking University, Beijing, China; Peking University, Beijing, China; Peking University, Beijing, China; Peking University, Beijing, China",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","206","209","Spiking neural networks (SNNs) can achieve lower power consumption than traditional artificial neural networks. To take full advantage of spiking neural networks, a large number of neuromorphic hardware has emerged. However, it is nontrivial to map SNNs onto neuromorphic hardware due to the hardware constraints and complex networks-on-chip (NoCs). In this paper, we propose a mapping model to bridge the gap between SNNs and neuromorphic hardware. The mapping model is general to neuromorphic hardware with various on-chip networks. The core of the model is a loop-based representation, which can model computation and connection in software and hardware space simultaneously. We further propose transformation primitives to transform networks from software space to hardware space. We evaluate the mapping model using realistic spiking neural networks and three on-chip network topologies. Experiments show that compared to the simulated annealing algorithm without using the model, the energy consumption of computation and communication can be reduced by 19.4% and 27.4% on average, respectively.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869998","National Natural Science Foundation of China (NSFC)(grant numbers:U21B2017); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869998","spiking neural network;neuromorphic hardware;mapping model","Energy consumption;Neuromorphics;Computational modeling;Transforms;Hardware;Software;System-on-chip","","1","","21","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Hybrid Neuromorphic Systems: An Algorithm-Application-Hardware-Neuroscience Co-Design Perspective: Invited Special Session Paper","S. Lu; A. Sengupta","School of Electrical Engineering and Computer Science, The Pennsylvania State University Electrical Engineering, West University Park, PA, USA; School of Electrical Engineering and Computer Science, The Pennsylvania State University Electrical Engineering, West University Park, PA, USA",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","210","213","Spiking Neural Networks (SNNs) are considered to be the third generation of artificial neural networks due to its unique temporal, event-driven characteristics. By leveraging bio-plausible spike-based computing between neurons in tandem with sparse on-demand computation, SNNs can demonstrate orders of magnitude power efficiency on neuromorphic hardware in contrast to traditional Machine Learning (ML) methods. This paper reviews recent developments in the domain of neuromorphic SNN algorithms from an overarching system science perspective with an end-to-end co-design focus from algorithms to hardware and applications. The paper outlines opportunities at designing hybrid neuromorphic platforms where leveraging benefits of both traditional ML methods and neuroscience concepts in the training and architecture design choice can actualize SNNs to their fullest potential.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869925","National Science Foundation(grant numbers:CCF 1955815,BCS 2031632,ECCS 2028213); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869925","Spiking Neural Networks;Hybrid Systems;Neuromorphic Computing","Training;Neuroscience;Machine learning algorithms;Neuromorphics;Neurons;Computer architecture;Machine learning","","","","29","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"ZEN: A flexible energy-efficient hardware classifier exploiting temporal sparsity in ECG data","M. Jobst; J. Partzsch; C. Liu; L. Guo; D. Walter; S. -U. Rehman; S. Scholze; S. Höppner; C. Mayr","Chair of Highly-Parallel VLSI-Systems and Neuro-Microelectronics, Technische Universität Dresden, Germany; Chair of Highly-Parallel VLSI-Systems and Neuro-Microelectronics, Technische Universität Dresden, Germany; Chair of Highly-Parallel VLSI-Systems and Neuro-Microelectronics, Technische Universität Dresden, Germany; Chair of Highly-Parallel VLSI-Systems and Neuro-Microelectronics, Technische Universität Dresden, Germany; Chair of Highly-Parallel VLSI-Systems and Neuro-Microelectronics, Technische Universität Dresden, Germany; Chair of Highly-Parallel VLSI-Systems and Neuro-Microelectronics, Technische Universität Dresden, Germany; Chair of Highly-Parallel VLSI-Systems and Neuro-Microelectronics, Technische Universität Dresden, Germany; Chair of Highly-Parallel VLSI-Systems and Neuro-Microelectronics, Technische Universität Dresden, Germany; Chair of Highly-Parallel VLSI-Systems and Neuro-Microelectronics, Technische Universität Dresden, Germany",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","214","217","State-of-the-art low-power ECG hardware classifiers rely on extraction of pre-defined, hand-tuned features. This hinders their usage in different applications, because of the time-consuming redesign of features for any new classification task. As an alternative, we present a machine-learning based approach to ECG classification in hardware that still relies on feature extraction but is much more flexible to use. We utilize a recurrent neural network with temporal sparsity inspired by biologically motivated event-based systems. Features are extracted by freely configurable time-domain filters that are fully integrated in the training process. These are sparsified via delta encoding, so that further processing only acts on changes in the features or the recurrent connections. A scalable hardware architecture derived from this concept allows for stand-alone classification on input data streams. Despite its flexibility, our design achieves a peak energy efficiency of 37 nJ per heartbeat and an ultra-low power consumption of 532 nW in real-time operation, driven by temporal sparsity and a systematic low-power implementation strategy. At the same time, its classification performance is on par with state-of-the-art software-based classifiers.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869958","German Research Foundation (DFG, Deutsche Forschungs-gemeinschaft)(grant numbers:390696704); Federal German ministry for science and education (BMBF)(grant numbers:16ESl147); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869958","Electrocardiography;Low-power electronics;Neural network hardware;Recurrent neural networks","Training;Systematics;Finite impulse response filters;Heart beat;Electrocardiography;Feature extraction;Hardware","","6","","15","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Biologically-inspired training of spiking recurrent neural networks with neuromorphic hardware","T. Bohnstingl; A. Šurina; M. Fabre; Y. Demirağ; C. Frenkel; M. Payvand; G. Indiveri; A. Pantazi","IBM Research, Zurich; IBM Research, Zurich; IBM Research, Zurich; Institute of Neuroinformatics, University of Zurich and ETH, Zurich; Institute of Neuroinformatics, University of Zurich and ETH, Zurich; Institute of Neuroinformatics, University of Zurich and ETH, Zurich; Institute of Neuroinformatics, University of Zurich and ETH, Zurich; IBM Research, Zurich",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","218","221","Recurrent spiking neural networks (SNNs) are inspired by the working principles of biological nervous systems that offer unique temporal dynamics and event-based processing. Recently, the error backpropagation through time (BPTT) algorithm has been successfully employed to train SNNs offline, with comparable performance to artificial neural networks (ANNs) on complex tasks. However, BPTT has severe limitations for online learning scenarios of SNNs where the network is required to simultaneously process and learn from incoming data. Specifically, as BPTT separates the inference and update phases, it would require to store all neuronal states for calculating the weight updates backwards in time. To address these fundamental issues, alternative credit assignment schemes are required. Within this context, neuromorphic hardware (NMHW) implementations of SNNs can greatly benefit from in-memory computing (IMC) concepts that follow the brain-inspired collocation of memory and processing, further enhancing their energy efficiency. In this work, we utilize a biologically-inspired local and online training algorithm compatible with IMC, which approximates BPTT, e-prop, and present an approach to support both inference and training of a recurrent SNN using NMHW. To do so, we embed the SNN weights on an in-memory computing NMHW with phase-change memory (PCM) devices and integrate it into a hardware-in-the-loop training setup. We develop our approach with respect to limited precision and imperfections of the analog devices using a PCM-based simulation framework and a NMHW consisting of in-memory computing cores fabricated in 14nm CMOS technology with 256×256 PCM crossbar arrays. We demonstrate that our approach is robust even to 4-bit precision and achieves competitive performance to a floating-point 32-bit realization, while simultaneously equipping the SNN with online training capabilities and exploiting the acceleration benefits of NMHW.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869963","SNSF(grant numbers:20CH21_186999/1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869963","online training;spiking neural networks;neuromorphic hardware;in-memory computing;phase-change memory","Training;Phase change materials;Neuromorphics;Computational modeling;In-memory computing;Hardware;Inference algorithms","","4","","20","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"A 200M-Query-Vector/s Computing-in-RRAM ADC-less k-Nearest-Neighbor Accelerator with Time-Domain Winner-Takes-All Circuits","C. Mu; Y. Wang; J. Zheng; S. Liu; K. Zhou; S. Tang; C. Chen; Q. Liu","State Key Laboratory of ASIC and System, Frontier Institute of Chip and System, Fudan University, Shanghai, China; State Key Laboratory of ASIC and System, Frontier Institute of Chip and System, Fudan University, Shanghai, China; State Key Laboratory of ASIC and System, Frontier Institute of Chip and System, Fudan University, Shanghai, China; State Key Laboratory of ASIC and System, Frontier Institute of Chip and System, Fudan University, Shanghai, China; State Key Laboratory of ASIC and System, Frontier Institute of Chip and System, Fudan University, Shanghai, China; BirenTech Research, Shanghai, China; State Key Laboratory of ASIC and System, Frontier Institute of Chip and System, Fudan University, Shanghai, China; State Key Laboratory of ASIC and System, Frontier Institute of Chip and System, Fudan University, Shanghai, China",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","222","225","The $k$-nearest neighbor($k$NN) is widely used for pattern matching, data mining, and object recognition [1]. However, the previous computing-in-memory accelerator for the $k$NN algorithm heavily relies on analog-digital converter(ADC) circuits leading to huge area and power consumption. This paper proposed a computing-in-RRAM ADC-less k-nearest-neighbor accelerator with time-domain winner-takes-all circuits. The proposed accelerator features a time-domain winner-takes-all circuit with high PVT-variation intolerance and a scalable binary tree structure. Moreover, we improve the performance of voltage control lines circuits with fewer delay stages through the codesign of the computing-in-RRAM module and winner-takes-all circuit. The designed and simulated $k$NN accelerator performs up to 200 million query vectors per second while consuming 0.75 mW, demonstrating> 24.5 × energy performance improvement over prior works.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869962","NSFC(grant numbers:62104040); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869962","","Power demand;Circuits and systems;Binary trees;Delays;Object recognition;Data mining;Time-domain analysis","","3","","7","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"A Vector Systolic Accelerator for Multi-Precision Floating-Point High-Performance Computing","K. Li; J. Zhou; B. Li; S. Yang; S. Huang; S. Luo; W. Mao; H. Yu","School of Microelectronics, Southern University of Science and Technology, Shenzhen, China; School of Microelectronics, Southern University of Science and Technology, Shenzhen, China; School of Microelectronics, Southern University of Science and Technology, Shenzhen, China; School of Microelectronics, Southern University of Science and Technology, Shenzhen, China; School of Microelectronics, Southern University of Science and Technology, Shenzhen, China; School of Microelectronics, Southern University of Science and Technology, Shenzhen, China; School of Microelectronics, Southern University of Science and Technology, Shenzhen, China; School of Microelectronics, Southern University of Science and Technology, Shenzhen, China",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","226","229","There is an emerging need to design multi-precision floating-point (FP) accelerators for high-performance-computing (HPC) applications. However, the existing multi-precision design using high-precision-split method and low-precision-combination method suffers either low hardware utilization rate and long multiple clock-cycle processing period, respectively. In this paper, a new pipelined multi-precision FP processing element (PE) is developed with proposed redundancy-minimized bit-partitioning method. 3.8× throughput improving is achieved by the elaborate designed pipeline. Besides, vector systolic structure is designed for PE array to increase the system-level throughput and energy efficiency. The proposed design is realized in a 28-nm process with 1.351-GHz clock frequency. Compared with the existing multi-precision FP methods, the proposed work exhibits the best energy-efficiency performance of 1193 GFLOPSIW at FP16, 317 GFLOPS/W at FP32 and 77.3 GFLOPS/W at FP64 with at least 22.3%, 30% and 3.3% improvement, respectively.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869969","National Natural Science Foundation of China (NSFC)(grant numbers:62034007); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869969","multi-precision;vector;floating-point;Systolic","Circuits and systems;High performance computing;Design methodology;Pipelines;Throughput;Energy efficiency;Systolic arrays","","4","","17","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"An Efficient CNN Training Accelerator Leveraging Transposable Block Sparsity","M. Xu; J. Lu; Z. Wang; J. Lin","School of Electronic Science and Engineering, Nanjing University, Nanjing, China; School of Electronic Science and Engineering, Nanjing University, Nanjing, China; School of Electronic Science and Engineering, Nanjing University, Nanjing, China; School of Electronic Science and Engineering, Nanjing University, Nanjing, China",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","230","233","Convolutional neural network (CNN) training is computationally intensive, requiring a great deal of time and resources. Exploiting data sparsity is a promising method to ac-celerate CNN training. In this work, we propose a novel algorithm for sparse training processes in which the weight matrices are pruned in a fine-grained block-wise manner. Both the forward propagation (FP) and backward propagation (BP) phases use the identical data layout. It can eliminate the matrix transposition procedure, reducing storage space and training time. Based on this pruning approach, we developed an FPGA-based accelerator for CNN training using a systolic array. The architecture can effectively skip the zero values calculation without incurring the imbalance between different processing elements (PEs). Our experimental results indicate that our design achieves 1.024 TOPS and 118.4 GOPS/W in terms of computational throughput and energy efficiency. Our design is 1.41× ~ 4.93× more energy efficient than the state-of-the-art training accelerator.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869938","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869938","CNN;sparsity;pruning algorithm;hardware accelerator","Training;Tensors;Computer architecture;Throughput;Energy efficiency;Hardware;Systolic arrays","","1","","11","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Design Exploration of An Energy-Efficient Acceleration System for CNNs on Low-Cost Resource-Constraint SoC-FPGAs","S. -C. Wen; P. -T. Huang","Institute of Electrical Engineering; International College of Semiconductor Technology, National Yang Ming Chiao Tung University",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","234","237","Deep convolutional neural networks (CNNs) require enormous computation capacity, great amounts of memory accesses and data movement among parallel processing elements (PEs). From an energy perspective, CNNs are difficult to be fully deployed to low-cost resource-constraint edge devices because of both memory-intensive and computation-intensive workloads. In this paper, energy-efficient software/hardware co-design is explored for CNN acceleration on a Xilinx resource-constraint SoC-FPGA device. The acceleration system is optimized based on the constraints of DRAM bandwidths, BRAM resources, computing resources, optimal frequency and the complexity of wire routing. Moreover, the efficient workload distribution and dataflow control are also implemented by both software and hardware to achieve the maximum resource utilization. Based on a low-cost Xilinx Zynq XC7Z020 SoC-FPGA device, the proposed acceleration system achieves the throughput of VGG16 and YOLOv3-tiny by 4.3 frame/s and 21 frame/s, respectively. Moreover, 34 GOPS/W and 38.9 GOPS/W can be realized for VGG16 and YOLOv3-tiny. Compared to other state-of-art designs on resource-constraint SoC-FPGA devices, the proposed acceleration system achieves the best energy efficiency with high resource utilization.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869955","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869955","","Design methodology;Random access memory;Bandwidth;Throughput;Energy efficiency;Software;Hardware","","1","","7","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Extensible and Modularized Processing Unit Design and Implementation for AI Accelerator","C. -B. Wu; Y. -K. Hsiao; W. -H. Chang","Department of Electrical Engineering, National Chung-Hsing University, Taichung, Taiwan, R.O.C; Department of Electrical Engineering, National Chung-Hsing University, Taichung, Taiwan, R.O.C; Department of Electrical Engineering, National Chung-Hsing University, Taichung, Taiwan, R.O.C",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","238","241","This paper proposes an extensible and modularized Processing Unit Cluster (PE Cluster) for neural network accelerators. Each unit of PE Cluster is composed of 36 PEs and can be arbitrarily extended to above 36X up to 2160PEs. The PE Cluster is designed to be quickly reconfigured into application requirements under certain memory size and hardware specifications. In addition, two convolution operation modes, 1×1 and 3×3, are supported to be adapted to the network architecture of the Yolo series. In FPGA implementation, two PE Clusters are configured to reach 3.95GOPS/W and four PE Clusters to reach 7.87GOPS/W. In 90nm ASIC Implementation, both two and four PE Clusters have high area efficiency. According to analyzing area into million gate equivalent (MGE), two PE Clusters can reach 43.0GOPS/MGE and four PE Clusters can reach 67.3GOPS/MGE.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869949","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869949","AI accelerator;Modular PE;Hardware architecture","Convolution;Circuits and systems;Neural networks;Memory management;AI accelerators;Network architecture;Logic gates","","","","3","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Radar and Camera Fusion for Vacant Parking Space Detection","B. -X. Wu; J. -J. Lin; H. -K. Kuo; P. -Y. Chen; J. -I. Guo","Department of Electronics Engineering, Institute of Electronics, National Yang Ming Chiao Yung University, Hsinchu, Taiwan; Department of Electronics Engineering, Institute of Electronics, National Yang Ming Chiao Yung University, Hsinchu, Taiwan; Mediatek Inc., Hsinchu, Taiwan; Mediatek Inc., Hsinchu, Taiwan; Department of Electronics Engineering, Institute of Electronics, National Yang Ming Chiao Yung University, Hsinchu, Taiwan",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","242","245","This paper proposed a parking space detection system using the fusion of both radar and camera. Such fused approach addresses the challenging issue in which the border of parking slots is missing and/or not well drawn. Considering the adoption cost of the system, we incorporate Mediatek's Autus R10 (MT2706) Ultra-Short Range Radar with single transmitter and receiver (1T1R) antenna configuration. Such 1T1R radar has a lower cost than mTmR counterparts used in a vast majority of papers on the subject of radar signal processing. To the best of our knowledge, this is the first system fusing camera and radar (1T1R) to detect vacant parking space and estimate precise parking space coordinate without border lines of parking slots. At the same time, the proposed approach can also tackle extreme use-cases e.g., (1) non-car object occupation on the parking slot and (2) in a dim light night or rainy day. In the proposed system, the camera and radar detect the vacant parking space separately, then the corresponding results are fused together to get the final parking space coordinate for the auto-parking system. The experimental evaluations showed that the space prediction error was less than 1% with sufficient light and around 8% for the extreme situation. In summary, the proposed system handles the use-cases in different light conditions and weather, such as sunny days, rainy days, and night.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869918","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869918","sensor fusion;deep learning;radar;computer vision","Costs;Spaceborne radar;Transmitting antennas;Radar detection;Receiving antennas;Cameras;Radar antennas","","2","","8","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"An SoC Integration Ready VLIW-Driven CNN Accelerator with High Utilization and Scalability","C. -H. Hu; I. -H. Tseng; P. -H. Kuo; J. -D. Huang","Institute of Electronics, National Yang Ming Chiao Tung University, Hsinchu, Taiwan; Institute of Electronics, National Yang Ming Chiao Tung University, Hsinchu, Taiwan; Institute of Electronics, National Yang Ming Chiao Tung University, Hsinchu, Taiwan; Institute of Electronics, National Yang Ming Chiao Tung University, Hsinchu, Taiwan",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","246","249","In this paper a highly scalable VLIW-driven CNN accelerator architecture is proposed. A new VLIW instruction, which specifies all settings of an entire convolution layer and natively supports layer concatenation, is defined. A multi-mode input aligner (MMIA) is developed to efficiently organize input data for various convolution modes. A zero-initial-latency (ZIL) buffer is created to further boost the performance. A strip-based dataflow is adopted to drastically minimize external DRAM accesses. The accelerator is also equipped with an AXI4 on-chip bus interface, an instruction queue, ping-pong DRAM I/O buffers, and is thus ready for efficient and easy SoC integration. An accelerator instance with 576 MACs has been implemented using TSMC 40nm process. The core logic only requires 490K gates and the total internal memory size is merely 286KB. The peak performance is 1440 GOPS @1.25GHz and the core power efficiency is 8.71 TOPS/W. Moreover, the proposed accelerator has also enabled a real-time image semantic segmentation system for autonomous driving on an FPGA system.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9870010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9870010","convolutional neural network (CNN);hardware accelerator;very long instruction word (VLIW);high performance;low power;SoC integration ready","Image segmentation;Convolution;Semantics;Random access memory;Accelerator architectures;Logic gates;Real-time systems","","1","","20","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"A Novel DNN Accelerator for Light-weight Neural Networks: Concept and Design","Y. -G. Chen; T. -H. Hsieh; Y. -C. Ho; J. -Y. Jou","Department of Electrical Engineering, National Central University, Taoyuan, Taiwan; Department of Electrical Engineering, National Central University, Taoyuan, Taiwan; Department of Electrical Engineering, National Central University, Taoyuan, Taiwan; Department of Electrical Engineering, National Central University, Taoyuan, Taiwan",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","250","253","Convolution Neural Network (CNN) has achieved great successes and has been widely applied in various visual applications such as object detections and image classifications. However, large amount of data and complicated computing process lower the inference performance if all data are collected and sent to a central process node for computation. Edge AI, which directly process the convolution on the edge device itself, has attracted huge attentions. Nevertheless, limited computation power and memory makes it impractical to process entire CNN computation. To overcome the challenge, light-weight neural networks have been proposed to reduce computation complexity with the accuracy drops as a cost. Recently, two light-weight neural networks, MobileNet and ShuffleNet, are widely discussed with acceptable accuracy degradation. However, most of the state-of-the-art DNN accelerators are not suitable for MobileNet and ShuffleNet. Therefore, in this paper, we propose a novel CNN accelerator which can support both depthwise separable convolution and channel shuffle for these light-weight neural networks. Experimental results show that our design can successfully compute MobileNet and ShuffleNet. Moreover, compare with previous works, we can achieve at most 20% area reduction while maintaining performance.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869919","Ministry of Science and Technology(grant numbers:110-2221-E-008-099-MY3,I09-2221-E-008-069-MY2,110-2224-E-007-007); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869919","Edge AI;light-weight neural networks;MobileNet;ShuffleNet;CNN Accelerators","Performance evaluation;Visualization;Costs;Convolution;Image edge detection;Neural networks;Object detection","","1","","13","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Efficient Deep Learning Algorithm for Alzheimer's Disease Diagnosis using Retinal Images","D. Y. Kim; Y. J. Lim; J. H. Park; M. H. Sunwoo","Department of Electrical and Computer Engineering, Ajou University, Suwon, Republic of Korea; Department of Electrical and Computer Engineering, Ajou University, Suwon, Republic of Korea; Department of Electrical and Computer Engineering, Ajou University, Suwon, Republic of Korea; Department of Electrical and Computer Engineering, Ajou University, Suwon, Republic of Korea",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","254","257","Alzheimer's Disease (AD) is crucial to detect in the early stage and recent studies suggest diagnosing AD using Machine Learning. We propose an efficient AD diagnosis Deep Learning algorithm using retinal fundus images. The proposed method employs MobileNetV3 as a backbone, and an Attention mechanism is applied. However, we modified the backbone structure into U-Net-like architecture to perform better. Furthermore, we modified the conventional Attention mechanism to the Weighted Attention mechanism. The masking-adding process has been applied in the training method of the model. Therefore, our model has 8.4% better classification performance than the current state-of-the-art model by achieving 0.929 AUC in the validation set.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869953","National Research Foundation of Korea (NRF)(grant numbers:NRF-2021R1A2C2010228); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869953","Deep Learning;Algorithm;Alzheimer's Disease;Diagnosis;Edge Devices;Neural Network","Training;Image quality;Deep learning;Computational modeling;Computer architecture;Retina;Robustness","","","","16","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"A single-stage detector of cerebral microbleeds using 3D feature fused region proposal network (FFRP-Net)","J. -H. Kim; M. A. Al-masni; H. -J. Lee; Y. -S. Choi; D. -H. Kim","Department of Electrical and Electronic Engineering, Yonsei University, Seoul; Department of Electrical and Electronic Engineering, Yonsei University, Seoul; Department of Electrical and Electronic Engineering, Yonsei University, Seoul; Department of Electrical and Electronic Engineering, Yonsei University, Seoul; Department of Electrical and Electronic Engineering, Yonsei University, Seoul",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","1","4","Cerebral Microbleeds (CMBs) are chronic deposits of small blood products in the brain tissues, which have explicit relation to cerebrovascular diseases including cognitive decline, intracerebral hemorrhage, cerebral infarction. However, manual detection of the CMBs is a time-consuming and error-prone process. In this paper, we propose an efficient single-stage deep learning framework for automatic detection of the CMBs. The framework consists of a 3D U-Net and a region proposal network employing a feature fusing method (FFRP-Net) for detecting small objects. This model utilizes Susceptibility-Weighted Imaging (SWI) and phase images as 3D input to efficiently capture 3D contextual information. The performance of the proposed FFRP-Net records a sensitivity of 94.66% and an average number of false positives per subject (FPavg) of 8.82.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869855","National Research Foundation of Korea (NRF); Ministry of Science, ICT & Future Planning(grant numbers:2018M3C7A1056884,NRF-2019R1A2C1090635); Korea Health Industry Development Institute (KHIDI)(grant numbers:HI14Cl135); Ministry of Trade, Industry and Energy(grant numbers:202011D23); Ministry of Food and Drug Safety(grant numbers:202011D23); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869855","Cerebral Microbleeds;Deep Learning;Region Proposal Network;Feature Fusion","Deep learning;Solid modeling;Three-dimensional displays;Sensitivity;Imaging;Manuals;Feature extraction","","","","26","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Contrast Agent Removal for Brain CT Angiography Using Switchable CycleGAN with AdaIN and Histogram Equalization","I. Han; B. Kim; E. Y. Kim; J. C. Ye","Kim Jaechul Graduate School of AI, KAIST, Daejeon, Republic of Korea; Department of Bio and Brain Engineering, KAIST, Daejeon; Department of Radiology, Samsung Medical Center, Sungkyunkwan University, School of Medicine, Seoul, Republic of Korea; Kim Jaechul Graduate School of AI, KAIST, Daejeon, Republic of Korea",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","262","265","Computed tomography angiography uses an injection of contrast agent into the blood vessels, and helps to diagnose diseases that occur in the vessels and soft tissues. This requires contrast-enhanced CT (CECT) and non-enhanced CT (NECT) images, and the rigid registration and bone subtraction techniques are applied for better vessel visualization. However, the visualization process needs additional radiation exposure for obtaining two scans for the CECT and NECT. Also, it has limitations in that some vessels can be partially deleted due to insufficient registration. In this work, we propose a method to synthesize NECT from CECT images, using cycle-consistent generative adversarial network (cycleGAN) with adaptive instance normalization. Especially, a single generator of our framework utilizes the histogram equalization of CECT and NECT images so that the generator to effectively learn the image contrast. The experimental results demonstrate that the proposed method provides synthetic NECT images from CECT with high quality than the original cycleGAN, which reduces not only the radiation exposure for patients but also computational cost for the vessel visualization.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869976","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869976","Computed tomography;contrast agent;cycle-consistent adversarial network;adaptive instance normalization;histogram equalization","Histograms;Subtraction techniques;Computed tomography;Angiography;Biological tissues;Data visualization;Switches","","","","14","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Quality Evaluation Method for Chest X-Ray Images using the Reference Patterns","S. Bea; Y. -S. Park; J. -S. Sun; J. -W. Lee","Department of AI Convergence Network, Ajou University, Suwon, Korea; Department of AI Convergence Network, Ajou University, Suwon, Korea; Department of Radiology, Ajou University School of Medicine Suwon, Suwon, Korea; Department of Electrical and Computer Engineering & AI Convergence Network, Ajou University, Suwon, Korea",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","266","269","Chest X-Ray image quality evaluation relies on clinicians' judgment with clinical guidelines and expertise. Recently, the deep learning model for disease diagnosis has been made using X-ray image datasets. In this case, the quality of the image, which is the training model's input, determines the diagnostic model's performance. However, there are cost and time limitations to relying solely on the evaluation of clinicians for the massive amount of images. Therefore, there is a need to automatically evaluate the checklist of a given guideline and select a high-quality image. This paper generates a high-quality pattern from the chest X-ray image, and the difference between pixels from the target image is imaged. It is a method of evaluating quality with a CNN-based model by patterning the pixel value distribution of the generated image. The proposed method shows that it is possible to evaluate multiple integrated items, not a single evaluation item. In addition, to confirm the effectiveness of the proposed model, data composed by refining only randomly configured data and high-quality data without applying quality evaluation were applied to the Nodule Diagnostics Model. As a result of the experiment, model performance improved by 19% accuracy and 21% AUC when training with high-quality data.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9870023","ITRC(Information Technology Research Center)(grant numbers:IITP-2022-2020-0-01461); IITP(Institute for Information & communications Technology Planning & Evaluation); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9870023","Chest X-ray;Quality Evaluation;Deep Learning;Machine Learning","Training;Image quality;Refining;Learning (artificial intelligence);Data models;Medical diagnosis;Integrated circuit modeling","","","","7","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Lightweight End-to-End Stress Recognition using Binarized CNN-LSTM Models","M. Yun; S. Hong; S. Yoo; J. Kim; S. -M. Park; Y. Lee","Department of Electrical Engineering, POSTECH, Pohang, Republic of Korea; Department of Electrical Engineering, POSTECH, Pohang, Republic of Korea; Department of Electrical Engineering, POSTECH, Pohang, Republic of Korea; School of Interdisciplinary Bioscience and Bioengineering, POSTECH, Pohang, Republic of Korea; Department of Electrical Engineering, POSTECH, Pohang, Republic of Korea; Department of Electrical Engineering, POSTECH, Pohang, Republic of Korea",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","270","273","In this paper, we propose a novel end-to-end stress recognition model by combining binarized convolutional neural network (CNN) and long short-term memory (LSTM) models. Based on the previous CNN-LSTM model using electrocardiogram (ECG) and respiration (RESP) signals, we newly apply the bandit-based hyperparameter optimization to find more accurate solutions. Analyzing the computational costs of the accuracy-aware model, we also introduce advanced memory-reduction techniques with downscaling and binarization for realizing the cost-efficient stress recognition solution. As a result, compared to the state-of-the-art methods, the proposed model reduces the memory size, the inference latency, and the energy consumption by 93 %, 39 %, and 42 %, respectively, while even increasing the recognition accuracy up to 87%.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869974","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869974","Mental stress detection;binarized neural network;cost-efficient AI processing;electrocardiogram","Performance evaluation;Energy consumption;Computational modeling;Memory management;Human factors;Hardware;Convolutional neural networks","","5","","16","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Convolutional Neural Network Classification of Basal Cell Carcinoma in Harmonically Generated Microscopy Images","Z. -H. Yu; G. G. C. Lee; Y. Liao; C. K. Sun","Department of Electrical Engineering, National Cheng Kung University, Taiwan; Department of Electrical Engineering, National Cheng Kung University, Taiwan; Department of Dermatology, National Taiwan University Hospital, Taiwan; Department of Electrical Engineering, National Taiwan University, Taiwan",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","274","278","Basal cell carcinoma (BCC) is the most common form of skin cancer, which could cause local damage of nerves or tissues. Since the tumor growth of BCC is slow and not painful, it could lead to delayed tumor detection and hence necessary subsequent prompt intervention. This paper proposes a computer-aided diagnosis (CAD) method which uses the Gabor filter to extract characteristic scale information according to the characteristic of infected dendritic melanocytes in the third harmonic generation image. Scale information of image which is extracted from Gabor filter allows automatic adjustment of scale range and more accurate segmentation of the infected basal cells in medical images. Subsequently, normal and infected collagen fiber images are used to train convolution neural network (CNN) which are initialized with extracted features as kernels within convolution layers, resulting in high tumor detection accuracy and speed of convergence in harmonically generated microscopy (HGM) images. Experimental results show that this algorithm can accurately classify HGM images, with reduction in time and labor, and thus provides an efficient assisted tool in biomedical image analytics.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869921","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869921","Second Harmonic Generation (SHG);Third Harmonic Generation (THG);BCC;CNN;feature extraction;Gabor filter","Training;Microscopy;Feature extraction;Frequency conversion;Gabor filters;Convolutional neural networks;Kernel","","","","12","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"GAN - Based Medical Image Registration for Augmented Reality Applications","T. -H. Lee; V. Munasinghe; Y. -M. Li; J. Xu; H. -J. Lee; J. -S. Kim","Department of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea; Department of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea; Department of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea; Department of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea; Department of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea; Department of Electronic Engineering, SunMoon University, Asan, South Korea",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","279","282","Recently, with the development of AR/VR technology, boosting virtual information to the real world has been applied to various fields to increase convenience. In particular, in the medical field, different types of image information, such as X-ray, CT, and MRI data are used in surgery with AR devices for medical diagnosis and analysis of the cause of a patient's disease. This paper proposes an approach by which to explore a patient's posture and joints to match X-ray image information in an AR environment using deep learning networks such as GAN along with pose estimation. Thereby, we employ the CP-VTON+ virtual try-on network architecture to map chest X-ray information to the patient's body. Finally, we compare the try-on results of the chest X-ray image of the patient's body using the proposed method and CP-VTON+. The mean SSIM value of the proposed method is 0.0272 higher than that of CP-VTON+, and the mean PSNR value is 5.49 higher than that of CP-VTON+. The proposed method is more appropriate for application to AR devices for medical diagnosis and analysis due to the characteristics of medical images, as even minor misdiagnoses can lead to fatalities.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869916","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869916","X-ray image;convolutional neural network;deep learning;virtual try-on;CP-VTON+","Training;Deep learning;PSNR;Pose estimation;Surgery;Network architecture;Generative adversarial networks","","2","","15","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"CMOS Implementation of Spiking Equilibrium Propagation for Real-Time Learning","B. Taylor; N. Ramos; E. Yeats; H. Li","Department of Electrical and Computer Engineering, Duke University, Durham, North Carolina, USA; Department of Electrical and Computer Engineering, Duke University, Durham, North Carolina, USA; Department of Electrical and Computer Engineering, Duke University, Durham, North Carolina, USA; Department of Electrical and Computer Engineering, Duke University, Durham, North Carolina, USA",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","283","286","Equilibrium propagation (EqProp) and its adaptations for spiking neural networks (SNN) are presented as biologically plausible alternatives to back-propagation (BP) which describe a potential low-energy means of learning complex tasks in neuromorphic hardware. These algorithms are conducive to extremely efficient analog computing approaches, but a detailed analog circuit implementation and architectural outline have not yet been presented. Furthermore, current theoretical analog designs of EqProp have not addressed synapse circuit-level implementations capable of simultaneous sensing and weight updates for real-time learning. To this end, we have designed and simulated a circuit-level implementation of a spiking EqProp neuron and synapse in CMOS 65 nm technology capable of concurrent inference and weight updates for real-time learning.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869989","Department of Energy (DOE)(grant numbers:DE-SC0021335); National Science Foundation (NSF)(grant numbers:OIA-2040588); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869989","neuromorphic;CMOS;equilibrium propagation","Neuromorphics;Neurons;Real-time systems;Biology;Robustness;Inference algorithms;Hardware","","3","","22","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Tiny-PULP-Dronets: Squeezing Neural Networks for Faster and Lighter Inference on Multi-Tasking Autonomous Nano-Drones","L. Lamberti; V. Niculescu; M. Barciś; L. Bellone; E. Natalizio; L. Benini; D. Palossi","Department of Electrical, Electronic and Information Engineering, University of Bologna, Italy; Integrated Systems Laboratory, ETH Zürich, Switzerland; Autonomous Robotics Research Center, Technology Innovation Institute, UAE; Autonomous Robotics Research Center, Technology Innovation Institute, UAE; Autonomous Robotics Research Center, Technology Innovation Institute, UAE; Department of Electrical, Electronic and Information Engineering, University of Bologna, Italy; Integrated Systems Laboratory, ETH Zürich, Switzerland",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","287","290","Pocket-sized autonomous nano-drones can revolutionize many robotic use cases, such as visual inspection in narrow, constrained spaces and ensure safer human-robot interaction due to their tiny form factor and weight - i.e., tens of grams. This compelling vision is challenged by the high level of intelligence needed aboard, which clashes against the limited computational and storage resources available on PULP (parallel-ultra-low-power) MCU class navigation and mission controllers that can be hosted aboard. This work moves from PULP-Dronet, a State-of-the-Art convolutional neural network for autonomous navigation on nano-drones. We introduce Tiny-PULP-Dronet: a novel methodology to squeeze by more than one order of magnitude model size (50× fewer parameters), and number of operations (27× less multiply-and-accumulate) required to run inference with similar flight performance as PULP-Dronet. This massive reduction paves the way towards affordable multi-tasking on nano-drones, a fundamental requirement for achieving high-level intelligence.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869931","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869931","","Visualization;Navigation;Computational modeling;Neural networks;Human-robot interaction;Inspection;Multitasking","","18","","13","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Robotic Computing on FPGAs: Current Progress, Research Challenges, and Opportunities","Z. Wan; A. Lele; B. Yu; S. Liu; Y. Wang; V. J. Reddi; C. Hao; A. Raychowdhury","School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; PerceptIn, Fremont, CA, USA; PerceptIn, Fremont, CA, USA; Department of Electronic Engineering, Tsinghua University, Beijing, China; School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","291","295","Robotic computing has reached a tipping point, with a myriad of robots (e.g., drones, self-driving cars, logistic robots) being widely applied in diverse scenarios. The continuous proliferation of robotics, however, critically depends on efficient computing substrates, driven by real-time requirements, robotic size-weight-and-power constraints, cybersecurity considerations, and dynamically changing scenarios. Within all platforms, FPGA is able to deliver both software and hardware solutions with low power, high performance, reconfigurability, reliability, and adaptivity characteristics, serving as the promising computing substrate for robotic applications. This paper highlights the current progress, design techniques, challenges, and open research challenges in the domain of robotic computing on FPGAs.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869951","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869951","","Reliability engineering;Software;Real-time systems;Software reliability;Integrated circuit reliability;Robots;Field programmable gate arrays","","8","","49","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Tiny Robot Learning: Challenges and Directions for Machine Learning in Resource-Constrained Robots","S. M. Neuman; B. Plancher; B. P. Duisterhof; S. Krishnan; C. Banbury; M. Mazumder; S. Prakash; J. Jabbour; A. Faust; G. C. H. E. de Croon; V. J. Reddi",Harvard University; Harvard University; CMU; Harvard University; Harvard University; Harvard University; Harvard University; University of Virginia; Google Brain; Delft University of Technology; Harvard University,2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","296","299","Machine learning (ML) has become a pervasive tool across computing systems. An emerging application that stress-tests the challenges of ML system design is tiny robot learning, the deployment of ML on resource-constrained low-cost autonomous robots. Tiny robot learning lies at the intersection of embedded systems, robotics, and ML, compounding the challenges of these domains. Tiny robot learning is subject to challenges from size, weight, area, and power (SWAP) constraints; sensor, actuator, and compute hardware limitations; end-to-end system tradeoffs; and a large diversity of possible deployment scenarios. Tiny robot learning requires ML models to be designed with these challenges in mind, providing a crucible that reveals the necessity of holistic ML system design and automated end-to-end design tools for agile development. This paper gives a brief survey of the tiny robot learning space, elaborates on key challenges, and proposes promising opportunities for future work in ML system design.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9870000","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9870000","","Actuators;Embedded systems;Circuits and systems;Computational modeling;Robot sensing systems;Robot learning;Hardware","","23","","49","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Low-power Autonomous Adaptation System with Deep Reinforcement Learning","J. Lee; W. Jo; S. -W. Park; H. -J. Yoo","School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; Samsung Advanced Institute of Technology (SAlT)2, Suwon, Republic of Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","300","303","Recently, a lot of autonomous systems such as self-driving have been as close to human-level due to the rapid improvement of deep neural networks (DNN). However, they only performed well in the pre-trained environment and cannot achieve the same performance for the sudden environmental changes. To resolve this issue, self-adaptation through deep reinforcement learning (DRL) has been highlighted. However, it is hard to utilize DRL in the autonomous system due to the massive memory bandwidth requirements. In this paper, we propose a low-power and high-performance DRL system with an energy-efficient DRL chip. The proposed DRL chip can seamlessly compress both weight and feature map to reduce the number of memory access. The proposed system with DRL chip demonstrates adaptation of humanoid to sudden environmental changes at Mujoco Humanoid-v2. The proposed system shows 10.3 iteration/J of training energy efficiency which is 3.9× higher than NVIDIA TX2.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9870002","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9870002","autonomous system;deep reinforcement learning;low power system;data compression;humanoid adaptation","Training;Autonomous systems;Memory management;Neural networks;Energy resolution;Humanoid robots;Reinforcement learning","","3","","8","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"An Optimization Framework for Efficient Vision-Based Autonomous Drone Navigation","M. Navardi; A. Shiri; E. Humes; N. R. Waytowich; T. Mohsenin","Department of Computer Science & Electrical Engineering, University of Maryland Baltimore County; Department of Computer Science & Electrical Engineering, University of Maryland Baltimore County; Department of Computer Science & Electrical Engineering, University of Maryland Baltimore County; US Army Research Laboratory; Department of Computer Science & Electrical Engineering, University of Maryland Baltimore County",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","304","307","Fully autonomous drones are a new emerging field that has enabled many applications such as gas source leakage localization, wild-fire detection, smart agriculture, and search and rescue missions in unknown limited communication and GPS denied environments. Artificial intelligence and deep Neural Networks (NN) have enabled applications such as visual perception and navigation which can be deployed to make drones smarter and more efficient. However, deploying such techniques on tiny drones is extremely challenging due to the limited computational resources and power envelope of edge devices. To achieve this goal, this paper proposes an efficient end-to-end optimization method for deploying deep NN models for vision-based autonomous drone navigation applications, such as obstacle avoidance and steering task. This paper formulates two different methods for implementing the NN inference phase onto tiny drones and analyzing the implementation results for each case: 1) a Cloud-IoT implementation and 2) Onboard Processing. Several models are trained with state-of-the-art scalable NN architectures and the most efficient cases in terms of computation complexity and accuracy are selected for implementation on a cloud server and several edge devices. By designing hardware-friendly NN models and optimal configuration of the implementation platforms, we were able to reach up to 97% accuracy, speed up the computation 2.3×, have 22× less complexity, and 53% energy reduction. Also, we achieve up to 25 fps on the GAP8 processor, which is enough for real-time drone navigation requirements, even when the model is running on a small IoT device.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869975","U.S. Army Research Laboratory(grant numbers:W911NF2120076); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869975","Autonomous Systems;Obstacle Avoidance;Drone Navigation","Navigation;Computational modeling;Artificial neural networks;Computer architecture;Task analysis;Integrated circuit modeling;Collision avoidance","","12","","14","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"A Buyer-traceable DNN Model IP Protection Method Against Piracy and Misappropriation","S. Wang; C. Xu; Y. Zheng; C. -H. Chang","School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","308","311","Recently proposed model functionality and attribute extraction techniques have exacerbated unauthorized low-cost reproduction of deep neural network (DNN) models for similar applications. In particular, intellectual property (IP) theft and unauthorized distribution of DNN models by dishonest buyers are very difficult to trace by existing framework of digital rights management (DRM). This paper presents a new buyer-traceable DRM scheme against model piracy and misappropriation. Unlike existing methods that require white-box access to extract the latent information for verification, the proposed method utilizes data poisoning for distributorship embedding and black-box verification. Composite backdoors are installed into the target model during the training process. Each backdoor is created by applying a data augmentation method to some clean images of a selected class. The data-augmented images with a wrong label associated with a buyer are injected into the training dataset. The ownership and distributorship of a backdoor-trained user model can be validated by querying the suspect model with a set of composite triggers. A positive suspect will output the dirty labels that pinpoint the dishonest buyer while an innocent model will output the correct labels with high confidence. The tracking accuracy and robustness of the proposed IP protection method are evaluated on CIFAR-10, CIFAR-100 and GTSRB datasets for different applications. The results show an average of 100% piracy detection rate, 0% false positive rate and 96.81 % traitor tracking success rate with negligible model accuracy degradation.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869923","National Research Foundation(grant numbers:CHFA-GC1-AW01); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869923","","Training;Degradation;Neural networks;Distributed databases;Predictive models;Robustness;Data models","","3","","22","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"A Survey on Side-Channel-based Reverse Engineering Attacks on Deep Neural Networks","Y. Liu; M. Zuzak; D. Xing; I. McDaniel; P. Mittu; O. Ozbay; A. Akib; A. Srivastava","University of Maryland, College Park; University of Maryland, College Park; University of Maryland, College Park; University of Maryland, College Park; University of Maryland, College Park; University of Maryland, College Park; University of Maryland, College Park; University of Maryland, College Park",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","312","315","Hardware side-channels have been exploited to leak sensitive information. With the emergence of deep learning, their hardware platforms have also been scrutinized for side-channel information leakage. It has been shown that the structure, weights, and input samples of deep neural networks (DNN) can all be the victim of reverse engineering attacks that rely on side-channel information leakage. In this paper, we survey existing work on hardware side-channel-based reverse engineering attacks on DNNs as well as the countermeasures.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869995","National Science Foundation(grant numbers:1953285); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869995","Reverse Engineering;Side-Channel Attacks;Deep Neural Networks","Deep learning;Circuits and systems;Reverse engineering;Neural networks;Side-channel attacks;Hardware;Resource management","","1","","34","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Sample-Specific Backdoor based Active Intellectual Property Protection for Deep Neural Networks","Y. Wu; M. Xue; D. Gu; Y. Zhang; W. Liu","College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China; NSFOCUS Information Technology CO., LTD, Beijing, China; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Electronic and Information Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, China",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","316","319","Recently, a number of researches have been proposed to protect the intellectual property (IP) of Deep Neural Network (DNN) models. However, most existing works are passive protection methods as they attempt to extract watermark from the pirated model after piracy occurs. In this paper, we propose an active IP protection method for DNN in which we utilize a variant of sample-specific backdoor attack to implement active authorization control for DNN models. During training, we mislabel all the clean images and keep the labels of backdoor instances as their ground-truth labels. Different from general backdoor trigger, we train a U-Net model to generate sample-specific trigger. This kind of trigger is sample-specific and invisible, which works as the secret key for each image and is hard to be noticed. Moreover, compared with existing active DNN IP protection methods, the proposed method can be applied in the black-box scenario. Experimental results on ImageNet and YouTube Aligned Face datasets demonstrate the effectiveness and robustness of the proposed method.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869927","National Natural Science Foundation of China(grant numbers:61602241); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869927","Deep Neural Network;Intellectual Property Protection;Active Authorization Control;Backdoor Attack;Sample-Specific Trigger","Authorization;Training;Deep learning;Video on demand;Computational modeling;Neural networks;Intellectual property","","3","","22","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Dynamic Backdoors with Global Average Pooling","S. Koffas; S. Picek; M. Conti","Delft University of Technology, The Netherlands; Radboud University, The Netherlands; University of Padua, Italy",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","320","323","Outsourced training and machine learning as a service have resulted in novel attack vectors like backdoor attacks. Such attacks embed a secret functionality in a neural network activated when the trigger is added to its input. In most works in the literature, the trigger is static, both in terms of location and pattern. The effectiveness of various detection mechanisms depends on this property. It was recently shown that countermeasures in image classification, like Neural Cleanse and ABS, could be bypassed with dynamic triggers that are effective regardless of their pattern and location. Still, such backdoors are demanding as they require a large percentage of poisoned training data. In this work, we are the first to show that dynamic backdoor attacks could happen due to a global average pooling layer without increasing the percentage of the poisoned training data. Nevertheless, our experiments in sound classification, text sentiment analysis, and image classification show this to be very difficult in practice.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869920","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869920","","Training;Sentiment analysis;Circuits and systems;Neural networks;Training data;Machine learning;Image classification","","6","","9","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Hardening DNNs against Transfer Attacks during Network Compression using Greedy Adversarial Pruning","J. O. Weiss; T. Alves; S. Kundu","Dept. of Electrical and Computer Engineering, University of Massachusetts Amherst, Amherst, MA; Dept. of Informatics and Computer Science, State University of Rio de Janeiro - UERJ, Rio de Janeiro, Brazil; Dept. of Electrical and Computer Engineering, University of Massachusetts Amherst, Amherst, MA",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","324","327","The prevalence and success of Deep Neural Network (DNN) applications in recent years have motivated research on DNN compression, such as pruning and quantization. These techniques accelerate model inference, reduce power consumption, and reduce the size and complexity of the hardware necessary to run DNNs, all with little to no loss in accuracy. However, since DNNs are vulnerable to adversarial inputs, it is important to consider the relationship between compression and adversarial robustness. In this work, we investigate the adversarial robustness of models produced by several irregular pruning schemes and by 8-bit quantization. Additionally, while conventional pruning removes the least important parameters in a DNN, we investigate the effect of an unconventional pruning method: removing the most important model parameters based on the gradient on adversarial inputs. We call this method Greedy Adversarial Pruning (GAP) and we find that this pruning method results in models that are resistant to transfer attacks from their uncompressed counterparts. Code is available at [1].","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869910","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869910","neural network;pruning;compression;adversarial robustness;transfer attack","Resistance;Deep learning;Quantization (signal);Power demand;Codes;Neural networks;Robustness","","1","","25","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"High-Fidelity Model Extraction Attacks via Remote Power Monitors","A. Dubey; E. Karabulut; A. Awad; A. Aysu","Department of Electrical and Computer Engineering, North Carolina State University, Raleigh, NC, USA; Department of Electrical and Computer Engineering, North Carolina State University, Raleigh, NC, USA; Department of Electrical and Computer Engineering, North Carolina State University, Raleigh, NC, USA; Department of Electrical and Computer Engineering, North Carolina State University, Raleigh, NC, USA",2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","328","331","This paper shows the first side-channel attack on neural network (NN) IPs through a remote power monitor. We demonstrate that a remote monitor implemented with time-to-digital converters can be exploited to steal the weights from a hardware implementation of NN inference. Such an attack alleviates the need to have physical access to the target device and thus expands the attack vector to multi-tenant cloud FPGA platforms. Our results quantify the effectiveness of the attack on an FPGA implementation of NN inference and compare it to an attack with physical access. We demonstrate that it is indeed possible to extract the weights using DPA with 25000 traces if the SNR is sufficient. The paper, therefore, motivates secure virtualization-to protect the confidentiality of high-valued NN model IPs in multi-tenant execution environments, platform developers need to employ strong countermeasures against physical side-channel attacks.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869973","NSF(grant numbers:1943245); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869973","Neural networks;model stealing;time-to-digital converters;secure virtualization","Cloud computing;Network topology;Artificial neural networks;Side-channel attacks;Machine learning;Topology;Virtualization","","4","","19","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Author Index","",,2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","60","81","Presents the author index for the conference.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869972","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869972","","","","","","","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Sponsors","",,2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"5 Sep 2022","2022","","","1","27","Presents a listing of conference sponsors.","","978-1-6654-0996-4","10.1109/AICAS54282.2022.9869912","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869912","","","","","","","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
