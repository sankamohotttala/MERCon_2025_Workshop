"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"AICAS 2024 Cover Page","",,2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","c1","c1","","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595978","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595978","","","","","","","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"AICAS 2024 Title Page","",,2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","i","i","","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595979","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595979","","","","","","","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"AICAS 2024 Copyright Page","",,2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","i","i","","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595879","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595879","","","","","","","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"AICAS 2024 Contributor Page","",,2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","i","i","","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595957","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595957","","","","","","","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"AICAS 2024 Welcome","",,2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","i","ii","","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595952","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595952","","","","","","","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"AICAS 2024 Committees","",,2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","i","i","","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595958","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595958","","","","","","","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"AICAS 2024 Speakers","",,2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","i","viii","","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595941","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595941","","","","","","","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"AICAS 2024 Awards Page","",,2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","i","vii","","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595899","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595899","","","","","","","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"AICAS 2024 Reviewers","",,2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","i","i","","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595986","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595986","","","","","","","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"AICAS 2024 TOC","",,2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","i","xxvi","","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595890","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595890","","","","","","","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"AICAS 2024 Author Index","",,2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","i","xiii","","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595984","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595984","","","","","","","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Analog Features Extractor for Ultra-Low Power Embedded AI Listening and Keyword Spotting","S. Marzetti; V. Gies; V. Barchasz; H. Barthélemy; H. Glotin","CNRS, IM2NP - UMR, Aix Marseille Université, Université de Toulon, France; CNRS, IM2NP - UMR, Aix Marseille Université, Université de Toulon, France; CNRS, IM2NP - UMR, Aix Marseille Université, Université de Toulon, France; CNRS, IM2NP - UMR, Aix Marseille Université, Université de Toulon, France; CNRS, LIS, DYNI, Université de Toulon, Aix Marseille Univ, Marseille, France",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","1","5","In this paper, a novel ultra-low power audio system is designed and tested on keyword spotting (KWS). It implements mixed (analog-digital) processing and allows always-on detection with an average power consumption of < 77 µW, detecting one word every 30 seconds. Combining mixed signal processing, it achieves 88% classification accuracy between 8 classes. It is based on an always-on Analog Features Extractor (AFE), which provides spectral information, and main processor wakes-up only when necessary for minimal power consumption. Then, this information is sampled by a low frequency ADC to compose a spectrogram processed with a Convolutional Neural Network (CNN) for classification. It can be used for long term environmental monitoring or intelligent Internet of Things (IoT) using small batteries such as a single CR2032 coin cell to reach up to 1 year of autonomy.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595968","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595968","Ultra Low-Power;Keyword Spotting;Signal Processing;Embedded System;Mixed signal processing;Analog;Digital;Embedded Artificial Intelligence;Machine Learning;Voice Detection;Long Term Monitoring;Soundscape Monitoring","Power demand;Accuracy;Low power electronics;Feature extraction;Machine listening;Batteries;Convolutional neural networks","","2","","17","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"On-Device Domain Learning for Keyword Spotting on Low-Power Extreme Edge Embedded Systems","C. Cioflan; L. Cavigelli; M. Rusci; M. de Prado; L. Benini","Integrated Systems Laboratory, ETH Zurich; Zurich Research Center, Huawei Technologies; ESAT, KU Leuven; VERSES AI; Integrated Systems Laboratory, ETH Zurich",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","6","10","Keyword spotting accuracy degrades when neural networks are exposed to noisy environments. On-site adaptation to previously unseen noise is crucial to recovering accuracy loss, and on-device learning is required to ensure that the adaptation process happens entirely on the edge device. In this work, we propose a fully on-device domain adaptation system achieving up to 14% accuracy gains over already-robust keyword spotting models. We enable on-device learning with less than 10 kB of memory, using only 100 labeled utterances to recover 5% accuracy after adapting to the complex speech noise. We demonstrate that domain adaptation can be achieved on ultra-low-power microcontrollers with as little as 806 mJ in only 14 s on always-on, battery-operated devices.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595987","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595987","On-Device Learning;Domain Adaptation;Low-Power Microcontrollers;Extreme Edge;TinyML;Noise Robustness;Keyword Spotting","Accuracy;Embedded systems;Microcontrollers;Circuits and systems;Noise;Refining;Neural networks","","3","","27","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Hardware-Friendly Lightweight Convolutional Neural Network Derivation at The Edge","L. Zhang; A. M. Eltawil; K. N. Salama","Computer, Electrical and Mathematical Science and Engineering Division, King Abdullah University of Science and Technology, Thuwal, Saudi Arabia; Computer, Electrical and Mathematical Science and Engineering Division, King Abdullah University of Science and Technology, Thuwal, Saudi Arabia; Computer, Electrical and Mathematical Science and Engineering Division, King Abdullah University of Science and Technology, Thuwal, Saudi Arabia",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","11","15","Convolutional neural networks(CNNs) have demonstrated remarkable capability and scalability in a variety of vision-related tasks. Due to privacy and latency constraints, in some scenarios, the CNNs are deployed on-site where power supply, computation power, and memory capacity are limited. These constraints hinder the traditional training or modification of CNN models, which typically involves network-scale backpropagation of the gradients. In this work, we proposed a framework enabling the derivation of lightweight models from the original model at the edge only utilizing hardware-friendly operations. In the proposed framework, all models are binary quantized and the gradients are obtained by layer-wise decision boundary matching. Hence, the whole flow can be executed with bit-wise and fixed-point arithmetic operations without network-scale gradient backpropagations. The derived model serves as a viable alternative to the original, in scenarios where the accuracy requirements are less stringent, delivering enhanced efficiencies in power and memory consumption. We validate the framework on digit recognition tasks, obtaining a better accuracy than naively deploying the same lightweight model. Furthermore, an FPGA demonstration of our framework achieved a throughput of 2.2 TOPS/s, underscoring its practical applicability.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595961","King Abdullah University of Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595961","binary neural network(BNN);FPGA accelerator;edge computing","Backpropagation;Training;Accuracy;Computational modeling;Scalability;Memory management;Throughput","","","","31","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"HeteroEML: Heterogeneous Design Methodology of Edge Machine Learning on CPU+FPGA Platform","Y. -T. Wu; T. -Y. Yen; Y. -P. Lin; B. -C. Lai","Institute of Electronics, National Yang Ming Chiao Tung University, Hsinchu, Taiwan; Institute of Electronics, National Yang Ming Chiao Tung University, Hsinchu, Taiwan; Institute of Electronics, National Yang Ming Chiao Tung University, Hsinchu, Taiwan; Institute of Electronics, National Yang Ming Chiao Tung University, Hsinchu, Taiwan",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","16","20","The diverse applications with a wide variety of machine learning (ML) models have made fast design and deployment of ML computing systems an imperative task. The integration of CPU and FPGA have become a suitable ML computing platform to concurrently support programmability on CPU as well as high performance processing on the logic of FPGA. However, deploying ML models on CPU+FPGA platforms is challenging due to increasing model complexity and the need for cross-layer optimization. This paper proposes HeteroML, a heterogeneous design methodology of edge ML on CPU+FPGA platforms. We developed a customized end-to-end compilation process of ML models. The proposed methodology is based on TVM compilation framework, and enables seamless SW/HW integration and fast and effective optimization flow. When compared to conventional CPU-based edge systems, the proposed design can attain 13.78x and 6.47x performance enhancement on VGG and YOLOv2 respectively.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595974","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595974","Heterogeneous integration;SW/HW co-design;machine learning compiler;accelerator","Computational modeling;Design methodology;Machine learning;Hardware;Real-time systems;Central Processing Unit;Integrated circuit modeling","","","","7","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"PF-Training: Parameter Freezing for Efficient On-Device Training of CNN-based Object Detectors in Low-Resource Environments","D. Chun; H. -J. Lee; H. Kim","Department of Electrical and Computer Engineering, Inter-University Semiconductor Research Center (ISRC) Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering, Inter-University Semiconductor Research Center (ISRC) Seoul National University, Seoul, Korea; Department of Electrical and Information Engineering, Research Center for Electrical and Information Technology, Seoul National University of Science and Technology, Seoul, Korea",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","21","25","There has been active research focusing on lightweight approaches for on-device CNN training. Convolutional neural network (CNN) training requires a substantial amount of computation and memory footprint, particularly when compared with inference. However, in the case of on-device training, the available resources are limited, making it particularly challenging to train CNNs on-device. This study proposes a lightweight algorithm for CNN training in low-resource environments using parameter freezing techniques. The proposed method reduces the training load by employing a batch size of one and mitigates the computational overhead by using normalization freezing and modified weight optimization techniques. Furthermore, we propose a simple algorithm based on weight distribution to select the layers for freezing, thereby enabling efficient training. The proposed method is applied to Tiny-YOLOv3, demonstrating 52.10% computation reduction, 55.79% memory footprint reduction, and 21.95% accuracy improvement compared to the fully trained fine-tuned model.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595928","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595928","on-device training;transfer learning;object detection;parameter freezing;model compression","Training;Accuracy;Quantization (signal);Memory management;Focusing;Detectors;Inference algorithms","","","","35","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"SNN Architecture for Differential Time Encoding Using Decoupled Processing Time","D. Windhager; B. A. Moser; M. Lunglmayr","Silicon Austria Labs, Intelligent Wireless Systems, Linz, Austria; JKU SAL IWS Lab, Institute of Signal Processing Johannes Kepler University, Linz, Austria; Institute of Signal Processing Johannes Kepler University, Linz, Austria",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","26","30","Spiking neural networks (SNNs) have gained attention in recent years due to their ability to handle sparse and event-based data better than regular artificial neural networks (ANNs). Since the structure of SNNs is less suited for typically used accelerators such as GPUs than conventional ANNs, there is a demand for custom hardware accelerators for processing SNNs. In the past, the main focus was on platforms that resemble the structure of multiprocessor systems. In this work, we propose a lightweight neuron layer architecture that allows network structures to be directly mapped onto digital hardware. Our approach is based on differential time coding of spike sequences and the decoupling of processing time and spike timing that allows the SNN to be processed on different hardware platforms. We present synthesis and performance results showing that this architecture can be implemented for networks of more than 1000 neurons with high clock speeds on a State-of-the-Art FPGA. We furthermore show results on the robustness of our approach to quantization. These results demonstrate that high-accuracy inference can be performed with bit widths as low as 4.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595876","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595876","Spiking neural network;hardware accelerator","Quantization (signal);Neurons;Spiking neural networks;Encoding;Robustness;Timing;Hardware acceleration","","","","17","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Stochastic Spiking Attention: Accelerating Attention with Stochastic Computing in Spiking Networks","Z. Song; P. Katti; O. Simeone; B. Rajendran","Department of Engineering, King’s College London, London, U.K.; Department of Engineering, King’s College London, London, U.K.; Department of Engineering, King’s College London, London, U.K.; Department of Engineering, King’s College London, London, U.K.",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","31","35","Spiking Neural Networks (SNNs) have been recently integrated into Transformer architectures due to their potential to reduce computational demands and to improve power efficiency. Yet, the implementation of the attention mechanism using spiking signals on general-purpose computing platforms remains ineffi-cient. In this paper, we propose a novel framework leveraging stochastic computing (SC) to effectively execute the dot-product attention for SNN-based Transformers. We demonstrate that our approach can achieve high classification accuracy (83.53%) on CIFAR-10 within 10 time steps, which is comparable to the performance of a baseline artificial neural network implementation (83.66%). We estimate that the proposed SC approach can lead to over 6.3× reduction in computing energy and 1.7× reduction in memory access costs for a digital CMOS-based ASIC design. We experimentally validate our stochastic attention block design through an FPGA implementation, which is shown to achieve 48× lower latency as compared to a GPU implementation, while consuming 15× less power.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595893","Horizon Europe; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595893","Spiking neural network;Transformer;attention;stochastic computing;hardware accelerator","Accuracy;Computational modeling;Stochastic processes;Spiking neural networks;Transformers;Mobile handsets;Task analysis","","1","","32","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Neuromorphic Event-based Line Detection on SpiNNaker","A. Gruel; A. F. Vincent; J. Martinet; S. Saïghi","Laboratoire de l’Intégration du Matériau au Système, Univ. Bordeaux, Bordeaux INP, CNRS, Talence, France; Laboratoire de l’Intégration du Matériau au Système, Univ. Bordeaux, Bordeaux INP, CNRS, Talence, France; Laboratoire I3S, Université Côte d’Azur, CNRS, Sophia-Antipolis, France; Laboratoire de l’Intégration du Matériau au Système, Univ. Bordeaux, Bordeaux INP, CNRS, Talence, France",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","36","40","The combined use of Spiking Neural Networks (SNNs) and neuromorphic data in recent years makes for a promising solution to the challenges currently raised in computer vision. Indeed, the natural match between SNNs and event data leads to improvements in terms of biological inspiration, energy savings, latency and memory use for dynamic visual data processing, especially when such networks are implemented on neuromorphic hardware. We propose to draw advantages from these technologies to propose, to the best of our knowledge, the first end-to-end neuromorphic model for straight line detection, a standard task in robotics and computer vision. Our architecture relies on SNN intrinsic dynamics and ensures the accurate detection of moving lines recorded by an event-based camera with no learning. It reaches an overall performance of over 90 % with a limited number of neurons and synapses allowing for its deployment on the neuromorphic board SpiNNaker.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595959","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595959","neuromorphic;spiking neural network;event-based camera;SpiNNaker","Adaptation models;Computer vision;Visualization;Accuracy;Neuromorphics;Neurons;Data models","","","","30","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Active Dendrites Enable Efficient Continual Learning in Time-To-First-Spike Neural Networks","L. Pes; R. Luiken; F. Corradi; C. Frenkel","Electrical Engineering Department, Eindhoven University of Technology, Eindhoven, The Netherlands; Electrical Engineering Department, Eindhoven University of Technology, Eindhoven, The Netherlands; Electrical Engineering Department, Eindhoven University of Technology, Eindhoven, The Netherlands; Microelectronics Department, Delft University of Technology, Delft, The Netherlands",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","41","45","While the human brain efficiently adapts to new tasks from a continuous stream of information, neural network models struggle to learn from sequential information without catastrophically forgetting previously learned tasks. This limitation presents a significant hurdle in deploying edge devices in real-world scenarios where information is presented in an inherently sequential manner. Active dendrites of pyramidal neurons play an important role in the brain’s ability to learn new tasks incrementally. By exploiting key properties of time-to-first-spike (TTFS) encoding and leveraging its high sparsity, we present a novel spiking neural network (SNN) model enhanced with active dendrites. Our model can efficiently mitigate catastrophic forgetting in temporally-encoded SNNs, which we demonstrate with an end-of-training accuracy across tasks of 88.3% on the test set using the Split MNIST dataset. Furthermore, we provide a novel digital hardware architecture that paves the way for real-world deployment in edge devices. Using a Xilinx Zynq-7020 SoC FPGA, we demonstrate a 100-% match with our quantized software model, achieving an average inference time of 37.3 ms and an 80.0% accuracy.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595872","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595872","Spiking Neural Networks (SNNs);Neuromorphic Computing;Continual Learning;Time-To-First-Spike (TTFS);Active Dendrites;Field Programmable-Gate Arrays (FPGAs)","Accuracy;Upper bound;Computer architecture;Spiking neural networks;Brain modeling;Hardware;Dendrites (neurons)","","","","28","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Neuromorphic Temporal Pattern Detection with Spiking Neural Networks using Synaptic Delays","H. Bulzomi; Y. Nakano; R. Bendahan; J. Martinet","i3S / CNRS / IMRA Europe, Université Côte d’Azur / IMRA, Sophia Antipolis, France; IMRA Europe IMRA, Sophia Antipolis, France; IMRA Europe IMRA, Sophia Antipolis, France; i3S / CNRS Université Côte d’Azur, Sophia Antipolis, France",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","46","50","Whereas conventional artificial neural networks rely on weights and biases to parametrize connections between neurons, spiking neural networks aim to emulate biological systems more closely by modeling synaptic delays as well. Delays, and training method to adjust them, have been studied for their potential to increase spiking neurons’ expressiveness in tasks involving processing of temporal information. Although there exists methods for training synaptic delays in order to recognize temporal patterns, those are still not widely used in the literature due to the difficulty of efficiently applying these methods to concrete tasks using real-life data. In this paper, we present a new method for identifying temporal patterns of interest from an event flow. Once these patterns are identified, specific detectors can be defined in the form of polychronous groups of spiking neurons able to extract these movements from event data. We present experimental results on both synthetic and real event data from a neuromorphic sensor, and show how our method could be used to create efficient classification systems.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595927","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595927","Neuromorphic;Event-Based Vision;Spiking Neural Networks;Temporal Pattern;Feature Extraction","Training;Neuromorphics;Neurons;Spiking neural networks;Detectors;Information retrieval;Delays","","","","14","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"RNN-Based Low Complexity High Speed Channel Estimation Architectures for Vehicular Networks","S. A. Ul Haq; B. P. Dangwal; S. Darak","Electronics and Communications Department, IIIT, Delhi, India; Electronics and Communications Department, IIIT, Delhi, India; Electronics and Communications Department, IIIT, Delhi, India",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","51","55","Wireless channel estimation (CE) in vehicular communication networks is challenging due to mobility, and various data-pilot-aided (DPA) and deep learning (DL) techniques have been proposed to improve the reliability of CE without increasing the pilot overhead. However, the complexity and latency of such approaches are a concern, especially when the wireless physical layer (PHY) is deployed on resource-constrained edge devices. In this paper, we propose a low-complexity, high-speed architecture of Recurrent Neural Network (RNN) based Gated Recurrent Unit (GRU) augmented CE and compare it with RNN-based long short-term memory (LSTM) augmented CE and other DL-based CE on the system on chip (SoC). We compare their bit-error-rate (BER) performance using end-to-end PHY over a wide range of signal-to-noise ratio (SNR) and vehicular channels. We demonstrate a significant improvement of 21 in latency over LSTM-augmented CE for nearly identical ×BER. When compared to other DL-based CE, GRU-based CE offers a latency improvement of 1.26× and 21% reductions in multipliers with significantly improved BER. For identical BER, GRU-based CE offers a latency improvement of 1.28× and 25% reductions in multipliers over DL-based CE.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595856","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595856","","Wireless communication;Performance evaluation;Recurrent neural networks;Channel estimation;Physical layer;Complexity theory;System-on-chip","","1","","20","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Low-Complexity High Speed Residual Network-Augmented Channel Estimation for mmWave Massive MIMO","A. Gulati; S. A. Ul Haq; S. Darak; V. Singh","Electronics and Communications Department, IIIT, Delhi, India; Electronics and Communications Department, IIIT, Delhi, India; Electronics and Communications Department, IIIT, Delhi, India; Electronics and Communications Department, IIIT, Delhi, India",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","56","60","This work addresses the crucial challenge of efficient design of computationally intensive channel estimation (CE) on resource-constrained edge platforms for millimeter-wave (mmWave) massive multiple-input-multiple-output (m-MIMO) in beyond 5G systems. We critically examine the performance limitation and computational bottlenecks of existing statistical CE methods such as least squares (LS) and linear minimum mean squared error (LMMSE) along with deep learning (DL) based CE. We propose a novel low-complexity high-speed CE algorithm based on Residual Network (ResNet) augmented LS (LS-ResNet) that significantly outperforms LS, LMMSE, and DL-based CE with an order of magnitude lower memory and complexity requirements than DL-based CE. The LS-ResNet offers signal-to-noise ratio (SNR) gains of 8 dB, 3 dB, and 2 dB over LS, LMMSE, and DL-based CE, respectively, for bit-error-rate (BER) of 10−3. The proposed LS-ResNet achieves remarkable speedups of nearly 1600 and 420 over DL-based CE on edge processors such as Cortex-A53 and Cortex-A9, respectively. An acceleration of existing DL-based CE with dedicated hardware is still slower than LS-ResNet on an embedded processor.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595955","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595955","Beyond-5G;mmWave;Massive MIMO;Channel Estimation;Deep Learning;Residual Network;Edge platform","Program processors;Simulation;Scalability;Millimeter wave technology;Channel estimation;Complexity theory;Millimeter wave communication","","","","20","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"A CNN-based One-shot Blind RX-side-only Equalization Scheme for High-speed SerDes links","Y. Hui; Y. Nong; H. Ma; J. Lv; L. Chen; L. Du; Y. Du","Nanjing University, Nanjing, China; Nanjing University, Nanjing, China; Nanjing University, Nanjing, China; Nanjing University, Nanjing, China; Beijing Microelectronics Technology Institute, Beijing, China; Nanjing University, Nanjing, China; Nanjing University, Nanjing, China",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","61","65","This paper proposes a Serializer/Deserializer (SerDes) equalization parameter optimization technique based on circular convolutional neural network (CNN). This method facilitates rapid and precise acquisition of optimal receiver (RX) side equalization parameters for various high-speed channel types by iterative learning processes. Upon completing neural network training, the parameter configurations are directly determined according to the current channel without iterative computation. Comparing with other equalization algorithms, it is able to optimize the equalization parameters of continuous time linear equalization (CTLE) and decision feedback equalization (DFE). Owing to the absence of iterations and RX-aligned training sequences, this approach accelerates the design and simulation of the equalizer, significantly enhancing SerDes equalization optimization efficiency.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595918","Research and Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595918","Convolutional neural network;SerDes;high-speed channel;equalization;adaptive equalization algorithm","Training;Blind equalizers;Deep learning;Convolution;Neural networks;Receivers;Decision feedback equalizers","","","","14","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"AI for Antenna Design Re-engineering: Yes, Radiation Patterns Predict Antenna Structures!","A. Gopi; E. George; R. RK; A. James","Digital University Kerala, Trivandrum, India; Digital University Kerala, Trivandrum, India; Digital University Kerala, Trivandrum, India; Digital University Kerala, Trivandrum, India",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","66","70","The identification of antenna type from radiation patterns with the view to re-engineer antenna designs using machine learning models is explored in this article. This technique can be deployed to identify the antenna type that is encapsulated or within a device without damaging the antenna. In this work, radiation patterns of different Patch, Monopole, and Dipole antenna are utilized and the dataset is increased using pixel samples with varying window shapes and sizes obtained through pixel sampling method. Different noise types including Gaussian, White, Pink, Speckle, and Salt and Pepper are added to this dataset to train and test the accuracy of different neural network models such as Convolutional Neural Network(CNN), YOLO, VG-19 Net and compared with Decision Tree, Naive Bayes,Random Forest, and K-Nearest Neighbours(KNN). The models can classify the antennas as dipole, monopole, and patch antenna with more than 98% accuracy.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595860","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595860","Antenna Pattern;Artificial Intelligence;Artificial Neural Network;Dipole Antenna;Monopole Antenna;Patch Antenna","YOLO;Accuracy;Dipole antennas;Patch antennas;Neural networks;Bayes methods;Decision trees","","2","","22","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Enhancing ASR Performance through Relative Word Frequency in OCR and Normal Word Frequency Analysis","K. Jung; S. Bae; N. -J. Kim; J. Lim; H. G. Ryu; H. -J. Lee",Chung-Ang University; Seoul National University; Seoul National University; Seoul National University; NVIDIA; Seoul National University,2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","71","74","With the growing interest in Conversational AI, a system that enables machines to engage in human-like dialogues, there has been an increased focus on Automatic Speech Recognition (ASR) as an essential component of Conversational AI. Despite ongoing research, ASR performance still falls short in real-life applications such as academic lectures with technical terms. This paper proposes methods to enhance the recognition of technical terms frequently used in academic lectures, thereby improving overall ASR performance. The proposed method is an improvement on the method of analyzing the ratio between the frequency of words extracted by Optical Character Recognition (OCR) and the frequency of common words to accurately recognize technical terms. It was made based on the Power law, which is widely used in the scientific community. The experimental result showed that the reduction of the Word Error Rate (WER) up to 3.22% from the 108 hours of ‘Advanced Compiler’ lecture is achieved.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595962","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595962","Power law;Automatic Speech Recognition;Relative Word Frequency;Normal Word Frequency;Optical Character Recognition","Radio frequency;Accuracy;Error analysis;Circuits and systems;Optical character recognition;Data processing;Noise measurement","","1","","11","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"An end-to-end RNS CNN Accelerator","V. Sakellariou; V. Paliouras; I. Kouretas; H. Saleh; T. Stouraitis","Electrical Engineering and Computer Science Department, Khalifa University, Abu Dhabi, UAE; Electrical and Computer Engineering Department, University of Patras, Patras, Greece; Electrical and Computer Engineering Department, University of Patras, Patras, Greece; Electrical Engineering and Computer Science Department, Khalifa University, Abu Dhabi, UAE; Electrical Engineering and Computer Science Department, Khalifa University, Abu Dhabi, UAE",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","75","79","This work presents a Residue Numbering System (RNS)-based Convolutional Neural Network (CNN) accelerator. The proposed system is fully RNS-based, requiring no intermediate conversions to a binary representation. RNS operation overhead is minimized by designing the architecture in such a way that the usage of the non-trivial RNS operations is amortized over a large number of MAC operations. This allows to exploit their periodic usage and further reduce power consumption through clock-gating. Implementation results on a 22-nm process, show that RNS can not only increase the maximum achievable frequency of the arithmetic circuits, but also results in 58% more energy-efficient processing, compared to the traditional binary counterparts. Compared to the state-of-the-art, RNS-based CNN accelerator, the proposed architecture is shown to be 8.5× more energy efficient, with an average energy efficiency of 1.91 TOPS/W.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595885","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595885","","Power demand;Circuits;Benchmark testing;Energy efficiency;Convolutional neural networks;Artificial intelligence;Arithmetic","","","","15","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"A 28nm 343.5fps/W Vision Transformer Accelerator with Integer-Only Quantized Attention Block","C. -C. Lin; W. Lu; P. -T. Huang; H. -M. Chen","International College of Semiconductor Technology, National Yang Ming Chiao Tung University, Taiwan; Institute of Electronics, National Yang Ming Chiao Tung University, Taiwan; International College of Semiconductor Technology, National Yang Ming Chiao Tung University, Taiwan; Institute of Electronics, National Yang Ming Chiao Tung University, Taiwan",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","80","84","Vision Transformer (ViT) has achieved state-of-the-art performance on various computer vision tasks. For the mobile/edge device, the energy efficiency is the most important issue. However, ViT requires huge computation and storage, which makes it difficult to be deployed on mobile/edge device. In this work, we focus on algorithm level and hardware level to improve efficiency of ViT inference. At algorithm level, we proposed energy efficient ViT model by adopting 4bit Quantization and Low-Rank Approximation to convert all the non-linear functions with floating point (FP) values in Multi-Head Attention (MHA) to linear function with integer (INT) values, to decrease the overhead caused by computation and storage. There are less accuracy drop compare with full-precision (<1.5%). At hardware level, we design an energy efficient row-based pipelined ViT accelerator for on-device inference. The proposed accelerator is consisted of integer-only quantizer, integer MACs PE array used for executing quantization and matrix operations, and approximated linear block adopted for executing low-rank approximation. As we know, in the research of ViT, this is the first accelerator uses 4-bits quantization and designs quantizer to operate integer-only quantization for on-device inference. This work can achieve energy efficiency of 343.5 fps/W and improve up to 8x energy efficiency compare to state-of-art works.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595969","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595969","Vision Transformer (ViT);On-Device Inference;Integer-Only Quantization;Low-Rank Approximation","Quantization (signal);Accuracy;Computational modeling;Transformers;Approximation algorithms;Taylor series;Energy efficiency","","","","18","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"A 54.61-GOPS 96.35-mW Digital Logic Accelerator For Underwater Object Recognition DNN Using 40-nm CMOS Process","C. -C. Wang; S. -H. Luo; H. -C. Wu; R. G. B. Sangalang; C. -P. Jou; H. Hsia; L. -C. Cho","Dept. of Electrical Engineering, National Sun Yat-Sen University, Kaohsiung, Taiwan; Dept. of Electrical Engineering, National Sun Yat-Sen University, Kaohsiung, Taiwan; Dept. of Electrical Engineering, National Sun Yat-Sen University, Kaohsiung, Taiwan; Dept. of Electrical Engineering, National Sun Yat-Sen University, Kaohsiung, Taiwan; Taiwan Semiconductor Manufacturing Company, Hsinchu, Taiwan; Taiwan Semiconductor Manufacturing Company, Hsinchu, Taiwan; Taiwan Semiconductor Manufacturing Company, Hsinchu, Taiwan",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","85","89","CNN (convolution neural network) and DNN (deep neural network) have been widely used in real-time artificial intelligent (AI) applications, particularly image or video recognitions, because they have been proved physically in many occasions. However, most prior AI hardware works are either suffered from high on-silicon area cost or low usage thereof. This paper presents a power efficient and high performance implementation of a digital logic accelerator (DLA) for the usage of real-time underwater object recognition. The proposed DLA is also featured with 2-dimentional PE (processing element) array to increase the processing throughput by the enhancement of parallelism. The design was realized and fabricated using TSMC 40-nm CMOS process. Not only the post-layout simulation results are shown, the on-silicon measurement outcome is also demonstrated to prove the function correctness and the performance. The area efficiency (GOPS/mm2) is 4.562, and the power efficiency (TOPS/W) is 0.5668 on silicon, which both are the best to date.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595977","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595977","deep neural networks (DNN);digital logic accelerator (DLA);deep learning;chip measurement;high degree of parallelism","Artificial neural networks;Parallel processing;Streaming media;CMOS process;Throughput;Real-time systems;Frequency measurement","","","","8","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"A 266.7 TOPS/W Computing-in Memory Using Single-Ended 6T 4-kb SRAM in 16-nm FinFET CMOS Process","C. -Y. Lo; L. K. Santos Tolentino; J. -Y. Ke; J. S. Walling; Y. Yi; C. -C. Wang","Department of Electrical Engineering, National Sun Yat-Sen University, Kaohsiung, Taiwan; Department of Electrical Engineering, National Sun Yat-Sen University, Kaohsiung, Taiwan; Department of Electrical Engineering, National Sun Yat-Sen University, Kaohsiung, Taiwan; Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA; Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA; Department of Electrical Engineering, National Sun Yat-Sen University, Kaohsiung, Taiwan",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","90","94","To minimize substantial energy and transmission latency cost caused by the von Neumann bottleneck, a novel computing-in-memory (CIM) architecture utilizing a single-ended 6T 4-kb SRAM in 16-nm 1P11M FinFET process is proposed in this paper. The use of the single-ended 6T SRAM is the CIM’s defining feature; the path directly connecting from the complement bitline (BLB) to Q was removed. By altering the value of Qb, write operations of 0 or 1 could be performed. Then, employing ultra-low threshold voltage (ULVT) transistors in the 2T Switch eliminates the need of a current compensation circuit and its corresponding coupled capacitor used in avoiding charge-sharing problems. Moreover, employing ULVT devices in the Control Circuits for both SRAM core array and CIM core minimizes the delay in these circuits due to the Vth drop in the 16-nm technology node with ultra-low supply voltage. This CIM enables the performance of operations such as addition, signed multiplication, and Boolean logical functions which are necessary for convolutional neural networks (CNN). At a maximum frequency of 1 GHz, it achieves an energy efficiency of 266.7 TOPS/W and area efficiency of 470.588 GOPS/mm2 as evidenced by post-layout simulation results.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595553","National Science and Technology Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595553","computing-in-memory (CIM);convolution;FinFET;SRAM;von Neumann bottleneck","Performance evaluation;Random access memory;In-memory computing;FinFETs;Common Information Model (computing);Energy efficiency;Threshold voltage","","1","","14","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"GA-Optimized 6.0-Gbps DDR5 SDRAM I/O Buffer Design for 16-nm FinFET CMOS Process","J. -Y. Ke; L. K. Santos Tolentino; C. -Y. Lo; T. -J. Lee; C. -C. Wang","Department of Electrical Engineering, National Sun Yat-Sen University, Kaohsiung, Taiwan; Department of Electrical Engineering, National Sun Yat-Sen University, Kaohsiung, Taiwan; Department of Electrical Engineering, National Sun Yat-Sen University, Kaohsiung, Taiwan; Department of Electrical Engineering, National Sun Yat-Sen University, Kaohsiung, Taiwan; Department of Electrical Engineering, National Sun Yat-Sen University, Kaohsiung, Taiwan",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","95","99","DDR5 SDRAMs have many requirements of duty cycle, system voltage, slew rate, etc., so that a specialized design approach for FinFET-based I/O buffers is needed. Genetic algorithm (GA) was used to model process, voltage, and temperature (PVT) variations to determine how temperature and voltage affect the I/O buffer’s characteristics. Interestingly, the study found that the temperature detector circuit was unnecessary, saving power and space. However, voltage variations significantly affected the slew rate. A new Voltage Detector circuit using ultra-low threshold voltage (ULVT) transistors was introduced. The innovative Voltage Level Converter circuit, Pre-Driver, and Digital Logic Control circuits improved the slew rate and throughput while stabilizing Output Buffer Stage. TSMC’s 16-nm FinFET CMOS technology implemented the I/O buffer, where its core area was 0.19339×0.056957 mm2. The device operated reliably at 6.0 Gbps, with a slew rate of 8.93 V/ns (0.8 V VDDIO) and 14.7 V/ns (1.2 V VDDIO maximum), and a duty cycle of 48.4% (0.8 V VDDIO) to 51.8% (1.2 V VDDIO maximum). By auto-tuning the driving current, high and low voltage modes attained a 19% and 30% increase in SR improvement, respectively.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595891","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595891","I/O buffer;DDR5;FinFET;genetic algorithm;slew rate","Temperature;Voltage fluctuations;Detectors;FinFETs;Threshold voltage;SDRAM;Integrated circuit reliability","","1","","17","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"DualNet: Efficient Integration of Artificial Neural Network and Spiking Neural Network with Equivalent Conversion","S. Hong; S. Kim; S. Kim; H. -J. Yoo","KAIST, Daejeon, Republic of Korea; KAIST, Daejeon, Republic of Korea; KAIST, Daejeon, Republic of Korea; KAIST, Daejeon, Republic of Korea",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","100","104","In this paper, we propose Dual Neural Network (DualNet), which integrates ANN and SNN into a single network with layer-by-layer combinations, resulting in high energy efficiency and accuracy. We introduce ANN-to-SNN equivalent conversion (ASEC) that converts ANN layers to the arithmetically equivalent SNN layers without any conversion error. This method enables the transfer of activation between SNN patches and ANN patches while maintaining the equivalence. Also, we propose a computational domain selection method to allocate the domain of each input patch between ANN and SNN for computational cost minimization. As a result, DualNets show no accuracy loss compared to ANNs on large-scale datasets such as CIFAR10 (94.13% top-1), CIFAR100 (72.78% top-1), and ImageNet (72.03% top-1), while their computational energy is up to 47.8% lower than ANNs and up to 35.1% lower than SNNs. The experimental results clearly show that DualNets outperform ANNs and SNNs in terms of accuracy and computational cost.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595881","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595881","Spiking Neural Network (SNN);Artificial Neural Network (ANN);ANN-to-SNN Conversion;Accuracy;Energy-efficiency","Energy consumption;Accuracy;Quantization (signal);Firing;Circuits and systems;Spiking neural networks;Minimization","","","","21","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Memory-Centric Computing for Image Classification Using SNN with RRAM","N. AbuHamra; B. Mohammad","Department of Electrical Engineering and Computer Science, Khalifa University, Abu Dhabi, UAE; Department of Electrical Engineering and Computer Science, Khalifa University, Abu Dhabi, UAE",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","105","109","Neuromorphic computing, exemplified by spiking neural networks (SNN), seeks to replicate human brain functionality through event-driven processes, encoding information via spikes, and adopting biological learning principles. Its comparative advantage over traditional computing lies in the event-driven nature of computations, promising notably high energy efficiency. However, the hardware implementation of SNN poses limitations for various applications. This study proposes an In-memory Computing (IMC) approach, utilizing a Resistive RAM-based (RRAM) crossbar array to expedite the SNN algorithm. The investigation scrutinizes the accuracy of three network variants—fp32, fp16, and int8—utilizing different data types. Remarkably, by reducing the datasize to one fourth of the original size, the accuracy increased by 1.17% after retraining. Additionally, quantizing the network from fp32 to 8-bit fixed point, and using an RRAM crossbar array, yielded savings of ~1634x in memory access energy, ~1636x in memory access latency, and ∼132x in computations energy. Furthermore, utilizing the RRAM crossbar array for the acceleration of the quantized SNN algorithm yielded ∼10x reduction in average power consumption per inference, and ~159x savings in required area.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595912","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595912","AI accelerator;SNN;LIF neuron;RRAM crossbar;IMC","Accuracy;Power demand;Neuromorphic engineering;Spiking neural networks;Inference algorithms;Hardware;Energy efficiency","","","","11","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"SPVT: Spiked Pyramid Vision Transformer","Y. Guo; Y. Qin; S. Chen; Y. Kang","University of Science and Technology of China, Hefei, China; University of Science and Technology of China, Hefei, China; University of Science and Technology of China, Hefei, China; University of Science and Technology of China, Hefei, China",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","110","113","Spiking Neural Networks (SNNs), characterized by spike-based inputs and outputs, exhibit lower power consumption but typically demonstrate modest network performance. On the other hand, the Transformer model excels in image classification, yet its high parameter and computation requirements result in increased energy consumption, posing a significant challenge. This paper introduces a model called Spiked Pyramid Vision Transformer (SPVT), which is structured into four stages. Each stage comprises patch embedding and encoder blocks, with the encoder block integrating spiking self-attention modules. Additionally, IF neurons are employed in SPVT, exhibiting low energy consumption. As the network depth increases, the number of output tokens gradually decreases while the channels progressively increase. Experimental results demonstrate that compared to State-of-the-Art (SOTA), SPVT improves classification accuracy (top 1) from 94.71%/77.35% to 95.53%/78.39% on CIFAR10/100 respectively while using fewer parameters (5.01M vs 9.32M) and consuming less power (238.54uJ vs 255.51uJ).","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595953","Chinese Academy of Sciences; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595953","SNN;spike;pyramid;Transformer","Energy consumption;Power demand;Accuracy;Circuits and systems;Computational modeling;Neurons;Spiking neural networks","","","","11","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"SNN-LIF Model for Glaucoma Classification","H. Chandra; A. Ghosh; R. Singh; M. B. Srinivas","R&D Intern, Reckitt, Dubai, UAE; IIT Roorkee, Roorkee, India; EEE Department, BITS Pilani Dubai Campus, Dubai, UAE; EEE Department, BITS Pilani Hyderabad Campus, Hyderabad, India",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","114","118","Glaucoma is a debilitating disease, that affects tens of millions of people worldwide. It causes optic nerve damage, that leads to a loss of vision. This makes its detection pertinent at an earlier stage. Several machine learning and deep learning approaches have been proposed in the past to classify the retinal fundus images into healthy and diseased. Traditional artificial neural networks (ANNs), which are used to classify images, have been known to be computationally expensive. On the other hand, spiking neural networks (SNNs) are computationally efficient given the binary spike-driven nature. However, datasets for SNN training are hard to find given the event-based data that SNN requires. Here we propose a novel hybrid ANN-SNN based glaucoma classifier, with multiple SNN-LIF layers in between the ANN layers. This does not require encoding the input pixel data into spikes which may be a bottleneck for several datasets. The proposed model has been trained and tested on the G1020 dataset, and achieves an accuracy score of 60%, recall score of 61%, precision score of 59%, and F1 score of 59.8%.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595951","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595951","Spiking Neural Networks;LIF model;Glaucoma Fundus Classification;Surrogate learning","Glaucoma;Training;Optical losses;Accuracy;Computational modeling;Spiking neural networks;Retina","","","","26","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Self-Resetting Magnetic Tunnel Junction Neuron-based Spiking Neural Networks","A. H. Lone; D. N. Rahimi; H. Fariborzi; G. Setti","CEMSE Division, KAUST, Saudi Arabia; CEMSE Division, KAUST, Saudi Arabia; CEMSE Division, KAUST, Saudi Arabia; CEMSE Division, KAUST, Saudi Arabia",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","119","123","Spintronic devices such as the magnetic tunnel junction show significant potential for energy-efficient neuromorphic computing applications. This paper presents a spintronic magnetic tunnel junction neuromorphic device capable of integration, spike, and self-reset neuron characteristics. The spin-orbit drives the neuron magnetization dynamics, which controls the neuron characteristics. The input pixels are encoded in the amplitude of the current, which controls the spiking frequency of the neuron. We model the neuron characteristics into a compact model to integrate the proposed spiking neuron into a 3-layer SNN and CSNN architecture. We train and test the spiking neuron model to classify the MNIST and FMNIST datasets. The network achieves classification accuracy above 97% on MNIST and 91% on FMNIST. Considering the classification performance, self-resetting functionality, and nanosecond operation range, the proposed device shows a substantial potential for energy-efficient neuromorphic computing.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595898","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595898","Spiking neural networks (SNN);spiking neurons;Magnetic tunnel junction;Spintronics;and Neuromorphic Computing","Neuromorphic engineering;Neurons;Spiking neural networks;Computer architecture;Nanoscale devices;Hardware;Energy efficiency","","","","28","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Driving Towards Safety: Online PPG-based Drowsiness Detection with TCNs","P. M. Rapa; M. Orlandi; A. Amidei; A. Burrello; R. Rabbeni; P. Pavan; L. Benini; S. Benatti","University of Bologna, Bologna, Italy; University of Bologna, Bologna, Italy; University of Modena and Reggio Emilia, Modena, Italy; Polytechnic University of Turin, Turin, Italy; Maserati, Modena, Italy; University of Modena and Reggio Emilia, Modena, Italy; University of Bologna, Bologna, Italy; University of Bologna, Bologna, Italy",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","124","128","Increasing driver and driving safety is one of the most compelling needs of the automotive industry, both in terms of economic and social impact. Current approaches primarily focus on analyzing unsafe vehicle behavior, often overlooking the critical factor of the driver’s physiological state. This paper introduces a novel solution leveraging temporal convolutional networks (TCNs) for unobtrusive driver drowsiness detection based on photoplethys-mography (PPG). PPG data is collected seamlessly using sensors integrated into the steering wheel, providing a non-invasive assessment of the autonomic nervous system (ANS). We benchmarked our model on 16 subjects using a leave-one-subject-out (LOSO) cross-validation scheme, achieving an average accuracy of 77.03%. The model also shows good performance in avoiding false alarms when the driver is alert with a false positive ratio of just 8.21% and correctly detecting drowsiness with a low false negative ratio of 13.92%, improving the state-of-the-art for PPG based approaches. A quantized version of the model is deployed on a commercial ultra-low-power (ULP) system-on-a-chip (SoC), demonstrating real-world feasibility with an inference time of 4.8 ms and energy per inference of 117 μJ. This work represents a significant step towards unobtrusive, real-time physiological monitoring in driving environments, contributing to the ongoing efforts to improve driver’s safety.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595972","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595972","","Accuracy;Computational modeling;Scalability;Wheels;Sensor systems;Safety;Sensors","","","","18","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"SVD-based Peephole and Clustering to Enhance Trustworthiness in DNN Classifiers","L. Manovi; L. Capelli; A. Marchioni; F. Martinini; G. Setti; M. Mangia; R. Rovatti","DEI, University of Bologna, Italy; DEI, University of Bologna, Italy; DEI, University of Bologna, Italy; DEI, University of Bologna, Italy; ARCES, University of Bologna, Italy; DEI, University of Bologna, Italy; DEI, University of Bologna, Italy",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","129","133","Deep Neural Networks have demonstrated impressive capabilities across various domains, yet their inherent complexity often obscures the rationale behind their predictions. This opacity poses challenges in domains where explainability is critical. Here, we present a novel methodology inspired by signal processing that leverages Singular Value Decomposition to both remove the redundancy in the neural network and derive compressed feature representations to be analyzed with clustering. We carried out empirical experiments with a network of the VGG family trained on CIFAR-10 and FMNIST datasets, and propose two strategies to address the trustworthiness issue in AI decisions.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595919","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595919","interpretability;trustworthiness;deep neural networks;singular value decomposition;clustering","Circuits and systems;Redundancy;Artificial neural networks;Signal processing;Vectors;Complexity theory;Artificial intelligence","","","","25","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Strategic Deployment of Honeypots in Blockchain-based IoT Systems","D. Commey; S. Hounsinou; G. V. Crosby","Multidisciplinary Engineering, Texas A&M University, Texas, USA; Computer Science & Cybersecurity, Metro State University, Minnesota, USA; Engineering Technology & Industrial Distribution, Texas A&M University, Texas, USA",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","134","138","This paper addresses the challenge of enhancing cybersecurity in Blockchain-based Internet of Things (BIoTs) systems, increasingly vulnerable to sophisticated cyberattacks. It introduces an AI-powered system model for the dynamic deployment of honeypots, utilizing an Intrusion Detection System (IDS) integrated with smart contract functionalities on IoT nodes. This model enables the transformation of regular nodes into decoys in response to suspicious activities, thereby strengthening the security of BIoT networks. Through a game-theoretic model, specifically Bayesian games, the paper analyses strategic interactions between potential attackers and the AI-enhanced IDS. The model focuses on understanding and predicting sophisticated attacks that may initially appear normal, emphasizing strategic decision-making, optimized honeypot deployment, and adaptive strategies in response to evolving attack patterns.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595866","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595866","Blockchain;Internet of Things;Honeypots;AI-powered Intrusion Detection System;Game Theory","Adaptation models;Biological system modeling;Smart contracts;Refining;Intrusion detection;Games;Predictive models","","1","","17","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Is Semantic Communication for Autonomous Driving Secured against Adversarial Attacks?","S. Ribouh; A. Hadid","Univ Rouen Normandie, INSA Rouen Normandie, Université Le Havre Normandie, Normandie Univ, LITIS UR 4108, Rouen, France; Sorbonne Center for Artificial Intelligence, Sorbonne University Abu Dhabi, United Arab Emirates",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","139","143","Artificial intelligence (AI) has emerged as a key driver toward the development of the next generation of wireless communication systems (6G), where deep learning (DL) has been widely used for designing the semantic communication modules. However, the utilization of deep neural networks (DNN) may increase the vulnerability of the semantic communication to adversarial attacks. In this paper, we introduce a state-of-the-art wireless semantic communication system for vision-based autonomous driving, integrating a semantic encoder/decoder for image transmission designed based on DNN architecture. We thoroughly evaluate the vulnerability of the model to various adversarial attacks. An adversarial attack consists of slightly modifying the transmitted images by adding small perturbations perhaps imperceptible to humans but harmful to the model. We inject various adversarial attacks including: Auto-PGD attack, FSGM attack, DeepFool attack, Square attack, and adversarial patch attack. Evaluated on semantic communication tasks, the experiments clearly show that semantic communication is vulnerable to adversarial attacks. This urgently calls for defense mechanisms to ensure reliability and safety of wireless semantic communication.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595916","Total; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595916","6G;Semantic communication;Adversarial attacks;Deep learning;Autonomous driving","Wireless communication;6G mobile communication;Transmitters;Semantic segmentation;Semantics;Artificial neural networks;Receivers","","2","","25","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Attacking a Joint Protection Scheme for Deep Neural Network Hardware Accelerators and Models","S. Wilhelmstätter; J. Conrad; D. Upadhyaya; I. Polian; M. Ortmanns","Institute of Microelectronics, University of Ulm, Ulm, Germany; Institute of Microelectronics, University of Ulm, Ulm, Germany; Institute for Computer Architecture and Computer Engingeering, University of Stuttgart, Stuttgart, Germany; Institute for Computer Architecture and Computer Engingeering, University of Stuttgart, Stuttgart, Germany; Institute of Microelectronics, University of Ulm, Ulm, Germany",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","144","148","The tremendous success of artificial neural networks (NNs) in recent years, paired with the leap of embedded, low-power devices (e.g. IoT, wearables and smart sensors), gave rise to specialized NN accelerators that enable the inference of NNs in power-constrained environments. However, manufacturing or operating such accelerators in un-trusted environments poses risks of undesired model theft and hardware counterfeiting. One way to protect NN hardware against those threats is by locking both the model and the accelerator with secret keys that can only be supplied by entitled authorities (e.g. chip designer or distributor). However, current locking mechanisms contain severe drawbacks, such as required model retraining and vulnerability to the powerful satisfyability checking (SAT)-attack.Recently, an approach for jointly protecting the model and the accelerator was proposed. Compared to previous locking mechanisms, it promises to avoid model retraining, not leak useful model information, and resist the SAT-attack, thereby securing the NN accelerator against counterfeiting and the model against intellectual property infringement. In this paper, those claims are thoroughly evaluated and severe issues in the technical evidence are identified. Furthermore, an attack is developed that does not require an expanded threat model but is still able to completely circumvent all of the proposed protection schemes. It allows to reconstruct all NN model parameters (i.e. model theft) and enables hardware counterfeiting.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595935","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595935","Neural Network;Inference;Accelerator;Logic Locking;Security;Protection Scheme","Threat modeling;Artificial neural networks;Resists;Robustness;Manufacturing;Security;Protection","","","","21","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"TENG: A General-Purpose and Efficient Processor Architecture for Accelerating DNN","Z. Zhang; Y. Cai; T. Liao; C. Xu; X. Jiao","State Key Laboratory of ASIC and System, Fudan University, Shanghai, China; State Key Laboratory of ASIC and System, Fudan University, Shanghai, China; SenseTime Research; SenseTime Research; SenseTime Research",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","149","153","Deep learning has been widely deployed in the fields such as computer vision and speech, etc. However, with the development of deep learning algorithms, neural networks have gradually become more complex, the subsequent computing requirements for huge amounts of data have posed greater challenges to hardware updates and improvements. In this work, a general-purpose and efficient deep neural network (DNN) accelerator is proposed, named TENG. In TENG, we proposed a unified architecture with general and dedicated coexistence to support various network operators, and the memory access engine in TENG optimizes off-chip data transmission to achieve better bandwidth utilization. The correctness of TENG is verified on FPGA and implemented in 7-nm FinFET technology. It achieves 4TOPS peak throughput@INT16 and has an energy efficiency of 5.15TOPS/W using VGG-16 at 1GHz clock frequency.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595854","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595854","Neural network;deep learning accelerator;hardware accelerator;DNN;ASIC","Deep learning;Spectral efficiency;System performance;Memory management;Artificial neural networks;Bandwidth;Throughput","","","","20","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"A Hybrid Heterogeneous Neural Network Accelerator based on Systolic Array","Z. Wang; Y. Zhong; G. Chen; S. Feng; Y. Yang; X. Cui; Y. Wang","School of Integrated Circuits, Peking University, Beijing, China; School of Integrated Circuits, Peking University, Beijing, China; School of Software and Microelectronics, Peking University, Beijing, China; School of Software and Microelectronics, Peking University, Beijing, China; School of Integrated Circuits, Peking University, Beijing, China; School of Integrated Circuits, Peking University, Beijing, China; School of Integrated Circuits, Peking University, Beijing, China",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","154","158","Spiking neural networks (SNNs) and artificial neural networks (ANNs) are two methods to achieve artificial intelligence. Realizing the long-term and ambitious ideal of a universal artificial intelligence platform requires hardware that supports both SNN and ANN models. ANNs, such as convolutional neural networks (CNNs), are adept at extracting features and have achieved outstanding achievements in many fields. Due to the event-driven processing paradigm, SNNs can achieve competitive accuracy with minimal power usage. The weight accumulation of SNN and ANN is similar, but the activation function is significantly different. How to integrate SNN and ANN on one hardware platform is a challenge. In this paper, we propose a hybrid heterogeneous neural network accelerator that can support both SNN and ANN models. It also has good compatibility with the binary neural network (BNN) models. Our design is implemented on Xilinx XCKU115 FPGA, which can achieve the peak performance of 48.51GSOP/s (SNN) and 26.38GOP/s (ANN). The energy efficiency is 25.8GSOP/W (SNN) and 12.05GOP/W (ANN). Moreover, it supports the SNN-ANN fusion mode, where each row of processing elements (PEs) can independently perform SNN or ANN computation, allowing the design to fully leverage the respective strengths of SNN and ANN.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595910","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595910","spiking neural network;artificial neural network;systolic array;FPGA","Computational modeling;Artificial neural networks;Spiking neural networks;Feature extraction;Systolic arrays;Hardware;Energy efficiency","","","","19","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Reusing Softmax Hardware Unit for GELU Computation in Transformers","C. Peltekis; K. Alexandridis; G. Dimitrakopoulos","Electrical and Computer Engineering, Democritus University of Thrace, Xanthi, Greece; Electrical and Computer Engineering, Democritus University of Thrace, Xanthi, Greece; Electrical and Computer Engineering, Democritus University of Thrace, Xanthi, Greece",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","159","163","Transformers have improved drastically the performance of natural language processing (NLP) and computer vision applications. The computation of transformers involves matrix multiplications and non-linear activation functions such as softmax and GELU (Gaussion Error Linear Unit) that are accelerated directly in hardware. Currently, function evaluation is done separately for each function and rarely allows for hardware reuse. To mitigate this problem, in this work, we map the computation of GELU to a softmax operator. In this way, the efficient hardware units designed already for softmax can be reused for computing GELU as well. Computation of GELU can enjoy the inherent vectorized nature of softmax and produce in parallel multiple GELU outcomes. Experimental results show that computing GELU via a pre-existing and incrementally modified softmax hardware unit (a) does not reduce the accuracy of representative NLP applications and (b) allows the reduction of the overall hardware area and power by 6.1% and 11.9%, respectively, on average.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595882","Siemens; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595882","","Computer vision;Accuracy;Power demand;Circuits and systems;Computer architecture;Transformers;Hardware","","","","29","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"A Low-power 3D Point Clouds Matching Processor with 1D-CNN Prediction and CAM-based In-memory kNN Searching","J. Shin; H. Jeong; S. Kim; K. Park; S. Lee; K. Lee","Department of Electrical Engineering / Graduate School of Artificial Intelligence, Ulsan National Institute of Science and Technology (UNIST), Ulsan, Republic of Korea; Department of Electrical Engineering / Graduate School of Artificial Intelligence, Ulsan National Institute of Science and Technology (UNIST), Ulsan, Republic of Korea; Department of Electrical Engineering / Graduate School of Artificial Intelligence, Ulsan National Institute of Science and Technology (UNIST), Ulsan, Republic of Korea; Department of Electrical Engineering / Graduate School of Artificial Intelligence, Ulsan National Institute of Science and Technology (UNIST), Ulsan, Republic of Korea; Department of Electrical Engineering / Graduate School of Artificial Intelligence, Ulsan National Institute of Science and Technology (UNIST), Ulsan, Republic of Korea; Department of Electrical Engineering / Graduate School of Artificial Intelligence, Ulsan National Institute of Science and Technology (UNIST), Ulsan, Republic of Korea",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","164","168","This paper presents a computing-CAM-in-memory (C2IM) system designed for energy-efficient k-nearest neighbor (kNN) operations within 3D point clouds, which is an essential process for autonomous driving applications. In mobile processors, a new paradigm is required to conduct 3D point cloud kNN searching, under the limited hardware resources. Therefore, three features are proposed: i) Prediction using a dilated 1D-CNN, which enables voxel-based partitioning by minimizing the external memory accesses from O(n2) to O(n). ii) Vertex clustering, which restructures groups of points into evenly distributed clusters based on the underlying data distribution and effectively reduces the number of points for comparison by 49.8%. iii) Data movement minimization through in-memory kNN with content addressable memory (CAM). Designed with 28 nm CMOS technology, the proposed C2IM achieves reductions of 2.07× in memory footprint and 206.68× in power consumption, compared to state-of-the-art (SOTA) architectures.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595947","National Research Foundation of Korea; IC Design Education Center; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595947","3D point cloud;k-nearest neighbor (kNN);dilated 1D-CNN;Content Addressable Memory (CAM);Processing-in-memory (PIM)","Point cloud compression;Three-dimensional displays;Program processors;Power demand;Memory management;Distributed databases;Nearest neighbor methods","","","","22","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Advancing Hardware Implementation of Hyperdimensional Computing for Edge Intelligence","E. Hassan; M. Bettayeb; B. Mohammad","Electrical Engineering and Computer Science Department, System on Chip Lab, Khalifa University of Science and Technology Abu Dhabi, United Arab Emirates; Electrical Engineering and Computer Science Department, System on Chip Lab, Khalifa University of Science and Technology Abu Dhabi, United Arab Emirates; Electrical Engineering and Computer Science Department, System on Chip Lab, Khalifa University of Science and Technology Abu Dhabi, United Arab Emirates",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","169","173","Hyperdimensional Computing (HDC) is a promising paradigm known for its energy efficiency and simplicity. Human brain functions inspire HDC, which operates in high-dimensional spaces with low-precision data, making it suitable for efficient machine-learning applications. This paper analyzes the State-of-the-Art (SOTA) significance and challenges of implementing HDC on diverse hardware platforms, including Application Specific Integrated Circuits (ASIC), Central Processing Units (CPU), and Field-Programmable Gate Arrays (FPGA), and explores its potential in In-Memory Computing (IMC). Also, the significance of hardware-accelerated Associative Memory (AM) in HDC systems is discussed, emphasizing its role in optimizing overall performance and efficiency.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595942","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595942","Hyperdimensional Computing;Encoders;Associative Memory;Hardware Implementation","Application specific integrated circuits;Associative memory;Circuits and systems;Machine learning;In-memory computing;Hardware;Energy efficiency","","2","","38","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"PyAIM: Pynq-Based Scalable Analog In-Memory Computing Prototyping Platform","M. Yu; M. Hong; S. Lee; S. Kim; J. Lee","Dept. of Electrical Engineering, Ulsan National Institute of Science and Technology (UNIST), Ulsan, Korea; AI Graduate School, Ulsan National Institute of Science and Technology (UNIST), Ulsan, Korea; Dept. of Electrical Engineering, Ulsan National Institute of Science and Technology (UNIST), Ulsan, Korea; Dept. of Electrical Engineering, Ulsan National Institute of Science and Technology (UNIST), Ulsan, Korea; Dept. of Electrical Engineering, Ulsan National Institute of Science and Technology (UNIST), Ulsan, Korea",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","174","178","Analog in-memory computing (IMC) has become increasingly popular along with the success of AI applications, especially in highly constrained environments such as IoT devices. However, many unique challenges of analog IMC including variability, faults, noise, endurance, programming disturbance, etc. make validation by hardware prototyping highly desirable. In this paper we present a reusable, extensible, and scalable prototyping platform called PyAIM, where several analog IMC devices can be connected with one another as well as with digital processors via digital interfaces and a communication network. We use a number of Pynq boards to make use of their build-in Python support and affordability as well as their decent CPUs to run some software tasks other than MVM kernels. We overcome the timing control and communication management issues by extending Python with custom C functions, while maintaining convenience of Python. We also demonstrate a high-throughput network inference system as an example of PyAIM, using multiple ReRAM chips with compute-communication pipelining.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595868","IC Design Education Center; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595868","","Program processors;Noise;Programming;In-memory computing;Software;Timing;Artificial intelligence","","","","32","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"ILP-based Multi-Branch CNNs Mapping on Processing-in-Memory Architecture","H. Han; J. Wang; B. Ding; S. Chen","University of Science and Technology of China, Hefei, China; University of Science and Technology of China, Hefei, China; University of Science and Technology of China, Hefei, China; University of Science and Technology of China, Hefei, China",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","179","183","3D-stacked-DRAM-based processing-in-memory (DRAM-PIM) architectures demonstrate benefits in memory access bandwidth and energy efficiency and effectively mitigate the storage wall challenge posed by CNNs. However, DRAM-PIM architectures have a huge mapping space for multi-branch CNNs and inadequate mapping increases the latency of CNNs and the memory requirement of nodes.In this work, we propose an integer linear programming (ILP) method that integrates layer scheduling and resource quantity allocation to minimize overall latency. An ILP-based binding method is introduced to bind layers onto a node array of DRAM-PIM architectures with the maximum memory requirement of nodes reduced. Experimental results demonstrate that our method reduces the latency of branching structures in CNNs and achieves better memory balancing between nodes compared to the baseline method.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595921","Chinese Academy of Sciences; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595921","convolutional neural network;mapping;3D-stacked DRAM;processing in memory","Circuits and systems;Memory management;Bandwidth;Integer linear programming;Energy efficiency;Resource management;Convolutional neural networks","","","","19","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"An Area and Energy-Efficient SRAM Based Time - Domain Compute-In-Memory Architecture For BNN","S. Chakraborty; D. Kushwaha; A. Bulusu; S. Dasgupta",Rajiv Gandhi Institute of Petroleum Technology; Indian Institute of Technology IIT Roorkee; Indian Institute of Technology IIT Roorkee; Indian Institute of Technology IIT Roorkee,2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","184","188","In this paper, we present an area and energy efficient SRAM based time-domain compute-in-memory (TDCIM) architecture to accelerate binary neural networks (BNNs). We have proposed an area efficient time-domain multiplication bit-cell (MC). The proposed MC is 1.5× times area efficient than state-of-the-art. The proposed TDCIM focuses on improving the energy efficiency of the multiplication and accumulation (MAC) operation. It achieves 1.6× higher energy efficiency compared to state of the art. The work uses a time domain computing approach by introducing a specific delay which is equivalent to the MAC operation performed. A proposed robust 10T1C SRAM bit cell has been used to perform in-memory XNOR operation. A time to digital converter (TDC) has been used instead of analog to digital converter (ADC) to save the power consumption. The designed architecture has been implemented using a 45 nm CMOS technology, resulting in the development of a 25×32 SRAM CIM macro. Post layout simulation results demonstrate the proposed architecture achieved an energy efficiency of 877.32 TOPS/W at VDD of 0.9 V. The architecture achieves an inference accuracy of 98.68% on the MNIST dataset.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595875","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595875","Analog;binary neural network (BNN);compute in-memory (CIM);energy efficiency;time domain computing","Accuracy;Microprocessors;Simulation;Neural networks;Computer architecture;In-memory computing;SRAM cells","","","","18","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"TNN-CIM: An In-SRAM CMOS Implementation of TNN-Based Synaptic Arrays with STDP Learning","H. Nair; D. Barajas-Jasso; Q. Jacobson; J. P. Shen","Electrical and Computer Engineering Department, Carnegie Mellon University; Electrical and Computer Engineering Department, Carnegie Mellon University; Electrical and Computer Engineering Department, Carnegie Mellon University; Electrical and Computer Engineering Department, Carnegie Mellon University",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","189","193","Temporal Neural Networks (TNNs), a special class of spiking neural networks (SNNs), process information via spike timings, analogous to the brain. Recent works have proposed microarchitecture and custom macros for directly implementing extremely energy-efficient TNNs with standard CMOS. However, prior works implement synapses using expensive register-based counters. Since synapses constitute most of the hardware complexity in TNNs, it is imperative to optimize their implementation. This work proposes TNN-CIM, an in-SRAM implementation of synaptic arrays, as a first attempt towards compute-in-memory (CIM) solution for TNNs. In TNN-CIM, not only are the synaptic weights stored in SRAM, but synaptic response function generation (inference) and spike timing dependent plasticity (learning) are also embedded directly within the SRAM array. Our results in 45nm CMOS demonstrate 1.3x and 1.7x reduction in power and area respectively while improving latency performance by 1.4x. Further, we provide transistor count equations to assess hardware complexity scaling of arbitrary TNN-CIM synaptic arrays.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595925","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595925","Temporal Neural Networks;Synaptic Arrays;STDP;SRAM;Compute-In-Memory;Neuromorphic Computing","Random access memory;Spiking neural networks;In-memory computing;Hardware;Timing;Complexity theory;Transistors","","","","23","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"End-to-End Edge Neuromorphic Object Detection System","D. A. Silva; A. Shymyrbay; K. Smagulova; A. Elsheikh; M. E. Fouda; A. M. Eltawil","Department of ECE, CEMSE Division, King Abdullah University of Science and Technology, Thuwal, Saudi Arabia; Department of ECE, CEMSE Division, King Abdullah University of Science and Technology, Thuwal, Saudi Arabia; Department of ECE, CEMSE Division, King Abdullah University of Science and Technology, Thuwal, Saudi Arabia; Department of Mathematics and Engineering Physics, Faculty of Engineering, Cairo University, Giza, Egypt; Rain Neuromorphics, Inc., San Francisco, CA, USA; Department of ECE, CEMSE Division, King Abdullah University of Science and Technology, Thuwal, Saudi Arabia",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","194","198","Neuromorphic accelerators are emerging as a potential solution to the growing power demands of Artificial Intelligence (AI) applications. Spiking Neural Networks (SNNs), which are bio-inspired architectures, are being considered as a way to address this issue. Neuromorphic cameras, which operate on a similar principle, have also been developed, offering low power consumption, microsecond latency, and robustness in various lighting conditions. This work presents a full neuromorphic system for Computer Vision, from the camera to the processing hardware, with a focus on object detection. The system was evaluated on a compiled real-world dataset and a new synthetic dataset generated from existing videos, and it demonstrated good performance in both cases. The system was able to make accurate predictions while consuming 66mW, with a sparsity of 83%, and a time response of 138ms.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595906","King Abdullah University of Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595906","SNN;DVS;Neuromorphic;Akida;YOLO","Power demand;Neuromorphics;Object detection;Spiking neural networks;Cameras;Robustness;Time factors","","","","35","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Fast Object Detection Algorithm using Edge-based Operation Skip Scheme with Viola-Jones Method","C. -H. Choi; J. Han; J. Cha; J. Shin; H. W. Oh","Pangyo Research and Development (R&D) Center Hanwha Systems, Co., Ltd., Seongnam, Republic of Korea; Pangyo Research and Development (R&D) Center Hanwha Systems, Co., Ltd., Seongnam, Republic of Korea; Pangyo Research and Development (R&D) Center Hanwha Systems, Co., Ltd., Seongnam, Republic of Korea; Pangyo Research and Development (R&D) Center Hanwha Systems, Co., Ltd., Seongnam, Republic of Korea; Pangyo Research and Development (R&D) Center Hanwha Systems, Co., Ltd., Seongnam, Republic of Korea",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","199","203","Machine learning approaches are preferred over deep learning in embedded systems due to their resource efficiency. The widely adopted Viola-Jones method and related algorithms are selected for their high detection accuracy and reasonable processing speed. However, a limitation arises as processing time increases with additional classification iterations based on sub-window operations. To address this issue, we propose an enhanced object detection algorithm that incorporates the Viola-Jones method with edge component calibration and an edge-based operation skip scheme. The introduction of edge component calibration ensures detection performance comparable to conventional methods. This scheme, relying on edge values, significantly reduces unnecessary computations in the background, leading to a marked decrease in classification operations compared to conventional methods. Visual comparisons in experimental results demonstrate that our method increases the detection precision factor while maintaining recall. In terms of classification operations, our approach reduces their number by 31.38% to 85.78% compared to conventional methods. In simpler terms, our method improves processing speed by minimizing classification operations, making it well-suited for embedded systems with limited resource utilization.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595932","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595932","Object detection;Machine learning;Viola-Jones method;Skip scheme;Wavelet transform","Visualization;Embedded systems;Machine learning algorithms;Image edge detection;Object detection;Transforms;Classification algorithms","","","","9","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"An Efficient and Fast Filter Pruning Method for Object Detection in Embedded Systems","H. Ko; J. -K. Kang; Y. Kim","Department of Electrical and Computer Engineering, Inha University, Incheon, Republic of Korea; Department of Electrical and Computer Engineering, Inha University, Incheon, Republic of Korea; Department of Technology Education, Korea National University of Education, Cheongju, Republic of Korea",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","204","207","Recently, CNN-based networks have exhibited high performance in computer vision. On the other hand, due to the networks becoming deeper and wider, it is hard to implement the model in real-time embedded environments. To overcome the drawback, filter pruning has been widely studied for neural network compression. Filter pruning does not need any special hardware or software because it removes filters of CNN and accelerates inference without any special software or hardware. In this paper, we proposed efficient and fast filter pruning (EFFP), which focuses on reducing the training computation resources and searching optimal pruned networks. The success stems from two significant improvements upon other pruning methods. (1) Short training time: In the pruning stage, we make redundant filters to zero to make the output feature map the same as a lightweight model, and (2) adjust the change of redundancy using regrowing: It is difficult to get an optimal pruned model by pruning redundant filters at once. Therefore, we use the pruning/regrowing method to gradually remove unimportant filters to avoid permanently pruning important filters to get an optimal lightweight model. Experimental results indicate that EFFP can reduce the FLOPs and parameters more efficiently and faster than other pruning methods on the object detection model. The inference time is measured on NVIDIA Jetson Xavier NX. As a result, we improve mAP and inference time by a maximum of 45 % compared to other pruning methods.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595873","National Research Foundation of Korea; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595873","CNN;Network compression;Filter pruning;Object detection;Inference time","Training;Computational modeling;Redundancy;Object detection;Search problems;Software;Loss measurement","","","","13","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"LATTE: Low-Precision Approximate Attention with Head-wise Trainable Threshold for Efficient Transformer","J. -P. Wang; M. -G. Lin; A. -Y. A. Wu","Graduate Institute of Electronics Engineering, National Taiwan University, Taipei, Taiwan; Graduate Institute of Electronics Engineering, National Taiwan University, Taipei, Taiwan; Graduate Institute of Electronics Engineering, National Taiwan University, Taipei, Taiwan",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","208","212","With the rise of Transformer models in NLP and CV domain, Multi-Head Attention has been proven to be a game-changer. However, its expensive computation poses challenges to the model throughput and efficiency, especially for the long sequence tasks. Exploiting the sparsity in attention has been proven to be an effective way to reduce computation. Nevertheless, prior works do not consider the various distributions among different heads and lack a systematic method to determine the threshold. To address these challenges, we propose Low-Precision Approximate Attention with Head-wise Trainable Threshold for Efficient Transformer (LATTE). LATTE employs a head-wise threshold-based filter with the low-precision dot product and computation reuse mechanism to reduce the computation of MHA. Moreover, the trainable threshold is introduced to provide a systematic method for adjusting the thresholds and enable end-to-end optimization. Experimental results indicate LATTE can smoothly adapt to both NLP and CV tasks, offering significant computation savings with only a minor compromise in performance. Also, the trainable threshold is shown to be essential for the leverage between the performance and the computation. As a result, LATTE filters up to 85.16% keys with only a 0.87% accuracy drop in the CV task and 89.91% keys with a 0.86 perplexity increase in the NLP task.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595864","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595864","transformer;sparse attention;trainable thresh-old","Systematics;Accuracy;Filtering;Computational modeling;Transformers;Throughput;Computational efficiency","","1","","13","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Exploration for Efficient Depthwise Separable Convolution Networks Deployment on FPGA","Z. Huang; A. Qie; C. Zhang; J. Yang; X. Wang","School of Electronic and Computer Engineering, Peking University; School of Electronic and Computer Engineering, Peking University; School of Electronic and Computer Engineering, Peking University; School of Electronic and Computer Engineering, Peking University; School of Electronic and Computer Engineering, Peking University",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","213","217","Depthwise Separable Convolution (DSC) has become the key structure in lightweight convolutional neural networks. However, the tight connection between network structure and hardware architecture has not received enough attention, resulting in inefficient hardware performance and resource utilization. In this paper, we propose a software-hardware co-design framework to explore the efficient hardware deployment for DSC networks. Begin with the analysis of network structure, the proposed framework employs pointwise-depthwise convolution layer-chaining to reduce on-chip memory. Furthermore, a multi-objective optimization mathematical model is proposed to explore the optimal architecture that balances both performance and resource utilization. Additionally, we optimize the hardware design with reconfigurable line buffers, DSP multiplications optimization, and deploying standard-depthwise convolution pipeline computation. Compared with reference designs, the simulation results show the proposed framework can at least reduce computation time by 19.1% and improve the DSP utilization by 27.5%. MobileNetV2 is implemented on Xilinx XC7Z020 FPGA, the proposed design achieves the best computation resource efficiency of 0.58 GOPS/DSP, with on-chip memory of only 3.2 Mb.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595964","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595964","Software-hardware co-desgin;depthwise separable convolution;multi-objective optimization","Convolution;Simulation;Memory management;Pipelines;Hardware;System-on-chip;Computational efficiency","","","","11","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Exploring Memory Access Techniques for Efficient FPGA based 3D CNN Accelerator Design","F. H. Khan; M. Adeel Pasha; S. Masud","Department of Electrical Engineering, Lahore University of Management Sciences (LUMS), Lahore, Pakistan; Department of Electrical Engineering, Lahore University of Management Sciences (LUMS), Lahore, Pakistan; Department of Electrical Engineering, Lahore University of Management Sciences (LUMS), Lahore, Pakistan",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","218","222","Recent advancements in 3D Convolutional Neural Network (CNN) architectures have demonstrated superior performance across diverse computer vision tasks, albeit with a trade-off of intense computational and memory demands. Thus, the tiling of incoming data becomes mandatory for 3D CNN acceleration in memory-constrained platforms such as Field Programmable Gate Arrays (FPGA). In this paper, different memory access techniques are explored to reduce the data traffic between on-chip and off-chip memories during the inference stage of a 3D CNN. The most suitable data traffic mode is identified by considering multiple parameters like latency, on-chip memory utilization and off-chip memory access. A parameterized and modular design approach for 3D CNNs has been implemented on an FPGA, where the input and weight data mapping modules are designed to minimize the on-chip memory requirements. These modules are parameterized for variable tiling sizes and different memory access modes while the main computation is performed on a systolic-array-based pipelined architecture. The experiments conducted on three widely adopted 3D networks, I3D, C3D, and R(2+1)D, have shown 16%, 28%, and 10% improvement in latency respectively. The proposed methodology also results in a lower energy dissipation profile.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595963","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595963","3D CNNs;Parameterized Hardware Accelerator;FPGA;Memory Access Optimization;Systolic Architecture","Three-dimensional displays;Memory management;Random access memory;Parallel processing;Logic gates;Hardware;System-on-chip","","","","20","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Towards Automated FPGA Compilation of Spiking Neural Networks","A. Shymyrbay; M. E. Fouda; A. Eltawil","Department of ECE, CEMSE Division, King Abdullah University of Science and Technology, Thuwal, Saudi Arabia; Rain Neuromorphics, Inc., San Francisco, CA, USA; Department of ECE, CEMSE Division, King Abdullah University of Science and Technology, Thuwal, Saudi Arabia",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","223","227","Edge computing and the Internet of Things (IoT) have created a growing demand for low-cost and low-power field programmable gate arrays (FPGAs) to facilitate rapid and efficient processing. At the same time, spiking neural networks (SNNs) have gained popularity for their capacity to replicate biological processes and efficiently handle temporal data, making them a favorable choice in various IoT applications. However, designers must possess a comprehensive knowledge of FPGA architecture and programming methodologies to fully exploit the potential of FPGAs for SNN implementations. In this work, we propose SpiComp framework aiming to automate the implementation of SNNs on FPGAs, leveraging their reconfigurable nature and high efficiency without requiring domain expertise. Results show that the SNN implementations produced by the framework achieve high throughput and have a small energy footprint compared to other implementations in the literature while providing design automation.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595982","King Abdullah University of Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595982","spiking neural networks;field programmable gate arrays;design automation;hardware accelerator","Design automation;Circuits and systems;Spiking neural networks;Computer architecture;Logic gates;Programming;Throughput","","","","17","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"FPGA-based CNN Acceleration using Pattern-Aware Pruning","L. Pradels; S. -I. Filip; O. Sentieys; D. Chillet; T. L. Calloch","Inria, CNRS, IRISA, Univ. Rennes, Rennes, France; Inria, CNRS, IRISA, Univ. Rennes, Rennes, France; Inria, CNRS, IRISA, Univ. Rennes, Rennes, France; Inria, CNRS, IRISA, Univ. Rennes, Rennes, France; Safran Electronics & Defense, Eragny, France",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","228","232","While convolutional neural networks (CNNs) have demonstrated exceptional performance in computer vision, optimizing FPGA-based CNN accelerators remains a challenge due to resource constraints. This is especially true for sequential designs, which are limited by external memory access. Despite the benefits of sparsity, most existing sparse accelerators are sequential and memory-bound. We introduce an innovative dataflow CNN architecture enriched with structured sparsity through pattern pruning at tile level. In our approach, pattern pruning serves as a fine-tuning step, effectively reducing FPGA resource consumption, including memory and logic. Experimental results indicate better latency than other dataflow approaches, while maintaining competitive accuracy compared to state-of-the-art unstructured pruning methods. We demonstrate the versatility of our approach in image classification and super-resolution applications, where we achieve a consistent 30 frames per second across a wide range of image sizes on the Set5 dataset.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595865","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595865","","Computer vision;Accuracy;Circuits and systems;Superresolution;Memory management;Convolutional neural networks;Logic","","","","32","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Efficient Hardware Implementation of Artificial Neural Networks on FPGA","K. Khalil; T. Mohaidat; M. Darwich; A. Kumar; M. Bayoumi","Department of Electrical and Computer Engineering, University of Mississippi, Mississippi, USA; Department of Electrical and Computer Engineering, University of Mississippi, Mississippi, USA; Department of Mathematics and Computer Science, University of Mount Union, Alliance, OH, USA; The Center for Advanced Computer Studies, University of Louisiana at Lafayette, LA, USA; Department of Electrical and Computer Engineering, University of Louisiana at Lafayette, LA, USA",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","233","237","A neural network finds widespread applications across various domains, with the primary challenge being the design of a network characterized by low area and power consumption. This paper introduces an efficient design strategy for a cost-effective neural network architecture. It leverages a shared multiplier and accumulator arrangement between neighboring nodes, halving the number of these units and subsequently reducing the overall area of the neural network. A configuration mechanism is employed to synchronize the operation between the two common nodes. The proposed method is implemented and tested using VHDL on an Altera 10 GX FPGA, and evaluations include testing with two datasets: MNIST and CIFAR-10. The results demonstrate that the proposed method maintains classification accuracy while achieving a 76% reduction in area compared to traditional methods, with a power consumption of 82 mW. These findings underscore the efficiency and suitability of the proposed method for applications prioritizing both area and energy efficiency.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595867","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595867","Neural network;hardware accelerators;FPGA;low-power","Power demand;VHDL;Accuracy;Circuits and systems;Hardware;Energy efficiency;Synchronization","","1","","27","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"An Analog Neural Network for Estimating Sea State or Wave Height from Inertial Sensor Data","V. Alimisis; A. Papathanasiou; G. Georgousis; P. P. Sotiriadis","Department of Electrical and Computer Engineering, National Technical University of Athens, Greece; Department of Electrical and Computer Engineering, National Technical University of Athens, Greece; Department of Electrical and Computer Engineering, National Technical University of Athens, Greece; Department of Electrical and Computer Engineering, National Technical University of Athens, Greece",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","238","242","This research introduces an alternative approach to design low-power analog artificial neural networks with a power consumption of only 532nW. The proposed network consists of sigmoid activation function circuit, tanh approximation circuit along with a current comparator. In order to validate the behavior as an analog classifier, a real-time vessel dataset is used, achieving an accuracy of 86.50% in predicting true waves from inertial sensor data. Moreover, a comparative assessment among other analog classifiers is conducted, all trained on the same dataset. These models underwent training via a software-based implementation. The architecture was implemented using the TSMC 90nm CMOS process and simulated using the Cadence IC Suite.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595926","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595926","Inertial sensor data;analog VLSI design;sea state;wave height;power-efficiency;artificial neural network","Semiconductor device modeling;Training;Accuracy;Power demand;Inertial sensors;Sea measurements;Very large scale integration","","","","29","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Characterization of an Analog MAC Cell with Multi-Bit Resolution for AI Inference Accelerators","R. Nägele; J. Finkbeiner; M. Grözing; M. Berroth; G. Rademacher","University of Stuttgart, Stuttgart, Germany; University of Stuttgart, Stuttgart, Germany; University of Stuttgart, Stuttgart, Germany; University of Stuttgart, Stuttgart, Germany; University of Stuttgart, Stuttgart, Germany",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","243","247","Energy-efficient artificial intelligence (AI) accelerator designs with analog multiply-accumulate (MAC) cells as a key computation element have emerged to meet the demand for executing AI applications on edge devices. In this paper, we characterize an energy-efficient MAC cell with an analog two-quadrant multiplier and a dynamic analog multi-bit weight memory by measurements. It is designed and fabricated in a 22nm FD-SOI CMOS technology. The experimental results confirm the operating principle of the analog MAC cell and demonstrate its advanced performance.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595889","Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595889","analog integrated circuits;edge computing;AI accelerators;energy efficiency","Weight measurement;Semiconductor device modeling;MOSFET;Circuits;Neural networks;Layout;CMOS technology","","","","8","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Evaluating an Analog Main Memory Architecture for All-Analog In-Memory Computing Accelerators","K. Adam; D. Monga; O. Numan; G. Singh; K. Halonen; M. Andraud","Department of Electronics and Nanoengineering, Aalto University, Finland; Department of Electronics and Nanoengineering, Aalto University, Finland; Department of Electronics and Nanoengineering, Aalto University, Finland; Department of Electronics and Nanoengineering, Aalto University, Finland; Department of Electronics and Nanoengineering, Aalto University, Finland; Department of Electronics and Nanoengineering, Aalto University, Finland",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","248","252","Analog in memory Computing (IMC) has emerged as a promising method to accelerate deep neural networks (DNNs) on hardware efficiently. Yet, analog computation typically focuses on the multiply and accumulate operation, while other operations are still being computed digitally. Hence, these mixed-signal IMC cores require extensive use of data converters, which can take a third of the total energy and area consumption. Alternatively, all-analog DNN computation is possible but requires increasingly challenging analog storage solutions, due to noise and leakage of advanced technologies. To enable all-analog DNN acceleration, this work demonstrates a feasible IMC architecture using an efficient analog main memory (AMM) cell. The proposed AMM cell is 42x and 5x more power and area efficient than a baseline analog storage cell. An all-analog architecture using this cell achieves potential efficiency gains of 15x compared with a mixed-signal IMC core using data converters.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595976","Academy of Finland; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595976","Analog in memory Computing;Analog Memory","Circuits and systems;Microprocessors;Noise;Memory architecture;AI accelerators;Computer architecture;Artificial neural networks","","","","14","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Characterization of a Femtojoule Voltage-to-Time Converter with Rectified Linear Unit Characteristic for Analog Neural Network Inference Accelerators","J. Finkbeiner; R. Nägele; M. Grözing; M. Berroth; G. Rademacher","University of Stuttgart, Stuttgart, Germany; University of Stuttgart, Stuttgart, Germany; University of Stuttgart, Stuttgart, Germany; University of Stuttgart, Stuttgart, Germany; University of Stuttgart, Stuttgart, Germany",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","253","257","This paper presents experimental results of a voltage-to-time converter featuring a rectified linear unit (ReLU) transfer characteristic. The circuit, manufactured in 22nm FD-SOI CMOS technology, is intended to be used together with charge-based multiply-accumulate circuits, using a pulse-width-encoded input activation, inside an all-analog artificial neural network accelerator. The adjustment of the ReLU slope and ReLU threshold via back-gate voltages is demonstrated. The primary limitation of the circuit is the variation of the output pulse width, caused by mismatch and noise, which results in a standard deviation of 10ps and 2.5ps.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595904","Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595904","AI accelerators;analog integrated circuits;artificial neural networks;energy efficiency","Pulse measurements;Noise;Layout;Artificial neural networks;CMOS technology;Threshold voltage;Frequency measurement","","1","","10","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Adaptive Mixed MLC-SLC FeFET Mapping for CIM AI Applications Through Simulated Annealing","A. Vardar; F. Müller; İ. Geçin; N. Laleni; T. Kämpfe","Fraunhofer IPMS, Dresden, Germany; Fraunhofer IPMS, Dresden, Germany; Fraunhofer IPMS, Dresden, Germany; Fraunhofer IPMS, Dresden, Germany; Fraunhofer IPMS, Dresden, Germany",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","258","262","This paper explores the novel use of ferroelectric field-effect transistors (FeFETs) in a mixed multi-level cell (MLC) and single-level cell (SLC) configuration, aiming to strike an optimal balance between area efficiency and data integrity. Addressing the inherent trade-offs in MLC configurations, which offer high bit capacity at the cost of increased error rates, we propose a mixed mapping scheme that effectively combines the advantages of both MLC and SLC configurations. Further, this study introduces a specialized fitting algorithm designed to identify the optimal configuration. Complemented by simulated annealing for hyperparameter tuning, this approach not only proves efficacious in this specific context but also offers adaptability for diverse design objectives.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595943","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595943","FeFET;Neural Networks;Non-Volatile Memory;Edge Computing;In-Memory Computing;Hyperparameter Optimization","Microprocessors;Neural networks;Simulated annealing;In-memory computing;Transistors;Resource management;Artificial intelligence","","","","18","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Early-Exit with Class Exclusion for Efficient Inference of Neural Networks","J. Wang; B. Li; G. L. Zhang","Hardware for AI Group, TU Darmstadt, Germany; Chair of Electronic Design Automation, TU Munich, Germany; Hardware for AI Group, TU Darmstadt, Germany",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","263","267","Deep neural networks (DNNs) have been successfully applied in various fields. In DNNs, a large number of multiply-accumulate (MAC) operations are required to be performed, posing critical challenges in applying them in resource-constrained platforms, e.g., edge devices. To address this challenge, in this paper, we propose a class-based early-exit for dynamic inference. Instead of pushing DNNs to make a dynamic decision at intermediate layers, we take advantage of the learned features in these layers to exclude as many irrelevant classes as possible, so that later layers only have to determine the target class among the remaining classes. When only one class remains at a layer, this class is the corresponding classification result. Experimental results demonstrate the computational cost of DNNs in inference can be reduced significantly with the proposed early-exit technique. The codes can be found at https://github.com/HWAI-TUDa/EarlyClassExclusion.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595861","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595861","","Performance evaluation;Codes;Circuits and systems;Artificial neural networks;Computational efficiency;Artificial intelligence","","","","22","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"An Efficient Anomalous Sound Detection by Robust Processing and Reformation of Objective","T. -L. Tsai; Y. -C. Lo; A. -Y. A. Wu","Graduate Institute of Electronics Engineering, National Taiwan University, Taipei, Taiwan; Graduate Institute of Electronics Engineering, National Taiwan University, Taipei, Taiwan; Graduate Institute of Electronics Engineering, National Taiwan University, Taipei, Taiwan",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","268","272","Boosted by the Internet of Things (IoT) and neural network (NN), an accurate anomalous sound detection (ASD) system is critical in Industry 4.0 for enabling proactive maintenance. Previous works have enhanced ASD’s accuracy by incorporating multi-domain features through advanced NN techniques. However, this often results in significant computational and memory overhead, which contradicts the IoT scenario. Therefore, we propose a lightweight ASD system by inspecting the core issues. First, to mitigate the noise effect of IoT, we propose dynamic signal processing to stabilize the feature extractor. Second, to adapt to the varying IoT environment, we apply structural learning to enhance the NN’s generalization. Additionally, to overcome ASD’s data scarcity, we improve the training strategy to strengthen NN’s interpretation capability. Finally, compared to the state-of-the-art method on the DCASE 2020 dataset, our approach shows 1.34% accuracy improvement, 16.9% computation reduction, and 43.5% storage reduction.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595946","National Science and Technology Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595946","Anomalous sound detection;Internet of Things;robustness design;dynamic signal processing;structural learning","Training;Accuracy;Circuits and systems;Noise;Artificial neural networks;Interference;Feature extraction","","1","","13","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Enhancing Anomaly Detection with Entropy Regularization in Autoencoder-based Lightweight Compression","A. Enttsel; A. Marchioni; G. Setti; M. Mangia; R. Rovatti","DEI, University of Bologna, Italy; DEI, University of Bologna, Italy; CEMSE, KAUST, Saudi Arabia; DEI, University of Bologna, Italy; DEI, University of Bologna, Italy",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","273","277","Monitoring systems produce and transmit large amounts of data. For an efficient transmission, data is often compressed and autoencoders are a widely adopted neural network-based solution. However, this processing step leads to a loss of information that may negatively impact the performance of downstream tasks, such as anomaly detection. In this work, we propose a loss function for an autoencoder that addresses both compression and anomaly detection. Our key contribution is the inclusion of a regularization term based on information-theoretic quantities that characterize an anomaly detector processing compressed signals. As a result, the proposed approach allows for a better use of the communication channel such that the information preserved by the compressed signal is optimized for both detection and reconstruction, even in scenarios with lightweight compression. We tested the proposed technique with ECG signals affected by synthetic anomalies and the experiments demonstrated an average 17% increase in the probability of detection across three standard detectors. Additionally, we proved that our approach is generalizable to image data.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595983","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595983","anomaly detection;dimensionality reduction;autoencoder;information theory;compression","Training;Measurement;Image coding;Detectors;Electrocardiography;Task analysis;Anomaly detection","","2","","39","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Auditory Anomaly Detection using Recurrent Spiking Neural Networks","S. Kshirasagar; B. Cramer; A. Guntoro; C. Mayr","Robert Bosch GmbH, Renningen, Germany; Robert Bosch GmbH, Renningen, Germany; Robert Bosch GmbH, Renningen, Germany; TU Dresden, Dresden, Germany",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","278","281","Brain-inspired networks promise capabilities of achieving high computational efficacy with low energy footprint. Auditory perception systems are resource constrained when deployed on low power edge AI devices. Hence, we employ spiking neural networks (SNNs) for auditory scene analysis, specifically targeting temporal detection of anomaly cues particularly siren sounds. We generate artificial audio sequences from a publicly available dataset containing various siren and noise sounds. We train small-scale recurrent SNNs with leaky-integrate-and-fire (LIF) neurons in the hidden layer and achieve accurate predictions with precious few parameters. Further, we provide a baseline for conventional RNNs of similar network topology on the same task. With comparable accuracy, reduced parameter, and sparse spiking activity in hidden layer in contrast to conventional methods, we found bio-inspired approach realized using SNNs to be promising in solving the time-series auditory anomaly detection task.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595878","Horizon Europe; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595878","brain-inspired computing;siren detection;spiking neural networks;auditory perception;anomaly detection","Accuracy;Image analysis;Neuromorphics;Network topology;Noise;Neurons;Spiking neural networks","","1","","21","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Fine-Tuned Based Transfer Learning with Temporal Attention and Physics-Informed Loss for Bearing RUL Prediction","P. K. Mp; Z. -X. Tu; K. -C. J. Chen","Department of Computer Science and Engineering, National Sun Yat-sen University, Taiwan; Department of Computer Science and Engineering, National Sun Yat-sen University, Taiwan; Institute of Electronics, National Yang Ming Chiao Tung University, Taiwan",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","282","286","In the realm of industrial applications, ensuring the reliability of rotating machinery components, specifically bearings, is crucial to prevent unexpected downtime. Despite the benefits of integrating Deep Learning (DL) into Prognostics and Health Management (PHM) for improved Remaining Useful Life (RUL) prediction, challenges persist due to limited labeled data and generalizability issues. Transfer Learning (TL) offers a solution, yet fine-tuning with scarce target domain data poses a risk of Negative Transfer Learning (NTL). To mitigate this, we introduce a Temporal Attention Mechanism (TAM), dynamically weighing the importance of temporal channels and capturing local and global temporal dependencies. This ensures optimal focus on relevant temporal features during fine-tuning. Additionally, the conventional reliance on historical patterns in data loss functions for predicting degradation patterns introduces interpretability limitations. Thus, we propose a novel physics-informed loss function incorporating mechanical degradation factors, offering a comprehensive approach to accurate RUL predictions. Experimental results showcase the efficacy of TAM, achieving an average percentage reduction of approximately 50.93% to 90.67% in Mean Absolute Percentage Error (MAPE) compared to related works. The proposed Physics-Informed approach consistently outperforms traditional Mean Squared Error (MSE), demonstrating robustness and superior adaptability in diverse operating conditions.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595914","National Science and Technology Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595914","Transfer Learning;Fine Tuning;physics-informed loss function;Bearing RUL prediction","Degradation;Deep learning;Accuracy;Attention mechanisms;Circuits and systems;Transfer learning;Robustness","","","","18","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"FlexBits: A Configurable Lightweight RISC-V Micro-architecture for Flexible Bit-Width Execution","Z. Xu; X. Kang; X. Wang; B. Chen; T. T. Ye","Southern University of Science and Technology, Shenzhen, China; Southern University of Science and Technology, Shenzhen, China; Southern University of Science and Technology, Shenzhen, China; Southern University of Science and Technology, Shenzhen, China; Southern University of Science and Technology, Shenzhen, China",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","287","291","Fixed-point Quantized Neural Networks (QNNs) can significantly reduce computational and bandwidth overhead on energy-efficient edge devices while maintaining comparable accuracy. However, edge devices do not have the flexibility to support multiple-precision fixed point QNN inferences. In this paper, we propose FlexBits, a RISC-V based configurable micro-architecture that supports multiple precisions fix-point QNN inference through Single Instruction Multiple Data (SIMD) custom instruction set. Using FlexBits extension architecture, we further build a VexRiscv compatible CPU, called FlexP that implements the FlexBits instructions with optimized pipeline and logics on FPGA platform. Experimental results demonstrate substantial improvements for convolution operations quantized to 2, 4, 8, and 16 bits, with average speedups of 20.8x, 7.6x, 3.0x, and 1.7x, respectively, as compared to the baseline processors without the extended instructions. In the inference task of 8-bit quantized MobileNetV1, the end-to-end inference speedup is 1.57x, achieving inference performance comparable to ARM Cortex-M4.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595975","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595975","SIMD;RISC-V;Quantized Neural Networks","Performance evaluation;Reduced instruction set computing;Single instruction multiple data;Convolution;Neural networks;Pipelines;Energy efficiency","","","","16","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"RISCV-FNT: A Fast FNT-based RISC-V Processor for CNN Acceleration","B. Chen; X. Wang; Y. Huang; Z. Xu","Southern University of Science and Technology, Shenzhen, China; Southern University of Science and Technology, Shenzhen, China; Southern University of Science and Technology, Shenzhen, China; Southern University of Science and Technology, Shenzhen, China",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","292","296","Convolution forms the basis of computation in neural network applications. Many different approaches have been proposed in the past years to optimize the convolution operation. In this paper, we propose to use Fermat Number Transform (FNT) technique to accelerate the computation of convolution in neural networks. Calculations in FNT are all based on real numbers, which significantly reduce the complexity as compared to complex-number-based FFT calculations. Furthermore, by using diminished-1 encoding, multiplication and modulo operations can also be simplified into bit manipulations. In this paper, we have constructed a RISC-V based processor, called RISCV-FNT, which incorporates an FNT-based convolution acceleration unit, along with custom instruction sets. FPGA implementation of RISCV-FNT demonstrated an 8.5× speedup compared to other RISC-V processors without FNT acceleration when performing inference tasks on Lenet-5. Synthesized results from Synopsys® DC achieved area energy efficiency of 93.9 GOPs/W/mm2.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595907","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595907","Convolutional Neural Network;Fermat Number Transform;RISC-V;Custom Instruction","Convolution;Instruction sets;Neural networks;Transforms;Inference algorithms;Energy efficiency;Encoding","","","","11","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"RTPE: A High Energy Efficiency Inference Processor with RISC-V based Transformation Mechanism","Z. Wang; H. Du; B. Han; Y. Xu; X. Tang; Y. Zhou; Z. Zheng; W. Cui; Y. Xiong; S. Wei; S. Qiao; S. Yin","School of Integrated Circuits, Tsinghua University, Beijing, China; School of Engineering, Hong Kong University of Science and Technology, Beijing, China; Beijing Branch, China Telecom Co., Ltd., Beijing, China; The Chinese University of Hong Kong, Shenzhen, China; Beijing Wisemay Science and Technology Co., Ltd., Beijing, China; School of Integrated Circuits, Tsinghua University, Beijing, China; Beijing Smart-Chip Microelectronics Technology Co., Ltd., Beijing, China; Beijing Smart-Chip Microelectronics Technology Co., Ltd., Beijing, China; Beijing Smart-Chip Microelectronics Technology Co., Ltd., Beijing, China; School of Integrated Circuits, Tsinghua University, Beijing, China; Institute of Microelectronics of Chinese Academy of Sciences, Beijing, China; School of Integrated Circuits, Tsinghua University, Beijing, China",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","297","301","The inference of DNN has always been widely applied in various scenarios, often requiring consideration of supporting different systems and deployment of artificial neural networks. This article introduces a 64-bit RISC-V based Transformation Processing Element (RTPE), which combines a RISC-V processors with DNN inference processors to support more flexible and comprehensive inference of artificial neural networks. At the same time, it has three technical improvements. Firstly, RTPE has an instruction based Real-time Data Segmentation and Reassembly (RDSR) method. Secondly, RTPE has a Typical Value Search and Correction (TVSC) system synchronized with the instruction stream, which converts direct computation into search and correction computation. Thirdly, RTPE includes instruction driven Data Format Preconfiguration and Precision-tuning (DFPP) schemes. Through the evaluation of the 28nm CMOS process, RTPE achieved better energy efficiency performance compared to the most typical pure inference processor UNPU.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595923","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595923","DNN Inference;Processor;RISC-V","Program processors;Circuits and systems;Random access memory;Artificial neural networks;CMOS process;Energy efficiency;Real-time systems","","2","","14","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"RCPE: An Excellent Performance Training Processor with RISC-V based Compression Mechanism","Z. Wang; H. Du; B. Han; Y. Xu; X. Tang; Y. Zhou; Z. Zheng; W. Cui; Y. Xiong; S. Wei; S. Qiao; S. Yin","School of Integrated Circuits, Tsinghua University, Beijing, China; School of Engineering, Hong Kong University of Science and Technology, Beijing, China; Beijing Branch, China Telecom Co., Ltd., Beijing, China; The Chinese University of Hong Kong, Shenzhen, China; Beijing Wisemay Science and Technology Co., Ltd., Beijing, China; School of Integrated Circuits, Tsinghua University, Beijing, China; Beijing Smart-Chip Microelectronics Technology Co., Ltd., Beijing, China; Beijing Smart-Chip Microelectronics Technology Co., Ltd., Beijing, China; Beijing Smart-Chip Microelectronics Technology Co., Ltd., Beijing, China; School of Integrated Circuits, Tsinghua University, Beijing, China; Institute of Microelectronics of Chinese Academy of Sciences, Beijing, China; School of Integrated Circuits, Tsinghua University, Beijing, China",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","302","306","In recent years, the training of DNN has always occupied a large resource cost, especially when edge device are operating accordingly. This article introduces a RISC-V based Compression Processing Element (RCPE) based on 64-bit RISC-V, which insides RISC-V processor into DNN training processors to support more flexible and comprehensive training of artificial neural networks. It also has three technical improvements. Firstly, RCPE has a method of Flexibly Controlling the Reuse of Data(FCRD) through the RISC-V instruction. Secondly, RCPE has an instruction based Redundant Computation Skip Mechanism(RCSM) that predicts sparse and duplicate fields in advance. Thirdly, RCPE includes a scheme to Quickly Adjust the Calculation Format(QACF) based on the instruction stream, which converts the input into various variable precision forms. Through the evaluation of the 28nm CMOS process, the RCPE achieved well performance.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595944","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595944","DNN Training;Processor;RISC-V","Training;Costs;Convolution;Circuits and systems;Random access memory;Artificial neural networks;Transforms","","2","","16","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"A Low-Latency and Scalable Vector Engine with Operation Fusion for Transformers","M. Cha; K. Lee; X. T. Nguyen; H. -J. Lee","Department of Electrical and Computer Engineering, Inter-University Semiconductor Research Center (ISRC), Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering, Inter-University Semiconductor Research Center (ISRC), Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering, Inter-University Semiconductor Research Center (ISRC), Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering, Inter-University Semiconductor Research Center (ISRC), Seoul National University, Seoul, Korea",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","307","311","Recently, transformer models have been widely deployed for AI services at data centers. However, one of the noticeable deployment challenges is the intensive usage of vector operations such as layer normalization (LayerNorm) and Softmax that generally show sub-optimal performance on general-purpose CPU and GPU due to their low arithmetic intensities and long data dependency. To address the problem, this study presents a low-latency and scalable FPGA-based engine for accelerating vector operations. Specifically, we built a dedicated circuit to effectively execute both element-wise operations and compound fused operations. More importantly, our engine can calculate input mean and variance in parallel, which significantly reduces the instruction count in computing LayerNorm and Softmax. Experimental results show that our design achieves a latency reduction of 50% and 40% for Softmax and LayerNorm, respectively, compared with the SOTA design, while only consuming an additional 20% DSPs, 27% BRAMs, 18% FFs, and 39% LUTs.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595857","Technology Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595857","Vector Processor Unit;VPU;Layer Normalization;Softmax;FPGA","Graphics processing units;Transformers;Vectors;Hardware;Data models;Table lookup;Vector processors","","","","15","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"NeuroSORT: A Neuromorphic Accelerator for Spike-based Online and Real-time Tracking","Z. Shen; X. Xie; C. Fang; F. Tian; S. Ma; J. Yang; M. Sawan","CenBRAIN Neurotech Center of Excellence, School of Engineering, Westlake University, Hangzhou, China; State Key Lab of Integrated Chips and Systems, Fudan University, Shanghai, China; CenBRAIN Neurotech Center of Excellence, School of Engineering, Westlake University, Hangzhou, China; Department of ECE, Hong Kong University of Science and Technology, Hong Kong SAR, China; State Key Lab of Integrated Chips and Systems, Fudan University, Shanghai, China; CenBRAIN Neurotech Center of Excellence, School of Engineering, Westlake University, Hangzhou, China; CenBRAIN Neurotech Center of Excellence, School of Engineering, Westlake University, Hangzhou, China",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","312","316","The increasing need for real-time computation with low-power consumption is driving the advancement of specialized neuromorphic processors on various applications. Multi object tracking, as one of the most challenging tasks in computer vision, has gained wide attention with many solutions proposed. Nevertheless, they consume huge resources and fail to adapt to edge application scenarios with strict power and resource constraints. In this work, we propose NeuroSORT, a neuromorphic accelerator for spike-based online and real-time object tracking, which leverages spiking neural network (SNN) to solve linear assignment problem and explores the hardware acceleration on tracking algorithms. Experimental results show that the proposed accelerator reaches an accuracy of 99.43% on linear assignment task and 69.641 HOTA score on MOT17 dataset, while consuming 0.257mW energy and 0.17mm2 area. The overall power consumption is reduced by 41.1% compared with SOTA works with equivalent performance.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595908","Westlake University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595908","Neuromorphic system;Multi-object Tracking;Spiking Neural Networks","Accuracy;Power demand;Program processors;Neuromorphics;Spiking neural networks;Real-time systems;Object tracking","","","","23","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"A 0.2-pJ/SOP Digital Spiking Neuromorphic Processor with Temporal Parallel Dataflow and Efficient Synapse Memory Compression","Y. -H. Lin; K. -T. Tang","National Tsing Hua University, Hsinchu, Taiwan; National Tsing Hua University, Hsinchu, Taiwan",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","317","321","The inherent high sparsity of the spiking neural networks (SNNs) and the low power consumption brought by the event-driven computing characteristics suit edge devices with extremely high energy efficiency requirements. On resource-constrained mobile devices, we also require memory saving. Unlike conventional artificial neural networks, SNNs are suitable for processing complex temporal data. However, computing in the time dimension requires repeated access to the data for multiple time steps, resulting in high energy consumption. We propose Temporally Parallel Weight-Friendly (TPWF) dataflow, which reduces energy consumption through parallel computing across time steps. At the same time, considering the high sparsity of the spike event, this paper proposes a sparse aware strategy, which can realize high-energy-efficiency membrane potential accumulation calculation by the neuron burst weight search circuit. Furthermore, this paper proposes an efficient synaptic memory structure to reduce hardware resource usage while maintaining performance and network size. Use run-length encoding to record weights, realize synaptic connections that can support different configurations, such as sparse connection networks, and save a lot of memory.Using a fully connected 256-128-128-10 network to classify 16×16 MNIST training images achieves energy per synaptic operation (SOP) of 0.2pJ, up to 1.9x speedup, and 2x reduction in memory accesses.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595887","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595887","Spiking neural networks (SNNs);accelerator;dataflow;weight sparsity;energy efficiency","Training;Energy consumption;Image coding;Memory management;Neurons;Spiking neural networks;Hardware","","1","","11","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"High-Density Digital Neuromorphic Processor with High-Precision Neural and Synaptic Dynamics and Temporal Acceleration","J. Park; Y. Jeong; J. Kim; S. Lee; J. Y. Kwak; J. -K. Park; I. Kim","Center for Neuromorphic Engineering, Korea Institute of Science and Technology, Seoul, Korea; Center for Neuromorphic Engineering, Korea Institute of Science and Technology, Seoul, Korea; Center for Neuromorphic Engineering, Korea Institute of Science and Technology, Seoul, Korea; Center for Neuromorphic Engineering, Korea Institute of Science and Technology, Seoul, Korea; Center for Neuromorphic Engineering, Korea Institute of Science and Technology, Seoul, Korea; Center for Neuromorphic Engineering, Korea Institute of Science and Technology, Seoul, Korea; Center for Neuromorphic Engineering, Korea Institute of Science and Technology, Seoul, Korea",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","322","326","This paper presents a large-scale digital neuromorphic processor for spiking neural network emulation. The processor is fabricated in a 28 nm CMOS and occupies a 9.00 mm2 die area for 262,144 neurons. A time-embedded floating-point leaky integrate-and-fire neuron model is implemented to reduce the size of SRAM and the number of SRAM accesses. It achieves a high-density neuron integration (34.9 k neurons/mm2), which is 13 times higher than other state-of-the-art designs. Additionally, it achieves a high-dynamic range synapse (8-bit floating-point) and low energy consumption (28.26 pJ/synaptic operation).","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595869","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595869","Customized floating-point number;energy-efficient;high-precision synapse;large-scale system;spiking neural network","Semiconductor device modeling;Energy consumption;Image coding;Neuromorphics;Neurons;Emulation;Random access memory","","","","16","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Device Feasibility Analysis of Multi-level FeFETs for Neuromorphic Computing","A. Saha; B. Manna; S. Lu; Z. Jiang; K. Ni; A. Sengupta","School of EECS, Penn State University, PA, USA; School of EECS, Penn State University, PA, USA; School of EECS, Penn State University, PA, USA; EE Department, University of Notre Dame, Notre Dame, IN, USA; EE Department, University of Notre Dame, Notre Dame, IN, USA; School of EECS, Penn State University, PA, USA",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","327","331","As an emerging non-volatile memory device technology, Ferroelectric Field-Effect Transistors (FeFETs) can enable low-power, adaptive intelligent system design. However, device dimension and operating voltage dependent reliability issues of scaled FeFETs can ultimately lead to degraded performance in solving machine learning tasks. In this work, detailed experimental characterization of FeFET devices of different dimensions have been carried out to explicitly evaluate the non-ideal behavior in device conductance programming properties like number of programming states, cycle-to-cycle (C2C) variations, device-to-device (D2D) variations, and state retention. A hardware-aware software simulation approach has been adopted to capture the adversarial effects of the non-idealities on recognition accuracy through algorithm-level performance assessment by including them in NeuroSim, a popular neural network hardware simulator, to execute a neural network model considering all other hardware constraints. With the added non-idealities, significant accuracy degradation has been observed compared to the ideal scenarios where D2D variations play the most critical role. Thereafter, feasibility of a variation-aware training method has been evaluated to tackle the accuracy drop.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595900","U.S. Department of Energy; Office of Science; Energy Frontier Research Centers; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595900","FeFET;Non-idealities;Variations;Neuromorphic Computing","Performance evaluation;Training;Degradation;Accuracy;Voltage;Programming;Inference algorithms","","1","","18","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"On-Chip Incremental Learning based on Unsupervised STDP Implementation","G. Chen; J. Cao; S. Feng; Z. Wang; Y. Zhong; Q. Li; X. Zhao; X. Zhang; Y. Wang","School of Software and Microelectronics, Peking University, Beijing, China; School of Software and Microelectronics, Peking University, Beijing, China; School of Software and Microelectronics, Peking University, Beijing, China; School of Integrated Circuits, Peking University, Beijing, China; School of Integrated Circuits, Peking University, Beijing, China; School of Software and Microelectronics, Peking University, Beijing, China; School of Software and Microelectronics, Peking University, Beijing, China; Key Laboratory of Microelectronic Devices and Circuits (MoE), MPW Center, Peking University, Beijing, China; Key Laboratory of Microelectronic Devices and Circuits (MoE), MPW Center, Peking University, Beijing, China",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","332","336","Spiking neural network (SNN), a bio-inspired neuron network, utilizes a learning rule named spike-timing-dependent plasticity (STDP) to achieve high-performance unsupervised learning. However, it may suffer from catastrophic forgetting when the distribution of new data significantly differs from that of old data. To address this issue, an incremental learning implementation for ship classification is presented in this paper. We develop an incremental learning algorithm based on STDP and corresponding platform. A competitive SNN is built into our algorithm, and add-STDP is utilized to update the weights of network for efficient learning. To enhance learning performance, we incorporate weight decay. And to avoid catastrophic forgetting, we incorporate data replay. The corresponding learning platform consists of the FPGA Zynq 7100 and the STDP neuromorphic prototype chip, and our algorithm is executed on the chip. We evaluate the ship classification task on our platform, which demonstrates the superior potential of our on-chip implementation for incremental learning.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595970","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595970","On-chip incremental learning;spike-timing-dependent plasticity (STDP);competitive spike neural network (SNN);weight decay;data replay","Incremental learning;Neuromorphics;Neurons;Prototypes;Spiking neural networks;Classification algorithms;System-on-chip","","","","24","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Optimizing Vision Transformers: Leveraging Max and Min Operations for Efficient Pruning","P. Bich; C. Boretti; L. Prono; F. Pareschi; R. Rovatti; G. Setti","DET, Politecnico di Torino, Italy; DET, Politecnico di Torino, Italy; DET, Politecnico di Torino, Italy; DET, Politecnico di Torino, Italy; DEI, University of Bologna, Italy; CEMSE, King Abdullah University of Science and Technology (KAUST), Saudi Arabia",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","337","341","The research on Deep Neural Networks (DNNs) continues to enhance the performance of these models over a wide spectrum of tasks, increasing their adoption in many fields. This leads to the need of extending their usage also on edge devices with limited resources, even though, with the advent of Transformer-based models, this has become an increasingly complex task because of their size. In this context, pruning emerges as a crucial tool to reduce the number of weights in the memory-hungry Fully Connected (FC) layers. This paper explores the usage of neurons based on the Multiply-And-Max/min (MAM) operation, an alternative to the conventional Multiply-and-Accumulate (MAC), in a Vision Transformer (ViT). This enhances the model prunability thanks to the usage of Max and Min operations. For the first time, many MAM-based FC layers are used in a large state-of-the-art DNN model and compressed with various pruning techniques available in the literature. Experiments show that MAM-based layers achieve the same accuracy of traditional layers using up to 12 times less weights. In particular, when using Global Magnitude Pruning (GMP), the FC layers following the Multi-head Attention block of a ViT-B/16 model, fine-tuned on CIFAR-100, count only 560000 weights if MAM neurons are used, compared to the 31.4 million that remain when using traditional MAC neurons.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595859","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595859","","Weight measurement;Training;Performance evaluation;Visualization;Neurons;Artificial neural networks;Transformers","","","","27","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Adaptive Image Downscaling for Rate-Accuracy-Latency Optimization of Task-Target Image Compression","H. Choi; S. Jeong; S. Kwak; S. -H. Jung; J. H. Ko","Department of Artificial Intelligence, Sungkyunkwan University, Korea; Department of Artificial Intelligence, Sungkyunkwan University, Korea; Media Research Division, Electronics and Telecommunications Research Institute, Korea; Media Research Division, Electronics and Telecommunications Research Institute, Korea; Department of Electrical and Computer Engineering, Sungkyunkwan University, Korea",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","347","351","As the computational cost of the compression frame-work increases due to improved image codecs and the proliferation of high-resolution images, downscaling can be used to reduce compression overhead before compression process. There are several existing deep learning-based downscaling approaches, but these studies have the limitation of outputting fixed sizes for all different input images. In this paper, we propose a novel approach of adaptive image downscaling framework for rate-accuracy-latency optimization. We utilize deep learning-based downscaling network that learns which size factor to use in downscaling operation adjusting the trade-off between rate and accuracy through λ. Our experimental results show that the proposed framework enhances the rate-accuracy performance of compression rate control or uniform downscaling by up to 43.5% BD-rate (mAP), while remaining minimal latency at the same accuracy compared to others.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595930","National Research Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595930","Deep Learning;Image Compression;Downscaling","Image coding;Accuracy;Codecs;Circuits and systems;Machine vision;Computational modeling;Computational efficiency","","","","21","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Fast, Efficient and Lightweight Compressed Image Super-Resolution Network for Edge Devices","J. Kim; J. -K. Kang; Y. Kim","Department of Electrical and Computer Engineering, Inha University, Incheon, South Korea; Department of Electrical and Computer Engineering, Inha University, Incheon, South Korea; The Department of Technology Education, Korea National University of Education, Cheongju, South Korea",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","352","356","In many applications, images are reduced in size and compressed to save storage and transmission bandwidth. This process leads to loss of detail and often generates undesirable artifacts that degrade visual quality and impact the performance of vision tasks. To solve this challenge, many studies have been proposed on compressed image super-resolution (CISR). However, most previous works have designed complicate architectures that require substantial computational resources, limiting their applicability in edge devices. To address this problem, we propose a fast, efficient and lightweight compressed image super-resolution network (FELCSRN) for edge devices. The proposed FELCSRN is a single network that reduces compression artifacts and enhances the resolution simultaneously. Furthermore, the re-parameterization and quantization methods are utilized to further reduce computational and memory costs. Experimental results demonstrate that the proposed FELCSRN outperforms existing efficient super-resolution methods in terms of quality metrics and efficiency. In addition, compared to state-of-the-art CISR methods, it significantly reduces computational costs and model size. As a result of evaluating the performance of the proposed FELCSRN by deploying it on the Xilinx ZCU104 board, it was confirmed that CISR tasks are performed in real-time.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595939","National Research Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595939","convolutional neural network;compressed image super-resolution;edge device","Performance evaluation;Visualization;Image coding;Quantization (signal);Limiting;Image edge detection;Superresolution","","","","23","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"GaitSpike: Event-based Gait Recognition With Spiking Neural Network","Y. Tao; C. -H. Chang; S. Saïghi; S. Gao","School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; CNRS@CREATE, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","357","361","Existing vision-based gait recognition systems are mostly designed based on video footage acquired with RGB cameras. Appearance-, model- and motion-based techniques commonly used by these systems require silhouette segmentation, skeletal contour detection and optical flow patterns, respectively for features extraction. The extracted features are typically classified by convolutional neural networks to identify the person. These preprocessing steps are computationally intensive due to the high visual data redundancies and their accuracies can be influenced by background variations and non-locomotion related external factors. In this paper, we propose GaitSpike, a new gait recognition system that synergistically combines the advantages of sparsity-driven event-based camera and spiking neural network (SNN) for gait biometric classification. Specifically, a domain-specific locomotion-invariant representation (LIR) is proposed to replace the static Cartesian coordinates of the raw address event representation of the event camera to a floating polar coordinate reference to the motion center. The aim is to extract the relative motion information between the motion center and other human body parts to minimize the intra-class variance to promote the learning of inter-class features by the SNN. Experiments on a real event-based gait dataset DVS128-Gait and a synthetic event-based gait dataset EV-CASIA-B show that GaitSpike achieves comparable accuracy as RGB camera based gait recognition systems with higher computational efficiency, and outperforms the state-of-the-art event camera based gait recognition systems.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595896","Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595896","","Visualization;Accuracy;Motion segmentation;Redundancy;Spiking neural networks;Feature extraction;Cameras","","","","22","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Approximate Adder Tree Design with Sparsity-Aware Encoding and In-Memory Swapping for SRAM-based Digital Compute-In-Memory Macros","M. -G. Lin; J. -P. Wang; C. -Y. Chang; A. -Y. A. Wu","Graduate Institute of Electronics Engineering, National Taiwan University, Taipei, Taiwan; Graduate Institute of Electronics Engineering, National Taiwan University, Taipei, Taiwan; Graduate Institute of Electronics Engineering, National Taiwan University, Taipei, Taiwan; Graduate Institute of Electronics Engineering, National Taiwan University, Taipei, Taiwan",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","362","366","SRAM-based digital compute-in-memory (DCIM) is a promising solution to accelerate the extensive multiply-and-accumulate (MAC) operations in deep neural networks (DNNs). Despite its remarkable potential to enhance performance and efficiency, the adder tree circuits dominate the power and area. While directly replacing the exact adder tree with approximate circuits can greatly reduce the overheads, it also induces severe accuracy drop without a laborious retraining process. This work adopts an OR-based approximate adder tree as a baseline and proposes two techniques to recover the accuracy drop without retraining the model: sparsity-aware encoding to introduce bit sparsity in the most significant bits (MSBs) and an in-memory swapping mechanism for error mitigation. Validated on large-scale datasets with advanced vision transformer (ViT) models, our methods effectively restore the accuracy by 72.08% to 78.56% across various ViT models, eliminating the need for expert-driven retraining.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595967","National Science and Technology Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595967","Digital Compute-in-memory;deep learning accelerator;vision transformer;approximate adder tree","Accuracy;Computational modeling;Prevention and mitigation;Artificial neural networks;Transformers;In-memory computing;Approximation error","","","","10","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"A Cost-Effective Baugh-Wooley Approximate Multiplier for FPGA-based Machine Learning Computing","S. Vakili","Énergie Matériaux Télécommunications Research Centre, Institut National de la Recherche Scientifique, Montreal, Canada",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","367","371","Deep learning hardware accelerators commonly incorporate a substantial quantity of multiplier units. Yet, the considerable complexity of multiplier circuits renders them a bottleneck, contributing to increased costs and latency. Approximate computing proves to be an effective strategy for mitigating the overhead associated with multipliers. This paper introduces an original approximation technique for signed multiplication on FPGAs. The approach involves a novel segmentation method applied to the Baugh-Wooley multiplication algorithm. Each segment is optimally accommodated within look-up table resources of modern AMD-Xilinx FPGA families. The paper details the design of an INT8 multiplier using the proposed approach, presenting implementation results and accuracy assessments for the inference of benchmark deep learning models. The implementation results reveal significant savings of 53.6% in LUT utilization compared to the standard INT8 Xilinx multiplier. Accuracy measurements conducted on four popular deep learning benchmarks show an average accuracy degradation of 4.8% in post-training deployment and 0.7% after retraining. The source code for this work is available on GitHub 1.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595892","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595892","approximate multiplier;field-programmable gate array;machine learning computing","Deep learning;Accuracy;Costs;Source coding;Benchmark testing;Approximation algorithms;Inference algorithms","","","","14","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"OTFC-LSTM: An Efficient Design of LSTM Accelerator based on On-The-Fly CORDIC","Z. Luo; J. Mai; E. Yao","School of Microelectronics, South China University of Technology, Guangzhou, China; School of Microelectronics, South China University of Technology, Guangzhou, China; School of Microelectronics, South China University of Technology, Guangzhou, China",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","372","376","Long short-term memory (LSTM) networks are frequently applied to the long time sequence tasks, such as natural language processing (NLP), automatic speech recognition (ASR) and long-term time series forecasting (LTSF), due to its superior memory properties. Nonlinear activation functions that simulate the behavior of neurons are ubiquitous in LSTM, and previous experiments have shown that high-precision nonlinear functions can contribute higher accuracy significantly. However, current hardware implementations of LSTM have been suffering the issues like low accuracy and large resource consumption. In this paper, we propose a hardware implementation of the on-the-fly coordinate rotation digital computer algorithm (On-the-fly CORDIC, OTFC) to compute the Sigmoid and tanh activation functions, which decreases the computation cycle by more than 50% and greatly reduces the resource consumption while ensuring a minimum accuracy loss. Based on this algorithm, a hardware architecture that can be configured to LSTM layer is developed, making it suitable for low power time series computing scenarios. The proposed hardware architecture validated on Xilinx ZYNQ-7020 FPGA achieves a low resource utilization with 2.46 GOPS throughput rate in 12-bit and 0.274 W power for MNIST dataset.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595924","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595924","CORDIC;LSTM;nonlinear activation function;hardware accelerator","Accuracy;Time series analysis;Computer architecture;Throughput;Hardware;Natural language processing;Resource management","","","","15","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Progressive Variable Precision DNN With Bitwise Ternary Accumulation","J. Suzuki; M. Yasunaga; K. Kawamura; T. Van Chu; M. Motomura","Tokyo Institute of Technology, Yokohama, Japan; Tokyo Institute of Technology, Yokohama, Japan; Tokyo Institute of Technology, Yokohama, Japan; Tokyo Institute of Technology, Yokohama, Japan; Tokyo Institute of Technology, Yokohama, Japan",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","377","381","Progressive variable precision networks are capable of adapting to changing computational needs over time using a single weight set. However, previous works have two problems: 1) the absence of zero representation, which limits potential performance gains, and 2) significant accuracy degradation at low bitwidths. To address these issues, this work proposes bitwise ternary (BWT) quantization that progressively accumulates ternary weights based on Booth encoding, achieving a stepwise representation extension from ternary to N-bit. Moreover, the low-bit-first training effectively minimizes the significant accuracy degradation and improves accuracy-computation tradeoff in lower bitwidths. The evaluation results show that the ternary model achieves 76.2 % accuracy with little loss at 8-bit for ResNet18 on CIFAR-100. Similarly, on ImageNet, the model achieves an accuracy of 61.4 % using a ternary weight with less than 1 % degradation at the 8-bit model. Remarkably, these results are obtained with a single weight set.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595894","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595894","Bit-sparsity;variable precision;neural networks","Degradation;Training;Accuracy;Quantization (signal);Circuits and systems;Performance gain;Encoding","","","","26","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Energy-Efficient Ternary Multiplier","R. Agrawal; N. S. Abhijith; U. Anil Kumar; S. Veeramachaneni; S. E. Ahmed","Department of Electrical and Electronics Engineering, BITS Pilani, Hyderabad, Telangana, India; Department of Electrical and Electronics Engineering, BITS Pilani, Hyderabad, Telangana, India; Department of Electronics and Communication Engineering, Faculty of Science and Technology (IcfaiTech), The ICFAI Foundation for Higher Education (Deemed to be University), Hyderabad, Telangana, India; Department of Electronics and Communication Engineering, GRIET, Hyderabad, Telangana, India; Department of Electrical and Electronics Engineering, BITS Pilani, Hyderabad, Telangana, India",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","382","387","Multiplication is a fundamental arithmetic operation with applications in various fields, such as neural networks, signal and image processing. Ternary multiplication, an emerging area of research, explores the multiplication of numbers represented in the ternary numeral system. This paper proposes a new technique for computing partial product trits of multi-digit multiplication, along with improved adder modules, intending to reduce power dissipation. Two parallel paths have been proposed to calculate the final product, thereby improving the latency of the multiplier. The internal adder modules of the multiplier have been designed to optimise the number of transistors, resulting in lower power consumption. Results prove that the proposed design significantly improves power, delay, and the power-delay product (PDP). The proposed three-trit multiplier shows a 20.7% improvement in power, 23.17% in delay, 39.11% in PDP, and 18.76% in transistor count compared to the existing design.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595938","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595938","Ternary multiplier;Low Power;Power-Delay Product;Three-Trit Multiplier","Power demand;Circuits and systems;Image processing;Neural networks;Energy efficiency;Delays;Power dissipation","","","","17","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Weight Update Scheme for 1T1R Memristor Array Based Equilibrium Propagation","B. Taylor; X. Yang; H. Li","Department of Electrical and Computer Engineering, Duke University, Durham, NC, USA; Department of Electrical and Computer Engineering, Duke University, Durham, NC, USA; Department of Electrical and Computer Engineering, Duke University, Durham, NC, USA",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","388","392","While local learning rules like equilibrium propagation have been theorized as efficient algorithms to implement with memristor technology, few works have simulated this algorithm with memristor nonidealities, such as cycle-to-cycle and device-to-device variations and nonlinear dynamics. Furthermore, a specific architecture and update scheme that can be implemented by peripheral circuitry needs to be outlined to move forward in this line of research. In this work, we propose an update scheme implementing equilibrium propagation that can be efficiently implemented in circuitry. We find that learning with memristor nonidealities achieves little or no accuracy degradation when compared to training without nonidealities.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595934","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595934","","Training;Performance evaluation;Multiplexing;Degradation;Accuracy;Heuristic algorithms;Memristors","","","","29","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Dynamic Detection and Mitigation of Read-disturb for Accurate Memristor-based Neural Networks","S. Diware; M. A. Yaldagard; A. Gebregiorgis; R. V. Joshi; S. Hamdioui; R. Bishnoi","Computer Engineering Lab, Delft University of Technology, Delft, The Netherlands; Computer Engineering Lab, Delft University of Technology, Delft, The Netherlands; Computer Engineering Lab, Delft University of Technology, Delft, The Netherlands; IBM Research Division, Yorktown Heights, NY, USA; Computer Engineering Lab, Delft University of Technology, Delft, The Netherlands; Computer Engineering Lab, Delft University of Technology, Delft, The Netherlands",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","393","397","Computation-in-memory (CIM) using memristors can facilitate data processing within the memory itself, leading to superior energy efficiency than conventional von-Neumann architecture. This makes CIM well-suited for data-intensive applications like neural networks. However, a large number of read operations can induce an undesired resistance change in the memristor, known as read-disturb. As memristor resistances represent the neural network weights in CIM hardware, read-disturb causes an unintended change in the network’s weights that leads to poor accuracy. In this paper, we propose a methodology for read-disturb detection and mitigation in CIM-based neural networks. We first analyze the key insights regarding the read-disturb phenomenon. We then introduce a mechanism to dynamically detect the occurrence of read-disturb in CIM-based neural networks. In response to such detections, we develop a method that adapts the sensing conditions of CIM hardware to provide error-free operation even in the presence of read-disturb. Simulation results show that our proposed methodology achieves up to 2× accuracy and up to 2× correct operations per unit energy compared to conventional CIM architectures.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595966","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595966","","Resistance;Accuracy;Prevention and mitigation;Simulation;Neural networks;Memory management;Memristors","","","","34","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"The Ouroboros of Memristors: Neural Networks Facilitating Memristor Programming","Z. Yu; M. -J. Yang; J. Finkbeiner; S. Siegel; J. P. Strachan; E. Neftci","Fakultät für Elektrotechnik und Informationstechnik, RWTH Aachen, Aachen, Germany; Peter Grünberg Institut, Forschungszentrum Jülich GmbH, Jülich, Germany; Fakultät für Elektrotechnik und Informationstechnik, RWTH Aachen, Aachen, Germany; Peter Grünberg Institut, Forschungszentrum Jülich GmbH, Jülich, Germany; Fakultät für Elektrotechnik und Informationstechnik, RWTH Aachen, Aachen, Germany; Fakultät für Elektrotechnik und Informationstechnik, RWTH Aachen, Aachen, Germany",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","398","402","Memristive devices hold promise to improve the scale and efficiency of machine learning and neuromorphic hardware, thanks to their compact size, low power consumption, and the ability to perform matrix multiplications in constant time. However, on-chip training with memristor arrays still faces challenges, including device-to-device and cycle-to-cycle variations, switching non-linearity, and especially SET and RESET asymmetry [1], [2]. To combat device non-linearity and asymmetry, we propose to program memristors by harnessing neural networks that map desired conductance updates to the required pulse times. With our method, approximately 95% of devices can be programmed within a relative percentage difference of ±50% from the target conductance after just one attempt. Our approach substantially reduces memristor programming delays compared to traditional write-and-verify methods, presenting an advantageous solution for on-chip training scenarios. Furthermore, our proposed neural network can be accelerated by memristor arrays upon deployment, providing assistance while reducing hardware overhead compared with previous works [3]–[6].This work contributes significantly to the practical application of memristors, particularly in reducing delays in memristor programming. It also envisions the future development of memristor-based machine learning accelerators.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595913","Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595913","","Training;Neural networks;Memristors;Machine learning;Programming;Hardware;System-on-chip","","1","","17","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Effect of Line Resistance of Passive Memristive Crossbars on Spiking Neural Network Performance","P. Lewden; A. F. Vincent; J. Tomas; C. -H. Chang; S. Saïghi","CNRS@CREATE, Singapore; CNRS, Bordeaux INP, IMS, UMR 5218, Univ. Bordeaux, Talence, France; CNRS, Bordeaux INP, IMS, UMR 5218, Univ. Bordeaux, Talence, France; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; CNRS, Bordeaux INP, IMS, UMR 5218, Univ. Bordeaux, Talence, France",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","403","407","Hardware spiking neural networks using memristors as synapses are promising candidates for highly integrated and low-power event-based computations. However, when using passive synaptic crossbars, a number of limitations linked to the high parallelism of the memristive synapses appear. In this paper, we focus on the detrimental effect of the synaptic line resistance of passive crossbars made of ferroelectric tunnel junction memristive devices on learning capabilities. Using a model of such memristive device that considers the actual voltage applied on the synapses when updating their weights, we show how this line resistance impacts the performance of a single layer all-to-all spiking neural network using unsupervised and reward-modulated learning, and how these detrimental effects can be mitigated.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595965","National Research Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595965","Memristors;passive crossbar;reward-modulated learning;spiking neural networks;unsupervised learning","Resistance;Training;Performance evaluation;Neurons;Supervised learning;Memristors;Voltage","","","","13","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Vibration may Break the Conductive Filament in amorphous Germanium based Memristor","Z. Li; P. D. Börner; M. Müller; A. Bablich; P. H. Bolívar; B. Choubey","Institute of Analogue Circuits and Image Sensors, University of Siegen, Siegen, Germany; Institute of Analogue Circuits and Image Sensors, University of Siegen, Siegen, Germany; Institute of High Frequency and Quantum Electronics, University of Siegen, Siegen, Germany; Institute of Graphene-Based Nanotechnology, University of Siegen, Siegen, Germany; Institute of High Frequency and Quantum Electronics, University of Siegen, Siegen, Germany; Institute of Analogue Circuits and Image Sensors, University of Siegen, Siegen, Germany",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","408","412","In this work, we present a memristor that utilises amorphous Germanium as its middle layer. This memristor exhibits a different bipolar switching behaviour, which is inverse to that of the typical electrical chemical metallization memristor. Additionally, we discovered that this memristor is sensitive to external vibrations, causing it to switch from a low resistance state to ultra-high resistance state. Our hypothesis is that the conductive filament passing through the amorphous Germanium is disrupted due to the vibrations.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595884","Ministry of Education; European Commission; Deutsche Forschungsgemeinschaft; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595884","Memristors;Electrochemical metallization;Amorphous germanium;vibration;conductive filament","Vibrations;Resistance;Metallization;Circuits and systems;Memristors;Voltage;Switches","","","","19","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"An Area-Efficient CNN Accelerator Supporting Global Average Pooling with Arbitrary Shapes","Y. Bai; X. Zhang; Q. Wang; J. Lv; L. Chen; Y. Du; L. Du","Nanjing University, Nanjing, China; Nanjing University, Nanjing, China; Nanjing University, Nanjing, China; Nanjing University, Nanjing, China; Beijing Microelectronics Technology Institute, Beijing, China; Nanjing University, Nanjing, China; Nanjing University, Nanjing, China",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","413","416","Integrating dedicated convolution neural network (CNN) accelerators within the processing chips has been a common solution for efficient CNN inference in internet-of-thing (IoT) devices. Fully in-accelerator processing of different computational layers is essential to support a wide range of CNN models. However, previous works lack in-depth discussion for hardware implementation of global average pooling (GAP) layers, which are widely used in classification models. This paper proposes a novel CNN accelerator with high area efficiency for event-driven IoT applications. Fully in-accelerator processing is supported for popular CNN models, such as MobileNet V2 and ResNet34. GAP layers with arbitrary shapes are also supported by software-hardware co-design to enable the low-cost deployment of customized CNN models. Compared with the reference, the proposed design reduces the gate count of the pooling module by 45.1% and achieves a 13.2% area-efficiency improvement of the overall CNN accelerator with negligible accuracy loss.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595877","Research and Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595877","convolution neural network;high area efficiency;global average pooling;arbitrary shapes;customized CNN model","Accuracy;Shape;Convolution;Circuits and systems;Computational modeling;Neural networks;Logic gates","","2","","9","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"ConvMapSim: Modeling and Simulating Convolutional Weight Mapping for PIM Arrays","K. E. Jeon; W. Seo; J. Rhe; J. H. Ko","Department of Electrical and Computer Engineering, Sungkyunkwan University, Suwon, Korea; Department of Semiconductor and Display Engineering, Sungkyunkwan University, Suwon, Korea; Department of Electrical and Computer Engineering, Sungkyunkwan University, Suwon, Korea; Department of Electrical and Computer Engineering, Sungkyunkwan University, Suwon, Korea",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","417","421","While the selection of convolutional weight mapping method significantly influences the latency and energy efficiency of PIM systems, existing PIM simulators lack the flexibility needed to assess and compare various mapping approaches. Additionally, a rigorous definition and formulation of the weight mapping problem remain outstanding challenges. To address this issue, this paper first establishes a formal definition of the convolutional weight mapping method accompanied by a rigorous mathematical model for evaluating its computing cycles. Then, we introduce ConvMapSim, a novel simulation platform designed to compute the energy and latency performance of state-of-the-art mapping methods. Furthermore, the platform offers visualizations of mapping methods, providing intuitive insights into their structures and behaviors.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595954","National Research Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595954","","Visualization;Circuits and systems;Computational modeling;Mathematical models;Energy efficiency;Artificial intelligence","","","","13","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"A Feature Map Lossless Compression Framework for Convolutional Neural Network Accelerators","Z. Zhang; X. Jiao; C. Xu","State Key Laboratory of ASIC and System, Fudan University, Shanghai, China; SenseTime Research; SenseTime Research",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","422","426","This paper proposes a predictor-based lossless compression algorithm for the feature maps present within convolutional neural networks (CNNs), which provides the possibility to solve the system bandwidth bottleneck and excessive power consumption problem of hardware acceleration. It is also an algorithm-hardware co-design methodology, yielding a hardware-friendly compression approach with low power consumption. The performance of the algorithm is evaluated in the detection, recognition, and segment CNN tasks respectively. Results show that an average compression ratio of 3.03x and a gain of nearly 50% over existing methods can be achieved for VGG-16; 2.78x and a gain of around 51% for ResNet-18; 2.45 and a gain of nearly 38% for SegNet.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595980","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595980","Feature map compression;deep learning;convolutional neural networks;hardware acceleration","Power demand;Circuits and systems;Fitting;Bandwidth;Prediction algorithms;Convolutional neural networks;Task analysis","","","","18","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"CNN Implementation of Bayesian Plasticity for Robust Learning","N. Ramos; H. Li","Department of Electrical and Computer Engineering, Duke University, Durham, NC, USA; Department of Electrical and Computer Engineering, Duke University, Durham, NC, USA",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","432","436","Bayesian plasticity is presented as an optimal alternative to the delta rule by incorporating uncertainty to guide weight updates. Originally adapted for reservoir computing schemes, Bayesian plasticity showed promise in accelerating the optimization of the mean square error (MSE) function. However, the impact that Bayesian learning rules have in accelerating classification tasks has not been explored. Furthermore, the influence that Bayesian plasticity has on backpropagating weight updates is unclear since reservoir computing only feeds back error to the output layer. Thus, we have simplified and adapted Bayesian plasticity rules to the output layer of non-spiking neural networks and evaluated the impact on training and robustness.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595888","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595888","CNN;Bayesian;plasticity;robustness","Training;Iris;Uncertainty;Neural networks;Reservoir computing;Mean square error methods;Robustness","","","","13","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"A Novel Number Representation and Its Hardware Support for Accurate Low-Bit Quantization on Large Recommender Systems","Y. -D. Chu; P. -H. Kuo; L. -M. Ho; J. -D. Huang","Institute of Electronics, National Yang Ming Chiao Tung University, Hsinchu, Taiwan; Institute of Electronics, National Yang Ming Chiao Tung University, Hsinchu, Taiwan; Institute of Electronics, National Yang Ming Chiao Tung University, Hsinchu, Taiwan; Institute of Electronics, National Yang Ming Chiao Tung University, Hsinchu, Taiwan",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","437","441","Deep learning based recommender systems with large embedding tables have become pivotal for web content recommendation. However, the growing size of those tables, reaching tens of gigabytes or even terabytes, presents a tough challenge for conducting inferences on resource-constrained hardware. In this paper, we present a novel 6-bit fixed-point number representation format for more precise quantization on recommender models. The proposed format is specifically designed to accommodate the nonuniform weight distribution inside those huge embedding tables. To further alleviate the model size, the well-known K-means quantization technique is utilized for 4-bit quantization and beyond. Moreover, we also propose dedicated hardware decoder architectures for both 6-bit and 4-bit quantization to ensure efficient runtime inference. Experimental results show that the proposed low-bit (8~3-bit) quantization techniques on embedding tables yield 4~10.7x model size reduction with minor accuracy loss as compared to the original FP32 model. Therefore, the proposed number representation format and low-bit quantization techniques can effectively and drastically reduce the model size of large recommender systems with a very low area cost while still keeping the accuracy loss minimized.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595902","National Science and Technology Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595902","recommendation system;number representation;quantization","Training;Deep learning;Quantization (signal);Accuracy;Runtime;Costs;Circuits and systems","","","","14","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"AdaQAT: Adaptive Bit-Width Quantization-Aware Training","C. Gernigon; S. -I. Filip; O. Sentieys; C. Coggiola; M. Bruno","Univ. Rennes, Inria, CNRS, IRISA, Rennes, France; Univ. Rennes, Inria, CNRS, IRISA, Rennes, France; Univ. Rennes, Inria, CNRS, IRISA, Rennes, France; Spacecraft Techniques, on-Board Data Handling CNES, Toulouse, France; Spacecraft Techniques, on-Board Data Handling CNES, Toulouse, France",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","442","446","Large-scale deep neural networks (DNNs) have achieved remarkable success in many application scenarios. However, high computational complexity and energy costs of modern DNNs make their deployment on edge devices challenging. Model quantization is a common approach to deal with deployment constraints, but searching for optimized bit-widths can be challenging. In this work, we present Adaptive Bit-Width Quantization Aware Training (AdaQAT), a learning-based method that automatically optimizes weight and activation signal bit-widths during training for more efficient DNN inference. We use relaxed real-valued bit-widths that are updated using a gradient descent rule, but are otherwise discretized for all quantization operations. The result is a simple and flexible QAT approach for mixed-precision uniform quantization problems. Compared to other methods that are generally designed to be run on a pretrained network, AdaQAT works well in both training from scratch and fine-tuning scenarios. Initial results on the CIFAR-10 and ImageNet datasets using ResNet20 and ResNet18 models, respectively, indicate that our method is competitive with other state-of-the-art mixed-precision quantization approaches.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595895","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595895","Neural Network Compression;Quantization Aware Training;Adaptive Bit-Width Optimization","Training;Learning systems;Adaptation models;Quantization (signal);Image coding;Costs;Computational modeling","","2","","30","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"HLC: A Hardware-friendly Quantization and Cache-based Accelerator for Transformer","X. Sun; Y. Zhang; Y. Jiang; Z. Li; B. Han; J. Mai; Z. Luo; E. Yao","School of Microelectronics, South China University of Technology, Guangzhou, China; School of Microelectronics, South China University of Technology, Guangzhou, China; School of Microelectronics, South China University of Technology, Guangzhou, China; School of Microelectronics, South China University of Technology, Guangzhou, China; School of Microelectronics, South China University of Technology, Guangzhou, China; School of Microelectronics, South China University of Technology, Guangzhou, China; School of Microelectronics, South China University of Technology, Guangzhou, China; School of Microelectronics, South China University of Technology, Guangzhou, China",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","447","451","Transformer-based language representations have demonstrated superior accuracy in various natural language processing (NLP) tasks. However, their deployment on terminal hardware is challenging due to the involvement of dense matrix operations and complex data flows. In this paper, we propose a heterogeneous multi-core low-power architecture design based on cache (HLC) for TIFP11: top-K half-precision integerized floating-point format. A quantization method is proposed to enable a hardware-friendly model compression technique, TIFP11. Furthermore, parallelized process elements (PE) and storage mechanisms for TIFP11 are carefully designed. Additionally, a cache architecture based on heterogeneous multi-core systems that significantly enhances the efficiency of transformer operations is described. We implement the transformer model using appropriate hardware scheduling. The IFP11 were deployed and verified the performance during storage and calculation. Experimental results demonstrate that the transformer deployed on VCK190 achieves a latency of 9.31ms with a batch size of 32, resulting in a 37.9× speedup compared to the CPU platform and a 1.94× speedup compared to the GPU platform.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595871","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595871","Transformer;Hardware Accelerator;TIFP11;Cache;Heterogeneous Multicore","Quantization (signal);Accuracy;Power demand;Multicore processing;Graphics processing units;Transformers;Natural language processing","","","","18","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"PQDE: Comprehensive Progressive Quantization with Discretization Error for Ultra-Low Bitrate MobileNet towards Low-Resolution Imagery","Z. Yue; R. Wu; L. Ma; C. Fu; C. -W. Sham","School of Computer Science, The University of Auckland, New Zealand; School of Computer Science, Harbin Institute of Technology, China; School of Computer Science, The University of Auckland, New Zealand; School of Information Science and Engineering, Northeastern University, China; School of Computer Science, The University of Auckland, New Zealand",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","452","456","In deep learning, quantization is employed to tackle deployment challenges of neural networks in resource-limited environments like mobile and edge devices. Traditional full-precision (32-bit floating-point) models, while effective, are restricted by their high memory and computational demands, limiting their use in devices with constrained computational power and resources. To address this problem, we present a neural network quantization methodology that is primarily geared to-wards resource-constrained devices and inputs. Our methodology focuses on optimizing network performance for resource-limited settings, featuring a unique forward quantization function. This function employs the Minimize Discretization Error (MDE) technique to reduce information loss during quantization, particularly targeting near-zero weights, while maintaining computational efficiency and model accuracy. Additionally, we integrate the Arctangent Soft Round (ASR) method in the forward process to further smooth the data in low-bit quantization scenarios. Finally, we design a progressive quantization method, progressively transitioning from full precision to low bits, stabilizing the network at each quantization level. Tested on a resource-efficient variant of MobileNetV2 and low-resolution input data (CIFAR10/100), our method surpasses most contemporary techniques in terms of lightweight model performance. Through progressive quantization, our 4-bit quantized model even exceeds the accuracy of its full-precision counterpart as evidenced by our ablation studies.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595949","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595949","Deep Learning;Quantization;Neural Network;Model compression","Performance evaluation;Deep learning;Quantization (signal);Accuracy;Limiting;Computational modeling;Neural networks","","","","41","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"SRU-Q: Hardware-friendly Stochastic Rounding Unit-based Gradient Quantization for CNN Training","S. Jeong; D. Choi; H. Kim","Department of Electrical and Information Engineering and Research, Center for Electrical and Information Technology, Seoul National University of Science and Technology, Seoul, Korea; Department of Electrical and Information Engineering and Research, Center for Electrical and Information Technology, Seoul National University of Science and Technology, Seoul, Korea; Department of Electrical and Information Engineering and Research, Center for Electrical and Information Technology, Seoul National University of Science and Technology, Seoul, Korea",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","457","461","Quantization in convolutional neural networks (CNNs) involves using a low precision to decrease convolution operation costs, resulting in reduced power consumption and faster network performance. Notably, gradient quantization plays a crucial role in CNN training accelerators, as backpropagation typically incurs higher computational costs for calculating weight gradients than forward propagation does. Stochastic rounding (SR), which employs random number generation, is recognized as an effective method for stabilizing backpropagation quantization. However, the process of generating random numbers in hardware has significant drawbacks—notably high computational costs and substantial difficulties in implementation. This paper introduces a technique for efficient SR using a hardware-optimized random number generator, termed linear feedback shift register-bitwise-stochastic rounding unit (LBSRU). The LBSRU efficiently conducts SR with a small amount of random number generation and adapts to various network types by altering the random number generation approach for different batch sizes. Specifically, we designed and synthesized our method on the FPGA platform to create a prototype. A comparison with previous studies revealed that our method requires significantly fewer resources: 98.19% fewer lookup tables (LUTs) and 98.38% fewer flip-flops (FFs).","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595985","National Research Foundation of Korea; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595985","stochastic rounding;convolutional neural networks;gradient quantization;FPGA;random number generator","Training;Backpropagation;Quantization (signal);Prototypes;Generators;Hardware;Computational efficiency","","1","","31","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Resistive Processing Unit-based On-chip ANN Training with Digital Memory","S. Deshmukh; S. Patil; A. Biswas; V. Saraswat; A. Kadam; A. K. Singh; L. Somappa; M. S. Baghini; U. Ganguly","Department of Electrical Engineering, Indian Institute of Technology Bombay, Mumbai, India; Department of Electrical Engineering, Indian Institute of Technology Bombay, Mumbai, India; Department of Electrical Engineering, Indian Institute of Technology Bombay, Mumbai, India; Department of Electrical Engineering, Indian Institute of Technology Bombay, Mumbai, India; Department of Electrical Engineering, Indian Institute of Technology Bombay, Mumbai, India; Department of Electrical Engineering, Indian Institute of Technology Bombay, Mumbai, India; Department of Electrical Engineering, Indian Institute of Technology Bombay, Mumbai, India; Department of Electrical Engineering, Indian Institute of Technology Bombay, Mumbai, India; Department of Electrical Engineering, Indian Institute of Technology Bombay, Mumbai, India",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","462","466","Artificial Neural Networks (ANNs) are popular for classification and regression tasks. Several in-memory computing architectures have been proposed to accelerate forward and backward passes in ANN training. However, the traditional ANN training operation (with backpropagation algorithm) is energy, area, and time-hungry due to separate and sequential computation units for the weight gradient calculation followed by weight update. A Resistive Processing Unit (RPU) architecture was explicitly proposed for the acceleration of weight gradient calculation and update for analog non-volatile memories. Despite valuable properties that enable RPU, the analog non-volatile memories suffer from issues like drift, non-linearity, asymmetry, variability, and high write energy, causing an increase in the array peripherals’ cost and accuracy degradation. In this work, we propose an adaptation of RPU to SRAM-based multi-bit weights for the ANN training acceleration. A simple combinational weight update control logic is proposed to facilitate the weight update. The proposed architecture shows an improvement in the linearity and symmetry for weight update, which further improves the training accuracy of the system.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595973","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595973","Artificial neural network (ANN);resistive processing unit (RPU);in-memory computation (IMC);static random access memory (SRAM);stochastic weight update","Training;Performance evaluation;Accuracy;Nonvolatile memory;Random access memory;Artificial neural networks;Computer architecture","","","","23","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"The Multilayer Neural Network Implementation Using SRAM-Based Reconfigurable Cognitive Computation Matrices","I. -C. Liu; C. -J. Chen; X. -Z. Li; Y. -Q. Cheng; C. -W. Huang; P. -H. Lin; H. -W. Pu; S. -Y. Peng; Y. Tsao","Department of Electrical Engineering, National Taiwan University of Science and Technology, Taipei City, Taiwan, R. O. C.; Department of Electrical Engineering, National Taiwan University of Science and Technology, Taipei City, Taiwan, R. O. C.; Department of Electrical Engineering, National Taiwan University of Science and Technology, Taipei City, Taiwan, R. O. C.; Department of Electrical Engineering, National Taiwan University of Science and Technology, Taipei City, Taiwan, R. O. C.; Department of Electrical Engineering, National Taiwan University of Science and Technology, Taipei City, Taiwan, R. O. C.; Department of Electrical Engineering, National Taiwan University of Science and Technology, Taipei City, Taiwan, R. O. C.; Department of Electrical Engineering, National Taiwan University of Science and Technology, Taipei City, Taiwan, R. O. C.; Department of Electrical Engineering, National Taiwan University of Science and Technology, Taipei City, Taiwan, R. O. C.; Academia Sinica, Research Center for Information Technology Innovation, Taipei City, Taiwan, R. O. C.",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","467","471","A multiple-layer network implementation with an array of static-random-access-memory (SRAM) based reconfigurable cognitive computation matrices (RCCMs) is presented. The multiply-accumulation output currents can be converted into single-ended currents by on-chip analog nonlinear circuits to realize three commonly used activation functions: the rectified linear unit (ReLU), radial basis function (RBF), and sigmoid function. The resultant output currents from the RCCM are designed to either broadcast to other RCCMs in voltage mode or be summed up in current mode. A concept-proving prototype chip, including a 17×16 RCCM with 4-bit input and weight resolutions, has been designed and fabricated in a 0.18µm CMOS process. The measured computation efficiency is 3.6TOPS/W. The computation accuracy deteriorated by process variation can be significantly improved by adopting 49 mismatch parameters after calibration. A handwritten digit recognition database, MNIST, is employed to evaluate the chip performance by implementing a 3-layer neural network, achieving an accuracy of 91.2%.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595936","Ministry of Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595936","","Semiconductor device measurement;Handwriting recognition;Accuracy;Databases;Current measurement;Neural networks;Prototypes","","","","5","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"ACC: Adaptive Compression Framework for Efficient On-device CNN Training","G. Lee; S. Lee; H. Kim","Department of Electrical and Information Engineering and Research, Center for Electrical and Information Technology, Seoul National University of Science and Technology, Seoul, Korea; Department of Electrical and Information Engineering and Research, Center for Electrical and Information Technology, Seoul National University of Science and Technology, Seoul, Korea; Department of Electrical and Information Engineering and Research, Center for Electrical and Information Technology, Seoul National University of Science and Technology, Seoul, Korea",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","472","476","Network compression methods have been studied in various forms, such as pruning and quantization, to enable the deployment of large-scale convolutional neural networks (CNNs) in resource-constrained environments. However, several challenges remain in utilizing these compressed CNNs on resource-constrained platforms (e.g., on-device environments). In particular, previous studies on network compression have mostly focused on inference, and pruning/quantization techniques have been performed separately. To address these issues, this paper proposes a new compression technique, called an adaptive compression framework for CNN training (ACC), which combines the advantages of conventional compression techniques. The ACC is an adaptive solution that addresses the memory bottleneck by reducing the resolution of activation/gradient in the beginning layers of the CNN with weights/activations/gradients all quantized to 8 bits and pruning a large number of CNN filters in the subsequent layers. In addition, the large kernel convolution compression (LKCC) included in the ACC helps minimize the amount of information loss and effectively reduces memory and computation by applying a 2×2 average pooling filter to the activation/gradient of the beginning layers. Fine-tuning experiments using the ResNet18 model on the CIFAR-100 dataset showed that the proposed ACC framework can achieve efficient CNN training on mobile/edge devices by reducing memory consumption and FLOPs by 85% and 37%, respectively, with only a negligible performance degradation of 0.17% compared with the baseline.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595863","National Research Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595863","Quantization;Pruning;Network Compression;CNN Training;On-device Training","Training;Degradation;Performance evaluation;Filters;Quantization (signal);Convolution;Memory management","","1","","35","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Deploying Artificial Intelligence in Design Verification to Accelerate IP/SoC Sign-off with Zero Escape","S. Bhattacherjee; D. Shah; D. Pal","Dept. of Electrical & Electronics Engg., Birla Institute of Technology & Science, Pilani, K.K. Birla, Goa, India; Dept. of Electrical & Electronics Engg., Birla Institute of Technology & Science, Pilani, K.K. Birla, Goa, India; Dept. of Electrical & Electronics Engg., Birla Institute of Technology & Science, Pilani, K.K. Birla, Goa, India",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","477","481","Design verification is a bottleneck in development of Intellectual Property (IP) subsystems and System-on-Chip (SoC). State-of-art verification processes practiced in VLSI-industries involve methodologies that are time-consuming, effort-hungry and expensive. They also have high possibilities of bug-escape for complex memory-intensive, computation-intensive, mathematical and logical design modules if the verification sign-off at the IP-SoC boundary is not tightly closed. The methodology proposed here recommends an alternate sign-off approach through Machine Learning (ML) applications on a complex design, namely, Temperature Sensor (TS) in Dual-In-line Memory Module (DIMM) of a Dynamic Random Access Memory (DRAM). Factual evidences derived from Random Forest classifier and regressor not only confirm behavioural accuracy of the Design Under Test (DUT) but also portray decision trees to visualize RTL implementation of the architectural specification. The experiment testifies a smooth integration of ML-adaptor for analyses of a formal verification data-set to claim faster debug-ability with high accuracy while predicting the output for sample stimuli to DUT.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595855","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595855","ML-Driven-Reference-Model;Intelligent-Data-Integrity-Analyzer;Design-Independent-Verification;Enhanced-Formal-Verification;AI-Driven-Verification","Temperature sensors;Visualization;Accuracy;Random access memory;Memory modules;Intellectual property;System-on-chip","","","","13","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Variable layout CMOS pixels for end-to-end learning in task specific Image Sensors","B. Choubey; H. Sommerhoff; M. Moeller; A. Kolb","Chair of Analogue Circuits and Image Sensors Center for Sensor Systems (ZESS), University of Siegen, Siegen, Germany; Chair of Computer Graphics and Multimedia Systems Center for Sensor Systems (ZESS), University of Siegen, Siegen, Germany; Chair of Computer Vision Center for Sensor Systems (ZESS), University of Siegen, Siegen, Germany; Chair of Computer Graphics and Multimedia Systems Center for Sensor Systems (ZESS), University of Siegen, Siegen, Germany",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","482","486","CMOS Image Sensors produce data used in several machine learning models. Typically, their layout is limited to rectangular grid of uniform pixels. However, their shape and size can provide another optimisation parameter in end-to-end training in specific machine learning tasks. Variable layout pixels are observed as one potential approach. An image sensor with such variable and learned layout is presented. A technique for automatic generation of such layouts is also described, along with data from a typical implementation of such pixels.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595862","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595862","","Image sensors;Semiconductor device modeling;Training;Shape;Layout;Data models;Transistors","","1","","12","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Accelerator Design using 3D Stacked Capacitorless DRAM for Large Language Models","J. Sharda; P. -K. Hsu; S. Yu","School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, USA",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","487","491","Large language models (LLMs) have been immensely useful for natural language processing tasks. However, the current model sizes are increasing exponentially, along with generating large amounts of intermediate data. Here, we propose to use the capacitorless 3D stackable DRAM, which is an emerging memory enabling scaling of DRAM in the vertical direction like 3D NAND Flash. A 3D DRAM can store much larger LLMs compared to conventional DRAM at higher density. Further, to reduce the intermediate data size, we propose to use a layer-wise sparsity-quantization hybrid (LSQH) algorithm, which induces sparsity based on calculations performed using low-bit quantization to reduce both the energy consumption and the data storage requirements. Finally, a 3D heterogeneously integrated accelerator is designed by stacking a 3D DRAM with logic dies designed in the 3 nm technology node, which exploits the LSQH algorithm for the Llama2 model. The evaluation of the proposed system shows an energy efficiency of > 25 TOPS/W and an area efficiency of > 14.4 TOPS/mm2, with minimal drop in accuracy. Further model scaling is performed to obtain the energy efficiency and area efficiency for larger LLMs.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595901","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595901","Large language model;3D stackable DRAM;hardware accelerator;heterogenous integration","Solid modeling;Three-dimensional displays;Accuracy;Large language models;Stacking;Random access memory;Energy efficiency","","2","","17","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Language Modeling on a SpiNNaker2 Neuromorphic Chip","K. K. Nazeer; M. Schöne; R. Mukherji; B. Vogginger; C. Mayr; D. Kappel; A. Subramoney","Chair of Highly-Parallel VLSI-Systems and Neuro-Microelectronics, Technische Universität, Dresden, Germany; Chair of Highly-Parallel VLSI-Systems and Neuro-Microelectronics, Technische Universität, Dresden, Germany; Birla Institute of Technology and Science, Goa, India; Chair of Highly-Parallel VLSI-Systems and Neuro-Microelectronics, Technische Universität, Dresden, Germany; Chair of Highly-Parallel VLSI-Systems and Neuro-Microelectronics, Technische Universität, Dresden, Germany; Institut für Neuroinformatik, Ruhr Universität Bochum, Bochum, Germany; Dept. of Computer Science, Royal Holloway, University of London, Egham, United Kingdom",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","492","496","As large language models continue to scale in size rapidly, so too does the computational power required to run them. Event-based networks on neuromorphic devices offer a potential way to reduce energy consumption for inference significantly. However, to date, most event-based networks that can run on neuromorphic hardware, including spiking neural networks (SNNs), have not achieved task performance even on par with LSTM models for language modeling. As a result, language modeling on neuromorphic devices has seemed a distant prospect. In this work, we demonstrate the first-ever implementation of a language model on a neuromorphic device – specifically the SpiNNaker2 chip – based on a recently published event-based architecture called the EGRU. SpiNNaker2 is a many-core neuromorphic chip designed for large-scale asynchronous processing, and the EGRU is architected to leverage such hardware efficiently while maintaining competitive task performance. This implementation marks the first time a neuromorphic language model matches LSTMs, setting the stage for taking task performance to the level of large language models. We also demonstrate results on a gesture recognition task based on inputs from a DVS camera. Overall, our results showcase the feasibility of this neuro-inspired neural network in hardware, highlighting significant gains versus conventional hardware in energy efficiency for the common use case of single batch inference.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595870","Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595870","Neuromorphic;Language model;Energy efficient;Sparse activity;Sparse weights","Performance evaluation;Neuromorphics;Large language models;Neural networks;Spiking neural networks;Hardware;Task analysis","","","","34","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Real Post-Training Quantization Framework for Resource-Optimized Multiplier in LLMs","M. Seo; S. Jeong; H. -J. Lee; X. T. Nguyen","Department of Electrical and Computer Engineering, Inter-University Semiconductor Research Center (ISRC), Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering, Inter-University Semiconductor Research Center (ISRC), Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering, Inter-University Semiconductor Research Center (ISRC), Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering, Inter-University Semiconductor Research Center (ISRC), Seoul National University, Seoul, Korea",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","497","501","Large language models (LLMs) offer unparalleled natural language processing capabilities but come with massive memory footprint and computation requirements. Post Training Quantization (PTQ) is widely adopted to tackle the challenges without expensive LLMs’ fine-tuning. However, quantizing LLMs with PTQ typically requires a scale and bias for accuracy and focuses on minimizing the total number of bits rather than hardware resources. To address the problem, we propose a new PTQ framework. Our method primarily focuses on minimizing the mantissa bits in floating-point multiplications, identified as the most resource-intensive components. More importantly, to mitigate large accuracy degradation, we introduce a distribution-based strategy for selecting quantization-target parameters and a Mean Squared Error-based quantization approach with extra exponent bias. The experimental results show that our framework outputs a new sub-8bit format, i.e., FP6 with four exponent bits and one mantissa bit, reducing GPT-2 models by 5.3 times with only a minimal increase in perplexity (0.36). In addition, we present a custom-designed multiplier, greatly enhancing resource-efficiency. Our multiplier design significantly reduces resource utilization by 53.2 times over a FP32 multiplier.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595874","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595874","","Training;Quantization (signal);Accuracy;Large language models;Memory management;Focusing;Hardware","","","","21","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Accelerate Large Language Model Inference on Edge TPU with OpenVX framework","Y. -E. Wu; H. -I. Wu; K. -C. Chin; Y. -C. Yang; R. -S. Tsay","Taipei Fuhsing Private School, Taiepi, Taiwan; DeepMentor, Hsin Chu, Taiwan; DeepMentor, Hsin Chu, Taiwan; Computer Science, Hua National Tsing Hua University, HsinChu, Taiwan; Computer Science, National Tsing Hua University, HsinChu, Taiwan",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","502","506","This paper proposes a novel method to accelerate inference of Large Language Models (LLMs) on Edge Tensor Processing Units (TPUs) by leveraging the OpenVX framework. The approach harnesses the synergistic integration of OpenVX with Edge TPUs to enable parallel processing capabilities and address precision challenges in performing convolutions exclusively through integer arithmetic. Since LLMs, unlike Convolutional Neural Networks (CNNs), cannot automatically construct network architectures via Open Neural Network Exchange (ONNX) parsing, manual network construction using the OpenVX API is necessitated. This demands precise understanding of each constituent component of the original model, as any inaccuracies propagate to entirely erroneous results. Through quantization, the proposed technique preserves accuracy during convolution operations while reusing the integer arithmetic convolution capabilities of Edge TPUs for efficient inference. The method showcases the collaborative synergy achieved between OpenVX and Edge TPUs, enhancing efficiency of LLM inference on resource-constrained edge devices.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595950","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595950","Large Language Model;OpenVX;edge TPU;Quantization","Convolutional codes;Tensors;Runtime;Quantization (signal);Large language models;Prototypes;Programming","","","","13","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Kinship Verification from Text: Towards Discovering Subtitle Textual Features Shared by Family Members using Large Language Models","S. E. Bekhouche; A. Hadid","University of the Basque Country UPV/EHU, San Sebastian, Spain; Sorbonne Center for Artificial Intelligence, Sorbonne University Abu Dhabi, Abu Dhabi, UAE",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","507","511","The objective of kinship verification is to assess whether two individuals are biologically related or not. Previous research has primarily focused on determining kinship from facial patterns and movements, voice, or human gait. In this paper, we explore for the first time in the literature the problem of kinship verification from text. This is a very timely topic given the emergence of generative artificial intelligence and large language models. Our main hypothesis is that two family members inherit and share subtitle textual features that can be seen in the way of writing. The subtle features can be related to genes, culture, experience etc. To address this problem, we propose a Siamese-based BERT transformer incorporating two novel modules, namely Attention and Fusion. The experiments show promising results on the role textual information in kinship verification.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595920","Total; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595920","Kinship;Natural language processing;Deep learning","Social networking (online);Generative AI;Circuits and systems;Large language models;Writing;Transformers;Biology","","","","40","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"ILD-MPQ: Learning-Free Mixed-Precision Quantization with Inter-Layer Dependency Awareness","R. Xu; Q. Duan; Q. Chen; X. Guo","University of Michigan – Shanghai Jiao Tong University Joint Institute, Shanghai Jiao Tong University, Shanghai, China; Inspur Academy of Science and Technology, Jinan, China; Inspur Academy of Science and Technology, Jinan, China; University of Michigan – Shanghai Jiao Tong University Joint Institute, Shanghai Jiao Tong University, Shanghai, China",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","512","516","With the increasing adoption of mixed-precision quantization (MPQ) on edge AI devices, deep neural networks (DNNs) can achieve a satisfactory balance between accuracy and efficiency. However, many existing MPQ methods assumed inter-layer independence in DNNs and focus on optimizing bit-width schemes at the single layer level, leading to an additional loss of accuracy. Recently, several work looked into the inter-layer dependency and applied it in finding optimal MPQ schemes. These work either relied on leaning-based solutions that gave less explanations or missed the empirical validation of various heuristics. In this paper, we dig into the factors that lead to the inter-layer dependency and propose a learning-free inter-layer dependency-aware search method using the NSGA-II algorithm, leveraging a novel per-layer influence metric. The evaluation results across MobileNetV2 and ResNet50 models demonstrate that the proposed method enhances the efficiency of post-training quantization (PTQ) models by 8.7%∼65.3% compared to state-of-the-art learning-free approaches, and guarantees a loss of model efficiency within 4.0%∼8.9% while reducing time costs by 90% compared to learning-based approaches, all under similar hardware consumption constraints.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595945","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595945","Edge AI;Mixed-precision Quantization;Interlayer Dependency","Measurement;Quantization (signal);Accuracy;Costs;Circuits and systems;Search methods;Edge AI","","","","24","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Q-Segment: Segmenting Images In-Sensor for Vessel-Based Medical Diagnosis","P. Bonazzi; Y. Li; S. Bian; M. Magno","ETH Zürich, D-ITET, Zürich, Switzerland; ETH Zürich, D-ITET, Zürich, Switzerland; ETH Zürich, D-ITET, Zürich, Switzerland; ETH Zürich, D-ITET, Zürich, Switzerland",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","517","521","This paper addresses the growing interest in deploying deep learning models directly in-sensor. We present ""Q-Segment"", a quantized real-time segmentation algorithm, and conduct a comprehensive evaluation on a low-power edge vision platform with an in-sensors processor, the Sony IMX500. One of the main goals of the model is to achieve end-to-end image segmentation for vessel-based medical diagnosis. Deployed on the IMX500 platform, Q-Segment achieves ultra-low inference time in-sensor only 0.23 ms and power consumption of only 72mW. We compare the proposed network with state-of-the-art models, both float and quantized, demonstrating that the proposed solution outperforms existing networks on various platforms in computing efficiency, e.g., by a factor of 75x compared to ERFNet. The network employs an encoder-decoder structure with skip connections, and results in a binary accuracy of 97.25 % and an Area Under the Receiver Operating Characteristic Curve (AUC) of 96.97 % on the CHASE dataset. We also present a comparison of the IMX500 processing core with the Sony Spresense, a low-power multi-core ARM Cortex-M microcontroller, and a single-core ARM Cortex-M4 showing that it can achieve in-sensor processing with end-to-end low latency (17 ms) and power consumption (254mW). This research contributes valuable insights into edge-based image segmentation, laying the foundation for efficient algorithms tailored to low-power environments.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595956","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595956","AIoT;neural networks;image segmentation;blood vessel segmentation;TinyML;edge processing;medical imagining;retina vessel","Image segmentation;Power demand;Program processors;Image edge detection;System performance;Receivers;Real-time systems","","","","20","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Microarchitecture Aware Neural Architecture Search for TinyML Devices","J. Guan; G. Liu; F. Zeng; R. Lai; R. Ding; Z. Zhu","Key Laboratory of Analog Integrated Circuits and Systems (Ministry of Education), Xidian University; Key Laboratory of Analog Integrated Circuits and Systems (Ministry of Education), Xidian University; Key Laboratory of Analog Integrated Circuits and Systems (Ministry of Education), Xidian University; Key Laboratory of Analog Integrated Circuits and Systems (Ministry of Education), Xidian University; Key Laboratory of Analog Integrated Circuits and Systems (Ministry of Education), Xidian University; Key Laboratory of Analog Integrated Circuits and Systems (Ministry of Education), Xidian University",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","522","526","Designing accurate and efficient models for tiny machine learning (TinyML) devices is challenging because of its strict power consumption limitations and accuracy requirements. This paper proposed a Microarchitecture Aware Neural Architecture Search (M-NAS) method to consider the detailed microarchitecture into NAS and improve the energy efficiency of TinyML devices. We first build a microarchitecture aware candidate operators pool with the limitation of microarchitecture to balance the inference efficiency and accuracy. Moreover, we generate a microarchitecture aware search space by integrating the microarchitecture-level power and latency into NAS with the help of back-end layout simulation based on the microarchitecture of NPU. These strategies assist our M-NAS to find the optimal model for the microarchitecture of the target NPU. Extensive experiments demonstrate that with the help of the M-NAS, the target NPU yields a considerable 67.1% Top-1 accuracy on ImageNet and achieves a record ultra-high energy efficiency of 3809.52 Frames/J.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595922","Young Scientists Fund; National Key Research and Development Program of China; Xidian University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595922","Neural architecture search;Tiny machine learning;Microarchitecture;Energy efficiency","Microarchitecture;Accuracy;Power demand;Circuits and systems;Tiny machine learning;Layout;Buildings","","","","8","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"An Energy-Efficient Look-up Table Framework for Super Resolution on FPGA","H. Li; S. Jia; J. Guan; R. Lai; S. Liu; Z. Zhu","Key Laboratory of Analog Integrated Circuits and Systems (Ministry of Education), Xidian University; Key Laboratory of Analog Integrated Circuits and Systems (Ministry of Education), Xidian University; Key Laboratory of Analog Integrated Circuits and Systems (Ministry of Education), Xidian University; Key Laboratory of Analog Integrated Circuits and Systems (Ministry of Education), Xidian University; Key Laboratory of Analog Integrated Circuits and Systems (Ministry of Education), Xidian University; Key Laboratory of Analog Integrated Circuits and Systems (Ministry of Education), Xidian University",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","527","531","In view of the demanding computational requirements and constraints on accuracy, the development of an accurate and energy-efficient accelerator for single-image super-resolution is a substantial challenge. This paper introduces a feature retrieval method based on high parallel memory access, which outputs the trained network’s feature values to replace intensive computation and improving the energy efficiency in hardware system. Firstly, we train a cascaded-parallel convolutional network by combining multiple receptive field (RF) shapes in order to optimize recovery accuracy. Then transferring the output features of the trained model to the memory units. Following this, the accelerator is designed based on a highly parallel memory access mechanism, and the features stored in the output memory units are retrieved, thereby circumventing a substantial number of convolution operations. Comprehensive experiments demonstrate that the proposed method achieves competitive recovery accuracy and frame rate when compared with deep neural network (DNN) methods on 3 widely used benchmarks, while also attaining an exceptional energy efficiency of 347.2 Mpixels/J.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595880","Research and Development; National Natural Science Foundation of China; Xidian University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595880","Single-image super-resolution;Look-up table;FPGA;Energy efficiency","Radio frequency;Accuracy;Convolution;Shape;Superresolution;Memory management;Memory architecture","","","","8","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"A Hardware-Efficient EMG Decoder with an Attractor-based Neural Network for Next-Generation Hand Prostheses","M. Kalbasi; M. Shaeri; V. A. Mendez; S. Shokur; S. Micera; M. Shoaran","Institute of Electrical and Micro Engineering and Neuro-X Institute, EPFL, Geneva, Switzerland; Institute of Electrical and Micro Engineering and Neuro-X Institute, EPFL, Geneva, Switzerland; Bertarelli Foundation Chair in Translational Neuroengineering, Neuro-X Institute, EPFL, Geneva, Switzerland; Bertarelli Foundation Chair in Translational Neuroengineering, Neuro-X Institute, EPFL, Geneva, Switzerland; Bertarelli Foundation Chair in Translational Neuroengineering, Neuro-X Institute, EPFL, Geneva, Switzerland; Institute of Electrical and Micro Engineering and Neuro-X Institute, EPFL, Geneva, Switzerland",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","532","536","Advancements in neural engineering have enabled the development of Robotic Prosthetic Hands (RPHs) aimed at restoring hand functionality. Current commercial RPHs offer limited control through basic on/off commands. Recent progresses in machine learning enable finger movement decoding with higher degrees of freedom, yet the high computational complexity of such models limits their application in portable devices. Future RPH designs must balance portability, low power consumption, and high decoding accuracy to be practical for individuals with disabilities. To this end, we introduce a novel attractor-based neural network to realize on-chip movement decoding for next-generation portable RPHs. The proposed architecture comprises an encoder, an attention layer, an attractor network, and a refinement regressor. We tested our model on four healthy subjects and achieved a decoding accuracy of 80.6±3.3%. Our proposed model is over 120 and 50 times more compact compared to state-of-the-art LSTM and CNN models, respectively, with comparable (or superior) decoding accuracy. Therefore, it exhibits minimal hardware complexity and can be effectively integrated as a System-on-Chip.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595960","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595960","","Accuracy;Computational modeling;Neural networks;Estimation;Predictive models;Electromyography;Decoding","","1","","34","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"A Calibratable Model for Fast Energy Estimation of MVM Operations on RRAM Crossbars","J. Cubero-Cascante; A. Vaidyanathan; R. Pelke; L. Pfeifer; R. Leupers; J. M. Joseph","Institute for Communication Technologies and Embedded Systems, RWTH Aachen University, Aachen, Germany; Institute for Communication Technologies and Embedded Systems, RWTH Aachen University, Aachen, Germany; Institute for Communication Technologies and Embedded Systems, RWTH Aachen University, Aachen, Germany; Institute for Communication Technologies and Embedded Systems, RWTH Aachen University, Aachen, Germany; Institute for Communication Technologies and Embedded Systems, RWTH Aachen University, Aachen, Germany; Institute for Communication Technologies and Embedded Systems, RWTH Aachen University, Aachen, Germany",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","537","538","The surge in AI usage demands innovative power reduction strategies. Novel Compute-in-Memory (CIM) architectures, leveraging advanced memory technologies, hold the potential for significantly lowering energy consumption by integrating storage with parallel Matrix-Vector-Multiplications (MVMs). This study addresses the 1T1R RRAM crossbar, a core component in numerous CIM architectures. We introduce an abstract model and a calibration methodology for estimating operational energy. Our tool condenses circuit-level behaviour into a few parameters, facilitating energy assessments for DNN workloads. Validation against low-level SPICE simulations demonstrates speedups of up to 1000× and energy estimations with errors below 1%.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595858","Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595858","RRAM;1T1R;MVM;Energy","Energy consumption;Quantization (signal);Memory architecture;Estimation;In-memory computing;SPICE;Energy efficiency","","","","32","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"TPC-NAS: Simple and Effective Neural Architecture Search Based on Total Path Count","M. -S. Huang; P. -C. Chen; T. -D. Chiueh","National Taiwan University, Taipei, Taiwan; National Taiwan University, Taipei, Taiwan; National Taiwan University, Taipei, Taiwan",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","542","546","With the explosive growth of neural network (NN) research and application areas, there is a pressing need to automate the NN model search process in order to attain optimal performance. Nevertheless, existing neural architecture search (NAS) algorithms are time-consuming, resource-intensive, and predominantly tailored for image-related applications. This paper presents the Total Path Count (TPC) score, a straightforward yet highly efficient accuracy predictor solely reliant on the architectural information of a model. The effectiveness of the TPC score is underscored by a robust rank correlation of 0.96 between TPC scores and the accuracies of CIFAR100 architectures. We further introduce TPC-NAS, a zero-shot NAS method that can complete a NAS task in under five CPU minutes without training and inference. TPC-NAS has found wide-ranging applications and it outperforms many other NAS solutions. In image classification, TPC-NAS achieves 78.3% ImageNet top-1 accuracy with 399M FLOPs, while in object detection, it improves mAP by at least 2% over other NAS-derived models. Moreover, TPC-NAS successfully discovers a super-resolution architecture with < 300K parameters and achieves 32.09dB PSNR. In NLP, TPC-NAS delivers a model that matches tinyBERT’s FLOPs but outperforms it by almost 10% in accuracy. These experiments illustrate TPC-NAS’s ability to rapidly generate high-performance CNN/transformer architectures for various applications.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595905","National Science and Technology Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595905","Neural Architecture Search (NAS);Image Classification;Super-Resolution;Object Detection;Natural Language Processing","Training;Accuracy;Superresolution;Object detection;Artificial neural networks;Natural language processing;Central Processing Unit","","1","","32","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Adapting Spatial Transformer Networks Across Diverse Hardware Platforms: A Comprehensive Implementation Study","M. Bettayeb; E. Hassan; M. U. Khan; Y. Halawani; H. Saleh; B. Mohammad","Computer and Communication Engineering Department, System-on-Chip (SoC) Lab, Khalifa University, Abu Dhabi, UAE; Computer and Communication Engineering Department, System-on-Chip (SoC) Lab, Khalifa University, Abu Dhabi, UAE; Computer and Communication Engineering Department, System-on-Chip (SoC) Lab, Khalifa University, Abu Dhabi, UAE; College of Engineering and IT, University of Dubai, Dubai, UAE; Computer and Communication Engineering Department, System-on-Chip (SoC) Lab, Khalifa University, Abu Dhabi, UAE; Computer and Communication Engineering Department, System-on-Chip (SoC) Lab, Khalifa University, Abu Dhabi, UAE",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","547","551","The field of artificial intelligence (AI) holds a variety of algorithms designed with the goal of achieving high accuracy at low computational cost and latency. One popular algorithm is the vision transformer (ViT), which excels at various computer vision tasks for its ability to capture long-range dependencies effectively. This paper analyzes a computing paradigm, namely, spatial transformer networks (STN), in terms of accuracy and hardware complexity for image classification tasks. The paper reveals that for 2D applications, such as image recognition and classification, STN is a great backbone for AI algorithms for its efficiency and fast inference time. This framework offers a promising solution for efficient and accurate AI for resource-constrained Internet of Things (IoT) and edge devices. The comparative analysis of STN implementations on the central processing unit (CPU), Raspberry Pi (RPi), and Resistive Random Access Memory (RRAM) architectures reveals nuanced performance variations, providing valuable insights into their respective computational efficiency and energy utilization.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595915","Abu Dhabi National Oil Company; BD; University of Sharjah; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595915","Spatial Transformer Network;Image Classification;vision transformer;raspberry Pi;hardware platforms;artificial intelligence","Accuracy;Resistive RAM;Transformers;Hardware;Computational efficiency;Classification algorithms;Central Processing Unit","","1","","15","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Error Checking for Sparse Systolic Tensor Arrays","C. Peltekis; D. Filippas; G. Dimitrakopoulos","Electrical and Computer Engineering, Democritus University of Thrace, Xanthi, Greece; Electrical and Computer Engineering, Democritus University of Thrace, Xanthi, Greece; Electrical and Computer Engineering, Democritus University of Thrace, Xanthi, Greece",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","552","556","Structured sparsity is an efficient way to prune the complexity of modern Machine Learning (ML) applications and to simplify the handling of sparse data in hardware. In such cases, the acceleration of structured-sparse ML models is handled by sparse systolic tensor arrays. The increasing prevalence of ML in safety-critical systems requires enhancing the sparse tensor arrays with online error detection for managing random hardware failures. Algorithm-based fault tolerance has been proposed as a low-cost mechanism to check online the result of computations against random hardware failures. In this work, we address a key architectural challenge with structured-sparse tensor arrays: how to provide online error checking for a range of structured sparsity levels while maintaining high utilization of the hardware. Experimental results highlight the minimum hardware overhead incurred by the proposed checking logic and its error detection properties after injecting random hardware faults on sparse tensor arrays that execute layers of ResNet50 CNN.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595917","Siemens; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595917","","Adaptation models;Tensors;Computational modeling;Hardware;Systolic arrays;Logic;Arrays","","","","29","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Too-Hot-to-Handle: Insights into Temperature and Noise Hyperparameters for Differentiable Neural-Architecture-Searches","J. Conrad; S. Wilhelmstätter; R. Asthana; V. Belagiannis; M. Ortmanns","Institute of Microelectronics, University of Ulm, Ulm, Germany; Institute of Microelectronics, University of Ulm, Ulm, Germany; Department of Electrical-Electronic-Communication Engineering, FAU, Erlangen, Germany; Department of Electrical-Electronic-Communication Engineering, FAU, Erlangen, Germany; Institute of Microelectronics, University of Ulm, Ulm, Germany",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","557","561","The deployment of neural networks on resource-constrained hardware requires architecture optimization algorithms that respect accuracy and computational cost. One emerging way for performing such an architecture optimization is the differentiable neural-architecture-search (DNAS). DNAS finds the weights of a neural network as well as its topology in a single training. The topology search-space is represented by instantiating different layer-candidates for each layer in parallel, thereby forming a so-called weighted super-network. The instances are connected via a gumbel-softmax function which employs important parameters commonly called temperature τ and noise-scale β. The temperature is scheduled during training and controls the convergence to selecting only a single final candidate per optimized layer. The noise-scale adds a random behavior in trying different candidates before deciding for a final one. The state-of-the-art (SotA) does not define rules for setting those important hyperparameters. Therefore, this work elaborates methods to predict feasible start- and end-temperature as well as noise-scale prior to training and to fine-tune the parameters from metrics obtained during a DNAS.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595971","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595971","differentiable neural-architecture-search;temperature;gumbel-softmax","Training;Schedules;Accuracy;Network topology;Neural networks;DNA;Computer architecture","","","","13","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"A 16-Channel GRU based On-Chip Seizure Classifier for Closed Loop Neuromodulation","L. Iyer; L. Somappa","Department of Electrical Engineering, IIT Bombay, Mumbai, India; Department of Electrical Engineering, IIT Bombay, Mumbai, India",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","562","566","The advancement of implantable on-chip machine learning (ML) classifiers enables the treatment of neurological disorders through closed-loop responsive neurostimulation. However, the hardware realization of the ML algorithm demands area and power efficiency along with low processing latency. This paper explores the time-series nature of the ECoG signal and introduces a scalable machine-learning model based on the Unidirectional Gated Recurrent Unit (GRU) for onset seizure detection. A 16-channel time-division multiplexed (TDM) GRU classifier is implemented on 65nm CMOS technology. The proposed SoC uses only 3 spectral features of different physiological frequency bands which were extracted using an FIR filter. Evaluated on the electroencephalography (EEG) data from the CHB-MIT scalp EEG database, the proposed implementation achieved a sensitivity of 93.1%, specificity of 89.1%, f1-score of 93.8% and an energy efficiency of 2 µJ/classification at 1.2 V supply voltage.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595911","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595911","Neuromodulation;Gated recurrent unit;Time-division multiplex;Feature extraction;SoC","Sensitivity;Time series analysis;Machine learning;Time division multiplexing;Feature extraction;Brain modeling;Electroencephalography","","","","12","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"A Pulse Correlation Model for PPG Signal Quality Assessment and Key Pulse Extraction","S. Cheng; R. Liu; H. Wu; K. S. -F. Sze; Q. Feng","College of Electronics and Information Engineering, Shenzhen University, Shenzhen, China; College of Electronics and Information Engineering, Shenzhen University, Shenzhen, China; College of Electronics and Information Engineering, Shenzhen University, Shenzhen, China; RingConn LLC, Wilmington, DE, United States; RingConn LLC, Wilmington, DE, United States",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","567","571","Photoplethysmograph (PPG) signals can be utilized to measure various physiological parameters such as heart rate and oxygen saturation. Also, PPG signals are a versatile tool for monitoring cardiovascular health and assessing the risk of cardiovascular disease including blood pressure, and arterial stiffness. A PPG pulse is a periodic signal that captures the blood flow pattern during a single heartbeat cycle. However, in dynamic measurements, there are often multiple similar pulses, and the quality of the pulses may be compromised by motion artifacts, making them difficult to analyze effectively. In this paper, we propose a pulse correlation model for conducting signal quality assessment (SQA), which primarily focuses on the morphological features. Additionally, we present a key pulse extraction framework aimed at reducing pulse redundancy and obtaining a representative pulse. Experiments were conducted using a public MIMIC-II waveform database. The results demonstrated that SQA based on PPG pulse morphology is feasible, and the extracted key pulses are not influenced by abnormal pulses. By utilizing the proposed model, there is a notable reduction in transmission consumption and computational complexity related to feature engineering.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595937","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595937","Photoplethysmograph Signal;Key Pulse Extraction;Signal Quality Assessment;Pulse Correlation Model","Correlation;Pulse measurements;Computational modeling;Redundancy;Morphology;Feature extraction;Quality assessment","","","","14","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"An Efficient Ventricular Arrhythmias Detection on Microcontrollers with Optimized 1D CNN","C. Hwang; J. So; J. Rhe; J. Kim; J. Park; K. E. Jeon; J. H. Ko","Department of Electrical and Computer Engineering, Sungkyunkwan University, South Korea; Department of Electrical and Computer Engineering, Sungkyunkwan University, South Korea; Department of Electrical and Computer Engineering, Sungkyunkwan University, South Korea; Department of Artificial Intelligence, Sungkyunkwan University, South Korea; Department of Electrical and Computer Engineering, Sungkyunkwan University, South Korea; Department of Electrical and Computer Engineering, Sungkyunkwan University, South Korea; Department of Electrical and Computer Engineering, Sungkyunkwan University, South Korea",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","572","576","This paper introduces a novel solution utilizing a 1D convolutional neural network (CNN) with optimizations like adaptive max-pooling, point-wise convolution, and a multi-objective gradient reversal layer (GRL) to address real-time ventricular arrhythmia (VA) detection challenges in implantable cardioverter defibrillators (ICDs). The proposed model achieves exceptional accuracy in discerning VAs and Non-VAs from single-channel intracardiac electrogram (IEGM) signals, boasting a Fβ score of 0.99265, a generalization score of 0.9375, a memory footprint of 24.332 KiB, and an inference latency of 2.593 ms. Compared to top models from the 2022 TinyML Design Contest, the proposed method demonstrates superior detection accuracy and generalization performance while maintaining competitive inference latency and memory usage.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595909","National Research Foundation; K2; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595909","","Accuracy;Convolution;Microcontrollers;Arrhythmia;Tiny machine learning;Memory management;Real-time systems","","","","19","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"An FPGA Accelerator for 3D Cone-beam Sparse-view Computed Tomography Reconstruction","Y. Gu; Q. Wu; Z. Yuan; X. Zhang; W. Su; Y. Zhang; X. Lou","School of Information Science and Technology, ShanghaiTech University; School of Information Science and Technology, ShanghaiTech University; School of Information Science and Technology, ShanghaiTech University; School of Information Science and Technology, ShanghaiTech University; School of Information Science and Technology, ShanghaiTech University; School of Information Science and Technology, ShanghaiTech University; School of Information Science and Technology, ShanghaiTech University",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","577","581","Computed tomography (CT) technique is a widely used clinical medical imaging method that employs X-rays to obtain detailed cross-sectional images of the human body. In order to minimize the ionizing radiation from X-rays, sparse-view computed tomography (SVCT) proves to be an effective solution. However, traditional reconstruction algorithms face challenges in producing satisfactory results in sparse-view scenarios. In this paper, we propose a 3D self-supervised projection network named SCOPE-3D to address the challenging sparse-view computed tomography problem. We also introduce a resource and energy efficient FPGA-based hardware accelerator that implement the proposed SCOPE-3D. Evaluation results demonstrate that the proposed accelerator reconstructs CT images with a speed and quality comparable to that of a graphics processing unit (GPU) card when running the same SCOPE-3D algorithm, while it consumes significantly fewer resources and less power.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595948","Shanghai Rising-Star Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595948","Computed Tomography (CT);sparse-view CT (SVCT);FPGA accelerator;3D self-supervised projection network","Three-dimensional displays;Ionizing radiation;Computed tomography;Graphics processing units;X-rays;Reconstruction algorithms;Energy efficiency","","","","12","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"CS-Net: An End-to-end Network for Motor Imagery Brain-Machine Interface with Adaptive Channel Selection and Compressed Sensing","J. Lu; G. Yu; L. Qian; J. Cao; L. Zheng; Z. Zou","School of Information Science and Technology, Fudan University, Shanghai, China; School of Information Science and Technology, Fudan University, Shanghai, China; School of Information Science and Technology, Fudan University, Shanghai, China; School of Microelectronics, Fudan University, Shanghai, China; School of Information Science and Technology, Fudan University, Shanghai, China; School of Information Science and Technology, Fudan University, Shanghai, China",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","582","586","Motor imagery (MI) based brain-machine interface (BMI) typically relies on multi-channel electroencephalogram (EEG) data and high-complexity algorithms, leading to huge computational burden. This paper proposes an end-to-end neural network for MI classification tasks, namely CS-Net, which integrates a Channel Selection layer and a Compressed Sensing layer to select the optimal channel subset while compressing data automatically. The parameters across the entire network are jointly optimized and the most compact network structure is explored by the Neural Architecture Search (NAS)-based framework. Evaluated on two public MI datasets (the High Gamma Dataset and BCI Competition IV-2a Dataset), the proposed network ensures competitive accuracies with minimal computational complexity. Compared to the full-channel and uncompressed situation, multiply-accumulate operations (MACs) are reduced by 90.90% and 60.72%, while the accuracies only drop by 2.14% and 1.37%, respectively. Compared to other state-of-the-art (SOTA) works, the proposed network achieves a comparable classification accuracy using fewer channels and better generalization ability without the subject-specific method.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595931","Research and Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595931","Brain-machine interface;motor imagery;channel selection;compressed sensing;neural network","Accuracy;Data compression;Motors;Brain-computer interfaces;Electroencephalography;Sensors;Computational complexity","","","","19","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Design and Implementation of an Easy-to-Deploy Energy-Efficient Inference Acceleration System for Multi-Precision Neural Networks","P. -C. Chen; Y. -T. Liu; G. -Y. Zeng; T. -D. Chiueh","National Taiwan University, Taipei, Taiwan; Mediatek Inc., Hsinchu, Taiwan; Mediatek Inc., Hsinchu, Taiwan; National Taiwan University, Taipei, Taiwan",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","587","591","With the increasing penetration of intelligent edge devices, fast and energy-efficient neural network inference has attracted the attention of many researchers. This paper proposes a mixed-precision neural network architecture and low-power circuit implementation. The proposed circuit supports weights in three precisions and achieves hardware usage flexibility through the im2col algorithm. In addition, we integrated the algorithm and hardware control flow with PyTorch to create a complete solution for users to perform quantized NN training and FPGA acceleration deployment within the same framework. We implemented the system on the KV260 FPGA-SoC platform. We then built several applications to validate that the multi-precision quantization approach is practical for real-world applications. Finally, the proposed inference acceleration system (running at 100MHz) achieved 9.1 and 2.1 times better energy efficiency compared to CPU and GPU, respectively.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595940","National Science and Technology Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595940","Deep Learning Accelerator;Quantized Neural Networks;FPGA Inference System;Obstacle Avoidance;Person Following","Training;Performance evaluation;Deep learning;Quantization (signal);Process control;Graphics processing units;Energy efficiency","","","","13","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"MSCA: Model-Driven Search for Optimal Configuration for SpMM Accelerators","Y. Qin; Y. Meng; H. Du; Y. Guo; Y. Kang","University of Science and Technology of China, Hefei, China; University of Science and Technology of China, Hefei, China; University of Science and Technology of China, Hefei, China; University of Science and Technology of China, Hefei, China; University of Science and Technology of China, Hefei, China",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","592","596","Sparse Matrix-Matrix multiplication (SpMM) is a cornerstone operation across AI algorithms, notably in advanced machine learning models such as transformers and graph neural networks. While various SpMM accelerators have been developed, optimal system configuration search method remains an underexplored area. Traditional exhaustive search methods are time-consuming and lack deep system understanding. This paper introduces a model-driven approach to efficiently search for optimal configurations. We transform the configuration search into a mixed integer problem, where we simplify sparsity impact with random experiments and a lookup table. For the first time, we model latency considering both simple and double buffering. Our approach allows flexible design goal setting for different scenarios. Experimental results show our model-derived configuration can outperform almost all counterparts in latency and it can effectively indicate the system’s minimum area requirements.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595929","Chinese Academy of Sciences; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595929","SpMM;MIP;Configuration Search","Machine learning algorithms;Circuits and systems;Transforms;Machine learning;Search problems;Transformers;Graph neural networks","","","","10","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"OSAHS Detection Capabilities of RingConn Smart Ring: A Feasibility Study","H. Guo; H. Wu; J. Xia; Y. Cheng; Q. Guo; Y. Chen; T. Xu; J. Wang; G. Wang","School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; RingConn LLC, Wilmington, DE, United States; Department of Cardiovascular Medicine, Centre for Epidemiological Studies and Clinical Trials, Shanghai Key Laboratory of Hypertension, The Shanghai Institute of Hypertension, National Research Centre for Translational Medicine, Ruijin Hospital, Shanghai Jiao Tong University School of Medicine, Shanghai, China; Department of Cardiovascular Medicine, Centre for Epidemiological Studies and Clinical Trials, Shanghai Key Laboratory of Hypertension, The Shanghai Institute of Hypertension, National Research Centre for Translational Medicine, Ruijin Hospital, Shanghai Jiao Tong University School of Medicine, Shanghai, China; Department of Cardiovascular Medicine, Centre for Epidemiological Studies and Clinical Trials, Shanghai Key Laboratory of Hypertension, The Shanghai Institute of Hypertension, National Research Centre for Translational Medicine, Ruijin Hospital, Shanghai Jiao Tong University School of Medicine, Shanghai, China; Department of Cardiovascular Medicine, Centre for Epidemiological Studies and Clinical Trials, Shanghai Key Laboratory of Hypertension, The Shanghai Institute of Hypertension, National Research Centre for Translational Medicine, Ruijin Hospital, Shanghai Jiao Tong University School of Medicine, Shanghai, China; Department of Cardiovascular Medicine, Centre for Epidemiological Studies and Clinical Trials, Shanghai Key Laboratory of Hypertension, The Shanghai Institute of Hypertension, National Research Centre for Translational Medicine, Ruijin Hospital, Shanghai Jiao Tong University School of Medicine, Shanghai, China; Department of Cardiovascular Medicine, Centre for Epidemiological Studies and Clinical Trials, Shanghai Key Laboratory of Hypertension, The Shanghai Institute of Hypertension, National Research Centre for Translational Medicine, Ruijin Hospital, Shanghai Jiao Tong University School of Medicine, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","597","601","Obstructive sleep apnea-hypopnea syndrome (OSAHS) is a significant public health concern. Wearable devices, such as smart rings and smart watches, provide a more convenient and less invasive alternative to traditional polysomnography (PSG) testing for detecting OSAHS. Smart rings, which collect signals from the finger base, offer superior signal quality and robustness compared to wrist signals from smart watches, making them a more convenient option for OSAHS detection. However, there is currently no research validating the performance of smart ring-based OSAHS detection. To our best knowledge, we are the first to investigate the feasibility and effectiveness of detecting OSAHS using smart rings. We analyzed 58 subjects, each wearing both a PSG device and RingConn smart rings for overnight OSAHS monitoring. Additionally, we propose a novel deep learning model to address the challenges posed by the distribution gap between photoplethysmography and blood oxygen saturation in OSAHS detection modeling, while efficiently capturing local and global features. Experimental results have demonstrated that smart rings detected OSAHS in good agreement with PSG, with a correlation coefficient of r =0.93. Our model also outperforms state-of-the-art methods.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595903","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595903","smart ring;obstructive sleep apnea-hypopnea syndrome;transformer","Performance evaluation;Deep learning;Wrist;Feature extraction;Photoplethysmography;Sleep apnea;Robustness","","2","","17","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Optimizing with phases: design and application space assessment for networks of phase-locked Ring Oscillators","A. Bazzi; E. Hardy; J. Ballester; F. Badets; L. Hutin","CEA-Leti, Univ. Grenoble Alpes, Grenoble, France; CEA-Leti, Univ. Grenoble Alpes, Grenoble, France; CEA-Leti, Univ. Grenoble Alpes, Grenoble, France; CEA-Leti, Univ. Grenoble Alpes, Grenoble, France; CEA-Leti, Univ. Grenoble Alpes, Grenoble, France",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","602","606","We investigate the operating conditions under which networks of coupled phase-locked Ring Oscillators can successfully map to Ising models in order to efficiently solve optimum search problems, shedding light on the fundamental design space trade-offs impacting solution quality. We designed and experimentally measured a test chip in 22nm FD-SOI technology with built-in readout. By solving various fully-connected 5-node graphs encoding 3-level Weighted MAX-CUT problems, we discuss the challenges associated to balancing the relative strength of coupling and synchronization signals.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595933","European Commission; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595933","Ising Networks;Coupled Oscillators;Optimization Problems","Couplings;Ring oscillators;Semiconductor device measurement;Accuracy;Simulated annealing;Search problems;Stability analysis","","","","12","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"Echo State Networks for Accurate and Efficient Modeling of Dynamic Circuits","P. Machado; R. Barbulescu; L. M. Silveira","INESC-ID Lisboa, Lisbon, Portugal; INESC-ID Lisboa, Lisbon, Portugal; INESC-ID Lisboa, Lisbon, Portugal",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","607","611","Neural network-based architectures have long been used as black-box regressors for developing macromodels of circuits and systems. From the more basic feed-forward artificial neural networks to the more recent complex and powerful recurrent structures, increasingly powerful structures have been proposed over the years. Unfortunately, the added modeling power has often been paired with equally increased training requirements and computational costs. In this paper, we introduce a novel macromodeling method, based on the well-known concept of reservoir computing, which can efficiently produce accurate models. When compared to commonly used recurrent neural network architectures, the proposed method is characterized by much lower training requirements, both in terms of training data and training time necessary for model development. Furthermore, the proposed architecture, based on Echo State Networks is not encumbered by the problem of vanishing or exploding gradients which is the cause of much difficulty in training recurrent architectures. The resulting model is shown to be adequately accurate, exhibiting small relative error on the examples shown, requires only modest training time when compared to commonly used recurrent alternatives, and is simple enough that its evaluation can be performed very rapidly, therefore proving to be a very interesting and general alternative for macromodeling dynamic circuits and systems.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595897","Fundação para a Ciência e a Tecnologia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595897","","Training;Accuracy;Recurrent neural networks;Computational modeling;Training data;Reservoir computing;Computer architecture","","","","27","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
"AICAS Grand Challenge 2024: Software and Hardware Co-optimization for General Large Language Model Inference on CPU","J. Tan; G. Yu; J. Li; X. Ma; F. Bao; E. Pan; D. Bian; Y. Li; Y. Du; L. Du; B. Li; W. Mao","Hangzhou Institute of Technology, Xidian University, Hangzhou, China; T-HEAD Semiconductor Co., Ltd, China; School of Electronic Science and Engineering, Nanjing University, China; T-HEAD Semiconductor Co., Ltd, China; Arm Technology (China) Co., Ltd.; Arm Technology (China) Co., Ltd.; Arm Technology (China) Co., Ltd.; Department of Micro-Nano Electronics, Shanghai Jiao Tong University, China; School of Electronic Science and Engineering, Nanjing University, China; School of Electronic Science and Engineering, Nanjing University, China; Hangzhou Institute of Technology, Xidian University, Hangzhou, China; Hangzhou Institute of Technology, Xidian University, Hangzhou, China",2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS),"19 Jul 2024","2024","","","1","5","Large Language Models (LLMs) have attained remarkable achievements in multi-domain tasks. However, LLMs’ performance is limited by hardware conditions due to billions of parameters. It requires highly efficient deployment and software hardware co-optimization such as quantization, pruning and operator fusion methods. Meanwhile, there is an emerging trend that LLMs run on edge devices like Arm-based CPUs. Thus, we organized the 2024 AICAS Grand Challenge on software and hardware co-optimization for general LLMs. In the preliminary round, participating teams deployed LLMs on either GPUs or CPUs to reduce model memory consumption and increase throughput. In the final round, the qualified teams applied different optimization methods to the Arm-based multi-core Yitian 710 CPU to maximize the performance of their model. The top 6 best teams presented their work in the AICAS 2024.","2834-9857","979-8-3503-8363-8","10.1109/AICAS59952.2024.10595886","National Key Research and Development Program of China; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595886","AICAS;Grand Challenge;Large Language Models;Software and Hardware Co-optimization;Edge Inference;Model Compression;Efficient Deployment","Performance evaluation;Quantization (signal);Large language models;Throughput;Hardware;Software;Central Processing Unit","","1","","19","IEEE","19 Jul 2024","","","IEEE","IEEE Conferences"
