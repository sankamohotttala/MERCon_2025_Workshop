"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"AICAS 2023 Cover Page","",,2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","c1","c1","","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168549","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168549","","","","","","","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Content","",,2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","i","v","","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168634","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168634","","","","","","","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Front Matter","",,2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168663","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168663","","","","","","","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"A Fully Differential 4-Bit Analog Compute-In-Memory Architecture for Inference Application","D. Kushwaha; R. Kohli; J. Mishra; R. V. Joshi; S. Dasgupta; A. Bulusu","Indian Institute of Technology Roorkee; NXP Semiconductor, Bengaluru; NXP Semiconductor, Bengaluru; IBM T.J. Watson, USA; Indian Institute of Technology Roorkee; Indian Institute of Technology Roorkee",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","A robust, fully differential multiplication and accumulate (MAC) scheme for analog compute-in-memory (CIM) architecture is proposed in this article. The proposed method achieves a high signal margin for 4-bit CIM architecture due to fully differential voltage changes on read bit-lines (RBL/RBLBs). The signal margin achieved for 4-bit MAC operation is 32 mV, which is 1.14×, 5.82×, and 10.24× higher than the state-of-the-art. The proposed scheme is robust against the process, voltage, and temperature (PVT) variations and achieves a variability metric (σ/µ) of 3.64 %, which is 2.36× and 2.66× lower than the reported works. The architecture has achieved an energy-efficiency of 2.53 TOPS/W at 1 V supply voltage in 65 nm CMOS technology, that is 6.2× efficient than digital baseline HW [25]. Furthermore, the inference accuracy of the architecture is 97.6% on the MNIST data set with a LeNet-5 CNN model. The figure-of-merit (FoM) of the proposed design is 355, which is 3.28×, 3.58×, and 17.75× higher than state-of-the-art.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168599","Semiconductor Research Corporation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168599","Analog;bit-line;compute-in-memory (CIM);differential;energy-efficiency;multiplication and accumulate (MAC)","Semiconductor device modeling;Circuits and systems;Computational modeling;Linearity;Computer architecture;Voltage;Dynamic range","","7","","27","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"A 115.1 TOPS/W, 12.1 TOPS/mm2 Computation-in-Memory using Ring-Oscillator based ADC for Edge AI","A. Singh; R. Bishnoi; A. Kaichouhi; S. Diware; R. V. Joshi; S. Hamdioui","Computer Engineering Laboratory, Delft University of Technology, Delft, The Netherlands; Computer Engineering Laboratory, Delft University of Technology, Delft, The Netherlands; Computer Engineering Laboratory, Delft University of Technology, Delft, The Netherlands; Computer Engineering Laboratory, Delft University of Technology, Delft, The Netherlands; IBM Thomas J. Watson Research Centre, Yorktown Heights, NY, USA; Computer Engineering Laboratory, Delft University of Technology, Delft, The Netherlands",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Analog computation-in-memory (CIM) architecture alleviates massive data movement between the memory and the processor, thus promising great prospects to accelerate certain computational tasks in an energy-efficient manner. However, data converters involved in these architectures typically achieve the required computing accuracy at the expense of high area and energy footprint which can potentially determine CIM candidacy for low-power and compact edge-AI devices. In this work, we present a memory-periphery co-design to perform accurate A/D conversions of analog matrix-vector-multiplication (MVM) outputs. Here, we introduce a scheme where select-lines and bit-lines in the memory are virtually fixed to improve conversion accuracy and aid a ring-oscillator-based A/D conversion, equipped with component sharing and inter-matching of the reference blocks. In addition, we deploy a self-timed technique to further ensure high robustness addressing global design and cycle-to-cycle variations. Based on measurement results of a 4Kb CIM chip prototype equipped with TSMC 40nm, a relative accuracy of up to 99.71% is achieved with an energy efficiency of 115.1 TOPS/W and computational density of 12.1 TOPS/mm2 for the MNIST dataset. Thus, an improvement of up to 11.3X and 7.5X compared to the state-of-the-art, respectively.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168647","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168647","Computation-in-memory;analog-to-digital converters;analog computing;ring-oscillator","Semiconductor device measurement;Prototypes;Computer architecture;Energy efficiency;Common Information Model (computing);Computational efficiency;Artificial intelligence","","4","","19","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Memory-Immersed Collaborative Digitization for Area-Efficient Compute-in-Memory Deep Learning","S. Nasrin; M. B. Hashem; N. Darabi; B. Parpillon; F. Fahim; W. Gomes; A. R. Trivedi","AEON Lab, University of Illinois at Chicago (UIC), Chicago, IL, USA; AEON Lab, University of Illinois at Chicago (UIC), Chicago, IL, USA; AEON Lab, University of Illinois at Chicago (UIC), Chicago, IL, USA; AEON Lab, University of Illinois at Chicago (UIC), Chicago, IL, USA; Fermi National Accelerator Lab (FNAL), Batavia, IL, USA; Intel Corp., Hillsboro, OR, USA; AEON Lab, University of Illinois at Chicago (UIC), Chicago, IL, USA",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","This work discusses memory-immersed collaborative digitization among compute-in-memory (CiM) arrays to minimize the area overheads of a conventional analog-to-digital converter (ADC) for deep learning inference. Thereby, using the proposed scheme, significantly more CiM arrays can be accommodated within limited footprint designs to improve parallelism and minimize external memory accesses. Under the digitization scheme, CiM arrays exploit their parasitic bit lines to form a within-memory capacitive digital-to-analog converter (DAC) that facilitates area-efficient successive approximation (SA) digitization. CiM arrays collaborate where a proximal array digitizes the analog-domain product-sums when an array computes the scalar product of input and weights. We discuss various networking configurations among CiM arrays where Flash, SA, and their hybrid digitization steps can be efficiently implemented using the proposed memory-immersed scheme. The results are demonstrated using a 65 nm CMOS test chip. Compared to a 40 nm-node 5-bit SAR ADC, our 65 nm design requires ~25 area× less and ∼1.4× less energy by leveraging in-memory computing structures. Compared to a 40 nm-node 5-bit Flash ADC, our design requires ∼51× less area and ∼13× less energy.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168632","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168632","Compute-in-Memory;SRAM;Deep Learning","Deep learning;Circuits and systems;Digital-analog conversion;Collaboration;Learning (artificial intelligence);Parallel processing;In-memory computing","","8","","19","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Optimization Strategies for Digital Compute-in-Memory from Comparative Analysis with Systolic Array","W. Li; J. Lee; S. Yu","School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Compute-in-memory (CIM) is a promising solution to accelerate the extensive multiply-and-accumulate (MAC) operations in deep neural networks (DNNs). Although mixed-signal or analog CIM can achieve high energy efficiency, loss of inference accuracy due to noises and variations is its main drawback. Digital CIM (DCIM) has recently been proposed to achieve both high efficiency and high accuracy. In this work, we first analyze the fundamental properties of DCIM by comparing SRAM-based DCIM with TPU-like systolic array, another popular choice for DNN acceleration. With both designs evaluated in 28-nm process, we observe that DCIM is superior to systolic array in terms of area and power consumption. However, DCIM exhibits poor scalability of latency with increasing array sizes. To mitigate, we propose parallel-input bitwise-weight compute scheme for DCIM shorten its critical path, such that 25% improvement in operating frequency can be obtained with minimal overhead. We then study the systolic DCIM architecture to further enhance the scalability of DCIM. Compared to the compute cores of TPU, systolic DCIM is evaluated to provide 47% and 17% improvements in compute and energy efficiencies.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168651","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168651","Hardware accelerator;deep neural network;digital compute-in-memory;systolic array;SRAM","Deep learning;Power demand;Scalability;Neural networks;Computer architecture;Systolic arrays;Energy efficiency","","3","","15","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"A Systolic Computing-in-Memory Array based Accelerator with Predictive Early Activation for Spatiotemporal Convolutions","X. Chen; R. Guo; Z. Yue; Y. Hu; L. Liu; S. Wei; S. Yin","Tsinghua University, Beijing, China; Tsinghua University, Beijing, China; Tsinghua University, Beijing, China; Tsinghua University, Beijing, China; Tsinghua University, Beijing, China; Tsinghua University, Beijing, China; Tsinghua University, Beijing, China",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Residual (2+1)-dimensional convolution neural network (R(2+1)D CNN) has achieved great success in video recognition due to the spatiotemporal convolution structure. However, R(2+1)D CNN incurs large energy and latency overhead because of intensive computation and frequent memory access. To solve the issues, we propose a digital SRAM-CIM based accelerator with two key features: (1) Systolic CIM array to efficiently match massive computations in regular architecture; (2) Digtal CIM circuit design with output sparsity predicition to avoid redundant computations. The proposed design is implemented in 28nm technology and achieves an energy efficiency of 21.87 TOPS/W at 200 MHz and 0.9 V supply voltage.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168581","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168581","Computing-In-Memory;Systolic Array;Spatiotemporal Convolution;Accelerator","Convolution;Power supplies;Neural networks;Voltage;Systolic arrays;Common Information Model (computing);Energy efficiency","","1","","15","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"RC-GNN: Fast and Accurate Signoff Wire Delay Estimation with Customized Graph Neural Networks","L. Zhu; Y. Gu; X. Guo","University of Michigan – Shanghai Jiao Tong University Joint Institute, Shanghai Jiao Tong University, Shanghai, China; University of Michigan – Shanghai Jiao Tong University Joint Institute, Shanghai Jiao Tong University, Shanghai, China; University of Michigan – Shanghai Jiao Tong University Joint Institute, Shanghai Jiao Tong University, Shanghai, China",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","As interconnect delay becomes more dominate in a timing path compared to the gate delay, accurate yet fast estimation of wire delay during the signoff stage is required. Prior machine learning-based wire delay estimation approaches either relied on tedious feature extraction processes or failed to capture the net topology information, incurring long turn around time. In this paper, we propose to leverage the power of graph neural networks (GNN) to estimate the interconnect delays during signoff. Different from other GNN-assisted timing analysis methods that were usually applied to a netlist, we harness the global message passing graph representation learning on RC graph directly to perform ultra-fast net delay estimation without requiring extra features. Furthermore, pre-processed graph features can be added to boost the estimation accuracy with slight run time penalty. Our proposed customized GNN models have been evaluated with the industrial design and compared against state of the art ML-based wire delay estimator. It shows that the proposed model outperforms the state-of-the-art ML-based signoff wire delay estimator by 4x in terms of run time while achieving similar accuracy levels.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168562","Tencent; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168562","GNN;RC Network;Interconnect;Signoff","Representation learning;Runtime;Network topology;Message passing;Wires;Estimation;Delay estimation","","","","25","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"FEEP: Functional ECO Synthesis with Efficient Patch Minimization","Y. Liu; Y. Zhang; Q. Zhang; R. Chen; Y. Li","Department of Micro-Nano Electronics and MoE Key Lab of Artificial Intelligence, Shanghai Jiao Tong University, Shanghai, China; Department of Micro-Nano Electronics and MoE Key Lab of Artificial Intelligence, Shanghai Jiao Tong University, Shanghai, China; Department of Micro-Nano Electronics and MoE Key Lab of Artificial Intelligence, Shanghai Jiao Tong University, Shanghai, China; Institute of Microelectronics, Chinese Academy of Sciences, Beijing, China; Department of Micro-Nano Electronics and MoE Key Lab of Artificial Intelligence, Shanghai Jiao Tong University, Shanghai, China",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Functional engineering change order (ECO) has been an essential process in modern complex integrated circuit design. Finding a high-quality circuit patch efficiently has long been a challenge. This paper proposes FEEP, an automatic and efficient synthesis-based functional ECO method. Structural pruning and stratified searching techniques are proposed to minimize search space without extra logical equivalence checks. Moreover, we propose a machine-learning-based two-stage patch size predictor that assists in predicting patch quality. Experimental results show that our algorithm can efficiently search and produce high-quality patches under various test cases.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168557","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168557","Engineering change order (ECO);equivalence checking (EC);electronics design automation (EDA);machine learning (ML);circuit patch","Integrated circuit synthesis;Design automation;Circuits and systems;Learning (artificial intelligence);Prediction algorithms;Minimization","","1","","31","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Reducing Overhead of Feature Importance Visualization via Static GradCAM Computation","A. Bhat; A. Raychowdhury","School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Explainable AI (XAI) methods provide insights into the operation of black-box Deep Neural Network (DNN) models. GradCAM, an XAI algorithm, provides an explanation by highlighting regions in the input feature space that were relevant to the model’s output. It involves a gradient computation step that adds a significant overhead compared to inference and hinders providing explanations to end-users. In this work, we identify the root cause of the problem to be the dynamic run-time automatic differentiation. To overcome this issue, we propose to offload the gradient computation step to compile time via analytic evaluation. We validate the idea by designing an FPGA implementation of GradCAM that schedules the entire computation graph statically. For a TinyML ResNet18 model, we achieve a reduction in the explanation generation overhead from > 2× using software frameworks on CPU/GPU systems to < 0.01× on the FPGA using our designed hardware and static scheduling.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168594","Semiconductor Research Corporation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168594","Convolutional Neural Network (CNN);Explainable AI (XAI);Feature Attribution;GradCAM;FPGA;High Level Synthesis (HLS);Domain Specific Hardware Accelerator","Visualization;Schedules;Runtime;Processor scheduling;Computational modeling;Software algorithms;Inference algorithms","","2","","23","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"WeightLock: A Mixed-Grained Weight Encryption Approach Using Local Decrypting Units for Ciphertext Computing in DNN Accelerators","J. Wang; Z. Chen; Y. Chen; Y. Xu; T. Wang; Y. Yu; V. Narayanan; S. George; H. Yang; X. Li","BNRist, EE, Tsinghua University; BNRist, EE, Tsinghua University; BNRist, EE, Tsinghua University; Penn State University; Daimler Greater China Ltd; Daimler Greater China Ltd; Penn State University; North Dakota State University; BNRist, EE, Tsinghua University; BNRist, EE, Tsinghua University",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","With the wide use of NVM-based DNN accelerators for higher computing efficiency, the long data retention time essentially causes a high risk of unauthorized weight stealing by attackers. Weight encryption is an effective method, but existing ciphertext computing accelerators cannot achieve high encryption complexity and flexibility. This paper proposes WeightLock, a mixed-grained hardware-software co-design approach based on local decrypting units (LDUs). This work proposes a key-controlled cell-level hardware design for higher granularity and two weight selection schemes for higher flexibility. The simulation results show that the accuracy of VGG-8 and ResNet-18 in the Cifar-10 classification drops from 80% to only 10% even if 80% of keys are leaked. This shows >20% higher key leakage tolerance and >17x longer retraining latency protection, compared with the prior state-of-the-art hardware and software approaches, respectively. The area cost of the encryption function is negligible, with ~600x, 2.2x, and 2.4x reduction from the state-of-the-art cell-wise, column-wise, and 1T4R structures, respectively.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168612","Tsinghua University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168612","Hardware security;IP;DNN;accelerator;ciphertext computing;compute-in-memory","Costs;Circuits and systems;Simulation;Neural networks;Hardware;Software;Common Information Model (computing)","","1","","23","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Securing Decision Tree Inference Using Order-Preserving Cryptography","R. R. Karn; K. Nawaz; I. A. M. Elfadel","Center for Cyber Physical Systems (C2PS), Khalifa University, Abu Dhabi, UAE; Cryptography Research Center, Technology Innovation Institute, Abu Dhabi, UAE; Center for Cyber Physical Systems (C2PS), Khalifa University, Abu Dhabi, UAE",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","In machine learning (ML) inference, two parties, Alice and Bob, are engaged in a transaction where Alice is the owner of a decision tree model but does not want to reveal its parameters to Bob, who has private data. Bob wants to use Alice’s model for inference, but does not want to reveal his data. Knowing the heavy computational cost of fully homomorphic encryption, Alice and Bob agree to use order-preserving encryption (OPE) for running the inference engine in full confidence without revealing either the decision tree model or the private data. In this paper, we describe how such an OPE computation is established between Alice and Bob. Specifically, we demonstrate how to secure full confidentiality in decision tree inference on an FPGA accelerator embodying an OPE protocol. A finite-state machine design of the encrypted decision tree is evaluated for throughput and resource utilization on an Intel Cyclone V FPGA using the MNIST dataset.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168588","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168588","","Protocols;Computational modeling;Automata;Machine learning;Throughput;Data models;Cyclones","","6","","23","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Binary is All You Need: Ultra-Efficient Arrhythmia Detection with a Binary-Only Compressive System","F. Tian; X. Wang; J. Chen; J. Yang; M. Sawan; C. -Y. Tsui; K. -T. T. Cheng","Department of ECE, HKUST, Hong Kong SAR; Department of ECE, HKUST, Hong Kong SAR; CenBRAIN Neurotech, Westlake University, Hangzhou, China; CenBRAIN Neurotech, Westlake University, Hangzhou, China; CenBRAIN Neurotech, Westlake University, Hangzhou, China; Department of ECE, HKUST, Hong Kong SAR; Department of ECE, HKUST, Hong Kong SAR",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Detecting cardiac arrhythmia is critical for preventing heart attacks, and wearable electrocardiograph (ECG) systems have been developed to address this issue. However, the energy consumption of existing wearable systems is still significant at both the circuit and system levels, posing a challenge for their design. In this paper, we propose a novel ultra-efficient binary-only compressive ECG system for edge cardiac arrhythmia detection, featuring an event-driven level-crossing analog-to-spike converter (ATS) for sensing and a computing-in-memory (CIM) based binarized neural network (BNN) processor for compressive processing. Through system-level co-design, our proposed system achieves high arrhythmia detection accuracy and ultra-low energy consumption. Our simulations using the MIT-BIH dataset show that the proposed system achieves a 90.1% reduction in sampled data points compared to Nyquist sampling. Moreover, our dedicated BNN on a CIM engine delivers 97.03% arrhythmia detection accuracy with energy efficiency as low as 0.17uJ/inference.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168576","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168576","Bio-signal processing;binarized neural network;computing-in-memory","Energy consumption;Circuits and systems;Sensitivity analysis;Arrhythmia;Systems architecture;Electrocardiography;Energy efficiency","","2","","20","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"A Convolved Self-Attention Model for IMU-based Gait Detection and Human Activity Recognition","S. Tao; W. L. Goh; Y. Gao","School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore, Republic of Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore, Republic of Singapore; Institute of Microelectronics (IME), Agency for Science, Technology and Research (A*STAR), Singapore, Republic of Singapore",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","This paper presents a convolved self-attention neural network model for gait detection and human activity recognition (HAR) tasks using wearable inertial measurement unit (IMU) sensors. By embedding a convolved window inside the self-attention module, prior time step knowledge is utilized by self-attention layer to improve accuracy. Moreover, a streamlined fully connected (FC) layer without hidden layers is proposed for the feature mixer. This arrangement enables significant reduction of overall network parameters, since hidden layers occupy the majority of the parameters in a transformer encoder. Compared to the other state-of-art neural networks, the proposed method achieved better accuracy of 95.83% and 96.01% with the smallest network size on HAR datasets UCI-HAR and MHEALTH respectively,","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168654","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168654","Human Activity Recognition;Wearable sensor;Transformer Model;Time-series Data Processing","Performance evaluation;Neural networks;Transformers;Rendering (computer graphics);Data models;Human activity recognition;Integrated circuit modeling","","7","","20","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"EpilepsyNet: Interpretable Self-Supervised Seizure Detection for Low-Power Wearable Systems","B. Huang; R. Zanetti; A. Abtahi; D. Atienza; A. Aminifar","Department of Electrical and Information Technology, Lund University, Sweden; Embedded Systems Laboratory, Swiss Federal Institute of Technology Lausanne (EPFL), Switzerland; Department of Electrical and Information Technology, Lund University, Sweden; Embedded Systems Laboratory, Swiss Federal Institute of Technology Lausanne (EPFL), Switzerland; Department of Electrical and Information Technology, Lund University, Sweden",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Epilepsy is one of the most common neurological disorders that is characterized by recurrent and unpredictable seizures. Wearable systems can be used to detect the onset of a seizure and notify family members and emergency units for rescue. The majority of state-of-the-art studies in the epilepsy domain currently explore modern machine learning techniques, e.g., deep neural networks, to accurately detect epileptic seizures. However, training deep learning networks requires a large amount of data and computing resources, which is a major challenge for resource-constrained wearable systems. In this paper, we propose EpilepsyNet, the first interpretable self-supervised network tailored to resource-constrained devices without using any seizure data in its initial offline training. At runtime, however, once a seizure is detected, it can be incorporated into our self-supervised technique to improve seizure detection performance, without the need to retrain our learning model, hence incurring no energy overheads. Our self-supervised approach can reach a detection performance of 79.2%, which is on par with the state-of-the-art fully-supervised deep neural networks trained on seizure data. At the same time, our proposed approach can be deployed in resource-constrained wearable devices, reaching up to 1.3 days of battery life on a single charge.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168560","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168560","epilepsy;real-time seizure detection;self-supervised learning;wearable systems;Internet of Things (IoT)","Performance evaluation;Training;Deep learning;Neurological diseases;Runtime;Wearable computers;Neural networks","","4","","28","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Bandit-supported care planning for older people with complex health and care needs","G. -S. Kim; Y. S. Hong; T. Hoon Lee; M. C. Paik; H. Kim","Department of Industrial Engineering & Artificial Intelligence Graduate School, UNIST, Ulsan, South Korea; Master of Health Informatics, School of Information, University of Michigan, Ann Arbor, MI, USA; Department of Public Health Sciences, Graduate School of Public Health, Seoul National University, Seoul, South Korea; Department of Statistics, Seoul National University, Seoul, South Korea; Department of Public Health Sciences, Graduate School of Public Health, Seoul National University, Seoul, South Korea",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Long-term care service for old people is in great demand in most of the aging societies. The number of nursing homes residents is increasing while the number of care providers is limited. Due to the care worker shortage, care to vulnerable older residents cannot be fully tailored to the unique needs and preference of each individual. This may bring negative impacts on health outcomes and quality of life among institutionalized older people. To improve care quality through personalized care planning and delivery with limited care workforce, we propose a new care planning model assisted by artificial intelligence. We apply bandit algorithms which optimize the clinical decision for care planning by adapting to the sequential feedback from the past decisions. We evaluate the proposed model on empirical data acquired from the Systems for Person-centered Elder Care (SPEC) study, a ICT-enhanced care management program.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168530","Seoul National University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168530","","Adaptation models;Circuits and systems;Medical services;Aging;Data models;Planning;Artificial intelligence","","2","","12","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"A Convolutional Spiking Network for Gesture Recognition in Brain-Computer Interfaces","Y. Ai; B. Rajendran","Department of Engineering, King’s College London, London, United Kindom; Department of Engineering, King’s College London, London, United Kindom",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Brain-computer interfaces are being explored for a wide variety of therapeutic applications. Typically, this involves measuring and analyzing continuous-time electrical brain activity via techniques such as electrocorticogram (ECoG) or electroencephalography (EEG) to drive external devices. However, due to the inherent noise and variability in the measurements, the analysis of these signals is challenging and requires offline processing with significant computational resources. In this paper, we propose a simple yet efficient machine learning-based approach for the exemplary problem of hand gesture classification based on brain signals. We use a hybrid machine learning approach that uses a convolutional spiking neural network employing a bio-inspired event-driven synaptic plasticity rule for unsupervised feature learning of the measured analog signals encoded in the spike domain. We demonstrate that this approach generalizes to different subjects with both EEG and ECoG data and achieves superior accuracy in the range of 92.74-97.07% in identifying different hand gesture classes and motor imagery tasks.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168627","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168627","Spiking Neural Network;Brain-computer interface;Event-driven plasticity;K-means clustering","Representation learning;Convolution;Neural networks;Electroencephalography;Brain-computer interfaces;Spatial databases;Real-time systems","","2","","29","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"A Novel Transpose 2T-DRAM based Computing-in-Memory Architecture for On-chip DNN Training and Inference","Y. Zhao; Z. Shen; J. Xu; K. C. T. Chai; Y. Wu; C. Wang","School of Optical and Electronic Information, Huazhong University of Science and Technology, Wuhan, China; School of Optical and Electronic Information, Huazhong University of Science and Technology, Wuhan, China; School of Optical and Electronic Information, Huazhong University of Science and Technology, Wuhan, China; School of Integrated Circuits, Peking University, Beijing, Beijing, China; Agency for Science, Technology and Research, Institute of Microelectronics, Singapore; School of Optical and Electronic Information, Huazhong University of Science and Technology, Wuhan, China",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","4","Recently, DRAM-based Computing-in-Memory (CIM) has emerged as one of the potential CIM solutions due to its unique advantages of high bit-cell density, large memory capacity and CMOS compatibility. This paper proposes a 2T-DRAM based CIM architecture, which can perform both CIM inference and training for deep neural networks (DNNs) efficiently. The proposed CIM architecture employs 2T-DRAM based transpose circuitry to implement transpose weight memory array and uses digital logic in the array peripheral to implement digital DNN computation in memory. A novel mapping method is proposed to map the convolutional and full-connection computation of the forward propagation and back propagation process into the transpose 2T-DRAM CIM array to achieve digital weight multiplexing and parallel computing. Simulation results show that the computing power of proposed transpose 2T-DRAM based CIM architecture is estimated to 11.26 GOPS by a 16K DRAM array to accelerate 4CONV+3FC @100 MHz and has an 82.15% accuracy on CIFAR-10 dataset, which are much higher than the state-of-the-art DRAM-based CIM accelerators without CIM learning capability. Preliminary evaluation of retention time in DRAM CIM also shows that a refresh-less training-inference process of lightweight networks can be realized by a suitable scale of CIM array through the proposed mapping strategy with negligible refresh-induced performance loss or power increase.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168641","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168641","Computing in Memory;back propagation algorithm;transpose matrix;DRAM;Deep Neural Network","Training;Neural networks;Random access memory;Computer architecture;Parallel processing;Common Information Model (computing);Inference algorithms","","4","","7","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"A Column-Parallel Time-Interleaved SAR/SS ADC for Computing in Memory with 2-8bit Reconfigurable Resolution","Y. Li; L. Du; Y. Du","Nanjing University, Nanjing, China; Nanjing University, Nanjing, China; Nanjing University, Nanjing, China",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Computing in Memory (CiM), as a computing system with non-von Neumann architecture, has been reported as one of the most promising neural network accelerators in the future. Compared with digital-based computation, CiM uses RAM arrays to calculate and store in the analog domain, avoiding the high delay and energy consumption caused by data transfer. However, the computational results require data converters for quantization, which often limits the development of high-performance CiMs. In this work, we propose a 2-8bit reconfigurable time-interleaved hybrid ADC architecture for high-speed CiMs, including successive approximation and single-slope stages. Reconfigurability introduces a trade-off between resolution and conversion speed for ADCs in different computing scenarios. A prototype was implemented in a 55 nm CMOS technology, which occupies an area of 330μm × 13μm and consumes a power of 1.429mW at 8-bit conversion mode. With a Nyquist frequency input sampled at 350 MS/s, the SNDR and SFDR are 40.93 dB and 51.08 dB, respectively. The resultant Walden figure of merit is 44.8 fJ/conv.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168604","Research and Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168604","Computing in Memory;time-interleaved ADC;hybrid ADC;SAR ADC;single-slope ADC;column-parallel readout;reconfigurable resolution","Energy consumption;Quantization (signal);Power demand;Energy resolution;Random access memory;Prototypes;Computer architecture","","4","","32","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"RRAM-Based Precision-Scaleable Computing-In-Memory Scheme and Its Error Correction Approach","W. Ma; L. Li; Z. Li; G. Zhao; X. Long; M. Huang","Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; CNRS-NTU-THALES Research, Alliances, Singapore; Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Resistive random access memories (RRAM) based Computing-in-memory (CIM) architecture has attracted enormous attention due to its high energy efficiency. However, the conductance states of RRAM devices are usually limited to 1-4bit which is much lower than the desired 8/16-bit precision, and the additional cost (such as the differential circuit) to map a negative parameter into positive conductance is large, leading to either large accuracy loss or low hardware efficiency. In this work, we propose an efficient precision-scaleable CIM scheme for high-performance computation, by which high-bit (INT8/16) signed multiplication-accumulation (MAC) operation can be constructed using the practical 3-bit RRAM devices with the unbalanced bit-slice method. Next, we analyze both the systemic error caused by the non-zero conductance of devices (when representing the bit of 0) and random errors caused by the conductance variation issue in the device. A linear regression correction approach is proposed to reduce the computation error. Finally, the proposed method is verified in terms of both software accuracy and hardware efficiency, the simulated result shows it is a promising method to be used in practical applications.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168585","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168585","Computing-In-Memory;RRAM;Precision Reconfiguration;Energy-efficient Computing","Fluctuations;Neural networks;Resistive RAM;Linear regression;Computer architecture;Common Information Model (computing);Hardware","","","","25","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Deep Learning Compiler Optimization on Multi-Chiplet Architecture","H. Xu; K. Mao; Q. Pan; Z. Tang; M. Wang; Y. Wang","Research Center for Advanced Computing Systems, Zhejiang Lab, Hangzhou, China; Research Center for Advanced Computing Systems, Zhejiang Lab, Hangzhou, China; Research Center for Advanced Computing Systems, Zhejiang Lab, Hangzhou, China; Research Center for Advanced Computing Systems, Zhejiang Lab, Hangzhou, China; Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Multi-chiplet architecture can provide a high-performance solution for new tasks such as deep learning models. In order to fully utilize chiplets and accelerate the execution of deep learning models, we present a deep learning compilation optimization framework for chiplets, and propose a scheduling method based on data dependence. Experiments show that our method improves the compilation efficiency, and the performance of the scheduling scheme is at least 1-2 times higher than the traditional algorithms.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168656","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168656","multi-chiplet architecture;deep learning;compiler optimization","Deep learning;Runtime;Costs;Circuits and systems;Simulation;Data models;Scheduling","","","","20","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"RISC-V based Fully-Parallel SRAM Computing-in-Memory Accelerator with High Hardware Utilization and Data Reuse Rate","H. Zhou; H. Hong; D. Liu; H. Liu; Y. Xia; K. Li; J. Liu; S. Luo; W. Mao; H. Yu","Southern University of Science and Technology, Shenzhen, China; Southern University of Science and Technology, Shenzhen, China; Southern University of Science and Technology, Shenzhen, China; Southern University of Science and Technology, Shenzhen, China; Southern University of Science and Technology, Shenzhen, China; Southern University of Science and Technology, Shenzhen, China; Southern University of Science and Technology, Shenzhen, China; Southern University of Science and Technology, Shenzhen, China; Southern University of Science and Technology, Shenzhen, China; Southern University of Science and Technology, Shenzhen, China",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Computing-In-memory (CIM) accelerators have the characteristics of storage and computing integration, which can effectively improve the computing efficiency of the convolutional neural network (CNN). To improve throughput and computational energy efficiency while maintaining accuracy, this paper proposes an SRAM CIM accelerator with the capacitor-coupling method. Charge-domain based accumulation scheme can reduce the impact of multiplication and accumulation (MAC) unit variations, which makes it possible to increase computational throughput and energy efficiency in a fully-parallel manner. Furthermore, the array size and the mapping of weights are designed to improve the utilization by considering the network characteristics and data volume. At the data flow level, this paper proposes a novel data reuse scheme to make full use of the input data. Besides, design-specific custom instructions based on RISC-V are designed to improve data transfer efficiency. Simulation results show that the proposed SRAM-based accelerator can achieve energy efficiency of 284.7, 71.2, and 17.8 TOPS/W at 2-bit, 4-bit, and 8-bit modes in 28-nm CMOS.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168630","Ministry of Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168630","CNN accelerator;SRAM;hardware utilization;data reuse;RISC-V","Power demand;Simulation;Random access memory;Throughput;Energy efficiency;Common Information Model (computing);Hardware","","1","","12","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Integrated System-on-Module for Design-Space Exploration of Spiking Neural Networks","M. El-Masry; T. Kourany; R. Kho; T. Werner; A. Zjajo; R. Weigel","Infineon Technologies AG, Neubiberg, Germany; Infineon Technologies AG, Neubiberg, Germany; Infineon Technologies AG, Neubiberg, Germany; Ferroelectric Memory GmbH, Dresden, Germany; Innatera Nanosystems, Rijswijk, The Netherlands; University of Erlangen–Nürnberg, Erlangen, Germany",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","We present an integrated system-on-module for design-space exploration of neurosynaptic behavior of complex, non-volatile memory enhanced, spiking neural networks. The system operates in a locally-analog, globally-digital manner, which enables both exploration and validation of individual computational components and characteristic spike-based features of neurosynaptic arrays. The system components are reconfigurable, adaptable and interchangeable enabling reproducible, precise firing patterns. The platform is coupled with an embedded resistive-RAM which acts as a weight retention mechanism. Experimental results obtained in 28 nm CMOS technology illustrate the feasibility of the methodology.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168582","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168582","Spiking neural networks;neuromorphic;system-on-module;non-volatile memory;near-memory computing;resistive-RAM","Weight measurement;Nonvolatile memory;Firing;Neurons;CMOS technology;Time measurement;Pins","","2","","37","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Validation of a CMOS SNN network based on a time-domain threshold neuron circuit achieving 114.90 pJ/inference on MNIST","D. Garcia; J. Granizo; L. Hernandez","Electronic Tech. Dept., Carlos III University, Leganes, Spain; Electronic Tech. Dept., Carlos III University, Leganes, Spain; Electronic Tech. Dept., Carlos III University, Leganes, Spain",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","This paper proves the computing capability of a recently proposed spiking neuron circuit. The novelty of the neuron resides in being based in a subthreshold-operated ring oscillator that is indirectly powered by the input spikes. This allows a very efficient power usage. In the paper, we derive an analytical model of the neuron. The neuron is then co-simulated using the analytical model along with a transistor-level circuit to check the model accuracy. Afterward, the analytical model is used to construct an spiking neural network that can be trained to 98% of accuracy on the MNIST data set, proving equivalent performance than other contemporary circuits. As an advantage, the estimated power for a LeNet-5 implementation is 114.90pJ/inference, which is competitive with the state-of-the-art.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168617","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168617","spiking neural network;SNN;ring oscillator;time-domain computation","Ring oscillators;Analytical models;Circuits and systems;Neurons;Time-domain analysis;Integrated circuit modeling;Artificial intelligence","","3","","16","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Neuromorphic analog circuits for robust on-chip always-on learning in spiking neural networks","A. Rubino; M. Cartiglia; M. Payvand; G. Indiveri","Institute of Neuroinformatics, University of Zurich and ETH Zurich; Institute of Neuroinformatics, University of Zurich and ETH Zurich; Institute of Neuroinformatics, University of Zurich and ETH Zurich; Institute of Neuroinformatics, University of Zurich and ETH Zurich",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Mixed-signal neuromorphic systems represent a promising solution for solving extreme-edge computing tasks without relying on external computing resources. Their spiking neural network circuits are optimized for processing sensory data on-line in continuous-time. However, their low precision and high variability can severely limit their performance. To address this issue and improve their robustness to inhomogeneities and noise in both their internal state variables and external input signals, we designed on-chip learning circuits with short-term analog dynamics and long-term tristate discretization mechanisms. An additional hysteretic stop-learning mechanism is included to improve stability and automatically disable weight updates when necessary, to enable continuous always-on learning. We designed a spiking neural network with these learning circuits in a prototype chip using a 180 nm CMOS technology. Simulation and silicon measurement results from the prototype chip are presented. These circuits enable the construction of large-scale spiking neural networks with online learning capabilities for real-world edge computing tasks.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168620","European Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168620","always-on learning;edge-computing;on-chip learning online;SNN;hysteresis;tristability","Upper bound;Neuromorphics;Prototypes;Switches;Analog circuits;Stability analysis;System-on-chip","","5","","25","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Unsupervised Learning of Spike-Timing-Dependent Plasticity Based on a Neuromorphic Implementation","Y. Zhong; Z. Wang; X. Cui; J. Cao; Y. Wang","Key Laboratory of Microelectronic Devices and Circuits (MoE), MPW Center, School of Integrated Circuits, Peking University; Key Laboratory of Microelectronic Devices and Circuits (MoE), MPW Center, School of Integrated Circuits, Peking University; Key Laboratory of Microelectronic Devices and Circuits (MoE), MPW Center, School of Integrated Circuits, Peking University; Key Laboratory of Microelectronic Devices and Circuits (MoE), MPW Center, School of Integrated Circuits, Peking University; Key Laboratory of Microelectronic Devices and Circuits (MoE), MPW Center, School of Integrated Circuits, Peking University",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Spiking neural network is a promising endeavor to fulfill brain-like intelligence on the chip. Its learning rule, i.e., spike-timing-dependent plasticity (STDP), derived from neurobiology, is perceived as a powerful candidate to facilitate low-cost and high-performance unsupervised training. In this paper, we present a temporal coding based STDP learning method (TC-STDP) to verify the counter and look-up table based circuit design on a neuromorphic prototype chip. In order to perform on-chip STDP learning in an unsupervised manner, this paper concentrates more on detailing the experimental procedures and practical evaluations, where we introduce the matching score as a quantitative index to carry out label assignment and accuracy confirmation. Evaluation experiments demonstrate that the unsupervised STDP learning achieves best on-chip recognition accuracies of 93.51%, 80.33% on MNIST and EMNIST datasets, respectively. Moreover, experiments conducted on ModelNet40 3D dataset also validate the effectiveness of unsupervised STDP rule to perform possible incremental learning.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168578","Research and Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168578","unsupervised learning;spike-timing-dependent plasticity (STDP);spiking neural network (SNN);neuromorphic computing;on-chip inference & learning","Training;Three-dimensional displays;Neuromorphics;Learning (artificial intelligence);Encoding;Table lookup;System-on-chip","","1","","19","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"FrameFire: Enabling Efficient Spiking Neural Network Inference for Video Segmentation","Q. Chen; C. Sun; C. Gao; X. Fang; H. Luan",NA; NA; NA; NA; NA,2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Fast video recognition is essential for real-time scenarios, e.g., autonomous driving. However, applying existing Deep Neural Networks (DNNs) to individual high-resolution images is expensive due to large model sizes. Spiking Neural Networks (SNNs) are developed as a promising alternative to DNNs due to their more realistic brain-inspired computing models. SNNs have sparse neuron firing over time, i.e., spatio-temporal sparsity; thus they are useful to enable energy-efficient computation. However, exploiting the spatio-temporal sparsity of SNNs in hardware leads to unpredictable and unbalanced workloads, degrading energy efficiency. In this work, we, therefore, propose an SNN accelerator called FrameFire for efficient video processing. We introduce a Keyframe-dominated Workload Balance Schedule (KWBS) method. It accelerates the image recognition network with sparse keyframes, then records and analyzes the current workload distribution on hardware to facilitate scheduling workloads in subsequent frames. FrameFire is implemented on a Xilinx XC7Z035 FPGA and verified by video segmentation tasks. The results show that the throughput is improved by 1.7× with the KWBS method. FrameFire achieved 1.04 KFPS throughput and 1.15 mJ/frame recognition energy.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168660","University of Shanghai for Science and Technology; Nanjing University; National Key Research and Development Program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168660","Workload balance;SNNs;VLSI","Schedules;Computational modeling;Streaming media;Throughput;Brain modeling;Hardware;Energy efficiency","","3","","17","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Landmark-Based Adversarial Network for RGB-D Pose Invariant Face Recognition","W. -J. Chen; C. -T. Chiu; T. -C. Lin","Department of Computer Science, National Tsing Hua University; Department of Computer Science, National Tsing Hua University; Department of Computer Science, National Tsing Hua University",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Even though numerous studies have been conducted, face recognition still suffers from poor performance in pose variance. Besides fine appearance details of the face from RGB images, we use depth images that present the 3D contour of the face to improve recognition performance in large poses. At first, we propose a dual-path RGB-D face recognition model which learns features from separate RGB and depth images and fuses the two features into one identity feature. We add associate loss to strengthen the complementary and improve performance. Second, we proposed a landmark-based adversarial network to help the face recognition model extract the pose-invariant identity feature. Our landmark-based adversarial network contains a feature generator, pose discriminator, and landmark module. After we use 2-stage optimization to optimize the pose discriminator and feature generator, we removed the pose factor in the feature extracted by the generator. We conduct experiments on KinectFaceDB, RealSensetest and LiDARtest. On KinectFaceDB, we achieve a recognition accuracy of 99.41%, which is 1.31% higher than other methods. On RealSensetest, we achieve a classification accuracy of 92.57%, which is 30.51% higher than other methods. On LiDARtest, we achieve 98.21%, which is 21.88% higher than other methods.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168669","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168669","face recognition;pose invariant face recognition;pose invariant feature;adversarial network;facial landmark","Training;Three-dimensional displays;Image recognition;Fuses;Circuits and systems;Face recognition;Feature extraction","","","","24","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"An Interpretable Pixel Intensity Reconstruction Model for Asynchronous Event Camera","H. Shan; L. Feng; Y. Zhang; Z. Zhu","School of Mircoelectronics, Xidian University, Xi’an, China; School of Mircoelectronics, Xidian University, Xi’an, China; School of Mircoelectronics, Xidian University, Xi’an, China; School of Mircoelectronics, Xidian University, Xi’an, China",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","4","Event cameras with high temporal resolution and high dynamic range have great potential in computer vision (CV) tasks. To utilize the deep neural networks directly, an efficient reconstruction method converting event-based data to frame-based is necessary. In this work, the interpretable Event Represented Intensity (ERI) model that recovers the logarithm of the intensity sensed by a dynamic vision pixel is proposed for the first time. The amplitude-frequency characteristic of the recovered logarithm of the intensity is used to construct the frame-based image to complete CV tasks. Experiment results on the N-Caltech101 dataset show that the proposed ERI model achieves the classification accuracy of 79.20%, which balances the performance and computation cost better.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168635","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168635","Event camera;Interpretable;Intensity Reconstruction","Program processors;Computational modeling;Vision sensors;Reconstruction algorithms;Cameras;Data models;Task analysis","","","","22","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Object-Augmented Skeleton-Based Action Recognition","Z. Li; H. Guo; L. -P. Chau; C. H. Tan; X. Ma; D. Lin; K. -H. Yap","Continental-NTU Corporate Lab, Nanyang Technological University, Singapore; Continental Automotive Singapore Pte. Ltd, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; Continental-NTU Corporate Lab, Nanyang Technological University, Singapore; Continental-NTU Corporate Lab, Nanyang Technological University, Singapore; Continental-NTU Corporate Lab, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","4","Human Skeleton-based Action Recognition (SAR) methods have made great advances in different applications in recent years. However, most existing SAR models mainly focus on the joint/limb pose estimation. They ignore the skeleton-object interaction, thereby resulting in underutilization of information available. For instance, drinking and eating actions may exhibit similar skeleton movements but different object interactions. Hence relying on joint/limb pose estimation alone may lead to incorrect action predictions; but leveraging skeleton-object interaction will help to discriminate such similar actions. In view of this, we propose a new effective method called Object-Augmented Skeleton-based Action Recognition (OA-SAR) to integrate skeleton-object interactions into action recognition. In specific, OA-SAR extracts the object and joint/limb heatmaps, and then integrates this information for subsequent action recognition. We evaluate the OA-SAR method on two benchmarks, NTU-RGB+D-60, and Drive&Act. Experimental results show that OA-SAR can achieve strong performance on both action datasets.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168565","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168565","skeleton-based action recognition;body keypoint heatmaps;human action recognition","Heating systems;Circuits and systems;Pose estimation;Benchmark testing;Skeleton;Human activity recognition;Data mining","","2","","20","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"CPGAN: Collective Punishment Generative Adversarial Network for Dry Fingerprint Image Enhancement","Y. -C. Su; C. -T. Chiu; C. -H. Cheng; K. -H. Liu; T. -C. Lee; J. -L. Chen; J. -Y. Luo; W. -C. Chung; Y. -R. Chang; K. -Y. Ho","Computer Science, National Tsing Hua University; Computer Science, National Tsing Hua University; Computer Science, National Tsing Hua University; MD Novatek; MD Novatek; MD Novatek; MD Novatek; MD Novatek; MD Novatek; MD Novatek",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Fingerprint has been widely used in our daily life, such as mobile. However, some circumstances may lead to low unlocking rate, like fingerprint at low temperature(dry fingerprint) or washed fingerprint. Our method mainly focuses on the former by making it close to normal temperature fingerprint. The main idea of our method, which called ""CPGAN"", is to improve GAN to boost the quality of the enhanced fingerprint. Our objective is to make the generator generates the high quality of enhanced fingerprint. The method is divided into two parts: ""strengthening the discriminator"" and ""strengthening the generator"". For strengthening the generator, we adopt the mechanism of ""Collective Punishment"" to our work. For strengthening the discriminator, we utilize two generators and feature extractor to boost the discriminator. In our experiments, the results surpass the state-of-the-arts on FVC2002 about 75%.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168628","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168628","Image enhancement;Dry fingerprints;GAN;Fingerprint recognition;Convolution Neural Network","Image recognition;Circuits and systems;Image matching;Neural networks;Fingerprint recognition;Generative adversarial networks;Feature extraction","","","","19","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Image Recovery Through Scattering Media via GAN Reconstruction and SNES Optimization","P. Qi; Y. Zheng","School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Optical image recovery through scattering media is a significant yet challenging problem. Iterative wavefront shaping is one of the powerful tools to re-distribute the diffusive light and compensate for the diffuser by controlling the incident wavefront. However, in the scenario that only a feedback signal on the camera can be obtained, this technology would fail due to the lack of target images. In this paper, we propose a new scheme for recovering images through scattering media in an absence of target images. In particular, we employ an improved Generative Adversarial Network (GAN) for computational reconstruction and separable natural evolution strategy (SNES) for wavefront shaping optimization. Both simulation and experimental results suggest that the proposed scheme will open up new opportunities in the applications of biomedical imaging, optical encryption, holographic display, etc.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168553","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168553","Inverse scattering;Computational imaging;Generative Adversarial Network;Wavefront shaping","Optical feedback;Scattering;Media;Holography;Generative adversarial networks;Optical imaging;Holographic optical components","","1","","21","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"In-memory Activation Compression for GPT Training","S. Lee; G. Yun; H. -J. Lee","ISRC, Electrical and Computer Engineering, Seoul National University, Seoul, South Korea; ISRC, Electrical and Computer Engineering, Seoul National University, Seoul, South Korea; ISRC, Electrical and Computer Engineering, Seoul National University, Seoul, South Korea",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Recently, a large number of parameters in Transformer-based language models have caused memory short-ages during training. Although solutions such as mixed precision and model parallelism have been proposed, they have the limitation of inducing communication overhead and requiring modification of the model by a programmer. To address this issue, we propose a scheme that compresses activation data in memory, enabling the reduction of memory usage during training in a user-transparent manner. The compression algorithm gathers activation data into a block and compresses it, using base-delta compression for the exponent and bit-plane zero compression for the sign and mantissa. Then, the important bits are arranged in order, and LSB truncation is applied to fit the target size. The proposed compression algorithm achieves a compression ratio of 2.09 for the sign, 2.04 for the exponent, and 1.21 for the mantissa. A compression ratio of 3.2 is obtained by applying up to the truncation, and we confirm the convergence of GPT-2 training with the compression.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168658","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168658","compression;memory;language model","Training;Circuits and systems;Memory management;Parallel processing;Transformers;Integrated circuit modeling;Artificial intelligence","","","","11","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Architecture-Aware Optimization of Layer Fusion for Latency-Optimal CNN Inference","M. Yoon; J. Choi","Department of Electronic Engineering, Hanyang University, Seoul, Korea; Department of Electronic Engineering, Hanyang University, Seoul, Korea",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","4","Layer fusion is an effective technique for accelerating latency-sensitive CNN inference tasks on resource-constrained accelerators that exploit distributed on-chip integrated memory-accelerator processing-in memory (PIM). However, previous research primarily focused on optimizing memory access, neglecting the significant impact of hardware architecture on latency. This study presents an analytical latency model for a 2D systolic array accelerator, taking into account various hardware factors such as array dimensions, buffer size, and bandwidth. We then investigate the influence of hardware architecture and fusion strategies, including weight and overlap reuse, on performance; these aspects are insufficiently addressed in existing access-based fusion models. By incorporating layer fusion with our proposed latency model across different architectures, dataflows, and workloads, we achieve up to a 53.1% reduction in end-to-end network latency compared to an access-based model.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168659","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168659","Layer fusion;systolic array;convolutional neural network;analytic cost model;dataflow optimization","Analytical models;Costs;Circuits and systems;Hardware;Systolic arrays;Inference algorithms;System-on-chip","","4","","6","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Context Swap: Multi-PIM System Preventing Remote Memory Access for Large Embedding Model Acceleration","H. Kal; C. Kim; M. Kim; W. W. Ro","School of Electrical and Electronic Engineering, Yonsei University; School of Electrical and Electronic Engineering, Yonsei University; School of Electrical and Electronic Engineering, Yonsei University; School of Electrical and Electronic Engineering, Yonsei University",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Processing-in-Memory (PIM) has been an attractive solution to accelerate memory-intensive neural network layers. Especially, PIM is efficient for layers using embeddings, such as the embedding layer and graph convolution layer, because of their large capacity and low arithmetic intensity. The embedding tables of such layers are stored across multiple memory nodes and processed by local PIM modules with sparse access patterns. Towards computing data from other memory nodes on a local PIM module, a naive approach is to allow the local PIM to retrieve data from remote memory nodes. This approach might incur significant performance degradation due to the long latency overhead of remote accesses. To avoid remote access, PIM system can adopt a framework based on MapReduce programming model, which enables PIMs to compute the local data only and CPUs to compute intermediate results of PIMs. However, the multi-PIM system still suffers from performance degradation because the framework is processed on the CPU and it has a long delay compared to the PIM kernel execution. Therefore, we propose a context swap technique that prevents remote data access even without a high-latency framework. We observe that transferring PIM contexts to the remote PIM node needs much fewer data traffic than remote accesses of data. Our PIM system makes PIM nodes swap their context data with each other when they complete their own computation and no longer have local data to compute. Until all PIMs calculate all local data, several context swaps occur. The context swap is performed by a memory controller between PIMs in the same CPU socket and simple software between PIMs in different CPU sockets. To this end, the proposed multi-PIM system outperforms the base PIM system transferring remote data and the PIM system with the kernel-managing framework by 4.1 × and 3.3 ×, respectively.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168595","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168595","","Degradation;Sockets;Computational modeling;Neural networks;Programming;Software;Data models","","1","","15","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"TRIO: a Novel 10T Ternary SRAM Cell for Area-Efficient In-memory Computing of Ternary Neural Networks","T. -D. Nguyen; M. -S. Le; T. -N. Pham; I. -J. Chang",Kyung Hee University; Kyung Hee University; Kyung Hee University; Kyung Hee University,2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","We introduce TRIO, a 10T SRAM cell for inmemory computing circuits in ternary neural networks (TNNs). TRIO's thin-cell type layout occupies only 0.492μm2 in a 28nm FD-SOI technology, which is smaller than some state-of-the-art ternary SRAM cells. Comparing TRIO to other works, we found that it consumes less analog multiplication power, indicating its potential for improving the area and power efficiency of TNN IMC circuits. Our optimized TNN IMC circuit using TRIO achieved high area and power efficiencies of 369.39 TOPS/mm2 and 333.8 TOPS/W in simulations.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168596","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168596","SRAM;Ternary neural networks;In-memory computing;Computation-in-memory","Circuits and systems;Computational modeling;Neural networks;Layout;SRAM cells;In-memory computing;Robustness","","3","","10","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"AI Processor based Data Correction for Enhancing Accuracy of Ultrasonic Sensor","J. Y. Shin; S. Ho Lee; K. Go; S. Kim; S. E. Lee","Dept. of Electronic Engineering, Seoul National University of Science and Technology, Seoul, Republic of Korea; Dept. of Electronic Engineering, Seoul National University of Science and Technology, Seoul, Republic of Korea; Dept. of Electronic Engineering, Seoul National University of Science and Technology, Seoul, Republic of Korea; Dept. of Electronic Engineering, Seoul National University of Science and Technology, Seoul, Republic of Korea; Dept. of Electronic Engineering, Seoul National University of Science and Technology, Seoul, Republic of Korea",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","4","The usage of various sensors in vehicles has increased with the generalization of advanced driver assistance systems (ADAS). To ensure the safety of drivers and pedestrians, considering the accuracy of measured sensor data is essential. In this paper, we propose a data correction system for enhancing the accuracy of distance data from an ultrasonic sensor utilizing an AI processor. The proposed system detects the motion of an object and adjusts the obtained distance data to align with an ideal gradient of sequential data. Experimental results of the proposed system show an error detection rate of 90.6%.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168652","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168652","AI Processor;Ultrasonic Sensor;Data Correction","Pedestrians;Ultrasonic variables measurement;Sensor systems;Acoustics;Data models;Real-time systems;Sensors","","3","","9","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"PN-TMS: Pruned Node-fusion Tree-based Multicast Scheme for Efficient Neuromorphic Systems","Z. Shen; C. Fang; F. Tian; J. Yang; M. Sawan","CenBRAIN Neurotech Center of Excellence, School of Engineering, Westlake University, Hangzhou, China; CenBRAIN Neurotech Center of Excellence, School of Engineering, Westlake University, Hangzhou, China; Department of ECE, Hong Kong University of Science and Technology, Hong Kong SAR, China; CenBRAIN Neurotech Center of Excellence, School of Engineering, Westlake University, Hangzhou, China; CenBRAIN Neurotech Center of Excellence, School of Engineering, Westlake University, Hangzhou, China",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","A growing demand for low-power and real-time computation is motivating the development of dedicated neuromorphic processors. To maximize scalability and power efficiency, multicore architecture has been broadly applied in existing neuromorphic processors. Nevertheless, mapping a Spiking Neural Network (SNN) on a multicore architecture requires a lot of multicast operations. Conventional routing algorithms like path-based routing and dimension order routing (DOR) lead to a severe overhead in both latency and power. To address these limitations, we propose a novel routing algorithm named Pruned Node-fusion Tree-based Multicast Scheme (PN-TMS). PN-TMS leverages multiple algorithms for route planning, optimizing latency and power simultaneously. Experiment results show that PN-TMS outperforms existing network processors’ routing schemes in terms of both energy consumption and latency, achieves an average energy delay product (EDP) reduction of 38.9%.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168590","Westlake University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168590","Network-on-Chip;Neuromorphic system;Multicast routing","Program processors;Multicast algorithms;Power demand;Neuromorphics;Multicore processing;Scalability;Computer architecture","","","","20","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"SNNOpt: An Application-Specific Design Framework for Spiking Neural Networks","J. He; Z. Shen; F. Tian; J. Chen; J. Yang; M. Sawan; T. Cheng; P. Bogdan; C. -Y. Tsui",Hong Kong University of Science and Technology; Westlake University; Hong Kong University of Science and Technology; Westlake University; Westlake University; Westlake University; Hong Kong University of Science and Technology; University of Southern California; Hong Kong University of Science and Technology,2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","We propose a systematic application-specific hardware design methodology for designing Spiking Neural Network (SNN), SNNOpt, which consists of three novel phases: 1) an Olliver-Ricci-Curvature (ORC)-based architecture-aware network partitioning, 2) a reinforcement learning mapping strategy, and 3) a Bayesian optimization algorithm for NoC design space exploration. Experimental results show that SNNOpt achieves a 47.45% less runtime and 58.64% energy savings over state-of-the-art approaches.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168605","National Science Foundation; Army Research Office; Advanced Research Projects Agency; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168605","Spiking Neural Network;Network-on-Chip;Reinforcement Learning","Systematics;Runtime;Design methodology;Neural networks;Reinforcement learning;Learning (artificial intelligence);Hardware","","","","17","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Embedded neuromorphic attention model leveraging a novel low-power heterogeneous platform","A. Gruel; A. d. Mauro; R. Hunziker; L. Benini; J. Martinet; M. Magno","i3S / CNRS, Université Côte d’Azur, Sophia Antipolis, France; Department of Information Technology and Electrical Enginering, ETH Zürich, Zürich, Switzerland; Department of Information Technology and Electrical Enginering, ETH Zürich, Zürich, Switzerland; Department of Information Technology and Electrical Enginering, ETH Zürich, Zürich, Switzerland; i3S / CNRS, Université Côte d’Azur, Sophia Antipolis, France; Department of Information Technology and Electrical Enginering, ETH Zürich, Zürich, Switzerland",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Neuromorphic computing has been identified as an ideal candidate to exploit the potential of event-based cameras, a promising sensor for embedded computer vision. However, state-of-the-art neuromorphic models try to maximize the model performance on large platforms rather than a trade-off between memory requirements and performance. We present the first deployment of an embedded neuromorphic algorithm on Kraken, a low-power RISC-V-based SoC prototype including a neuromorphic spiking neural network (SNN) accelerator. In addition, the model employed in this paper was designed to achieve visual attention detection on event data while minimizing the neuronal populations’ size and the inference latency. Experimental results show that it is possible to achieve saliency detection in event data with a delay of 32ms, maintains classification accuracy of 84.51% and consumes only 3.85mJ per second of processed input data, achieving all of this while processing input data 10 times faster than real-time. This trade-off between decision latency, power consumption, accuracy, and run time significantly outperforms those achieved by previous implementations on CPU and neuromorphic hardware.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168603","CHIST-ERA; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168603","Neuromorphic;Embedded system;Event camera;Academic platform;Visual attention","Visualization;Neuromorphics;Computational modeling;Inference algorithms;Hardware;Data models;Real-time systems","","","","18","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Synaptic metaplasticity with multi-level memristive devices","S. D’Agostino; F. Moro; T. Hirtzlin; J. Arcamone; N. Castellani; D. Querlioz; M. Payvand; E. Vianello","CEA-Leti, Université Grenoble Alpes, Grenoble, France; CEA-Leti, Université Grenoble Alpes, Grenoble, France; CEA-Leti, Université Grenoble Alpes, Grenoble, France; CEA-Leti, Université Grenoble Alpes, Grenoble, France; CEA-Leti, Université Grenoble Alpes, Grenoble, France; Université Paris-Saclay, CNRS, Centre de Nanosciences et de Nanotechnologies, Palaiseau, France; Institute for Neuroinformatics, University of Zurich and ETH Zurich, Zurich, Switzerland; CEA-Leti, Université Grenoble Alpes, Grenoble, France",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Deep learning has made remarkable progress in various tasks, surpassing human performance in some cases. However, one drawback of neural networks is catastrophic forgetting, where a network trained on one task forgets the solution when learning a new one. To address this issue, recent works have proposed solutions based on Binarized Neural Networks (BNNs) incorporating metaplasticity. In this work, we extend this solution to quantized neural networks (QNNs) and present a memristor-based hardware solution for implementing metaplasticity during both inference and training. We propose a hardware architecture that integrates quantized weights in memristor devices programmed in an analog multi-level fashion with a digital processing unit for high-precision metaplastic storage. We validated our approach using a combined software framework and memristor based crossbar array for in-memory computing fabricated in 130 nm CMOS technology. Our experimental results show that a two-layer perceptron achieves 97% and 86% accuracy on consecutive training of MNIST and Fashion-MNIST, equal to software baseline. This result demonstrates immunity to catastrophic forgetting and the resilience to analog device imperfections of the proposed solution. Moreover, our architecture is compatible with the memristor limited endurance and has a 15× reduction in memory footprint compared to the binarized neural network case.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168563","European Research Council; Horizon Europe; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168563","Memory;Metaplasticity;Quantized Neural Networks (QNNs);In-Memory-Computing;Memristor;On-Chip learning","Training;Neural networks;Software algorithms;Memristors;Learning (artificial intelligence);Computer architecture;Hardware","","1","","22","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Mapping-aware Biased Training for Accurate Memristor-based Neural Networks","S. Diware; A. Gebregiorgis; R. V. Joshi; S. Hamdioui; R. Bishnoi","Computer Engineering Lab, Delft University of Technology, Delft, The Netherlands; Computer Engineering Lab, Delft University of Technology, Delft, The Netherlands; IBM Research Division, Yorktown Heights, NY, USA; Computer Engineering Lab, Delft University of Technology, Delft, The Netherlands; Computer Engineering Lab, Delft University of Technology, Delft, The Netherlands",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Memristor-based computation-in-memory (CIM) can achieve high energy efficiency by processing the data within the memory, which makes it well-suited for applications like neural networks. However, memristors suffer from conductance variation problem where their programmed conductance values deviate from the desired values. Such variations lead to computational errors that result in degraded inference accuracy in CIM-based neural networks. In this paper, we present a mapping-aware biased training methodology to mitigate the impact of conductance variation on CIM-based neural networks. We first determine which conductance states of the memristor are inherently more immune to variation. The neural network is then trained under the constraint that important weights can only take numeric values which directly get mapped to such favorable states. Simulation results show that our proposed mapping-aware biased training achieves up to 2.4× hardware accuracy compared to the conventional training.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168661","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168661","","Training;Circuits and systems;Simulation;Neural networks;Memory management;Memristors;Hardware","","5","","36","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"E-Track: Eye Tracking with Event Camera for Extended Reality (XR) Applications","N. Li; A. Bhat; A. Raychowdhury","School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, USA",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Eye tracking is an essential functionality to enable extended reality (XR) applications. However, the latency and power constraints of an XR headset are tight. Unlike fix-rate frame-based RGB cameras, the event camera senses brightness changes and generates asynchronous sparse events with high temporal resolution. Although the event camera exhibits suitable characteristics for eye tracking in XR systems, processing an event-based data stream is a challenging task. In this paper, we present an event-based eye-tracking system that extracts pupil features. It is the first system that operates only with an event camera and requires no additional sensing hardware. We first propose an event-to-frame conversion method that encodes the events triggered by eye motion into a 3-channel frame. Secondly, we train a Convolutional Neural Network (CNN) on 24 subjects to classify the events representing the pupil. Finally, we employ a region of interest (RoI) mechanism that tracks pupil location and reduces the amount of CNN inference by 96%. Our eye-tracking pipeline is able to locate the pupil with an error of 3.68 pixels at 160 mW system power.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168551","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168551","Eye Tracking;Event Camera;Neuromorphic Hardware;Convolutional Neural Network;Extended Reality","Headphones;Extended reality;Tracking;Gaze tracking;Cameras;Feature extraction;Hardware","","6","","15","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"KP2Dtiny: Quantized Neural Keypoint Detection and Description on the Edge","T. Rüegg; M. Giordano; M. Magno","D-ITET ETH Zurich, Zurich, Switerland; Center for Project Based Learning, ETH Zurich, Zurich, Switzerland; Center for Project Based Learning, ETH Zurich, Zurich, Switzerland",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Detection and description of keypoints in images is a fundamental component of a wide range of tasks such as Simultaneous Localization And Mapping (SLAM), image alignment and structure from motion (SfM). Efficient computation of these features is crucial for real-time applications and has been addressed by multiple handcrafted algorithms and, recently, by deep neural network-based detectors. Learned detectors achieve high detection performance, but pose high computational requirements, making them slow and impractical for low-power resource constraint platforms. This paper presents a quantized neural keypoint detector and descriptor optimized for edge devices exploiting two recent AI platforms such as MAX78000 by Analog Devices and the Coral AI USB accelerator from Google. To accommodate the diverse constraints and requirements of various applications, we propose and evaluate two model architectures (KP2DtinySmall and KP2DtinyFast) and deploy them on the aforementioned platforms using full 8-bit integer quantization. Furthermore, we extensively evaluate these models in terms of power, latency and accuracy, reporting results on three image sizes (88x88, 320x240 and 640x480), evaluating both quantized and non-quantized models. Fully quantized, KP2DtinySmall reduces network size by a factor of 54x while improving homographic estimation accuracy on 88x88 images on the most stringent threshold (Correctness d1) by 32.4% (0.550) and on 320x240 images by 10.7% (0.648) compared to the KeypointNet architecture by Yang You et. al. This result is achieved by designing a new network with low power platforms in mind, particularly addressing the lower resolution by increasing the density of detectable features. Deployed on the MAX78000 MCU, inference of low-resolution images is run at 59 FPS, consuming 1.1 mJ per image. On the Coral usb accelerator, KP2DtinyFast runs inference on low-resolution images at 527 FPS consuming 3.1 mJ, on high resolution it achieves 70 FPS at 19.9 mJ per inference.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168598","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168598","Keypoint detection;EdgeAI;Neural Network;Low Power","Simultaneous localization and mapping;Image resolution;Image edge detection;Estimation;Detectors;Computer architecture;Feature extraction","","1","","23","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"FPGA-Based High-Speed and Resource-Efficient 3D Reconstruction for Structured Light System","F. Bao; Z. Dong; J. Yu; S. Mai","Shenzhen International Graduate School, Tsinghua University, Shenzhen, China; Shenzhen International Graduate School, Tsinghua University, Shenzhen, China; Shenzhen International Graduate School, Tsinghua University, Shenzhen, China; Shenzhen International Graduate School, Tsinghua University, Shenzhen, China",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","To achieve high-speed and low-resource consumption 3D measurement, we propose a parallel and full-pipeline FPGA architecture for the phase measuring profilometry algorithm. The proposed system uses four-step phase-shifting and gray code decoding to generate accurate 3D point clouds. Experimental results show that the proposed architecture can process 12 frames of images with a resolution of 720 × 540 in just 12.2 ms, which is 110 times faster than the same implementation in software, and has the smallest resource consumption compared with other similar FPGA systems. This makes the proposed system very suitable for high-speed embedded 3D shape measurement applications.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168616","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168616","FPGA;phase measuring profilometry;parallel and full-pipeline architecture","Point cloud compression;Three-dimensional displays;Phase measurement;Image resolution;Shape measurement;Software algorithms;Computer architecture","","","","18","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"AI-assisted ISP hyperparameter auto tuning","F. Xu; Z. Liu; Y. Lu; S. Li; S. Xu; Y. Fan; Y. -K. Chen","State Key Laboratory of ASIC & System, Fudan University, Shanghai, China; Alibaba Group; Alibaba Group; Alibaba Group; Alibaba Group; State Key Laboratory of ASIC & System, Fudan University, Shanghai, China; Alibaba Group",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Images and videos are vital visual information carriers, and the image signal processor (ISP) is an essential hardware component for capturing and processing these visual signals. ISPs convert raw data into high-quality color images, which requires various function modules to control different aspects of image quality. However, the results of these modules are interdependent and have crosstalk with each other, making it tedious and time-consuming for manual tuning to obtain a set of ideal parameter configurations to achieve stable performance. In this paper, we introduce xkISP, a self-developed open-source ISP project which includes both a C model and hardware implementation of an 8-stage ISP pipeline. Most importantly, we present a novel proxy function-based AI-assisted ISP tuning solution that is demonstrated to accelerate the ISP parameter configuration process and improve performance for both human vision and computer vision tasks.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168574","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168574","Image signal processor;AI-assisted parameter search","Image quality;Visualization;Computer vision;Pipelines;Crosstalk;Manuals;Hardware","","","","16","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Image Frequency Separation Residual Network for End-to-end RAW to RGB Mapping","M. Dong; W. Zhou; C. Pang; X. Zhang; X. Lou","ShanghaiTech University, Shanghai, China; ShanghaiTech University, Shanghai, China; ShanghaiTech University, Shanghai, China; ShanghaiTech University, Shanghai, China; ShanghaiTech University, Shanghai, China",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Due to the limitations of hardware specification of smartphones' camera system, there is still a visible gap in imaging quality between smartphones and digital singlelens reflex (DSLR) cameras. Sophisticated learning-based image processing becomes a promising solution to close this gap. In this paper, we propose an Image Frequency Separation Residual Network (IFS Net) to perform the end-to-end RAW to RGB image mapping. Different from existing methods that directly train the input image and the ground truth image one-to-one as a whole, our proposed method first divides the input image and the ground truth into high-frequency and low-frequency parts by discrete wavelet transform (DWT). These two parts are then trained separately using different networks for details and global information, and finally synthesized into the output image using inverse DWT. Experimental results show that the proposed IFS Net outperforms other existing algorithms in both PSNR and SSIM. Visual comparison shows that the images produces by IFS Net preserves more details and look close to that captured by DSLR cameras.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168597","Shanghai Rising-Star Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168597","Image Signal Processing (ISP);learning-based ISP;smartphone camera;imaging","Visualization;Image color analysis;Neural networks;Signal processing algorithms;Transforms;Signal processing;Cameras","","","","32","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Machine Learning using Logarithmic Arithmetic with Preconditioned Input to Mitchell's Method","M. Arnold","Lehigh University, USA",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Mitchell's method often has approximated base-two antilogarithms using low-cost hardware in low-accuracy systems. Another application of identical circuits is to approximate the the addition-logarithm function needed for the sum of values represented by the Logarithmic Number System (LNS). This paper shows how preconditioning the input to Mitchell's method improves the accuracy of Mitchell logarithmic addition and subtraction at lower cost than other methods. One promising application is machine learning. The proposed preconditioning has MNIST training performance nearly identical to full FP.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168554","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168554","Logarithmic arithmetic;Approximate computation;Machine learning;back-propagation","Training;Semiconductor device modeling;Costs;Circuits and systems;Moore's Law;Machine learning;Hardware","","","","40","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Modified Logarithmic Multiplication Approximation for Machine Learning","I. Kouretas; V. Paliouras; T. Stouraitis","University of Patras, Greece; University of Patras, Greece; Khalifa University, UAE",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","In this paper, a novel approximation that allows exploitation of the full potential of logarithmic multiplication is proposed. More specifically, the proposed approximation is quantified in terms of mean square error (MSE) and compared to a competitive recent publication. Subsequently, an LSTM network is used as an illustrative test case and the proposed approximation is validated in terms of the accuracy of the netowrk. It has been shown that for short data wordlengths, the proposed approximation can achieve small loss values, for the particular LSTM network. Finally, the circuit implementation of the logarithmic multiplier is synthesized in a 28 nm standard-cell library. Results show reduced hardware complexity for similar loss values on the specific LSTM network.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168664","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168664","","Circuits and systems;Artificial neural networks;Mean square error methods;Machine learning;Hardware;Libraries;Complexity theory","","","","19","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Reduced-Precision Floating-Point Arithmetic in Systolic Arrays with Skewed Pipelines","D. Filippas; C. Peltekis; G. Dimitrakopoulos; C. Nicopoulos","Electrical and Computer Engineering, Democritus University of Thrace, Greece; Electrical and Computer Engineering, Democritus University of Thrace, Greece; Electrical and Computer Engineering, Democritus University of Thrace, Greece; Electrical and Computer Engineering, University of Cyprus, Cyprus",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","The acceleration of deep-learning kernels in hardware relies on matrix multiplications that are executed efficiently on Systolic Arrays (SA). To effectively trade off deep-learning training/inference quality with hardware cost, SA accelerators employ reduced-precision Floating-Point (FP) arithmetic. In this work, we demonstrate the need for new pipeline organizations to reduce latency and improve energy efficiency of reduced-precision FP operators for the chained multiply-add operation imposed by the structure of the SA. The proposed skewed pipeline design reorganizes the pipelined operation of the FP multiplyadd units to enable new forwarding paths for the exponent logic, which allow for parallel execution of the pipeline stages of consecutive PEs. As a result, the latency of the matrix multiplication operation within the SA is significantly reduced with minimal hardware cost, thereby yielding an energy reduction of 8% and 11% for the examined state-of-the-art CNNs.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168556","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168556","systolic arrays;floating-point arithmetic;pipeline;deep learning","Costs;Pipelines;Computer architecture;Organizations;Learning (artificial intelligence);Systolic arrays;Hardware","","7","","31","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"F-CNN: Faster CNN Exploiting Data Re-Use with Statistical Analysis","F. Alantali; Y. Halawani; B. Mohammad; M. Al-Qutayri","Electrical Engineering and Computer Science Department, System-on-Chip Lab, Khalifa University, Abu Dhabi, UAE; College of Engineering & Information Technology, University of Dubai, Dubai, UAE; Electrical Engineering and Computer Science Department, System-on-Chip Lab, Khalifa University, Abu Dhabi, UAE; Electrical Engineering and Computer Science Department, System-on-Chip Lab, Khalifa University, Abu Dhabi, UAE",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","4","Many of the current edge computing devices need efficient implementation of Artificial Intelligence (AI) applications due to strict latency, security and power requirements. Nonetheless, such devices, face various challenges when executing AI applications due to their limited computing and energy resources. In particular, Convolutional Neural Networks (CNN) is a popular machine learning method that derives a high-level function from being trained on various visual input examples. This paper contributes to enabling the use of CNN on resource-constrained devices offline, where a trade-off between accuracy, running time and power efficiency is verified. The paper investigates the use of minimum pre-processing methods of input data to identify nonessential computations in the convolutional layers. In this work, Spatial locality of input data is considered along with an efficient pre-processing method to mitigate the accuracy loss caused by the computational re-use approach. This technique was tested on LeNet and CIFAR-10 structures and was responsible for 1.9% and 1.6% accuracy loss while reducing the processing time by 38.3% and 20.9% and reducing the energy by 38.3%, and 20.7%, respectively. The models were deployed and verified on Raspberry Pi 4 B platform using the MATLAB coder to measure time and energy.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168606","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168606","CNN;statistical analysis;computation reuse;input similarity;pre-processing","Visualization;Statistical analysis;Energy resources;Machine learning;Time measurement;Convolutional neural networks;Security","","1","","13","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Task-aware Scheduling and Performance Optimization on Yitian710 SoC for GEMM-based Workloads on the Cloud","G. Yu; Z. Lv; H. Wang; Z. Huang; J. Chen","T-Head Semiconductor Co., Ltd, Alibaba Group, Hangzhou, China; T-Head Semiconductor Co., Ltd, Alibaba Group, Hangzhou, China; T-Head Semiconductor Co., Ltd, Alibaba Group, Hangzhou, China; T-Head Semiconductor Co., Ltd, Alibaba Group, Hangzhou, China; T-Head Semiconductor Co., Ltd, Alibaba Group, Hangzhou, China",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","The YiTian710 SoC is a server processor based on ARM Neoverse N2 architecture and developed by T-HEAD Semiconductor Co., Ltd. to accelerate the compute-intensive tasks in Alicloud, where the ML related workloads play an important role in various applications. The General Matrix Multiplication is the fundamental and the most important computing kernel routine extensively utilized in the ML workloads. Generally, the whole GEMM workload is partitioned into a series of blocks and the sub-tasks are professionally assembled to exploit the parallel hardware. However, it is not the case for the cloud workloads which process multi-tasks concurrently and expect guaranteed QoS for commercial consideration. We introduce the task-aware parallel scheduling method to process the ML workloads and balance the response delay and the throughput of the YiTian710 ECS instance. We furtherly design a multi-thread scheduling algorithm with two-level division for the GEMM sub-tasks to achieve high efficiency. The optimized GEMM kernels are developed to attain the optimal performance. We evaluate the performance in YiTian710 based Alicloud ECS for different applications. The results show that our method can achieve remarkable performance improvement for different applications.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168586","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168586","YiTian710 SoC;GEMM;QoS;ARM server;ECS","Program processors;Scheduling algorithms;Quality of service;Throughput;Multitasking;Hardware;Servers","","","","14","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Efficient Algorithms for Accelerating Spiking Neural Networks on MAC Array of SpiNNaker 2","J. Huang; F. Kelber; B. Vogginger; B. Wu; F. Kreutz; P. Gerhards; D. Scholz; K. Knobloch; C. G. Mayr",Infineon Technologies Dresden; Technische Universität Dresden; Technische Universität Dresden; Infineon Technologies Dresden; Infineon Technologies Dresden; Infineon Technologies Dresden; Infineon Technologies Dresden; Infineon Technologies Dresden; Technische Universität Dresden,2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","The CPU-based system is widely used for simulating the brain-inspired spiking neural networks (SNN) by taking the benefit of flexibility, while processing high input spiking rates caused by immature coding mechanism costs many CPU cycles, and the introduction of additional information required by serial execution needs the time-consuming pre- and post-neuron matching algorithm. To address these issues, we propose an algorithm set leveraging the multiply-accumulate (MAC) array to accelerate the SNN inference. By rearranging and compressing operands losslessly, we retain the advantage of the MAC array on fast parallel computing, as well as alleviate the ineffective memory occupation and the waste of computing resources, which result from the inherent sparse feature of SNN and reluctant memory alignment from fixed MAC hardware structure. Benchmarking with an SNN radar gesture recognition model, the algorithms jointly optimize 82.71% of the execution time compared to the serial computation on the ARM M4F of the SpiNNaker 2 chip; 49.89% of the memory footprint is reduced contrasted with the unoptimized MAC calculation. This article explicitly expands the application field of the General Sparse Matrix-Matrix Multiplication (SpGEMM) issue to SNN, developing novel SpGEMM optimization algorithms fitting the SNN feature and MAC array.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168559","Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168559","Neuromorphic computing;multiply-accumulate;SNN;SpiNNaker 2;parallel computing;SpGEMM","Program processors;Computational modeling;Memory management;Radar;Gesture recognition;Parallel processing;Inference algorithms","","3","","16","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Read-disturb Detection Methodology for RRAM-based Computation-in-Memory Architecture","M. A. Yaldagard; S. Diware; R. V. Joshi; S. Hamdioui; R. Bishnoi","Computer Engineering Lab, Delft University of Technology, Delft, The Netherlands; Computer Engineering Lab, Delft University of Technology, Delft, The Netherlands; IBM Research Division, Yorktown Heights, NY, USA; Computer Engineering Lab, Delft University of Technology, Delft, The Netherlands; Computer Engineering Lab, Delft University of Technology, Delft, The Netherlands",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Resistive random access memory (RRAM) based computation-in-memory (CIM) architectures can meet the unprecedented energy efficiency requirements to execute AI algorithms directly on edge devices. However, the read-disturb problem associated with these architectures can lead to accumulated computational errors. To achieve the necessary level of computational accuracy, after a specific number of read cycles, these devices must undergo a reprogramming process which is a static approach and needs a large counter. This paper proposes a circuit-level RRAM read-disturb detection technique by monitoring real-time conductance drifts of RRAM devices, which initiate the reprogramming when actually it needs. Moreover, an analytic method is presented to determine the minimum conductance detection requirements, and our proposed read-disturb detection technique is tuned for the same to detect it dynamically. SPICE simulation result using TSMC 40 nm shows the correct functionality of our proposed detection technique.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168638","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168638","","Simulation;Resistive RAM;Computer architecture;SPICE;Energy efficiency;Real-time systems;Common Information Model (computing)","","4","","21","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Online low-power large-scale real-time decision-making all at once","T. Pontoizeau; É. Jacopin","LightOn, Paris, France; Hawkswell Studios, Paris, France",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","In this paper, we set up a simulation under Unreal Engine 5 that communicates with an Optical Processing Unit (OPU) in order to make real-time decisions on the current state of the actors of the simulation. Our experiment shows that the OPU is able to manage at least 50 000 actors in real-time and is able to make decisions depending of the current state of the actors.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168570","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168570","decision-making;optical processing unit;low-power;real-time","Circuits and systems;Decision making;Real-time systems;Integrated circuit modeling;Artificial intelligence;Engines","","","","12","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"NeuroBMI: A New Neuromorphic Implantable Wireless Brain Machine Interface with A 0.48 µW Event-Driven Noise-Tolerant Spike Detector","J. Chen; H. Wu; X. Liu; R. Eskandari; F. Tian; W. Zou; C. Fang; J. Yang; M. Sawan","CenBRAIN Neurotech, School of Engineering, Westlake University, Hangzhou, China; CenBRAIN Neurotech, School of Engineering, Westlake University, Hangzhou, China; CenBRAIN Neurotech, School of Engineering, Westlake University, Hangzhou, China; CenBRAIN Neurotech, School of Engineering, Westlake University, Hangzhou, China; Department of ECE, HKUST, Hong Kong SAR, China; CenBRAIN Neurotech, School of Engineering, Westlake University, Hangzhou, China; CenBRAIN Neurotech, School of Engineering, Westlake University, Hangzhou, China; CenBRAIN Neurotech, School of Engineering, Westlake University, Hangzhou, China; CenBRAIN Neurotech, School of Engineering, Westlake University, Hangzhou, China",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","The use of Brain-Machine Interfaces (BMIs) in neuroscience research and neural prosthetics has seen widespread application. With the technology trend shifting from wearable to implantable wireless BMIs featuring increasing channel counts, the volume of data generated requires impractically high bandwidth and transmission power for the implants. In this paper, we present NeuroBMI, a novel neuromorphic implantable wireless BMI that leverages a unified neuromorphic strategy for neural signal sampling, processing, and transmission. The proposed NeuroBMI and neuromorphic strategy reduces transmitted data rate and overall power consumption. NeuroBMI takes into account the high sparsity of neural signals by employing an integrateand-fire sampling based analog-to-spike converter (ASC), which generates digital spike trains based on triggered events and avoids unnecessary data sampling. Additionally, an event-driven noise-tolerant spike detector and event-driven spike transmitter are also proposed, to further reduce the energy consumption and transmitted data rate. Simulation results demonstrate that the proposed NeuroBMI achieves a data compression ratio of 520, with the proposed spike detector consuming only 0.48 µW.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168619","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168619","Neuromorphic system;implantable wireless BMI;analog-to-spike converter;spike detector;spike transmitter","Wireless communication;Power demand;Neuromorphics;Transmitters;Simulation;Signal sampling;Data compression","","1","","20","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Bringing Touch to the Edge: A Neuromorphic Processing Approach For Event-Based Tactile Systems","H. Patel; A. Vanarse; K. D. Carlson; A. Osseiran","Brainchip Research Institute, Perth, Australia; Brainchip Research Institute, Perth, Australia; Brainchip Inc., Laguna Hills, USA; Brainchip Research Institute, University of Western Australia, Perth, Australia",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","The rise of neuromorphic applications has highlighted the remarkable potential of biologically-inspired systems. Despite significant advancements in audio and visual technologies, research directed towards tactile sensing has not been as extensive. We propose a neuromorphic tactile system for sensing and processing that presents promising results for edge devices and applications. In this study, a neuromorphic tactile sensor, two data encoding techniques, and a two-layer spiking neural network (SNN) deployed on the AKD1000 Akida Neuromorphic System on Chip (NSoC) were used to demonstrate the system's capabilities. Results from experiments on the ST-MNIST dataset showed high accuracy, with the complement-coded variant achieving 93.1%, outperforming previous state-of-the-art models for this dataset. Additionally, an exploratory study showed that early classification was possible, with most samples requiring only 38% of the available events to classify correctly, reducing the amount of data that needs to be processed. The low power consumption and high throughput of both SNN models, with an average dynamic power consumption of 6.37 mW and 7.76 mW and an average throughput of 586 and 589 frames-per-second respectively, make the proposed system suitable for edge devices with limited power and processing resources. Overall, the proposed tactile sensing system presents a promising solution for edge applications that require high accuracy, low power consumption, and high throughput.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168592","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168592","bio-inspired sensing;event-based processing;neuromorphic tactile;spiking neural networks","Visualization;Power demand;Neuromorphics;Neural networks;Tactile sensors;Throughput;Dynamic scheduling","","","","11","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Temporal Similarity-Based Computation Reduction for Video Transformers in Edge Camera Nodes","U. De Alwis; Z. Xie; M. Alioto","ECE Dept., National University of Singapore, Singapore; ECE Dept., National University of Singapore, Singapore; ECE Dept., National University of Singapore, Singapore",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Recognizing human actions in video sequences has become an essential task in video surveillance applications. In such applications, transformer models have rapidly gained wide interest thanks to their performance. However, their advantages come at the cost of a high computational and memory cost, especially when they need to be incorporated in edge devices. In this work, temporal similarity tunnel insertion is utilized to reduce the overall computation burden in video transformer networks in action recognition tasks. Furthermore, an edge-friendly video transformer model is proposed based on temporal similarity, which substantially reduces the computation cost. Its smaller variant EMViT achieves 38% computation reduction under the UCF101 dataset, while keeping the accuracy degradation insignificant (<0.02%). Also, the larger variant CMViT reduces computation by 14% (13%) with an accuracy degradation of 2% (3%) in scaled Kinetic400 and Jester datasets.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168610","National Research Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168610","Video action recognition;multi-scale visual transformers;computational efficiency;temporal similarity","Degradation;Performance evaluation;Visualization;Costs;Computational modeling;Video sequences;Transformers","","","","16","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Free Bits: Latency Optimization of Mixed-Precision Quantized Neural Networks on the Edge","G. Rutishauser; F. Conti; L. Benini","Departement Informationstechnologie und Elektrotechnik, ETH Zürich, Switzerland; Dipartimento di Ingegneria Dell’Energia Elettrica e Dell’Informazione, Università di Bologna, Bologna, Italy; Departement Informationstechnologie und Elektrotechnik, ETH Zürich, Switzerland",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Mixed-precision quantization, where a deep neural network’s layers are quantized to different precisions, offers the opportunity to optimize the trade-offs between model size, latency, and statistical accuracy beyond what can be achieved with homogeneous-bit-width quantization. To navigate the in-tractable search space of mixed-precision configurations for a given network, this paper proposes a hybrid search methodology. It consists of a hardware-agnostic differentiable search algorithm followed by a hardware-aware heuristic optimization to find mixed-precision configurations latency-optimized for a specific hardware target. We evaluate our algorithm on MobileNetV1 and MobileNetV2 and deploy the resulting networks on a family of multi-core RISC-V microcontroller platforms with different hardware characteristics. We achieve up to 28.6 % reduction of end-to-end latency compared to an 8-bit model at a negligible accuracy drop from a full-precision baseline on the 1000-class ImageNet dataset. We demonstrate speedups relative to an 8-bit baseline, even on systems with no hardware support for sub-byte arithmetic at negligible accuracy drop. Furthermore, we show the superiority of our approach with respect to differentiable search targeting reduced binary operation counts as a proxy for latency.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168577","Horizon Europe; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168577","Edge AI;Mixed-Precision Neural Networks","Quantization (signal);Navigation;Microcontrollers;Circuits and systems;Heuristic algorithms;Neural networks;Hardware","","4","","18","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"TinyissimoYOLO: A Quantized, Low-Memory Footprint, TinyML Object Detection Network for Low Power Microcontrollers","J. Moosmann; M. Giordano; C. Vogt; M. Magno",Center for Project Based Learning - ETH Zürich; Center for Project Based Learning - ETH Zürich; Center for Project Based Learning - ETH Zürich; Center for Project Based Learning - ETH Zürich,2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","This paper introduces a highly flexible, quantized, memory-efficient, and ultra-lightweight object detection network, called TinyissimoYOLO. It aims to enable object detection on microcontrollers in the power domain of milliwatts, with less than 0.5 MB memory available for storing convolutional neural network (CNN) weights. The proposed quantized network architecture with 422 k parameters, enables real-time object detection on embedded microcontrollers, and it has been evaluated to exploit CNN accelerators. In particular, the proposed network has been deployed on the MAX78000 microcontroller achieving high frame-rate of up to 180 fps and an ultra-low energy consumption of only 196 µJ per inference with an inference efficiency of more than 106 MAC/Cycle. TinyissimoYOLO can be trained for any multi-object detection. However, considering the small network size, adding object detection classes will increase the size and memory consumption of the network, thus object detection with up to 3 classes is demonstrated. Furthermore, the network is trained using quantization-aware training and deployed with 8-bit quantization on different microcontrollers, such as STM32H7A3, STM32L4R9, Apollo4b and on the MAX78000’s CNN accelerator. Performance evaluations are presented in this paper.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168657","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168657","YOLO;ML;computer vision;object detection;CNN accelerator;microcontroller;quantization;quantization-aware training","Training;Performance evaluation;Quantization (signal);Microcontrollers;Image edge detection;Memory management;Object detection","","10","","27","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Searching Tiny Neural Networks for Deployment on Embedded FPGA","H. Qin; Y. Zeng; J. Bai; W. Kang","School of Integrated Circuit Science and Engineering, Beihang University; School of Integrated Circuit Science and Engineering, Beihang University; School of Integrated Circuit Science and Engineering, Beihang University; School of Integrated Circuit Science and Engineering, Beihang University",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Embedded FPGAs have become increasingly popular as acceleration platforms for the deployment of edge-side artificial intelligence (AI) applications, due in part to their flexible and configurable heterogeneous architectures. However, the complex deployment process hinders the realization of AI democratization, particularly at the edge. In this paper, we propose a software-hardware co-design framework that enables simultaneous searching for neural network architectures and corresponding accelerator designs on embedded FPGAs. The proposed framework comprises a hardware-friendly neural architecture search space, a reconfigurable streaming-based accelerator architecture, and a model performance estimator. An evolutionary algorithm targeting multi-objective optimization is employed to identify the optimal neural architecture and corresponding accelerator design. We evaluate our framework on various datasets and demonstrate that, in a typical edge AI scenario, the searched network and accelerator can achieve up to a 2.9% accuracy improvement and up to a 21 speedup compared to manually designed networks based on× common accelerator designs when deployed on a widely used embedded FPGA (Xilinx XC7Z020).","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168571","Nova; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168571","Software-Hardware Co-desgin;FPGA;Multi-objective optimization","Deep learning;Circuits and systems;Accelerator architectures;Artificial neural networks;Evolutionary computation;Artificial intelligence;Field programmable gate arrays","","","","20","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Energy Efficient Software-hardware Co-design of Quantized Recurrent Convolutional Neural Network for Continuous Cardiac Monitoring","J. Hu; C. S. Leow; W. L. Goh; Y. Gao","School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore, Republic of Singapore; Agency for Science, Technology and Research (A*STAR), Institute of Microelectronics (IME), Singapore, Republic of Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore, Republic of Singapore; Agency for Science, Technology and Research (A*STAR), Institute of Microelectronics (IME), Singapore, Republic of Singapore",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","This paper presents an electrocardiogram (ECG) signal classification model based on Recurrent Convolutional Neural Network (RCNN). With recurrent connections and data buffers, a single convolutional layer is reused to implement multiple layers function. Using a 5-layers CNN network as an example, this approach reduces the number of parameters by more than 50% while achieving the same feature extraction size. Furthermore, quantized RCNN (QRCNN) is proposed where the input signal, interlayer output, and kernel weights are quantized to unsigned INT8, INT4, and signed INT4 respectively. For hardware implementation, pipelining and data reuse within the 1-D convolution kernel can potentially reduce latency. QRCNN model achieved 98.08% validation accuracy on MIT-BIH datasets with only 1% degradation due to quantization. The estimated dynamic power consumption of the QRCNN is less than 60% of a conventional quantized CNN when implemented on a Xilinx Artix-7 FPGA, showing the potential for resource-constraint edge devices.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168601","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168601","RCNN;Fixed-point quantization;FPGA;ECG classification","Semiconductor device modeling;Convolution;Computational modeling;Electrocardiography;Hardware;Classification algorithms;Convolutional neural networks","","7","","28","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"A Lightweight Convolutional Neural Network for Atrial Fibrillation Detection Using Dual-Channel Binary Features from Single-Lead Short ECG","J. Liu; X. Liu; L. Zhou; L. Chang; J. Zhou","School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Atrial fibrillation (AF) is a prevalent cardiovascular disease in the elderly, significantly increasing the risk of stroke and heart failure, etc. While the artificial neural network (ANN) has recently demonstrated high accuracy in ECG-based AF detection, its high computation complexity makes it challenging for real-time and long-term monitoring on low-power wearable devices, which is critical for detecting paroxysmal AF. Therefore, in this work, a lightweight convolutional neural network for AF detection is proposed using a dual-channel binary features extraction technique from single-lead short ECG to achieve both high classification accuracy and low computation complexity, and evaluated on the 2017 PhysioNet/CinC Challenge dataset, the proposed method achieves 93.6% sensitivity and 0.81 F1 score for AF detection. Moreover, this design consumes only 1.83M parameters, achieving up to 27x reductions compared with prior works, and only needs 57M MACs for calculation. As a result, it is suitable for deployment in low-power wearable devices for long-term AF monitoring.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168645","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168645","Atrial fibrillation (AF);neural networks;Lightweight;single-lead ECG","Sensitivity;Wearable computers;Atrial fibrillation;Electrocardiography;Stroke (medical condition);Feature extraction;Convolutional neural networks","","1","","21","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Classification of ECG based on Hybrid Features using CNNs for Wearable Applications","L. Xiaolin; F. Xiang; R. C. Panicker; B. Cardiff; D. John",University College Dublin; University College Dublin; National University of Singapore; University College Dublin; University College Dublin,2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","4","Sudden cardiac death and arrhythmia account for a large percentage of all deaths worldwide. Electrocardiography (ECG) is the most widely used screening tool for cardiovascular diseases. Traditionally, ECG signals are classified manually, requiring experience and great skill, while being time-consuming and prone to error. Thus machine learning algorithms have been widely adopted because of their ability to perform complex data analysis. Features derived from the points of interest in ECG - mainly Q, R, and S, are widely used for arrhythmia detection. In this work, we demonstrate improved performance for ECG classification using hybrid features and three different models, building on a 1-D convolutional neural network (CNN) model that we had proposed in the past. An RR interval features based model proposed in this work achieved an accuracy of 98.98%, which is an improvement over the baseline model. To make the model immune to noise, we updated the model using frequency features and achieved good sustained performance in presence of noise with a slightly lower accuracy of 98.69%. Further, another model combining the frequency features and the RR interval features was developed, which achieved a high accuracy of 99% with good sustained performance in noisy environments. Due to its high accuracy and noise immunity, the proposed model which combines multiple hybrid features is well suited for ambulatory wearable sensing applications.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168568","China Scholarship Council; Irish Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168568","ECG classification;Arrhythmia detection;RR interval;FFT;Deep Learning;CNN;IoT Sensors","Machine learning algorithms;Arrhythmia;Electrocardiography;Sensor phenomena and characterization;Feature extraction;Sensor systems and applications;Convolutional neural networks","","6","","17","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Integrating Delta Modulation and Stochastic Computing for Real-time Machine Learning based Heartbeats Monitoring in Wearable Systems","X. Tang; S. Liu; F. Niknia; W. Tang; P. Reviriego; F. Lombardi","Klipsch School of ECE, New Mexico State University, Las Cruces, USA; Klipsch School of ECE, New Mexico State University, Las Cruces, USA; Department of ECE, Northeastern University, Boston, USA; Klipsch School of ECE, New Mexico State University, Las Cruces, USA; Telematic Systems Engineering Department, Universidad Politécnica de Madrid, Madrid, Spain; Department of ECE, Northeastern University, Boston, USA",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Real-time electrocardiogram (ECG) monitoring using wearable devices is crucial for early cardiovascular disease diagnosis and by using machine learning (ML) algorithms, it can be automated. Unfortunately, wearable devices face stringent hardware resource constraints, and thus low-complexity designs that can implement ML-based detection of heartbeat anomalies are required. This paper proposes the integration of a delta modulator (DM) used to digitize the ECG signal with a Stochastic Computing (SC) implementation of the ML algorithms. The DM enables a low-cost conversion of the ECG to binary sequences that are then directly processed in the SC implementation of an ML algorithm. This eliminates the need of converting the DM outputs to integers and then to stochastic sequences and thus the proposed integrated design considerably reduces the complexity of the system. The proposed scheme has been evaluated on a premature ventricular contraction (PVC) heartbeat recognition system based on a support vector machine classifier. The estimated chip area and power dissipation of the proposed system using a commercial 180nm CMOS technology are 0.36 mm2 and 0.6 µW, respectively, so achieving more than 38% and 54% reduction in these metrics compared to state-of-the-art solutions while providing similar performance in terms of heartbeat anomaly detection.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168665","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168665","Wearable ECG measurement;stochastic computing;support vector machine;PVC heartbeat classification","Heart beat;Wearable computers;Modulation;Support vector machine classification;Machine learning;Electrocardiography;Real-time systems","","","","20","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"A 12-Lead ECG Delineation Algorithm based on a Quantized CNN-BiLSTM Auto-encoder with 1-12 Mapping","X. Xu; Q. Cai; H. Wang; Y. Suo; Y. Zhao; W. Tianwei; G. Wang; Y. Lian","Department of Micro-Nano Electronics, Shanghai Jiao Tong University, Shanghai, China; Department of Micro-Nano Electronics, Shanghai Jiao Tong University, Shanghai, China; Department of Micro-Nano Electronics, Shanghai Jiao Tong University, Shanghai, China; Department of Micro-Nano Electronics, Shanghai Jiao Tong University, Shanghai, China; Department of Micro-Nano Electronics, Shanghai Jiao Tong University, Shanghai, China; Qingdao Tianzhuo Technology Invest-Holding Limited Company, Qingdao, China; Department of Micro-Nano Electronics, Shanghai Jiao Tong University, Shanghai, China; Department of Micro-Nano Electronics, Shanghai Jiao Tong University, Shanghai, China",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","12-lead electrocardiogram (ECG) delineation is a critical step in diagnosing of various heart diseases. Current practices for 12-lead ECG delineation typically involve processing each of the 12 leads separately using a network, which is computationally expensive. To solve this issue, 1-12 mapping strategy is proposed to directly map one lead network predictions to other leads and then fine-tune boundaries. CNN-BiLSTM autoencoder architecture is employed to model the sequential dependencies of ECG signal. Besides, data augmentation and mixed losses are utilized to enhance the robustness of the network. Evaluated on QTDB and LUDB, the delineation results for 12-lead ECG achieve a Se of 97%, 99%, and 98%, DS of 95.3%, 96.2%, and 94.4% for P-wave, QRS complex, and T-wave respectively. At last, quantization-aware training is employed to convert float32 model to int8 one with only about a 2% drop of accuracy.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168552","National Key Research and Development Program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168552","12-lead ECG;ECG delineation;CNN-BiLSTM auto-encoder;data augmentation;mixed losses;1-12 mapping;quantization-aware training","Training;Heart;Sensitivity;Simulation;Electrocardiography;Prediction algorithms;Data augmentation","","1","","16","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"LungHeart-AtMe: Adventitious Cardiopulmonary Sounds Classification Using MMoE with STFT and MFCCs Spectrograms","C. Chen†; Q. Zhang; S. Sheng; H. Huang; Y. Zhang; Y. Li","Department of Micro-Nano Electronics and MoE Key Lab of Artificial Intelligence, Shanghai Jiao Tong University, China; Department of Micro-Nano Electronics and MoE Key Lab of Artificial Intelligence, Shanghai Jiao Tong University, China; Department of Micro-Nano Electronics and MoE Key Lab of Artificial Intelligence, Shanghai Jiao Tong University, China; Department of Micro-Nano Electronics and MoE Key Lab of Artificial Intelligence, Shanghai Jiao Tong University, China; Department of Micro-Nano Electronics and MoE Key Lab of Artificial Intelligence, Shanghai Jiao Tong University, China; Department of Micro-Nano Electronics and MoE Key Lab of Artificial Intelligence, Shanghai Jiao Tong University, China",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Adventitious cardiopulmonary (lung and heart) sound detection and classification through a digital stethoscope plays a vital role in early diagnosis and telehealth services. However, automatically detecting the adventitious sounds is challenging since they are easily susceptible to each other’s influence and noises. In this paper, for the first time, we simultaneously classify adventitious lung and heart sounds using our proposed LungHeart-AtMe model based on a mixed dataset of the ICBHI 2017 lung sounds dataset and the PhysioNet 2016 heart sounds dataset. Based on characteristics of lung and heart sounds, Wavelet Decomposition is applied first to perform noise reduction, then two time-frequency feature extraction techniques, which are Short Time Fourier Transform (STFT) and Mel Frequency Cepstral Coefficients (MFCCs), are chosen to extract preliminary features of sounds and transform sounds data to spectrograms that are easy to analyze. Our LungHeart-AtMe model is improved by introducing MMoE structure and by using the attention mechanism-based CNN model to extend its global feature extraction capability. From our experimental result, LungHeart-AtMe has achieved a Sensitivity of 71.55% and a Specificity of 28.06% for cardiopulmonary sounds classification.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168624","Research and Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168624","Cardiopulmonary Sound Classification;Feature Extraction;Data Augmentation;Short Time Fourier Transform;Mel Frequency Cepstral Coefficients;Neural Network","Heart;Wavelet transforms;Time-frequency analysis;Telemedicine;Lung;Stethoscope;Feature extraction","","7","","35","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Bit-Offsetter: A Bit-serial DNN Accelerator with Weight-offset MAC for Bit-wise Sparsity Exploitation","S. He; H. Zhang; M. Li; H. Zhu; C. Chen; Q. Liu; X. Zeng","State Key Laboratory of Integrated Chips and Systems, Frontier Institute of Chip and System, Fudan University, Shanghai, China; State Key Laboratory of Integrated Chips and Systems, Frontier Institute of Chip and System, Fudan University, Shanghai, China; State Key Laboratory of Integrated Chips and Systems, Frontier Institute of Chip and System, Fudan University, Shanghai, China; State Key Laboratory of Integrated Chips and Systems, Frontier Institute of Chip and System, Fudan University, Shanghai, China; State Key Laboratory of Integrated Chips and Systems, Frontier Institute of Chip and System, Fudan University, Shanghai, China; State Key Laboratory of Integrated Chips and Systems, Frontier Institute of Chip and System, Fudan University, Shanghai, China; State Key Laboratory of Integrated Chips and Systems, Frontier Institute of Chip and System, Fudan University, Shanghai, China",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","With the rapid evolution of deep neural networks (DNNs), the massive computational burden brings about the difficulty of deploying DNN on edge devices. This situation gives rise to specialized hardware aiming at exploiting the sparsity of DNN parameters. Bit-serial architectures (BSAs) possess great performance potential by leveraging the abundant bit-wise sparsity. However, the distribution of effective bits of weights confines the performance of BSA designs. To improve the efficiency of BSA, we propose a weight-offset multiply-accumulation (MAC) scheme and an associated hardware design called Bit-offsetter in this paper. Weight-offsetting not only significantly boosts bit-wise sparsity but also brings out a more balanced distribution of essential bits. For Bit-offsetter, aside from leveraging the abundant bitwise sparsity induced by weight-offsetting, it’s also equipped with a load-balancing scheduler to reduce idle cycles and mitigate utilization degradation. According to our experiment on a series of DNN models, weight-offsetting can increase bit-wise sparsity for pre-trained weight up to 77.4% on average. The weight-offset MAC scheme associated with Bit-offsetter achieves 3.28×/2.94× speedup/energy efficiency over the baseline.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168618","Chinese Academy of Sciences; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168618","neural network accelerator;bit-serial architecture;multiply-accumulator;sparsity","Performance evaluation;Degradation;Deep learning;Circuits and systems;Neural networks;Computer architecture;Hardware","","","","19","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"A 40nm area-efficient Effective-bit-combination-based DNN accelerator with the reconfigurable multiplier","Y. Zheng; Z. Li; K. Sun; K. -P. Lee; K. -T. Tang","Department of Electrical Engineering, National Tsing Hua University, Hsinchu, Taiwan; Department of Electrical Engineering, National Tsing Hua University, Hsinchu, Taiwan; Department of Electrical Engineering, National Tsing Hua University, Hsinchu, Taiwan; Department of Electrical Engineering, National Tsing Hua University, Hsinchu, Taiwan; Department of Electrical Engineering, National Tsing Hua University, Hsinchu, Taiwan",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Deep neural networks (DNNs) are widely used in various tasks, such as image classification and speech recognition. When deploying DNN to the edge device, the inputs and weights are usually quantized. And there are obvious patterns in the data distribution. Most data have numerous redundant bits, which reduce the utilization rate of computation resources. We proposed an area-efficient DNN accelerator with an effective bit combination mechanism and a reconfigurable multiplier. Based on the modified Baugh-Wooly multiplier, we proposed a multiplier that can process two 4-bit multiplication operations in one cycle, consuming only 1.57 times the area and 2.31 times the power consumption of a traditional multiplier. Based on the data distribution in DNN, we propose a gating approach for the weights of 0, -1, and 1, resulting in a 34.96% reduction in power consumption. The normalized area efficiency of the proposed DNN accelerator using 40nm CMOS technology is 1.11 to 4.90 times higher than previous works [4] - [7].","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168550","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168550","DNN accelerator;Effective Bit Combination Mechanism;multiplier;area-efficient","Deep learning;Power demand;Circuits and systems;Image edge detection;Neural networks;Speech recognition;Computational efficiency","","","","7","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Low-Power Convolutional Neural Network Accelerator on FPGA","K. Khalil; A. Kumar; M. Bayoumi","Department of Electrical and Computer Engineering, University of Mississippi, Mississippi, USA; The Center for Advanced Computer Studies, University of Louisiana at Lafayette, LA, USA; Department of Electrical and Computer Engineering, University of Louisiana at Lafayette, LA, USA",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Convolutional Neural Network (CNN) accelerator is highly beneficial for mobile and resource-constrained devices. One of the research challenges is to design a power-economic accelerator. This paper proposes a CNN accelerator with low power consumption and acceptable performance. The proposed method uses pipelining between the used kernels for the convolution process and a shared multiplication and accumulation block. The available kernels work consequently while each one performs a different operation in sequence. The proposed method utilizes a series of operations between the kernels and memory weights to speed up the convolution process. The proposed accelerator is implemented using VHDL and FPGA Altera Arria 10 GX. The results show that the proposed method achieves 26.37 GOPS/W of energy consumption, which is lower than the existing method, with acceptable resource usage and performance. The proposed method is ideally suited for small and constrained devices.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168646","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168646","Convolutional neural network;CNN accelerator;FPGA;low-power","Performance evaluation;Energy consumption;VHDL;Power demand;Convolution;Simulation;Convolutional neural networks","","6","","25","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Group Vectored Absolute-Value-Subtraction Cell Array for the Efficient Acceleration of AdderNet","J. Chen; W. Hu; W. Ma; Z. Zhang; M. Huang","Chinese Academy of Sciences, Shenzhen Institute of Advanced Technology, Shenzhen, China; Chinese Academy of Sciences, Shenzhen Institute of Advanced Technology, Shenzhen, China; Chinese Academy of Sciences, Shenzhen Institute of Advanced Technology, Shenzhen, China; Chinese Academy of Sciences, Shenzhen Institute of Advanced Technology, Shenzhen, China; Chinese Academy of Sciences, Shenzhen Institute of Advanced Technology, Shenzhen, China",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Convolutional neural networks (CNN) have been widely used for boosting the performance of Artificial Intelligence (AI) tasks. However, the CNN models are usually computational intensive. Recently, the novel absolute-value-subtraction (ABS) operation based CNN, namely the AdderNet is proposed to reduce the computation complexity and energy burden. But the specific hardware design has rarely been explored. In this work, we propose an energy-efficient AdderNet accelerator to address such issue. At the hardware architecture level, we develop a flexible and group vectored systolic array to balance the circuit area, power, and speed. Thanks to the low delay of ABS operation, the systolic array can reach extremely high frequency up to 2GHz. Meanwhile the power- and area- efficiency exhibits about 3× improvement compared with its CNN counterpart. At the processing element level, we propose new ABS cell based on algorithm optimization, which shows about 10% higher performance than the naive design. Finally, the accelerator is practically deployed on FPGA platform to accelerate the AdderNet ResNet-18 network as a case study. The peak throughput is 424.2 GOP/s, which is much higher than previous works.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168637","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168637","Neural Network;AdderNet;CNN Accelerator;Energy-Efficient Computing","Microprocessors;Computer architecture;Throughput;Systolic arrays;Energy efficiency;Hardware;Delays","","","","25","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Configurable Multi-Precision Floating-Point Multiplier Architecture Design for Computation in Deep Learning","P. -H. Kuo; Y. -H. Huang; J. -D. Huang","Department of Electronics and Electrical Engineering & Institute of Electronics, National Yang Ming Chiao Tung University, Hsinchu, Taiwan; Department of Electronics and Electrical Engineering & Institute of Electronics, National Yang Ming Chiao Tung University, Hsinchu, Taiwan; Department of Electronics and Electrical Engineering & Institute of Electronics, National Yang Ming Chiao Tung University, Hsinchu, Taiwan",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","The increasing AI applications demands efficient computing capabilities to support a huge amount of calculations. Among the related arithmetic operations, multiplication is an indispensable part in most of deep learning applications. To support computing in different precisions demanded by various applications, it is essential for a multiplier architecture to meet the multi-precision demand while still achieving high utilization of the multiplication array and power efficiency. In this paper, a configurable multi-precision FP multiplier architecture with minimized redundant bits is presented. It can execute 16× FP8 operations, or 8× brain-floating-point (BF16) operations, or 4× half-precision (FP16) operations, or 1× single-precision (FP32) operation every cycle while maintaining a 100% multiplication hardware utilization ratio. Moreover, the computing results can also be represented in higher precision formats for succeeding high-precision computations. The proposed design has been implemented using the TSMC 40nm process with 1GHz clock frequency and consumes only 16.78mW on average. Compared to existing multi-precision FP multiplier architectures, the proposed design achieves the highest hardware utilization ratio with only 4.9K logic gates in the multiplication array. It also achieves high energy efficiencies of 1212.1, 509.6, 207.3, and 42.6 GFLOPS/W at FP8, BF16, FP16 and FP32 modes, respectively.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168572","National Science and Technology Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168572","floating-point multiplier design;configurable;multi-precision computation;deep learning","Deep learning;Pipelines;Computer architecture;Learning (artificial intelligence);Logic gates;Throughput;Hardware","","5","","18","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"GPIL: Gradient with PseudoInverse Learning for High Accuracy Fine-Tuning","G. Lee; N. J. Kim; H. Kim","Department of Electrical and Information Engineering, Research Center for Electrical and Information Technology, Seoul National University of Science and Technology, Seoul, Korea; Department of Electrical and Information Engineering, Research Center for Electrical and Information Technology, Seoul National University of Science and Technology, Seoul, Korea; Department of Electrical and Information Engineering, Research Center for Electrical and Information Technology, Seoul National University of Science and Technology, Seoul, Korea",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","PseudoInverse learning (PIL) is proposed to increase the convergence speed of conventional gradient descent. PIL can be trained with fast and reliable convolutional neural networks (CNNs) without a gradient using a pseudoinverse matrix. However, PIL has several problems when training a network. First, there is an out-of-memory problem because all batches are required during one epoch of training. Second, the network cannot be deeper because more unreliable input pseudoinverse matrices are used as the deeper PIL layer is stacked. Therefore, PIL has not yet been effectively applied to widely used deep models. Inspired by the limitation of the existing PIL, we propose a novel error propagation methodology that allows the fine-tuning process, which is often used in a resource-constrained environment, to be performed more accurately. In detail, by using both PIL and gradient descent, we not only enable mini-batch training, which was impossible in PIL, but also achieve higher accuracy through more accurate error propagation. Moreover, unlike the existing PIL, which uses only the pseudoinverse matrix of the CNN input, we additionally use the pseudoinverse matrix of weights to compensate for the limitations of PIL; thus, the proposed method enables faster and more accurate error propagation in the CNN training process. As a result, it is efficient for fine-tuning in resource-constrained environments, such as mobile/edge devices that require an accuracy comparable to small training epochs. Experimental results show that the proposed method improves the accuracy after ResNet-101 fine-tuning on the CIFAR-100 dataset by 2.78% compared to the baseline.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168584","National Research Foundation of Korea; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168584","Convolutional neural network;Pseudoinverse Learning;Fine-tuning;Gradient descent","Training;Performance evaluation;Privacy;Circuits and systems;Energy efficiency;Convolutional neural networks;Integrated circuit reliability","","","","26","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"SLIM-Net: Rethinking how neural networks use systolic arrays","T. Dalgaty; M. Lepecq","CEA, List, Univ. Grenoble-Alpes, Grenoble, France; CEA, List, Univ. Paris-Saclay, Gif-sur-Yvette, France",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Systolic arrays of processing elements are widely used to massively parallelise neural network layers. However, the execution of traditional convolutional and fully-connected layers on such hardware typically requires a non-negligible latency to distribute data over the array before each operation - data is not immediately in-place. This arises from the fundamental incompatibility between the physical spatial nature of a systolic array and the un-physical form of existing neural networks. We propose the systolic lateral mixer network (SLIM-Net) in an effort to reconcile this mismatch. The architecture of SLIM-Net maps directly onto the physical structure of a systolic array such that, after evaluating one layer, data immediately finds itself where it needs to be to begin the next. To evaluate the potential of SLIM-Net we compare it to a UNet model on a COCO segmentation task and find that, for models of equivalent size, SLIM-Net not only achieves a slightly better performance but requires almost an order of magnitude fewer MAC operations. Furthermore, we implement a lateral mixing layer on a systolic smart imager chip which executes seven times faster than similar convolutional layers on the same hardware and provides encouraging initial insights into the practicality of this new neuromorphic approach.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168580","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168580","Neural networks;Neuromorphic;Smart imagers","Neuromorphics;Neural networks;Benchmark testing;Transformers;Systolic arrays;Hardware;Arrays","","","","25","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Online Spatio-Temporal Learning with Target Projection","T. Ortner; L. Pes; J. Gentinetta; C. Frenkel; A. Pantazi","IBM Research – Zurich; IBM Research – Zurich; IBM Research – Zurich; Microelectronics Department, Delft University of Technology, Delft, The Netherlands; IBM Research – Zurich",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Recurrent neural networks trained with the backpropagation through time (BPTT) algorithm have led to astounding successes in various temporal tasks. However, BPTT introduces severe limitations, such as the requirement to propagate information backwards through time, the weight symmetry requirement, as well as update-locking in space and time. These problems become roadblocks for AI systems where online training capabilities are vital. Recently, researchers have developed biologically-inspired training algorithms, addressing a subset of those problems. In this work, we propose a novel learning algorithm called online spatio-temporal learning with target projection (OSTTP) that resolves all aforementioned issues of BPTT. In particular, OSTTP equips a network with the capability to simultaneously process and learn from new incoming data, alleviating the weight symmetry and update-locking problems. We evaluate OSTTP on two temporal tasks, showcasing competitive performance compared to BPTT. Moreover, we present a proof-of-concept implementation of OSTTP on a memristive neuromorphic hardware system, demonstrating its versatility and applicability to resource-constrained AI devices.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168623","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168623","Online learning;bio-inspired training;neuromorphic hardware;update locking;phase-change memory","Training;Performance evaluation;Backpropagation;Recurrent neural networks;Neuromorphics;Circuits and systems;Learning (artificial intelligence)","","1","","25","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"LG-LSQ: Learned Gradient Linear Symmetric Quantization for Low-Precision Integer Hardware","S. -T. Lin; Z. Li; Y. -H. Cheng; H. -W. Kuo; R. -H. Wang; N. -J. Sung; C. -C. Lu; K. -T. Tang","Department of Electrical Engineering, National Tsing Hua University, Hsinchu, Taiwan; Department of Electrical Engineering, National Tsing Hua University, Hsinchu, Taiwan; Department of Electrical Engineering, National Tsing Hua University, Hsinchu, Taiwan; Department of Electrical Engineering, National Tsing Hua University, Hsinchu, Taiwan; Department of Electrical Engineering, National Tsing Hua University, Hsinchu, Taiwan; Department of Electrical Engineering, National Tsing Hua University, Hsinchu, Taiwan; Information and Communication Labs, Industrial Technology Research Institute, Hsinchu, Taiwan; Department of Electrical Engineering, National Tsing Hua University, Hsinchu, Taiwan",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","To design a deep learning accelerator hardware in edge devices, lower precision weights and activation have advantages regarding area and power. We propose learned gradient linear symmetric quantization (LG-LSQ) as a method for quantizing weights and activation functions to low bit-widths with high accuracy and an integer-only accelerator as hardware for LG-LSQ. First, we introduce the scaling simulated gradient (SSG) method for determining the appropriate gradient for the scaling factor of the linear quantizer during the training process. Second, we introduce the arctangent soft round (ASR) method, which differs from the straight-through estimator (STE) method in its ability to prevent the gradient from becoming zero, thereby solving the discrete problem caused by the rounding process. Finally, to bridge the gap between full-precision and low-bit quantization networks, we propose the minimize discretization error (MDE) method to determine an accurate gradient in backpropagation. In our evaluation on ImageNet, the proposed quantizer achieved full-precision baseline accuracy in various 3-bit networks, including ResNet18, ResNet34, and ResNet50, and an accuracy drop of less than 1% in the quantization of 4-bit weights and 4-bit activations in lightweight models such as MobileNetV2 and ShuffleNetV2.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168649","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168649","Model Compression;Quantization;Machine Learning","Training;Deep learning;Quantization (signal);Image coding;Circuits and systems;Learning (artificial intelligence);Integrated circuit modeling","","3","","28","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"HNSG – A SNN Training Method Ultilizing Hidden Network","C. Wu; W. Fang; Y. Kang","University of Science and Technology of China, Hefei City, China; University of Science and Technology of China, Hefei City, China; University of Science and Technology of China, Hefei City, China",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Spiking Neural Network is more energy efficient compared to traditional ANNs, and many training methods of SNNs have been proposed in past decades. However, traditional backward-propagation based training methods are difficult to deploy on SNN due to its discontinuous gradient. Previous works mainly focused on weight training or weight transferring. The Hidden Network inspired by Lottery Ticket Hypothesis that is proposed for convolutional neural networks opens possibility of network connection training on SNN. In this article, a training algorithm based on Hidden Network is applied to SNN to show its potential on neuromorphic spiking networks. A novel training method called HNSG is proposed that modifies hidden network search using surrogate gradient function based back propagation. The proposed HNSG method is tested on image classification task using MNIST with simple two fully-connected layer SNN model. Simulation shows HNSG reaches 93.73% accuracy on average fire intensity of 0.138 with LIF neuron.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168579","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168579","SNN training;hidden network;surrogate gradient","Training;Backpropagation;Neuromorphics;Neurons;Energy efficiency;Classification algorithms;Convolutional neural networks","","","","18","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"CSwin2SR: Circular Swin2SR for Compressed Image Super-Resolution","H. Li; M. Trocan; M. Sawan; D. Galayko","College of Information Engineering, Yanghzou University, Yangzhou, China; LISITE Research Laboratory, Institut Supérieur d'Électronique de Paris, Paris, France; College of Engineerig, Westlake University, Hangzhou, China; Laboratoire d'Informatique de Paris 6, Sorbonne University, Paris, France",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Closed-loop negative feedback mechanism is extensively utilized in automatic control systems and brings about extraordinary dynamic and static performance. In order to further improve the reconstruction capability of current methods of compressed image super-resolution, a circular Swin2SR (CSwin2SR) approach is proposed. The CSwin2SR contains a serial Swin2SR for initial super-resolution reestablishment and circular Swin2SR for enhanced super-resolution reestablishment. Simulated experimental results show that the proposed CSwin2SR dramatically outperforms the classical Swin2SR in the capacity of super-resolution recovery. On DIV2K valid dataset, the average increment of PSNR is greater than 0.18 dB and the related average increment of SSIM is greater than 0.004.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168621","Google; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168621","closed-loop;negative feedback;Swin2SR;CSwin2SR;compressed image;super-resolution","Image coding;Negative feedback;Circuits and systems;Superresolution;Hardware;Artificial intelligence;Image reconstruction","","3","","10","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Efficiency Comparison of Machine Learning Algorithms for EEG Interpretation","X. Han; F. Amiel; X. Zhang; K. Wei; C. Yan; W. Hu; Z. Wang","LISIT-ECoS, Institut Supérieur D’électronique de Paris, Paris, France; LISIT-ECoS, Institut Supérieur D’électronique de Paris, Paris, France; LISIT-ECoS, Institut Supérieur D’électronique de Paris, Paris, France; The School of Life Sciences, Beijing University of Chinese Medicine, Beijing, China; The School of Life Sciences, Beijing University of Chinese Medicine, Beijing, China; The School of Information Engineering, Huzhou University, Huzhou, China; The School of Information Engineering, Huzhou University, Huzhou, China",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","This paper intends to use a small protocol to detect stroke disease on a patient by using signals provided by only three EEG probes. To achieve this objective, we compare the performances in terms of accuracy and time of six machine learning (ML) algorithms (Random Forest, Logistic Regression, Support Vector Machine, K-Nearest Neighbor, Decision Tree and CatBoost) during a process of EEG-based classification pathology. We use a database of EEG recording signals collected by three electrodes, established by Beijing University of Chinese Medicine and carried out on subjects healthy or affected by strokes when they are exposed to the vision of planes of five different colors. The subjects are known to be healthy or affected by strokes. The records are used to train each algorithm for 70% of the population, and the performances are estimated on the remaining 30%. Then the process is repeated one hundred times when changing the set used for training and the set used to test. We then consider a statistic on the results obtained using each method for comparison. Our results show that the SVM algorithm is the most efficient in terms of the accuracy of the results, and can detect stoke disease with a reliability of 70%.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168626","China Scholarship Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168626","Machine Learning;EEG;stroke EEG classification;algorithm performance","Training;Support vector machines;Electrodes;Machine learning algorithms;Protocols;Image color analysis;Electroencephalography","","1","","28","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"A High Performance Accelerating CNN Inference on FPGA with Arrhythmia Classification","M. -Y. Ku; T. -S. Zhong; Y. -T. Hsieh; S. -Y. Lee; J. -Y. Chen","Department of Electrical Engineering, National Cheng-Kung University, Tainan, Taiwan; Department of Electrical Engineering, National Cheng-Kung University, Tainan, Taiwan; Department of Electrical Engineering, National Cheng-Kung University, Tainan, Taiwan; Department of Electrical Engineering, National Cheng-Kung University, Tainan, Taiwan; Department of Internal Medicine, National Cheng Kung University Hospital, Taiwan",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","4","A high-performance artificial intelligence accelerator (AIA) for arrhythmia classification on electrocardiography (ECG) is presented in this paper, which proposes an efficient one-dimensional convolutional neural network (1DCNN) with novel multiplicative behavioral and data reuse. The convolutional layer uses weight stationary (WS) to achieve low memory access on tensor-tensor multiplication (TTM) operations and the fully connected layer uses input stationary (IS) to achieve low memory access on inner product matrix-vector multiplication (IPMVM). The lab database and MIT-BIH arrhythmia database are selected to verify the proposed algorithm. The accuracy of software simulation classification on two databases is 97.3% and 98.3%, respectively. Combined with the hardware implementation of quantization and pruned with the architecture of parallel shift processing element array arrangement (PSPEAA) proposed in this work, the accuracies are 96.6% and 96.5%, respectively. The hardware is implemented on Xilinx PYNQ-Z2, and it takes only 0.233 ms operated at 10 MHz and consumes 0.131 W to classify arrhythmia. Finally, according to the proposed technology, the time of memory access is optimized by 29 times and latency is optimized by 22.5 times compared to using a single multiply-accumulate (MAC). Therefore, the proposed architecture can achieve real-time low-power consumption and high-accuracy arrhythmia classification.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168615","Ministry of Science and Technology; National Science and Technology Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168615","Electrocardiography;convolution neural network;edge computing;artificial intelligence accelerator;tensor-tensor multiplication;inner product matrix-vector multiplication;parallel shift processing element array arrangement;arrhythmia database.","Quantization (signal);Databases;Arrhythmia;Computer architecture;Electrocardiography;Parallel processing;Hardware","","2","","7","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Hardware-Friendly Activation Function Designs and Its Efficient VLSI Implementations for Transformer-Based Applications","Y. -H. Huang; P. -H. Kuo; J. -D. Huang","Department of Electronics and Electrical Engineering, Institute of Electronics National Yang Ming Chiao Tung University, Hsinchu, Taiwan; Department of Electronics and Electrical Engineering, Institute of Electronics National Yang Ming Chiao Tung University, Hsinchu, Taiwan; Department of Electronics and Electrical Engineering, Institute of Electronics National Yang Ming Chiao Tung University, Hsinchu, Taiwan",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","The activation function is one of key elements in modern machine learning algorithms. However, some broadly-used activation functions are exceptionally complex, e.g., GELU in Transformer-based algorithms, which makes their precise yet efficient VLSI implementations extremely hard. In this paper, two series of hardware-friendly activation function designs, DNR and PWL, and their VLSI implementations are proposed. Both are specifically designed to replace GELU, which is widely used in Transformer-related applications. Instead of utilizing traditional lookup-table (LUT)-based approximation methods, this paper introduces new activation functions that are not only hardware-friendly but successfully alleviate the dying neuron issue. Besides, each series includes a number of members, which can be freely selected through programming to best fit a given application. Experimental results indicate that the proposed new activation functions achieve comparable or even better model accuracy as compared to GELU. Moreover, the highly efficient and flexible VLSI implementations support 16 different Q-formats to maximize the output precision under various input scales. Compared with approximation-based implementation strategies, the proposed activation function designs and the corresponding LUT-free hardware implementations do achieve a significant improvement in speed, area, and power.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168591","National Science and Technology Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168591","hardware-friendly activation function design;GELU;dying neuron issue;efficient VLSI implementation","Machine learning algorithms;Power demand;Circuits and systems;Neurons;Computer architecture;Very large scale integration;Programming","","1","","21","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"A Memristor-Inspired Computation for Epileptiform Signals in Spheroids","I. D. de los Ríos; J. Wesley Ephraim; G. Palazzolo; T. Serrano-Gotarredona; G. Panuccio; B. Linares-Barranco","Instituto de Microelectrónica de Sevilla (IMSE-CNM), CSIC and Univ. de Sevilla, Sevilla, SPAIN; Istituto Italiano di Tecnologia (IIT), Genoa, Italy; Istituto Italiano di Tecnologia (IIT), Genoa, Italy; Instituto de Microelectrónica de Sevilla (IMSE-CNM), CSIC and Univ. de Sevilla, Sevilla, SPAIN; Istituto Italiano di Tecnologia (IIT), Genoa, Italy; Instituto de Microelectrónica de Sevilla (IMSE-CNM), CSIC and Univ. de Sevilla, Sevilla, SPAIN",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","In this paper we present a memristor-inspired computational method for obtaining a type of running ""spectrogram"" or ""fingerprint"" of epileptiform activity generated by rodent hippocampal spheroids. It can be used to compute on the fly and with low computational cost an alert-level signal for epileptiform events onset. Here, we describe the computational method behind this ""fingerprint"" technique and illustrate it using epileptiform events recorded from hippocampal spheroids using a microelectrode array system.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168611","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168611","Regenerative medicine;biohybrid neuromorphic systems;epileptic signals;spiking neural networks;memristors.","Microelectrodes;Neuromorphics;Circuits and systems;Rodents;Fingerprint recognition;Computational efficiency;Artificial intelligence","","","","25","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"SALSA: Simulated Annealing based Loop-Ordering Scheduler for DNN Accelerators","V. J. B. Jung; A. Symons; L. Mei; M. Verhelst; L. Benini","Integrated Systems Laboratory, ETH, Zürich, Switzerland; Department of Electrical Engineering, KU, Leuven, Belgium; Department of Electrical Engineering, KU, Leuven, Belgium; Department of Electrical Engineering, KU, Leuven, Belgium; Integrated Systems Laboratory, ETH, Zürich, Switzerland",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","To meet the growing need for computational power for DNNs, multiple specialized hardware architectures have been proposed. Each DNN layer should be mapped onto the hardware with the most efficient schedule, however, SotA schedulers struggle to consistently provide optimum schedules in a reasonable time across all DNN-HW combinations.This paper proposes SALSA, a fast dual-engine scheduler to generate optimal execution schedules for both even and uneven mapping. We introduce a new strategy, combining exhaustive search with simulated annealing to address the dynamic nature of the loop ordering design space size across layers. SALSA is extensively benchmarked against two SotA schedulers, LOMA [1] and Timeloop [2] on 5 different DNNs, on average SALSA finds schedules with 11.9% and 7.6% lower energy while speeding-up the search by 1.7× and 24× compared to LOMA and Timeloop, respectively.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168625","Horizon Europe; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168625","DNN;accelerator;scheduling;energy-efficiency;combinatorial optimization;simulated annealing","Measurement;Schedules;Annealing;Circuits and systems;Simulated annealing;Optimal scheduling;Benchmark testing","","1","","17","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Simulation-driven Latency Estimations for Multi-core Machine Learning Accelerators","Y. Braatz; D. S. Rieber; T. Soliman; O. Bringmann","Robert Bosch Corporate Research, Renningen, Germany; Robert Bosch Corporate Research, Renningen, Germany; Robert Bosch Corporate Research, Renningen, Germany; Eberhard Karls Universität Tübingen, Tübingen, Germany",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Underutilization of compute resources leads to decreased performance of single-core machine learning (ML) accelerators. Therefore, multi-core accelerators divide the computational load among multiple smaller groups of processing elements (PEs), keeping more resources active in parallel. However, while producing higher throughput, the accelerator behavior becomes more complex. Supplying multiple cores with data demands adjustments to the on-chip memory hierarchy and direct memory access controller (DMAC) programming. Correctly estimating these effects becomes crucial for optimizing multi-core accelerators, especially in design space exploration (DSE). This work introduces a novel semi-simulated prediction methodology for latency estimations in multi-core ML accelerators. Simulating only dynamic system interactions while determining the latency of isolated accelerator elements analytically makes the proposed methodology precise and fast. We evaluate our methodology on an in-house configurable accelerator with various computational cores on two widely used convolutional neural networks (CNNs). We can estimate the accelerator latency with an average error of 4.7%.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168589","Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168589","multi-core machine learning accelerators;latency estimations;simulation","Analytical models;Multicore processing;Computational modeling;Machine learning;Computer architecture;Throughput;System-on-chip","","","","19","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"A Systolic Array with Activation Stationary Dataflow for Deep Fully-Connected Networks","H. Wan; C. Rao; Y. Zheng; P. Zhou; X. Lou","School of Information Science and Technology, ShanghaiTech University, Shanghai, China; School of Information Science and Technology, ShanghaiTech University, Shanghai, China; School of Information Science and Technology, ShanghaiTech University, Shanghai, China; School of Information Science and Technology, ShanghaiTech University, Shanghai, China; School of Information Science and Technology, ShanghaiTech University, Shanghai, China",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","This paper presents an activation stationary (AS) dataflow suitable for networks with pure fully-connected (FC) layers. It is shown that the proposed AS dataflow can help to reduce the required memory size in hardware design and optimize energy efficiency by reducing data movement. Based on the AS dataflow, an output stationary (OS) systolic array is proposed to compute FC networks. To evaluate the proposed design, we further implement an accelerator for the FC-based implicit representation for MRI (IREM) algorithm. A proofof-concept demonstration system is developed based on field programmable gate array (FPGA). To evaluate the proposed design, We also map the IREM accelerator to 40nm CMOS technology and compare it with CPU, GPU-based and ASIC implementations.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168602","Shanghai Rising-Star Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168602","Fully-Connected (FC) network;Activation stationary;Systolic array;Hardware accelerator","Industries;Magnetic resonance imaging;Memory management;Logic gates;CMOS technology;Systolic arrays;Silicon","","","","16","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"TPE: A High-Performance Edge-Device Inference with Multi-level Transformational Mechanism","Z. Wang; J. Wei; X. Tang; B. Han; H. He; L. Liu; S. Wei; S. Yin","School of Integrated Circuits, Tsinghua University, Beijing, China; School of Integrated Circuits, Tsinghua University, Beijing, China; Beijing Wisemay Tech Co., Ltd, Beijing, China; China Mobile Research Institute, Beijing, China; China Mobile Research Institute, Beijing, China; School of Integrated Circuits, Tsinghua University, Beijing, China; School of Integrated Circuits, Tsinghua University, Beijing, China; School of Integrated Circuits, Tsinghua University, Beijing, China",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","DNN inference of edge devices has been very important for a long time with large computing and energy consumption demand. This paper proposes a TPE(Transformation Process Element) with three characteristics. Firstly, TPE has a method of Data Segmentation Skip and Pre-Reorganization(DSSPR). Secondly, TPE has a Typical Value Matching and Calibration Computer (TVMCC) system, which converts direct calculation into matching and calibration calculation. Thirdly, TPE includes a Data Format Pre-Configuration and Self-Adjustment (DFPCSA) scheme. Compared with the most typical pure reasoning processor UNPU, TPE achieves 1.25× better energy consumption.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168614","Research and Development; Tsinghua University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168614","DNN Inference;Transformational Mechanism;Processor;Edge-devices","Energy consumption;Circuits and systems;Random access memory;Transforms;Cognition;Calibration;Artificial intelligence","","2","","12","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"A Hardware-Centric Approach to Increase and Prune Regular Activation Sparsity in CNNs","T. Hotfilter; J. Hoefer; F. Kreß; F. Kempf; L. Kraft; T. Harbaum; J. Becker",Karlsruhe Institute of Technology (KIT); Karlsruhe Institute of Technology (KIT); Karlsruhe Institute of Technology (KIT); Karlsruhe Institute of Technology (KIT); Karlsruhe Institute of Technology (KIT); Karlsruhe Institute of Technology (KIT); Karlsruhe Institute of Technology (KIT),2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","A key challenge in computing convolutional neural networks (CNNs) besides the vast number of computations are the associated numerous energy-intensive transactions from main to local memory. In this paper, we present our methodical approach to maximize and prune coarse-grained regular blockwise sparsity in activation feature maps during CNN inference on dedicated dataflow architectures. Regular sparsity that fits the target accelerator, e.g., a systolic array or vector processor, allows simplified and resource inexpensive pruning compared to irregular sparsity, saving memory transactions and computations. Our threshold-based technique allows maximizing the number of regular sparse blocks in each layer. The wide range of threshold combinations that result from the close correlation between the number of sparse blocks and network accuracy can be explored automatically by our exploration tool Spex. To harness found sparse blocks for memory transaction and MAC operation reduction, we also propose Sparse-Blox, a low-overhead hardware extension for common neural network hardware accelerators. Sparse-Blox adds up to 5× less area than state-of-the-art accelerator extensions that operate on irregular sparsity. Evaluation of our blockwise pruning method with Spex on ResNet-50 and Yolo-v5s shows a reduction of up to 18.9% and 12.6% memory transfers, and 802 M (19.0%) and 1.5 G (24.3%) MAC operations with a 1% or 1 mAP accuracy drop, respectively.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168566","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168566","structured activation pruning;sparse DNNs","Neural network hardware;Correlation;Circuits and systems;Computer architecture;Systolic arrays;Hardware;Convolutional neural networks","","1","","19","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"An Integrated CPU-GPU Frequency Scaling Governor Based on Deep Recurrent Q-Network for Partially Observable Rendering Applications","Q. Zhou; Y. Zhao; W. Zhang","School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Dynamic voltage and frequency scaling (DVFS) is an effective approach to balance the performance and power consumption of the CPU-GPU-based video rendering applications. Operating System (OS) based DVFS governors are general in nature and thus lack of regulation effectiveness for workload with different characteristics. Reinforcement learning (RL) enhances power management ability for application-specific DVFS, whereas the regulation robustness is limited due to partial observability of complex SoCs. To mitigate this issue, in this paper, a deep recurrent Q-Network (DRQN) based DVFS governor for rendering applications is proposed where a recurrent neural network (RNN) exploiting historical information is embedded in a Deep Q-Network (DQN). Evaluated on the Nvidia Jetson NX platform with various settings, the proposed DRQN policy achieves an up to ×2.11 improvement in Valid Performance Per Watt (VPPW) compared with Linux default governors and shows superior regulation stability compared with other RL-based state-of-the-art.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168668","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168668","DVFS;Power Management;Partial Observability;DRQN;Multimedia","Recurrent neural networks;Power demand;Power system management;Operating systems;Linux;Reinforcement learning;Rendering (computer graphics)","","2","","16","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"A Byte Sequence is Worth an Image: CNN for File Fragment Classification Using Bit Shift and n-Gram Embeddings","W. Liu; Y. Wang; K. Wu; K. -H. Yap; L. -P. Chau","School of Electrical and Electronics Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronics Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronics Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronics Engineering, Nanyang Technological University, Singapore; Dept. of Electronic and Information Engineering, The Hong Kong Polytechnic University, Hong Kong",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","File fragment classification (FFC) on small chunks of memory is essential in memory forensics and Internet security. Existing methods mainly treat file fragments as 1d byte signals and utilize the captured inter-byte features for classification, while the bit information within bytes, i.e., intra-byte information, is seldom considered. This is inherently inapt for classifying variable-length coding files whose symbols are represented as the variable number of bits. Conversely, we propose Byte2Image, a novel data augmentation technique, to introduce the neglected intra-byte information into file fragments and re-treat them as 2d gray-scale images, which allows us to capture both inter-byte and intra-byte correlations simultaneously through powerful convolutional neural networks (CNNs). Specifically, to convert file fragments to 2d images, we employ a sliding byte window to expose the neglected intra-byte information and stack their n-gram features row by row. We further propose a byte sequence & image fusion network as a classifier, which can jointly model the raw 1d byte sequence and the converted 2d image to perform FFC. Experiments on FFT-75 dataset validate that our proposed method can achieve notable accuracy improvements over state-of-the-art methods in nearly all scenarios. The code will be released at https://github.com/wenyang001/Byte2Image.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168636","National Research Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168636","CNN;file fragment classification;byte2image;memory forensics","Correlation;Codes;Forensics;Internet security;Symbols;Gray-scale;Data augmentation","","5","","19","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Deep-learning-based X-ray CT Slice Analysis for Layout Verification in Printed Circuit Boards","D. Cheng; Y. Shi; Y. -Y. Tee; J. Song; X. Wang; B. Wen; B. -H. Gwee","School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","3D X-ray Computational Tomography (CT) systems have been employed to inspect Printed Circuit Boards (PCB) for security analysis, considering the heightened trustworthiness concern on the globalized supply chain. In this paper, we propose a deep-learning-based layout verification (DELVer) framework to automatically extract PCB layout information from X-ray CT slices and verify against the design files. Leveraging on geometrical projective transformation, our proposed DELVer framework aligns the acquired CT slice of each PCB layer with their corresponding design file, to train state-of-the-art deep learning models for layout extraction and verification. It thus alleviates the laborious manual data labeling for deep learning models. With a cross-device evaluation on 4 multi-layer satellite PCBs of board size around 90 cm2, our proposed DELVer framework demonstrates how deep learning models can generalize to unseen target PCBs for layout verification, establishing an efficient solution for PCB assurance and industrial failure analysis.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168608","National Research Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168608","Printed circuit boards;hardware security;X-ray computed tomography;deep learning","Deep learning;Three-dimensional displays;Computed tomography;Layout;Printed circuits;Failure analysis;Manuals","","1","","16","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Multi-Head Attention based Bi-LSTM for Anomaly Detection in Multivariate Time-Series of WSN","M. Matar; T. Xia; K. Huguenard; D. Huston; S. Wshah","University of Vermont, Burlington, VT, USA; University of Vermont, Burlington, VT, USA; University of Maine, Orono, ME, USA; University of Vermont, Burlington, VT, USA; University of Vermont, Burlington, VT, USA",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Anomaly detection is a widely utilized technique in the field of wireless sensor networks (WSNs) data stream analysis, aimed at identifying unusual events or anomalies in an early stage. However, the constraints of WSN applications pose a significant challenge in achieving effective and efficient anomaly detection. In this work, we proposes a new multi-head attention-based Bi-LSTM approach for anomaly detection in multivariate time-series. Rather than modeling the time series of individual sensor independently, the proposed approach models the time series of multiple sensors concurrently, taking into account potential latent interactions among them, thereby enhancing the accuracy of anomaly detection. The proposed approach does not require labeled data and can be directly applied in real-world scenarios where labeling a large stream of data from heterogeneous sensors is both difficult and time-consuming. Finally, empirical evaluations using a real-world WSN demonstrate effectiveness and robustness of the proposed approach, outperforming traditional deep learning approaches.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168670","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168670","Wireless Sensor Network (WSN);anomaly detection;multivariate time series;outlier detection;deep learning;Bi-LSTM;Multi-Head attention","Deep learning;Wireless sensor networks;Circuits and systems;Time series analysis;Robustness;Labeling;Artificial intelligence","","2","","23","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"PCB Identification Based on Machine Learning Utilizing Power Consumption Variability","A. Golder; A. Raychowdhury","School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","4","Manufacturing variability demonstrates significant variations in dynamic power consumption profiles during program execution, even if the printed circuit boards (PCB) are identical and the processors execute the same operations on the same data. In this work, we show how this variability can be leveraged to the benefit of manufacturers by utilizing machine learning (ML) based PCB identification. The proposed technique based on power consumption variability achieves 100% accuracy in identifying PCBs from their power consumption traces after training a linear discriminant analysis (LDA) classifier on a collection of 30 identical PCBs for two test sets collected several months apart.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168655","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168655","Manufacturing Variation;Power Consumption Variability;Machine Learning;PCB Identification","Training;Power demand;Program processors;Circuits and systems;Printed circuits;Machine learning;Fingerprint recognition","","2","","15","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Performance Assessment of an Extremely Energy-Efficient Binary Neural Network Using Adiabatic Superconductor Devices","O. Chen; Z. Li; T. Yamauchi; Y. Wang; N. Yoshikawa","Dept. Computer Science, Tokyo City University, Tokyo, Japan; Dept. Electrical and Computer Engineering, Northeasetern University, Boston, USA; Grad. Sch. Informative Engineering, Tokyo City University, Tokyo, Japan; Dept. Electrical and Computer Engineering, Northeasetern University, Boston, USA; Dept. Electrical and Computer Engineering, Yokohama National University, Yokohama, Japan",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Binary Neural Networks (BNNs) are gaining popularity for solving real-world problems using Deep Neural Networks (DNNs), such as image recognition and natural language processing. BNNs use binary precision for weights and activations, reducing memory usage by 32 times compared to conventional networks using 32-bit floating-point precision. Among various types of BNNs, AQFP-based BNNs utilizing superconducting logic families are promising for energy-efficient computing, using magnetic flux quantization and quantum interference in Josephson-junction-based superconductor loops. This paper presents a performance assessment of a novel AQFP-based BNN architecture, highlighting scalability issues caused by increased inductance in the analog accumulation circuit. We also discuss potential optimization approaches to address these issues and improve scalability.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168607","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168607","AQFP;BNN;in-memory computing;performance evaluation","Performance evaluation;Inductance;Quantum computing;Quantization (signal);Superconducting logic circuits;Scalability;Computer architecture","","1","","22","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Efficient Parameter Learning of Bayesian Network with Latent Variables from High-Dimensional Data","X. Wu; X. Chen; K. Yue","School of Information Science and Engineering, Yunnan University, Kunming, China; School of Information Science and Engineering, Yunnan University, Kunming, China; School of Information Science and Engineering, Yunnan University, Kunming, China",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Bayesian network with latent variables (BNLV) plays an important role in the representation of dependence relations and inference of uncertain knowledge with unobserved variables. The variables with large cardinalities in high-dimensional data make it challenging to efficiently learn the large-scaled probability parameters as the conditional probability distributions (CPDs) of BNLV. In this paper, we first propose the multinomial parameter network to parameterize the CPDs w.r.t. latent variables. Then, we extend the M-step of the classic EM algorithm and give the efficient algorithm for parameter learning of BNLV. Experimental results show that our proposed method outperforms some state-of-the-art competitors.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168662","National Natural Science Foundation of China; Yunnan University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168662","Bayesian network;Latent variable;Parameter Learning;Multinomial parameter network;EM algorithm","Training;Knowledge engineering;Circuits and systems;Learning (artificial intelligence);Probability distribution;Data models;Bayes methods","","","","17","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Three Challenges in ReRAM-Based Process-In-Memory for Neural Network","Z. Yang; K. Liu; Y. Duan; M. Fan; Q. Zhang; Z. Jin","China University of Petroleum, Beijing, Beijing, China; China University of Petroleum, Beijing, Beijing, China; China University of Petroleum, Beijing, Beijing, China; China University of Petroleum, Beijing, Beijing, China; China University of Petroleum, Beijing, Beijing, China; China University of Petroleum, Beijing, Beijing, China",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Artificial intelligence (AI) has been successfully applied to various fields of natural science. One of the biggest challenges in AI acceleration is the performance and energy bottleneck caused by the limited capacity and bandwidth of massive data movement between memory and processing units. In the past decade, much AI accelerator work based on process-in-memory (PIM) has been studied, especially on emerging non-volatile resistive random access memory (ReRAM). In this paper, we provide a comprehensive perspective on ReRAM-based AI accelerators, including software-hardware co-design, the status of chip fabrications, researches on ReRAM non-idealities, and support for the EDA tool chain. Finally, we summarize and provide three directions for future trends: support for complex patterns of models, addressing the impact of non-idealities such as improving endurance, process perturbations, and leakage current, and addressing the lack of EDA tools.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168640","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168640","Process-In-Memory;Resistive Random Access Memory;AI accelerator","Surveys;Program processors;Nonvolatile memory;Perturbation methods;Resistive RAM;Neural networks;AI accelerators","","1","","40","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Computer-Aided-Prediction of Body Constitution with Efficient Cock-Tail Learning","G. Shi; Y. Kan; R. Zhang","Yunnan University, Kunming, China; School of Information Science, Nara Institute of Science and Technology, Nara, Japan; School of Information Science, Nara Institute of Science and Technology, Nara, Japan",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","In this paper, the clinical data thru the questionnaire of body constitution (BC) is analyzed by multiple efficient machine learning algorithms for wide use in traditional Chinese medicine (TCM). This research aims at precisely categorizing the BCs from the life-style; offering the health guidance on the life-styles for recovering the so-called ""biased"" BCs to the healthy status known as the ""Gentle BC"". The key features of life-style are identified by machine learning (ML). However, the conventional sole ML algorithm for such application, known as random forest (RF), partial least squares (PLS), or least absolute shrinkage and selection operator (LASSO) hardly offers a small set of significant life-style features. In this work, a special scheme of LASSO learning technology is developed for identifying the reasonably few medical features and improve the diagnosis accuracy simultaneously. By pairing each ""biased"" BC against the gentle BC, the categorization task is conducted with reduced features. Similarly to the federated learning process, the common features among multiple algorithms are refined. From the real clinical data validation, the BC categorization accuracy is 94.6% which is 24.7% higher than the state-of-the-art (SOTA) works; the average key features are reduced to 17 where the best effort of SOTA is 31. Finally, the common key features are summarized among multiple algorithms.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168613","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168613","Body constitution;life-style;LASSO;feature reduction","Radio frequency;Machine learning algorithms;Sociology;Prediction algorithms;Feature extraction;Classification algorithms;Task analysis","","","","20","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Novel Knowledge Distillation to Improve Training Accuracy of Spin-based SNN","H. Li; A. H. Lone; F. Tian; J. Yang; M. Sawan; N. El-Atab","CEMSE Department, SAMA Labs, KAUST, Thuwal, Saudi Arabia; CEMSE Department, SAMA Labs, KAUST, Thuwal, Saudi Arabia; CenBRAIN Neurotech, School of Engineering, Westlake University, Hangzhou, China; CenBRAIN Neurotech, School of Engineering, Westlake University, Hangzhou, China; CenBRAIN Neurotech, School of Engineering, Westlake University, Hangzhou, China; CEMSE Department, SAMA Labs, KAUST, Thuwal, Saudi Arabia",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Spintronics-based magnetic tunnel junction (MTJ) devices have shown the ability working as both synapse and spike threshold neurons, which is perfectly suitable with the hardware implementation of spike neural network (SNN). It has the inherent advantage of high energy efficiency with ultra-low operation voltage due to its small nanometric size and low depinning current densities. However, hardware-based SNNs training always suffers a significant performance loss compared with original neural networks due to variations among devices and information deficiency as the weights map with device synaptic conductance. Knowledge distillation is a model compression and acceleration method that enables transferring the learning knowledge from a large machine learning model to a smaller model with minimal loss in performance. In this paper, we propose a novel training scheme based on spike knowledge distillation which helps improve the training performance of spin-based SNN (SSNN) model via transferring knowledge from a large CNN model. We propose novel distillation methodologies and demonstrate the effectiveness of the proposed method with detailed experiments on four datasets. The experimental results indicate that our proposed training scheme consistently improves the performance of SSNN model by a large margin.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168575","King Abdullah University of Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168575","SNN;magnetic tunnel junction;knowledge distillation;transfer learning","Training;Performance evaluation;Knowledge engineering;Neurons;Learning (artificial intelligence);Hardware;Junctions","","1","","22","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"4b/4b/8b Precision Charge-Domain 8T-SRAM Based CiM for CNN Processing","Q. Zang; W. L. Goh; Y. S. Chong; A. T. Do","School of Electrical and Electronic Engineering, Nanyang Technological University (NTU), Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University (NTU), Singapore; Institute of Microelectronics, A*STAR, Singapore; Institute of Microelectronics, A*STAR, Singapore",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Compute-in-memory (CiM) is a promising solution for solving the bottleneck of frequent data movement between the memory and processor in Von-Neumann architecture. In conventional multi-bit CiM architecture, when computing N-bit input and N-bit weight MAC operation, 2N 1 cycles are needed for N-bit input modulation and normally 3-4−cycles with complex switch operation are needed for N-bit weight realization, which significantly degrades the final throughput and power efficiency. In this work, a C-2C DAC built in the 8T SRAM CiM array is designed for 4-bit weight and 4-bit input MAC operation, which can be completed in just one cycle. In the final power efficiency evaluation, our 4b/4b/8b CiM architecture attained up to 640 TOPS/W (normalized to 1b/1b/1b precision) which is a 6-10 times improvement as compared to the conventional multi-bit CiM architectures. The proposed architecture with 4b/4b/8b precision can provide 91.47% and 68.10% accuracy on CIFAR-10 and CIFAR-100 dataset classification, respectively.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168593","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168593","SRAM;compute-in-memory (CiM);multiply-and-accumulate (MAC)","Circuits and systems;Capacitors;Random access memory;Modulation;Computer architecture;Switches;Throughput","","1","","15","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"A Low-Power Hardware Accelerator of MFCC Extraction for Keyword Spotting in 22nm FDSOI","L. Guo; M. Jobst; J. Partzsch; S. Scholze; A. Dixius; M. Lohrmann; S. M. A. Zeinolabedin; C. Mayr","Chair of Highly-Parallel VLSI-Systems and Neuro-Microelectronics Circuits, Technische Universität, Dresden, Germany; Chair of Highly-Parallel VLSI-Systems and Neuro-Microelectronics Circuits, Technische Universität, Dresden, Germany; Chair of Highly-Parallel VLSI-Systems and Neuro-Microelectronics Circuits, Technische Universität, Dresden, Germany; Chair of Highly-Parallel VLSI-Systems and Neuro-Microelectronics Circuits, Technische Universität, Dresden, Germany; Chair of Highly-Parallel VLSI-Systems and Neuro-Microelectronics Circuits, Technische Universität, Dresden, Germany; Chair of Highly-Parallel VLSI-Systems and Neuro-Microelectronics Circuits, Technische Universität, Dresden, Germany; Chair of Highly-Parallel VLSI-Systems and Neuro-Microelectronics Circuits, Technische Universität, Dresden, Germany; Chair of Highly-Parallel VLSI-Systems and Neuro-Microelectronics Circuits, Technische Universität, Dresden, Germany",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","With the development of artificial intelligence, the real-time feature extraction of acoustic signals is required in a wide variety of applications, such as keyword spotting and speech recognition. Feature extraction based on Mel-frequency cepstral coefficients (MFCCs) is one of the most significant methods thereinto. A software implementation of the MFCC extraction results in relatively high power consumption and computational time limitation, often making it unsuitable for tiny battery powered devices. Therefore, an on-chip accelerator of MFCC extraction is of interest in cutting-edge scenarios. This paper presents a fixed-point low-power hardware accelerator of MFCC feature extraction implemented in 22nm FDSOI technology. It consumes an average power of 2.78µW for 1024-sample frame at a clock frequency of 1MHz. For keyword spotting, the quantized accelerator achieves an average accuracy of around 96% working along with different classification networks.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168587","Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168587","Mel-frequency cepstral coefficients;keyword spotting;acoustic signal feature extraction;digital signal processing;low-power design","Silicon-on-insulator;Speech recognition;Feature extraction;Software;Table lookup;System-on-chip;Mel frequency cepstral coefficient","","1","","22","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"High-Accuracy and Energy-Efficient Acoustic Inference using Hardware-Aware Training and a 0.34nW/Ch Full-Wave Rectifier","S. Zhou; X. Chen; K. Kim; S. -C. Liu","Institute of Neuroinformatics, University of Zurich and ETH Zurich, Zurich, Switzerland; Institute of Neuroinformatics, University of Zurich and ETH Zurich, Zurich, Switzerland; Institute of Neuroinformatics, University of Zurich and ETH Zurich, Zurich, Switzerland; Institute of Neuroinformatics, University of Zurich and ETH Zurich, Zurich, Switzerland",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","A full-wave rectifier (FWR) is a necessary component of many analog acoustic feature extractor (FEx) designs targeted at edge audio applications. However, analog circuits that perform close-to-ideal rectification contribute a significant portion of the total power of the FEx. This work presents an energy-efficient FWR design by using a dynamic comparator and scaling the comparator clock frequency with its input signal bandwidth. Simulated in a 65nm CMOS process, the rectifier circuit consumes 0.34nW per channel for a 0.6V supply. Although the FWR does not perform ideal rectification, an acoustic FEx behavioral model in Python is proposed based on our FWR design, and a neural network trained with the output of the proposed behavioral model recovers high classification accuracy in an audio keyword spotting (KWS) task. The behavioral model also included comparator noise and offset extracted from transistor-level simulation. The whole KWS chain using our behavioral model achieves 89.45% accuracy for 12-class KWS on the Google Speech Commands Dataset.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168561","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168561","","Semiconductor device modeling;Training;Rectifiers;Bandwidth;Feature extraction;CMOS process;Acoustics","","2","","16","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"A Ternary Weight Mapping and Charge-mode Readout Scheme for Energy Efficient FeRAM Crossbar Compute-in-Memory System","T. Cao; Z. Zhang; W. L. Goh; C. Liu; Y. Zhu; Y. Gao","School of Electrical and Electronic Engineering, Nanyang Technological University, Republic of Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Republic of Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Republic of Singapore; Institute of Microelectronics (IME), Agency for Science, Technology and Research (A*STAR), Republic of Singapore; Institute of Microelectronics (IME), Agency for Science, Technology and Research (A*STAR), Republic of Singapore; Institute of Microelectronics (IME), Agency for Science, Technology and Research (A*STAR), Republic of Singapore",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","This work presents an edge-AI system built on capacitive ferroelectric random-access memory (FeRAM) crossbar array, which is compatible with CMOS backend-of-line (BEOL) fabrication process. A novel capacitive crossbar circuit and a ternary mapping technique are proposed. Compared to the conventional binary representation, the proposed ternary mapping improves the storage efficiency exponentially in weight resolution. The feasibility of neuromorphic computing system implemented on FeRAM crossbar array is explored with speech command classification task. A ResNet-32 model with 0.45M parameters is implemented on 64 × 64 FeRAM crossbar array with the measured FeRAM model. It achieved 97.12% inference accuracy with 2 ternary digits and 5% device variation on Google Speech Command dataset 35-command classification task.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168639","Scan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168639","Capacitive crossbar;FeRAM;Speech recognition;Edge-AI;neuromorphic system","Semiconductor device modeling;Nonvolatile memory;Ferroelectric films;Computational modeling;Random access memory;Internet;Task analysis","","3","","25","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"A 1W8R 20T SRAM Codebook for 20% Energy Reduction in Mixed-Precision Deep-Learning Inference Processor System","R. Ohara; K. Masaya; M. Taichi; A. Fukunaga; Y. Yasuda; R. Hamabe; S. Izumi; H. Kawaguchi","Graduate School of System Informatics, Kobe University, Kobe, Japan; Graduate School of Science, Technology and Innovation, Kobe University, Kobe, Japan; Graduate School of System Informatics, Kobe University, Kobe, Japan; Graduate School of Science, Technology and Innovation, Kobe University, Kobe, Japan; Graduate School of System Informatics, Kobe University, Kobe, Japan; Graduate School of System Informatics, Kobe University, Kobe, Japan; Graduate School of Science, Technology and Innovation, Kobe University, Kobe, Japan; Graduate School of Science, Technology and Innovation, Kobe University, Kobe, Japan",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","This study introduces a 1W8R 20T multiport memory for codebook quantization in deep-learning processors. We manufactured the memory in a 40 nm process and achieved memory read-access time at 2.75 ns and 2.7-pj/byte power consumption. In addition, we used NVDLA, which was NVIDIA’s deep-learning processor, as a motif and simulated it based on the power obtained from the actual proposed memory. The obtained power and area reduction results are 20.24% and 26.24%, respectively.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168555","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168555","codebook;multiport memory;deep neural network","Program processors;Quantization (signal);Power demand;Circuits and systems;Memory management;Neural networks;Random access memory","","2","","13","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"An Efficient Design Framework for 2×2 CNN Accelerator Chiplet Cluster with SerDes Interconnects","Y. Wu; T. Li; Z. Shao; L. Du; Y. Du","Nanjing University, Nanjing, China; Nanjing University, Nanjing, China; Nanjing University, Nanjing, China; Nanjing University, Nanjing, China; Nanjing University, Nanjing, China",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Multi-Chiplet integrated systems for high-performance computing with dedicated CNN accelerators are highly demanded due to ever-increasing AI-related training and inferencing tasks; however, many design challenges hinder their large-scale applications, such as complicated multi-task scheduling, high-speed die-to-die SerDes (Serializer/Deserializer) link modeling, and detailed communication and computation hardware co-simulation. In this paper, an optimized 2×2 CNN accelerator chiplet framework with a SerDes link model is presented, which addresses the above challenges. A methodology for designing a 2×2 CNN accelerator chiplet framework is also proposed, and several experiments are conducted. The system performances of different designs are compared and analyzed with different design parameters of computation hardware, SerDes links, and improved scheduling algorithms. The results show that with the same interconnection structure and bandwidth, every 1TFLOPS increase in one chiplet’s computing power can bring an average 3.7% execution time reduction.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168573","Research and Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168573","multi-chiplet;framework;SerDes;scheduling algorithms","Training;Scheduling algorithms;Computational modeling;High performance computing;Design methodology;Integrated circuit interconnections;Bandwidth","","1","","15","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"MF-DSNN:An Energy-efficient High-performance Multiplication-free Deep Spiking Neural Network Accelerator","Y. Zhang; S. Wang; Y. Kang","University of Science and Technology of China, Hefei, China; University of Science and Technology of China, Hefei, China; University of Science and Technology of China, Hefei, China",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","4","Inspired by the brain structure, Spiking Neural Networks (SNNs) are computing models communicating and calculating through spikes. SNNs that are well-trained demonstrate high sparsity in both weight and activation, distributed spatially and temporally. This sparsity presents both opportunities and challenges for high energy efficiency inference computing of SNNs when compared to conventional artificial neural networks (ANNs). Specifically, the high sparsity can significantly reduce inference delay and energy consumption. However, the temporal dimension greatly complicates the design of spiking accelerators. In this paper, we propose a unique solution for sparse spiking neural network acceleration. First, we adopt a temporal coding scheme called FS coding which differs from the rate coding used in traditional SNNs. Our design eliminates the need for multiplication due to the nature of FS coding. Second, we parallelize the computation required for the neuron at each time point to minimize the access of the weight data. Third, we fuse multiple spikes into one new spike to reduce inference delay and energy consumption. Our proposed architecture exhibits better performance and energy efficiency with less cost. Our experiments show that running MobileNet-V2, MF-DSNN achieves 6× to 22× energy efficiency improvements while having an accuracy degradation of less than 0.9% and using less silicon area on the ImageNet dataset compared to state-of-the-art artificial neural network accelerators.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168643","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168643","spiking neurol network;few spikes;spatial-temporal sparsity;spike fuse","Energy consumption;Fuses;Simulation;Artificial neural networks;Computer architecture;Energy efficiency;Encoding","","2","","14","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"A Hierarchically Reconfigurable SRAM-Based Compute-in-Memory Macro for Edge Computing","R. Wang; X. Guo","University of Michigan – Shanghai Jiao Tong University Joint Institute Shanghai Jiao Tong University, Shanghai, China; University of Michigan – Shanghai Jiao Tong University Joint Institute Shanghai Jiao Tong University, Shanghai, China",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","AI running on the edge requires silicon that can meet demanding performance requirements while meeting the aggressive power and area budget. Frequently updated AI algorithms also demand matched processors to well employ their advantages. Compute-in-memory (CIM) architecture appears as a promising energy-efficient solution that completes the intensive computations in-situ where the data are stored. While prior works have shown great progress in designing SRAM-based CIM macros with fixed functionality that were tailored for specific AI applications, the flexibility reserved for wider usage scenarios is missing. In this paper, we propose a novel SRAM-based CIM macro that can be hierarchically configured to support various boolean operations, arithmetic operations, and macro operations. In addition, we demonstrate with an example that the proposed design can be expanded to support more essential edge computations with minimal overhead. Compared with the existing reconfigurable SRAM-based CIM macros, this work achieves a greater balance of reconfigurability vs. hardware cost by implementing flexibility at various design hierarchies.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168564","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168564","SRAM;Compute-in-Memory;Reconfigurable Computing;Edge Computing;Edge AI","Program processors;Costs;Computer architecture;Common Information Model (computing);Silicon;Hardware;Energy efficiency","","2","","24","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"SpatialHD: Spatial Transformer Fused with Hyperdimensional Computing for AI Applications","M. Bettayeb; E. Hassan; B. Mohammad; H. Saleh","Electrical Engineering and Computer Science Department, System on Chip Lab, Khalifa University of Science and Technology, Abu Dhabi, United Arab Emirates; Electrical Engineering and Computer Science Department, System on Chip Lab, Khalifa University of Science and Technology, Abu Dhabi, United Arab Emirates; Electrical Engineering and Computer Science Department, System on Chip Lab, Khalifa University of Science and Technology, Abu Dhabi, United Arab Emirates; Electrical Engineering and Computer Science Department, System on Chip Lab, Khalifa University of Science and Technology, Abu Dhabi, United Arab Emirates",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Brain-inspired computing methods have shown remarkable efficiency and robustness compared to deep neural networks (DNN). In particular, HyperDimensional Computing (HDC) and Vision Transformer (ViT) have demonstrated promising achievements in facilitating effective and reliable cognitive learning. This paper proposes SpatialHD, the first framework that combines spatial transformer networks (STN) and HDC. First, SpatialHD exploits the STN, which explicitly allows the spatial manipulation of data within the network. Then, it employs HDC to operate over STN output by mapping feature maps into high-dimensional space, learning abstracted information, and classifying data. In addition, the STN output is resized to generate a smaller input feature map. This further reduces computing complexity and memory storage compared to HDC alone. Finally, to test the model’s functionality, we applied spatial HD for image classification, utilizing the MNIST and Fashion-MNIST datasets, using only 25% of the dataset for training. Our results show that SpatialHD improves accuracy by ≈ 8% and enhances efficiency by approximately 2.5x compared to base-HDC.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168629","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168629","Spatial Transformers;Hyperdimensional Computing;Image Classification","Training;Image coding;Computational modeling;Neural networks;Speech recognition;Transformers;Spatial databases","","5","","19","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Multi-agent Cooperative Control in Neural MMO Environment Based on MAPPO Algorithm","G. Lyu; M. Li","College of Big Data and Internet, Shenzhen Technology University, Shenzhen, China; College of Big Data and Internet, Shenzhen Technology University, Shenzhen, China",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","4","In recent years, with the increasing number of artificial intelligence and deep learning algorithms and applications, reinforcement learning, as a branch of machine learning, has shown its advantages over other machine learning algorithms in highly complex environments, including famous events such as AlphaGo defeating human chess players. Various branches of reinforcement learning algorithms and experimental environments have been developed for research. Reinforcement learning and multi-agent reinforcement learning are applied in this paper. The multi-agent reinforcement learning algorithm MAPPO with a proposed reward function is validated under a Neural MMO environment. The result verifies that the MAPPO algorithm can provide strategies for agents running in the Neural MMO environment.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168653","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168653","Multi-Agent Reinforcement Learning;MAPPO Algorithm;Neural MMO Environment","Training;Deep learning;Machine learning algorithms;Circuits and systems;Reinforcement learning;Aerospace electronics","","","","10","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"PPT-KP: Pruning Point Training-based Kernel Pruning for Deep Convolutional Neural Networks","K. Koo; H. Kim","Department of Electrical and Information Engineering, Research Center for Electrical and Information Technology, Seoul National University of Science and Technology, Seoul, Korea; Department of Electrical and Information Engineering, Research Center for Electrical and Information Technology, Seoul National University of Science and Technology, Seoul, Korea",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","Pruning, which is a representative method for compressing huge convolutional neural network (CNN) models, has been mainly studied in two directions: weight pruning and filter pruning, with both approaches having clear limitations caused by their intrinsic characteristics. To solve this problem, research on kernel pruning, which has the advantages of both methods, has recently advanced. In this study, pruning point training-based kernel pruning (PPT-KP) is proposed to address the problems of existing kernel pruning methods. With PPT-KP, the L1 norm of the kernel converges to zero through an adaptive regularizer that applies L1 regularization of different intensities depending on the size of the L1 norm of the kernel to secure network sparsity and obtain multiple margin spaces for pruning. Thus, outstanding kernel pruning is possible because several pruning points can be created. PPT-KP outperformed several existing filter pruning and kernel pruning methods on various networks and datasets in terms of the trade-off between FLOPs reduction and accuracy drops. In particular, PPT-KP reduced parameters and FLOPs by 77.2% and 68.9%, respectively, in ResNet-56 on the CIFAR-10 dataset with only a 0.05% accuracy degradation.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168622","National Research Foundation of Korea; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168622","deep learning;convolutional neural network;kernel pruning;network compression","Degradation;Training;Adaptive systems;Circuits and systems;Complex networks;Convolutional neural networks;Iterative methods","","3","","30","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Convergent Waveform Relaxation Schemes for the Transient Analysis of Associative ReLU Arrays","I. A. M. Elfadel","Department of EECS, Center for Cyber Physical Systems (C2PS), Khalifa University, Abu Dhabi, UAE",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","In this circuit-theoretic paper, we establish a new result for the global convergence of the waveform relaxation (WR) algorithm in the specific context of analog associative arrays having the Rectified Linear Unit (ReLU) as an activation function. The traditional methods for proving WR convergence on generic analog circuits rely on the use of exponentially weighted norms to control the behavior of the transient waveforms for large simulation intervals. The main contribution of this paper is to show that in the particular case of analog associative ReLU arrays, WR convergence for large simulation intervals does not require exponentially weighted norms and can instead be ascertained using the common norm of uniform convergence. Using the connectivity matrix of the associativity array, a practical criterion for guaranteeing WR convergence is provided.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168567","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168567","Analog Networks;ReLU Activation;Associative Memories;Global Dynamics;Circuit Simulation;Transient Analysis;Waveform Relaxation","Parallel programming;Circuits and systems;Heuristic algorithms;Graphics processing units;Analog circuits;Behavioral sciences;Trajectory","","","","20","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Enhancing Fault Resilience of QNNs by Selective Neuron Splitting","M. H. Ahmadilivani; M. Taheri; J. Raik; M. Daneshtalab; M. Jenihhin","Tallinn University of Technology, Tallinn, Estonia; Tallinn University of Technology, Tallinn, Estonia; Tallinn University of Technology, Tallinn, Estonia; Tallinn University of Technology, Tallinn, Estonia; Tallinn University of Technology, Tallinn, Estonia",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","The superior performance of Deep Neural Networks (DNNs) has led to their application in various aspects of human life. Safety-critical applications are no exception and impose rigorous reliability requirements on DNNs. Quantized Neural Networks (QNNs) have emerged to tackle the complexity of DNN accelerators, however, they are more prone to reliability issues.In this paper, a recent analytical resilience assessment method is adapted for QNNs to identify critical neurons based on a Neuron Vulnerability Factor (NVF). Thereafter, a novel method for splitting the critical neurons is proposed that enables the design of a Lightweight Correction Unit (LCU) in the accelerator without redesigning its computational part.The method is validated by experiments on different QNNs and datasets. The results demonstrate that the proposed method for correcting the faults has a twice smaller overhead than a selective Triple Modular Redundancy (TMR) while achieving a similar level of fault resiliency.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168633","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168633","","Deep learning;Circuits and systems;Neurons;Redundancy;Complexity theory;Circuit faults;Integrated circuit reliability","","7","","16","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Grand Challenge on Software and Hardware Co-Optimization for E-Commerce Recommendation System","J. Li; J. Liu; X. Hu; Y. Zhang; G. Yu; S. Qian; W. Mao; L. Du; Y. Li; Y. Du","School of Electronic Science and Engineering, Nanjing University, China; School of Electronic Science and Engineering, Nanjing University, China; School of Electronic Science and Engineering, Nanjing University, China; Department of Micro-Nano Electronics and MoE Key Lab of Artificial Intelligence, Shanghai Jiao Tong University, China; T-Head Semiconductor Co., Ltd, China; T-Head Semiconductor Co., Ltd, China; School of Microelectronics, Southern University of Science and Technology, Shenzhen, China; School of Electronic Science and Engineering, Nanjing University, China; Department of Micro-Nano Electronics and MoE Key Lab of Artificial Intelligence, Shanghai Jiao Tong University, China; School of Electronic Science and Engineering, Nanjing University, China",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","5","E-commerce has become an indispensable part of the whole commodity economy with rapid expansion. A great deal of time is required for customers to search products by manual work. A good automatic recommendation system can not only bring the customers good shopping experience, but also help companies gain profit growth. In the IEEE AICAS 2023 conference, we have organized the grand challenge on software and hardware co-optimization for e-commerce recommendation system. The desensitized data from Alibaba Group which recorded online purchase behaviors of online shopping users in China are provided. We organize two rounds of the challenge with two different parts of data, separately encouraging participating teams to propose novel ideas for the recommendation algorithm design and deployment. In the preliminary round, participating teams are required to design a recommendation system with high accuracy performance. In the final round, the qualified teams from the preliminary round will be offered with an ARM-based multi-core Yitian 710 CPU cloud server, the teams are required to design an acceleration scheme for the hardware resolution. In the final, 6 best teams will be awarded by using standard evaluation criteria.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168648","National Key Research and Development Program of China; National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168648","Grand challenge;software and hardware co-optimization;recommendation system;open-source;efficient deployment;machine-learning algorithms","Circuits and systems;Software algorithms;Hardware;Software;Inference algorithms;Central Processing Unit;Electronic commerce","","3","","16","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Live Demonstration: An Efficient Neural Network Processor with Reduced Data Transmission and On-chip Shortcut Mapping","Y. Bai; Z. Shao; C. Zhang; A. Jiang; Y. Du; L. Du","Nanjing University, Nanjing, China; Nanjing University, Nanjing, China; Nanjing University, Nanjing, China; Nanjing University, Nanjing, China; Nanjing University, Nanjing, China; Nanjing University, Nanjing, China",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","2","This demonstration showcases an efficient neural network processor implemented in TSMC 28nm CMOS technology. The processor conducts neural network inference with 16-bit dynamic fix-point activation and 10-bit dynamic fix-point weight. The reconfigurable streaming architecture is employed for off-chip data transmission reduction and on-chip shortcut mapping. An integrated neural network toolchain, including network model converter, quantitative analysis tool, and deep learning compiler, is also developed for fast network deployment.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168666","National Key Research and Development Program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168666","neural network processor;reconfigurable streaming architecture;data transmission reduction;on-chip shortcut mapping;neural network toolchain","Semiconductor device modeling;Deep learning;Statistical analysis;Circuits and systems;Neural networks;CMOS technology;System-on-chip","","2","","6","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Live Demonstration: An Integrated Computing and Communication Platform for Vehicle-Infrastructure Cooperative Autonomous Driving","Y. Gu; W. Zhang; Y. Shi; L. Jiang; S. Li; S. Cao; Z. Jiang; R. Mao; Z. Lou; S. Zhou","School of Information and Communication Engineering, Shanghai University, Shanghai, China; School of Information and Communication Engineering, Shanghai University, Shanghai, China; School of Information and Communication Engineering, Shanghai University, Shanghai, China; School of Information and Communication Engineering, Shanghai University, Shanghai, China; School of Information and Communication Engineering, Shanghai University, Shanghai, China; School of Information and Communication Engineering, Shanghai University, Shanghai, China; School of Information and Communication Engineering, Shanghai University, Shanghai, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","2","Perception, computing and communication are usually decoupled in today’s vehicle-road coordination applications, which significantly adds to the system delay and cost. In contrast, we showcase a platform that integrates perception, communication and computing to provide timely roadside bird-eye-view (BEV) maps to vehicles for vision fusion. A neural processing unit and a cellular vehicle-to-everything (C-V2X) wireless baseband are both implemented on FPGA.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168600","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168600","","Wireless communication;Costs;Baseband;Circuits and systems;Delays;Artificial intelligence;Vehicle-to-everything","","","","3","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Live Demonstration: Supervised-learning-based Visual Quantification for Image Enhancement","W. Zhang; J. Chang; Z. Peng; L. Chen; F. An","Southern University of Science and Technology, Shenzhen, China; Shenzhen Semiconductor Industry Association, Shenzhen, China; Southern University of Science and Technology, Shenzhen, China; Southern University of Science and Technology, Shenzhen, China; Southern University of Science and Technology, Shenzhen, China",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","2","This demonstration showcases a framework of visual quantification for image enhancement where multivariate Gaussian (MVG) models are trained to assess image visibility. The visibility of an image is depicted by statistical features such as the contrast energy of the gray channel, yellow-blue channel, and red-green channel, average saturation, and gradients. The predicted visibility scores are then applied to define adaptive histogram equalization clip parameters for image enhancement. Finally, the hardware architecture is implemented on an FPGA to demonstrate the results for real-time image enhancement.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168650","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168650","Low visibility enhancement;image enhancement;visual perception","Visualization;Histograms;Adaptation models;Circuits and systems;Adaptive equalizers;Real-time systems;Hardware","","","","6","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Live Demonstration: Real-time Analyses of Biosignals based on a Dedicated CMOS Configurable Deep Learning Engine","J. Wang; S. Zhao; C. Fang; J. Yang; M. Sawan","Center of Excellence in Biomedical Research on Advanced Integrated-on-Chips Neurotechnologies School of Engineering, Westlake University, Hangzhou, China; Center of Excellence in Biomedical Research on Advanced Integrated-on-Chips Neurotechnologies School of Engineering, Westlake University, Hangzhou, China; Center of Excellence in Biomedical Research on Advanced Integrated-on-Chips Neurotechnologies School of Engineering, Westlake University, Hangzhou, China; Center of Excellence in Biomedical Research on Advanced Integrated-on-Chips Neurotechnologies School of Engineering, Westlake University, Hangzhou, China; Center of Excellence in Biomedical Research on Advanced Integrated-on-Chips Neurotechnologies School of Engineering, Westlake University, Hangzhou, China",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","2","Biosignals generated by human bodies contain valuable information about a person’s physical or psychological states. In recent years, machine-learning algorithms have significantly increased the accuracy and usefulness of biosignal analysis in areas such as disease diagnoses and treatments. To make these analyses more portable and accessible, we have designed and fabricated a dedicated processor named CODE, which supports machine-learning processing of various types of biosignals, including electroencephalography (EEG), electromyography (EMG), and electrocardiography (ECG), with high power efficiency and low latency. In this demonstration, we will show how the CODE chip processes biosignal data in real-time and show measurements of its power consumption and efficiency.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168631","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168631","biosignal processing;digital chip;machine learning;signal analysis","Semiconductor device measurement;Codes;Power measurement;Power demand;Psychology;Electrocardiography;Real-time systems","","","","3","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Live Demonstration: Efficient Organic Photodetector based Active Matrix Imager for Real-time Optical Character Recognition","T. Shan; J. Li; X. Hou; P. Huang; X. Guo","School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","2","This live demonstration presents real-time character recognition using a portable system composed of an organic photodetectors-based imaging array and a smartphone. The high specific detectivity of the organic photodiode enables sensitive imaging with an ultra-low light intensity. Furthermore, a smartphone application using deep learning-based algorithm training has been applied for character recognition.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168609","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168609","Machine vision;Active matrix imaging array;Optoelectronic devices;Neural network","Training;Circuits and systems;Optical character recognition;Imaging;Real-time systems;Character recognition;Photodiodes","","","","5","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Live Demonstration: Face Recognition at The Edge Using Fast On-Chip Deep Learning Neuromorphic Chip","Z. Zhong; T. Wang; H. Wang; Z. Zhou; J. He; F. Tang; X. Zhou; S. -M. Yu; L. Liu; N. Wu; M. Tian; C. Shi","School of Microelectronics and Communication Engineering, Chongqing University, Chongqing, China; School of Microelectronics and Communication Engineering, Chongqing University, Chongqing, China; School of Microelectronics and Communication Engineering, Chongqing University, Chongqing, China; Institute of Electronic Technology, Chongqing Xianfeng Company, Chongqing, China; School of Microelectronics and Communication Engineering, Chongqing University, Chongqing, China; School of Microelectronics and Communication Engineering, Chongqing University, Chongqing, China; School of Microelectronics and Communication Engineering, Chongqing University, Chongqing, China; Institute of Semiconductors, Chinese Academy of Sciences, Beijing, China; Institute of Semiconductors, Chinese Academy of Sciences, Beijing, China; Institute of Semiconductors, Chinese Academy of Sciences, Beijing, China; School of Microelectronics and Communication Engineering, Chongqing University, Chongqing, China; School of Microelectronics and Communication Engineering, Chongqing University, Chongqing, China",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","2","Spiking neural networks (SNNs) and neuromorphic systems have attracted ever increasing interests recently, due to their high computational and energy efficiencies originated from closely imitating the functional mechanism of cerebral cortex, which adopts sparse spikes for information processing. In this work, we present a low-cost real-time face recognition system for potential edge-side intelligent applications. This system is mainly built upon our prior reported MorphBungee neuromorphic chip, which is capable of fast on-chip deep learning for fully-connected (FC) SNN of up to 4 layers, 1K spiking neurons and 256K synapses, under a low power consumption of about 100 mW. Our face recognition system achieves 20-fps and 30-fps image frame rates for real-life human face learning and inference, respectively, and obtains a high face recognition accuracy of 100% among 6 persons. It demonstrates that our face recognition system with the neuromorphic chip is suitable for resource-limited real-time intelligent edge applications.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168667","Research and Development; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168667","spiking neural network;SNN;neuromorphic;tempotron;on-chip learning;direct feedback alignment","Deep learning;Training;Neuromorphics;Face recognition;Image edge detection;Real-time systems;Energy efficiency","","1","","7","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"An Energy-Efficient and Reconfigurable CNN Accelerator Applied To Lung Cancer Detection","Y. H. Liao; H. -H. Chen; K. -T. Tang; S. Y. Lin; D. Xiao Wu; Y. -C. Chen; H. W. Luo","Electrical Engineering, National Tsinghua University, Hsinchu, Taiwan; Electrical Engineering, National Tsinghua University, Hsinchu, Taiwan; Electrical Engineering, National Tsinghua University, Hsinchu, Taiwan; Electrical Engineering, National Tsinghua University, Hsinchu, Taiwan; Electrical Engineering and Computer Science, National Tsinghua University, Hsinchu, Taiwan; Electrical Engineering, National Tsinghua University, Hsinchu, Taiwan; Electrical Engineering and Computer Science, National Tsinghua University, Hsinchu, Taiwan",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","3","We propose a system to fast and easily detect lung cancer by breathing into the device, which is not invasive. Some particular substances only exist in lung cancer patients' breathing. Based on this, we use the CNN model to extract the feature in the gas exhaled by the testee. Then, the neural network will give out the prediction of lung cancer. To accelerate the computation of CNN, we design a hardware accelerator and implement it with FPGA (Field Programmable Gate Array). By comparing the performance, like power consumption and energy efficiency of different architectures, we could find the most appropriate architecture for us. Ultimately, we could reduce memory access by about 20% and reduce 12% of the energy consumption, achieving low power at edge devices. The performance of the CNN model is with a training accuracy 88.41%, a testing accuracy 85.29%, a false negative rate 5.8%, and a false positive rate 41.17%","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168583","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168583","lung cancer detection;CNN accelerator","Performance evaluation;Training;Power demand;Neural networks;Lung cancer;Life estimation;Feature extraction","","","","5","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Live Demonstration: SRAM Compute-In-Memory Based Visual & Aural Recognition System","A. Fan; B. Hu; Z. Jin; H. Han; Y. Zhang; Y. Yang; Y. Yang; B. Yan; R. Huang","Institute for Artificial Intelligence, Peking University, Beijing, China; Pimchip Technology, Beijing, China; Pimchip Technology, Beijing, China; Pimchip Technology, Beijing, China; Pimchip Technology, Beijing, China; Pimchip Technology, Beijing, China; Institute for Artificial Intelligence, Peking University, Beijing, China; Institute for Artificial Intelligence, Peking University, Beijing, China; Institute for Artificial Intelligence, Peking University, Beijing, China",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","2","We propose a live demonstration at AICAS’2023 for commercial SRAM compute-in-memory (CIM) accelerators. This live demonstration includes both visual and aural signal processing and classification performed by SRAM-based CIM engines. The visual part is a low-power face recognition platform, which can display and detect the audience’s faces in real-time. The aural part is a key word spotting engine, with which the audience can interact and control the device for designated tasks (such as ""volume up"" and ""volume down""). This live demonstration is interactive and can bring a live feeling of energy efficiency improvement using the commercial CIM accelerators.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168569","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168569","Compute-In-Memory;Processing-In-Memory;SRAM;Accelerator","Performance evaluation;Visualization;Face recognition;Random access memory;Signal processing;Real-time systems;Energy efficiency","","","","1","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"A Demonstration Platform for Large-Scaled Point Cloud Network Based on 28nm 2D/3D Unified Sparse Convolution Accelerator","X. Feng; W. Sun; S. Fan; C. Tang; Y. Yang; J. Yue; Q. Liao; H. Yang; Y. Liu",Tsinghua University; Tsinghua Shenzhen International Graduated School; Tsinghua University; Tsinghua University; Tsinghua University; Chinese Academy of Sciences; Tsinghua Shenzhen International Graduated School; Tsinghua University; Tsinghua University,2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","2","3D point cloud processing plays an important role in many emerging applications such as autonomous driving, visual navigation, and virtual reality. It calls for hardware acceleration of multiple key operations, including 3D Submanifold SCONV, 3D non-Submanifold SCONV, and 2D SCONV. This work presents a 2D/3D unified sparse convolution accelerator for large-scale voxel-based point cloud networks. The chip is fabricated in TSMC 28nm CMOS technology to achieve 3.3-16.9 FPS running from 60-400MHz when computing the SECOND network on KITTI dataset. This work has been included by ISSCC2023 [1]. A demonstration is given to show the real-time 3D processing with a lidar sensor.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168558","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168558","point clouds;sparse convolution;accelerator","Point cloud compression;Visualization;Cloud computing;Three-dimensional displays;Laser radar;Convolution;Navigation","","","","7","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Live Demonstration: A Smart Ring for Continuous Health Data Monitoring Based on Photoplethysmography","B. Liu; H. Wu; G. Wang","Department of Micro-Nano Electronics, Shanghai Jiao Tong University, Shanghai, China; Department of Information and Communication Engineering, Shenzhen University, Shenzhen, China; Department of Micro-Nano Electronics, Shanghai Jiao Tong University, Shanghai, China",2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","1","3","In this paper, a smart ring based on Photoplethys-mography (PPG) that can monitor users’ daily health data continuously is presented. Multi-wavelength reflective PPG signals are collected through PPG sensors attached to the finger pulp and deployed on the smart ring. Signals are first preprocessed to remove noise, artifacts, and baseline wandering. Physiological indicators like activity status, heart rate(HR), heart rate variability(HRV), respiratory rate(RR), and blood oxygen saturation(SpO2) are calculated on the ring. Results and specific PPG signals are transmitted to smartphones with Bluetooth Low Energy (BLE) module. some signals are also transmitted to the cloud server from the smartphone to implement sleep staging and nap algorithms. With the smart ring, users can continuously obtain their health data and evaluate their health condition through RingConn APP and data management platform. Ultra-low power hardware and algorithm design make the battery life of RingConn up to 7 days. This smart ring-based continuous health monitoring system can bring many benefits to people.","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168644","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168644","PPG;HR;HRV;RR;Sleep Staging;Activity;Stress;SpO2;Nap;Continuous Health Data Monitoring","Heart rate;Photoplethysmography;Sleep apnea;Batteries;Servers;Low-power electronics;Biomedical monitoring","","1","","6","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Author Index","",,2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS),"7 Jul 2023","2023","","","562","566","","2834-9857","979-8-3503-3267-4","10.1109/AICAS57966.2023.10168642","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168642","","","","","","","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
