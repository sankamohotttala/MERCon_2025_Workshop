"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Improving the Robustness of Threshold-Based Single Hidden Layer Neural Networks via Regularization","E. Ragusa; C. Gianoglio; R. Zunino; P. Gastaldo","Department of Electrical, DITEN University of Genoa, Genova, Italy; Department of Electrical, DITEN University of Genoa, Genova, Italy; Department of Electrical, DITEN University of Genoa, Genova, Italy; Department of Electrical, DITEN University of Genoa, Genova, Italy",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","276","280","Edge computing can take full advantage of data-driven models only if the eventual inference function can be deployed on low-power, resource-constrained digital devices. In this regard, single layer feedforward neural networks (SLFNs) based on the threshold activation function represent a suitable option, as they can suitably balance generalization performances and computational costs. Their robustness to perturbations at the node level, though, is an issue: a small perturbation affecting the input to the activation might result in a sign inversion at the output of the neuron. This in turn may severely affect the accuracy of the inference function when implemented on hardware. This paper shows that the robustness of this class of SLFNs can be improved by introducing in the cost function a regularization term specifically designed to limit the impacts of perturbations at the node level. The novel cost function indeed admits a closed-form solution. Experimental validation involved six real world benchmarks.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073976","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073976","","Robustness;Perturbation methods;Neurons;Training;Cost function;Biological neural networks;Hardware","","2","","30","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"High-Speed, Real-Time, Spike-Based Object Tracking and Path Prediction on Google Edge TPU","J. Sengupta; R. Kubendran; E. Neftci; A. Andreou","John Hopkins University, Baltimore, MD, USA; University of California San Diego, La Jolla, CA, USA; 3University of California Irvine, Irvine, CA, USA; John Hopkins University, Baltimore, MD, USA",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","134","135","As computation and advanced high-dimensional signal processing is pushed to edge computational devices, energy efficient, unconventional architectures are needed to ameliorate this growing need. The Google Edge TPU, first used on a Cloud platform, is one such accelerator that is now commercially available for consumer use. Similarly, low-power, data-efficient vision sensors, such as the Dynamic Vision Sensor (DVS), have been developed and commercialized as well to improve upon the large data redundancy seen in these ML applications. This live demonstration is linking these two technologies to benchmark the Coral Edge TPU Board in a high-speed object tracking and prediction application. In comparison to a floating point architecture of similar form factor, the Intel Compute Stick, the Edge TPU has been show to outperform in terms of latency and computational efficiency.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073867","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073867","Edge Computing;Tensor Processing unit (TPU);Dynamic Vision Sensor (DVS)","Computer architecture;Google;Conferences;Vision sensors;Task analysis;Real-time systems;Object tracking","","21","","4","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Tradeoff between Parallel Efficiency and Coding Efficiency of HEVC: A Load Balancing Solution with Convolutional Neural Networks","J. -W. Yang; P. -R. Lai; P. -C. Fu; J. -S. Wang","Department of Computer Science, National Tsing Hua University, Hsinchu, Taiwan; Department of Computer Science, National Tsing Hua University, Hsinchu, Taiwan; Department of Computer Science, National Tsing Hua University, Hsinchu, Taiwan; Department of Computer Science, National Tsing Hua University, Hsinchu, Taiwan",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","248","250","The concept of tiles was introduced in HEVC as a parallelization strategy. Tiles in HEVC enable the video to be split into independent rectangular regions, thus can be processed in parallel. However, as more threads are devoted to the execution of a parallelized program, the load imbalance among tiles would make threads' idle time to be expected to increase, thus harm the aggregated coding time and speedup performance as well. To expose as much parallelism of HEVC encoding as possible, in this paper, several skills including CNN are conducted. Our design is based on the tradeoff between parallel efficiency and coding efficiency. The goal of CNN filtering are two folds. Firstly, the CNN model gives the prediction of the quadtree structure for each CTU, avoiding the time-consuming CU partition in HEVC if the prediction is reliable. In addition, these CNN outputs (probabilities) can be employed as a filter to decide whether a CTU will be processed by a low-complexity CNN partition mode or the original HEVC mode. The experimental results show that the proposed method could perform well in terms of speedup and aggregated coding time with negligible (minor) coding efficiency loss.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073933","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073933","CNN;HEVC;Parallel Video Coding;Speedup;Tiles;Load Balancing","Encoding;Partitioning algorithms;Load management;Instruction sets;Parallel processing;Predictive models;Task analysis","","2","","7","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Multi-stage Attention Convolutional Neural Networks for HEVC In-Loop Filtering","P. -R. Lai; J. -S. Wang","Department of Computer Science, National Tsing Hua University, Hsinchu, Taiwan; Department of Computer Science, National Tsing Hua University, Hsinchu, Taiwan",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","173","177","In High Efficiency Video Coding (HEVC), lossy compression techniques bring various visual artifacts such as blocking, ringing, and blurring, etc. Recently, to explore convolutional neural networks (CNN) potential of removing such artifacts, researchers presented several CNN models. In this paper, we proposed a Multi-stage Attention Convolutional Neural Network (MACNN) to replace in-loop filters or postprocessing. Our proposed method has three characteristics of effective training and inferencing: employing a 3-stage design fashion with various loss criteria, adopting the revised Inception module, and utilizing Self-attention block. Such a design has several advantages. The 3-stage design clarifies the function of each stage, effectively alleviating the burden of the network; inception module along with self-attention block benefit our model having the ability to acquire global information with fewer layers. Hence, MACNN could reach the performance gain competitive to deeper models. The experimental results show that our MACNN achieves an average 6.5% BD-rate reduction compared to HEVC in all-intra configuration, beating state-of the-art methods.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073980","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073980","High Efficiency Video Coding (HEVC);In-loop filters;convolutional neural networks;Inception module;Selfattention Block","Convolution;Training;Computational modeling;Convolutional neural networks;High efficiency video coding;Computer architecture;Image restoration","","5","","26","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"A Pipeline-Based Scheduler for Optimizing Latency of Convolution Neural Network Inference over Heterogeneous Multicore Systems","H. -I. Wu; D. -Y. Guo; H. -H. Chin; R. -S. Tsay","National Tsing Hua University, Hsinchu, Taiwan; National Tsing Hua University, Hsinchu, Taiwan; National Tsing Hua University, Hsinchu, Taiwan; National Tsing Hua University, Hsinchu, Taiwan",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","46","49","Parallelization is a common design practice for throughput improvement on multicore systems. However, the existing operating systems' schedulers for CNN inference essentially divide the computational tasks of each convolution layer onto different CPU cores and cause significant inter-core feature-map data movement. Therefore, the overall performance is often degraded. In this paper, we propose a pipeline-based scheduler for convolution neural network inference parallelization with minimal feature-map data movement requirements. The experimental results show that our approach can achieve 73% performance improvement on throughput compared to the existing multi-thread scheduler.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073977","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073977","embedded system;heterogeneous scheduler;parallel computing","Pipelines;Convolution;Multicore processing;Computational modeling;Kernel;Task analysis;Delays","","12","","12","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Accelerating Deep Neural Networks with Analog Memory Devices","S. Ambrogio; P. Narayanan; H. Tsai; C. Mackin; K. Spoon; A. Chen; A. Fasoli; A. Friz; G. W. Burr","IBM Research–Almaden, 650 Harry Road, San Jose, CA; IBM Research–Almaden, 650 Harry Road, San Jose, CA; IBM Research–Almaden, 650 Harry Road, San Jose, CA; IBM Research–Almaden, 650 Harry Road, San Jose, CA; IBM Research–Almaden, 650 Harry Road, San Jose, CA; IBM Research–Almaden, 650 Harry Road, San Jose, CA; IBM Research–Almaden, 650 Harry Road, San Jose, CA; IBM Research–Almaden, 650 Harry Road, San Jose, CA; IBM Research–Almaden, 650 Harry Road, San Jose, CA",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","149","152","Acceleration of training and inference of Deep Neural Networks (DNNs) with non-volatile memory (NVM) arrays, such as Phase-Change Memory (PCM), shows promising advantages in terms of energy efficiency and speed with respect to digital implementations using CPUs and GPUs. By leveraging a combination of PCM devices and CMOS circuits, high training accuracy can be achieved, leading to software-equivalent results on small and medium datasets. In addition, weights encoded with multiple PCM devices can lead to high speed and low-power inference, as shown here for Long-Short Term Memory (LSTM) networks.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073978","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073978","NVM;PCM;AI;Accelerator;Analog computing;Training;Inference","Phase change materials;Training;Nonvolatile memory;Software;Programming;Neural networks;Matlab","","7","","15","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"XNORAM: An Efficient Computing-in-Memory Architecture for Binary Convolutional Neural Networks with Flexible Dataflow Mapping","S. Liu; H. Zhu; C. Chen; L. Zhang; C. . -J. Richard Shi","State Key Laboratory of ASIC and System; State Key Laboratory of ASIC and System; Shanghai Engineering Research Center for AI & Robotics, Fudan University, Shanghai; Shanghai Engineering Research Center for AI & Robotics, Fudan University, Shanghai; State Key Laboratory of ASIC and System",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","21","25","In this paper, an energy-efficient computing-inmemory architecture for binary convolutional neural networks, called XNORAM, is proposed. The XNORAM employs 6T feature cells and 10T weight cells to form one XNORAM column. Multiplexed XNOR operations are embedded in each column. To address the data reuse in convolutional neural networks, flexible dataflow mapping is supported on XNORAM to minimize the external data access. To verify the architecture, we design a 4-KB XNORAM prototype in 65nm CMOS technology. It achieves a throughput of 18. 5GOPs at 100-MHz clock rate and 1.0-V power supply. XNOR-AlexNet is performed on the design achieving 39.86 TOPS/W and 4.63 GOPS/KB utilization with only 1.3% accuracy loss comparing to the original XNOR-Net result on GPUs.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073848","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073848","","Convolution;Computer architecture;Prototypes;Topology;Convolutional neural networks;CMOS technology;Throughput","","2","","12","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Temporal Variability Analysis in sEMG Hand Grasp Recognition using Temporal Convolutional Networks","M. Zanghieri; S. Benatti; F. Conti; A. Burrello; L. Benini","Department of Electronic and Electric Engineering, University of Bologna, Italy; Department of Electronic and Electric Engineering, University of Bologna, Italy; Department of Electronic and Electric Engineering, University of Bologna, Italy; Department of Electronic and Electric Engineering, University of Bologna, Italy; Department of Electronic and Electric Engineering, University of Bologna, Italy",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","228","232","Hand movement recognition via surface electromyographic (sEMG) signal is a promising approach for the advance in Human-Computer Interaction. However, this field has to deal with two main issues: (1) the long-term reliability of sEMG-based control is limited by the variability affecting the sEMG signal (especially, variability over time); (2) the classification algorithms need to be suitable for implementation on embedded devices, which have strict constraints in terms of power budget and computational resources. Current solutions present a performance over-time drop that makes them unsuitable for reliable gesture controller design. In this paper, we address temporal variability of sEMG-based grasp recognition, proposing a new approach based on Temporal Convolutional Networks, a class of deep learning algorithms particularly suited for time series analysis and temporal pattern recognition. Our approach improves by 7.6% the best results achieved in the literature on the NinaPro DB6, a reference dataset for temporal variability analysis of sEMG. Moreover, when targeting the much more challenging inter-session accuracy objective, our method achieves an accuracy drop of just 4.8% between intra- and inter-session validation. This proves the suitability of our setup for a robust, reliable long-term implementation. Furthermore, we distill the network using deep network quantization and pruning techniques, demonstrating that our approach can use down to 120 lower memory footprint than the initial network and 4 lower memory footprint than a baseline Support Vector Machine, with an inter-session accuracy degradation of only 2.5%, proving that the solution is suitable for embedded resource-constrained implementations.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073888","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073888","","Training;Convolution;Support vector machines;Reliability;Gesture recognition;Electromyography;Feature extraction","","17","","23","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Prediction of Gas Concentration Using Gated Recurrent Neural Networks","S. Wang; Y. Hu; J. Burgués; S. Marco; S. -C. Liu","Institute of Neuroinformatics, University of Zürich and ETH Zürich, Zurich, Switzerland; Institute of Neuroinformatics, University of Zürich and ETH Zürich, Zurich, Switzerland; Institute for Bioengineering of Catalonia, The Barcelona Institute of Science and Technology, Barcelona, Spain; Institute for Bioengineering of Catalonia, The Barcelona Institute of Science and Technology, Barcelona, Spain; Institute of Neuroinformatics, University of Zürich and ETH Zürich, Zurich, Switzerland",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","178","182","Low-cost gas sensors allow for large-scale spatial monitoring of air quality in the environment. However they require calibration before deployment. Methods such as multivariate regression techniques have been applied towards sensor calibration. In this work, we propose instead, the use of deep learning methods, particularly, recurrent neural networks for predicting the gas concentrations based on the outputs of these sensors. This paper presents a first study of using Gated Recurrent Unit (GRU) neural network models for gas concentration prediction. The GRU networks achieve on average, a 44.69% and a 25.17% RMSE improvement in concentration prediction on a gas dataset when compared with Support Vector Regression (SVR) and Multilayer Perceptron (MLP) models respectively. With the current advances in deep network hardware accelerators, these networks can be combined with the sensors for a compact embedded system suitable for edge applications.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073806","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073806","","Robot sensing systems;Predictive models;Logic gates;Gas detectors;Training;Temperature measurement;Support vector machines","","14","","31","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Multi-Resolution Siamese Networks for One-Shot Learning","I. A. Lungu; Y. Hu; S. -C. Liu","Institute of Neuroinformatics, University of Zurich and ETH Zurich, Zurich, Switzerland; Institute of Neuroinformatics, University of Zurich and ETH Zurich, Zurich, Switzerland; Institute of Neuroinformatics, University of Zurich and ETH Zurich, Zurich, Switzerland",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","183","187","Few-shot learning, a rapidly evolving theme in deep learning research, aims to endow artificial intelligence with the same ability of humans to assimilate new information very quickly. Siamese networks have been used in this context to learn similarity between image pairs and quickly classify novel objects. This work proposes an improved architecture and a novel training method that increases a 1-shot 5-way classification accuracy on 5 entirely novel classes by around 5%, 19%, 18% and 13% respectively compared to vanilla Siamese networks when tested on Omniglot, Tiny-Imagenet, CIFAR100 as well as a custom dataset recorded with an event-driven camera. These networks, when run on a Jetson TX2 GPU can be executed within 108 ms on average.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073996","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073996","event camera;machine learning;one-shot learning;computer vision;Siamese networks","Training;Computer architecture;Task analysis;Kernel;Network architecture;Cameras;Graphics processing units","","7","","40","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Using Libraries of Approximate Circuits in Design of Hardware Accelerators of Deep Neural Networks","V. Mrazek; L. Sekanina; Z. Vasicek","Faculty of Information Technology, IT4Innovations Centre of Excellence Brno University of Technology, Brno, Czech Republic; Faculty of Information Technology, IT4Innovations Centre of Excellence Brno University of Technology, Brno, Czech Republic; Faculty of Information Technology, IT4Innovations Centre of Excellence Brno University of Technology, Brno, Czech Republic",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","243","247","Approximate circuits have been developed to provide good tradeoffs between power consumption and quality of service in error resilient applications such as hardware accelerators of deep neural networks (DNN). In order to accelerate the approximate circuit design process and to support a fair benchmarking of circuit approximation methods, libraries of approximate circuits have been introduced. For example, EvoApprox8b contains hundreds of 8-bit approximate adders and multipliers. By means of genetic programming we generated an extended version of the library in which thousands of 8- to 128-bit approximate arithmetic circuits are included. These circuits form Pareto fronts with respect to several error metrics, power consumption and other circuit parameters. In our case study we show how a large set of approximate multipliers can be used to perform a resilience analysis of a hardware accelerator of ResNet DNN and to select the most suitable approximate multiplier for a given application. Results are reported for various instances of the ResNet DNN trained on CIFAR-10 benchmark problem.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073837","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073837","Approximate circuit;genetic programming;convolutional neural network;hardware accelerator","Libraries;Hardware;Power demand;Measurement;Genetic programming;Resilience;Logic gates","","11","","18","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Uncertainty-based Object Detector for Autonomous Driving Embedded Platforms","J. Choi; D. Chun; H. -J. Lee; H. Kim","Department of Electrical and Computer Engineering, Inter-university Semiconductor Research Center (ISRC), Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering, Inter-university Semiconductor Research Center (ISRC), Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering, Inter-university Semiconductor Research Center (ISRC), Seoul National University, Seoul, Korea; Department of Electrical and Information Engineering, Research Center for Electrical and Information Technology, Seoul National University of Science and Technology, Seoul, Korea",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","16","20","For self-driving cars that operate based on battery-generated power, detection and control are commonly performed in embedded systems to reduce power consumption. To drive safely without driver intervention, it is essential to operate object detection algorithms with high accuracy and fast detection speed within autonomous driving embedded systems. This paper proposes new methods to predict the localization uncertainty by applying Gaussian modeling to the DNN-based tiny YOLOv3 algorithm and consequently, to drastically improve accuracy at the expense of a slight penalty of detection speed by using it in post-processing. Compared to the baseline algorithm (i.e., tiny YOLOv3), the proposed algorithm, tiny Gaussian YOLOv3, improves the mean average precision (mAP) by 2.62 and 4.6 on the Berkeley deep drive (BDD) and KITTI datasets, respectively. Nevertheless, the proposed algorithm is capable of performing real-time detection at 55.56 frames per second (fps) on the BDD dataset and 69.74 fps on the KITTI dataset, respectively, under the mode 0 of the autonomous driving embedded platform, Jetson AGX Xavier.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073907","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073907","Uncertainty;object detection;tiny YOLOv3;autonomous driving;Jetson AGXXavier;post-processing","Uncertainty;Autonomous vehicles;Prediction algorithms;Object detection;Predictive models;Real-time systems;Graphics processing units","","37","","10","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Memory Efficient Training using Lookup-Table-based Quantization for Neural Network","K. Onishi; J. yu; M. Hashimoto","Osaka University, Osaka, Japan; Tokyo Institute of Technology, Tokyo, Japan; Osaka University, Osaka, Japan",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","251","255","Modern neural networks require a tremendous number of parameters, which causes unaffordable requirements of memory and computation resources for embedded systems. To tackle this issue, we propose a LUT-based training method in this paper. The proposed method consists of two components: cluster swap and factorization. Cluster swap is an extension to the quantization process in Deep Compression that overcomes its drawback of unstable training by reassigning each parameter to the proximate cluster. Factorization is a computation trick to reduce the computational cost of neural networks. The experimental results show that the proposed method can decrease memory usage for forward and backward processes to 22.2% and 60.0%,respectively, and reduce the number of multiplications to 11.7%, with 1.41% accuracy loss.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073989","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073989","neural network;lookup table training;cluster swap;Deep Compression;hardware acceleration","Training;Quantization (signal);Neural networks;Memory management;Table lookup;Embedded systems;Computational efficiency","","3","","9","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"In-memory PageRank using a Crosspoint Array of Resistive Switching Memory (RRAM) devices","Z. Sun; G. Pedretti; E. Ambrosi; A. Bricalli; D. Ielmini","Dipartimento di Elettronica, Informazione e Bioingegneria Politecnico di Milano, Milan, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria Politecnico di Milano, Milan, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria Politecnico di Milano, Milan, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria Politecnico di Milano, Milan, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria Politecnico di Milano, Milan, Italy",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","26","30","Thanks to the high parallelism endowed by physical rules, in-memory computing with crosspoint resistive memory arrays has been applied to accelerate typical dataintensive tasks such as the training and inference of deep learning. Recently, it has been shown that a crosspoint resistive switching memory (RRAM) circuit with a feedback configuration can be used to solve linear systems, compute eigenvectors, and rank webpages in just one step. Here, we demonstrate the PageRank with a real database (the Harvard500) together with an 8-level RRAM model that is based on experimental measurements, including the max/min conductance ratio, the high conductance range and the standard deviation of each level. By using a verify algorithm for the RRAM device programming, the PageRank result from the crosspoint circuit shows a cosine similarity of 93.5% with respect to the floating-point solution. With more discrete conductance levels and a broader high conductance range in the RRAM model, a better performance of cosine similarity up to 97% can be achieved. This work supports the feasibility of in-memory PageRank with realistic RRAM devices for real-world networks.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073964","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073964","In-memory computing;PageRank;resistive switching memory (RRAM);eigenvector.","Integrated circuit modeling;Computational modeling;Eigenvalues and eigenfunctions;Programming;Transistors;Mathematical model;Sparse matrices","","1","","16","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Convolutional-Recurrent Neural Networks on Low-Power Wearable Platforms for Cardiac Arrhythmia Detection","A. Faraone; R. Delgado-Gonzalo","ETH Zürich, Switzerland; CSEM, Neuchâtel, Switzerland",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","153","157","Low-power sensing technologies, such as wearables, have emerged in the healthcare domain since they enable continuous and non-invasive monitoring of physiological signals. In order to endow such devices with clinical value, classical signal processing has encountered numerous challenges. However, data-driven methods, such as machine learning, offer attractive accuracies at the expense of being resource and memory demanding. In this paper, we focus on the inference of neural networks running in microcontrollers and low-power processors which wearable sensors and devices are generally equipped with. In particular, we adapted an existing convolutional-recurrent neural network, designed to detect and classify cardiac arrhythmias from a single-lead electrocardiogram, to the low-power embedded System-on-Chip nRF52 from Nordic Semiconductor with an ARM's CortexM4 processing core. We show our implementation in fixed-point precision, using the CMSIS-NN libraries, yields a drop of F1 score from 0.8 to 0.784, from the original implementation, with a memory footprint of 195.6 KB, and a throughput of 33.98 MOps/s.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073950","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073950","","Hardware;Quantization (signal);Convolution;Artificial neural networks;Training;Sensitivity","","22","","20","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Exploiting Variable Precision Computation Array for Scalable Neural Network Accelerators","S. Yang; L. Liu; B. Li; H. Sun; N. Zheng","Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China; Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China; Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China; Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China; Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","315","319","In this paper, we present a flexible Variable Precision Computation Array (VPCA) component for different accelerators, which leverages a sparsification scheme for activations and a low bits serial-parallel combination computation unit for improving the efficiency and resiliency of accelerators. The VPCA can dynamically decompose the width of activation/weights (from 32bit to 3bit in different accelerators) into 2-bits serial computation units while the 2bits computing units can be combined in parallel computing for high throughput. We propose an on-the-fly compressing and calculating strategy SLE-CLC (single lane encoding, cross lane calculation), which could further improve performance of 2-bit parallel computing. The experiments results on image classification datasets show VPCA can outperforms DaDianNao, Stripes, Loom-2bit by 4.67×, 2.42×, 1.52× without other overhead on convolution layers.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073832","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073832","Deep Neural Networks;Accelerator;Energy Efficiency Computing Array;Dynamic Quantization;Resiliency","Encoding;Convolution;Parallel processing;Quantization (signal);Microsoft Windows;Computational efficiency;Neural networks","","","","23","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Distributed Clique-Based Neural Networks for Data Fusion at the Edge","B. Larras; A. Frappé","Univ. Lille, CNRS, Centrale Lille, Yncréa ISEN, Univ. Polytechnique, Hauts–de–France, UMR 8520 - IEMN, Lille, France; Univ. Lille, CNRS, Centrale Lille, Yncréa ISEN, Univ. Polytechnique, Hauts–de–France, UMR 8520 - IEMN, Lille, France",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","55","58","Distributed smart sensors are more and more used in applications such as biomedical or domestic monitoring. However, each sensor broadcasts data wirelessly to the others or to an aggregator, which leads to energy-hungry sensors not ensuring data privacy. To tackle both challenges, this work proposes to distribute a part of a clique-based neural network in each sensor. This scheme allows standardizing data at the sensor level, ensuring privacy if the data is intercepted. Besides, a lower number of bits is transmitted, thus limiting the communication overhead. The circuit implementation is possible with the use of single-cluster iterative clique-based circuits. To this end, a hardware circuit has been fabricated and performs a classification using 115fJ per synaptic event per neuron in 83ns.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073801","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073801","","Neurons;Synapses;Monitoring;Wireless sensor networks;Artificial neural networks;Shift registers;Data privacy","","2","","9","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"A 1.15-TOPS 6.57-TOPS/W DNN Processor for Multi-Scale Object Detection","R. Kawamoto; M. Taichi; M. Kabuto; D. Watanabe; S. Izumi; M. Yoshimoto; H. Kawaguchi","Graduate School of Science, Technology and Innovation, Kobe University, Kobe, Japan; Graduate School of System Informatics, Kobe University, Kobe, Japan; Graduate School of Science, Technology and Innovation, Kobe University, Kobe, Japan; Graduate School of Science, Technology and Innovation, Kobe University, Kobe, Japan; Graduate School of Science, Technology and Innovation, Kobe University, Kobe, Japan; Graduate School of Science, Technology and Innovation, Kobe University, Kobe, Japan; Graduate School of Science, Technology and Innovation, Kobe University, Kobe, Japan",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","203","207","We present a 40-nm multi-scale object detection processor with only three operations: 3 × 3 convolution, 1 × 1 convolution, and 4 × 4 deconvolution. The multi-scale object detection at high accuracy is possible by virtue of the deconvolution feature. Input memory for a feature map has 8-bit width as well as a multiplier for the inputs has 8-bit precision. Partial-sum memory, however, has 16-bit width to suppress detection accuracy deterioration in a layer with 5 12 channels or more. By fixed-point bit precision, the external memory bandwidth and internal memory capacity are reduced. Optimized parallelization in input and output channels reduces the external memory bandwidth to 0.50 GB per 1280 × 384 image with internal memory capacity of 400 kB. The detection error is 1.9% of that using single-precision floating point. The maximum operating frequency is 500 MHz at a supply voltage of 1 V. Its peak performance is 1. 15 TOPS. The maximum energy efficiency is 6.57 TOPS/W at 174 MHz and 0.6 V.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073858","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073858","Self-driving cars;Convolutional neural network;Deconvolution;Multi-scale object detection","Conferences;Autonomous automobiles;Convolutional neural networks;Deconvolution;Object detection;Integrated circuits","","1","","18","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Error-triggered Three-Factor Learning Dynamics for Crossbar Arrays","M. Payvand; M. E. Fouda; F. Kurdahi; A. Eltawil; E. O. Neftci","Institute of neuroinformatics, University and ETH of Zurich, Zurich, Switzerland; Electrical Engineering and Computer Science Dept, UC Irvine, Irvine, USA; Electrical Engineering and Computer Science Dept, UC Irvine, Irvine, USA; Electrical Engineering and Computer Science Dept, UC Irvine, Irvine, USA; Cognitive Sciences Dept. and Computer Science Dept., UC Irvine, Irvine, USA",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","218","222","Recent breakthroughs suggest that local, approximate gradient descent learning is compatible with Spiking Neural Networks (SNNs). Although SNNs can be scalably implemented using neuromorphic VLSI, an architecture, that can learn in situ as accurately as conventional processors, is still missing. Here, we propose a subthreshold circuit architecture designed through insights obtained from machine learning and computational neuroscience that could achieve such accuracy. Using a surrogate gradient learning framework, we derive local, error-triggered learning dynamics compatible with crossbar arrays and the temporal dynamics of SNNs. The derivation reveals that circuits used for inference and training dynamics can be shared, which simplifies the circuit and suppresses the effects of fabrication mismatch. We present SPICE simulations on XFAB 180nm process, as well as large-scale simulations of the spiking neural networks on event-based benchmarks, including a gesture recognition task. Our results show that the number of updates can be reduced hundred-fold compared to the standard rule while achieving performances that are on par with the state-of-the-art.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073998","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073998","","Neurons;Biological neural networks;Computer architecture;Neuromorphics;Integrated circuit modeling;Hardware;Sparse matrices","","13","","27","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Low-power ECG acquisition by Compressed Sensing with Deep Neural Oracles","M. Mangia; A. Marchioni; L. Prono; F. Pareschi; R. Rovatti; G. Setti","DEI; DEI; DET, Politecnico di Torino, Italy; ARCES, University of Bologna, Italy; DEI; ARCES, University of Bologna, Italy",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","158","162","The recovery of sparse signals from their linear mapping on a lower-dimensional space is traditionally performed by finding the sparsest solution compatible with such solutions. This task can be partitioned in two phases: support estimation and coefficient estimation. We propose to perform the former with a deep neural network jointly trained with the encoder that divines a support that is used in the latter phase to estimate the coefficients by pseudo-inversion. Numerical evidence demonstrates that the proposed encoder-decoder architecture outperforms state-of-the-art Compressed Sensing (CS) approaches in the recovery of synthetic ECG signals for a compression ratio higher than 2.5. Further tests on real ECG prove the applicability in real-world scenarios.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073945","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073945","","Electrocardiography;Sensors;Decoding;Training;Image reconstruction;Estimation;Neural networks","","6","","29","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"EdgeDRNN: Enabling Low-latency Recurrent Neural Network Edge Inference","C. Gao; A. Rios-Navarro; X. Chen; T. Delbruck; S. -C. Liu","Institute of Neuroinformatics, University of Zurich and ETH Zurich, Zurich, Switzerland; Robotic and Technology of Computers Lab, Universidad de Sevilla, Seville, Spain; Institute of Neuroinformatics, University of Zurich and ETH Zurich, Zurich, Switzerland; Institute of Neuroinformatics, University of Zurich and ETH Zurich, Zurich, Switzerland; Institute of Neuroinformatics, University of Zurich and ETH Zurich, Zurich, Switzerland",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","41","45","This paper presents a Gated Recurrent Unit (GRU) based recurrent neural network (RNN) accelerator called EdgeDRNN designed for portable edge computing. EdgeDRNN adopts the spiking neural network inspired delta network algorithm to exploit temporal sparsity in RNNs. It reduces off-chip memory access by a factor of up to 10x with tolerable accuracy loss. Experimental results on a 10 million parameter 2-layer GRURNN, with weights stored in DRAM, show that EdgeDRNN computes them in under 0.5 ms. With 2.42 W wall plug power on an entry level USB powered FPGA board, it achieves latency comparable with a 92W Nvidia 1080 GPU. It outperforms NVIDIA Jetson Nano, Jetson TX2 and Intel Neural Compute Stick 2 in latency by 6X. For a batch size of 1, EdgeDRNN achieves a mean effective throughput of 20.2 GOp/s and a wall plug power efficiency that is over 4X higher than all other platforms.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9074001","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9074001","edge computing;FPGA;embedded system;deep learning;RNN;GRU;delta network","Throughput;Recurrent neural networks;Logic gates;Random access memory;Plugs;Graphics processing units;Field programmable gate arrays","","13","","16","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Zero Block Caching for CNN Applications Running on a Vision DSP","S. Lee; W. Kim; H. -J. Lee; K. Lee","Department of Electrical Engineering and Computer Science, Inter-university Semiconductor Research Center (ISRC), Seoul National University, Seoul, Korea; Department of Electrical Engineering and Computer Science, Inter-university Semiconductor Research Center (ISRC), Seoul National University, Seoul, Korea; Department of Electrical Engineering and Computer Science, Inter-university Semiconductor Research Center (ISRC), Seoul National University, Seoul, Korea; Department of Electronics Engineering, Sunmoon University, Asan, Korea",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","310","314","Digital Signal Processors (DSPs) nowadays are widely used for edge devices due to their power-efficiency in inference operations of Convolutional neural networks (CNNs). In most DSP systems, the ratio of zero-valued feature map data in a CNN is very high due to fixed-point quantization and activation functions like ReLu. This paper presents a new cache for a DSP system, zero block skip (ZBS) cache, to reduce off-chip memory access by caching the addresses of zero blocks in which all data are zero. In addition, a data remapping method is proposed for more zero block accesses to off-chip memory, which successfully increases the portion of zero blocks among all feature data blocks from 21.66% to 3S.7l% in Tiny YOLO network. However, it is observed that a ZBS cache using typical cache structure suffers from frequent capacity misses in some cases. To relieve the frequent capacity misses, zero block skip vector (ZBSV) for a group of blocks, each bit of which indicates whether a block is zero or not, is proposed. A ZBSV cache keeps the ZBSV entry for the currently accessed group. With DDR3 as an off-chip memory model, experiments show that four 2 KB ZBSV caches operate together effectively, with relatively lower SRAM power consumption. As a result, the proposed ZBSV cache reduces the off-chip memory access by 19.15% and 15.87% for Tiny YOLO and VDSR networks, respectively.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9074004","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9074004","DSP;feature map compression;off-chip memory access;memory power reduction;zero data cache","Random access memory;Quantization (signal);Indexes;Compression algorithms;Registers;Power demand;Neural networks","","","","18","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Accelerated Simulation of a Neuronal Population via Mathematical Model Order Reduction","M. Lehtimäki; I. Seppälä; L. Paunonen; M. -L. Linne","Faculty of Medicine and Health Technology, Tampere University, Tampere, Finland; Faculty of Medicine and Health Technology, Tampere University, Tampere, Finland; Faculty of Information Technology and Communication Sciences, Tampere University, Tampere, Finland; Faculty of Medicine and Health Technology, Tampere University, Tampere, Finland",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","118","122","Mathematical modeling of biological neuronal networks is important in order to increase understanding of the brain and develop systems capable of brain-like learning. While mathematical analysis of these comprehensive, stochastic, and complex models is intractable, and their numerical simulation is very resource intensive, mean-field modeling is an effective tool in enabling the analysis of these models. The mean-field approach allows the study of populations of biophysically detailed neurons with some assumptions of the mean behaviour of the population, but ultimately requires numerical solving of highdimensional differential equation systems. Mathematical model order reduction methods can be employed to accelerate the analysis of high-dimensional nonlinear models with a purely softwarebased approach. Here we compare state-of-the-art methods for improving the simulation time of a neuronal mean-field model and show that a nonlinear Fokker-Planck-McKean-Vlasov model can be accurately approximated in low-dimensional subspaces with these methods. Using Proper Orthogonal Decomposition and different variations of the Discrete Empirical Interpolation Method, we improved the simulation time by over three orders of magnitude while achieving low approximation error.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073844","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073844","","Mathematical model;Biological system modeling;Numerical models;Computational modeling;Sociology;Statistics;Brain modeling","","2","","40","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"An error-propagation spiking neural network compatible with neuromorphic processors","M. Cartiglia; G. Haessig; G. Indiveri","Institute of Neuroinformatics, University of Zurich and ETH Zurich, Zurich, Switzerland; Institute of Neuroinformatics, University of Zurich and ETH Zurich, Zurich, Switzerland; Institute of Neuroinformatics, University of Zurich and ETH Zurich, Zurich, Switzerland",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","84","88","Spiking neural networks have shown great promise for the design of low-power sensory-processing and edge-computing hardware platforms. However, implementing onchip learning algorithms on such architectures is still an open challenge, especially for multi-layer networks that rely on the back-propagation algorithm. In this paper, we present a spike-based learning method that approximates back-propagation using local weight update mechanisms and which is compatible with mixed-signal analog/digital neuromorphic circuits. We introduce a network architecture that enables synaptic weight update mechanisms to back-propagate error signals across layers and present a network that can be trained to distinguish between two spike-based patterns that have identical mean firing rates, but different spike-timings. This work represents a first step towards the design of ultra-low power mixed-signal neuromorphic processing systems with on-chip learning circuits that can be trained to recognize different spatio-temporal patterns of spiking activity (e.g. produced by event-based vision or auditory sensors).","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073856","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073856","","Neurons;Neuromorphics;Biological neural networks;Integrated circuit modeling;Mathematical model;Training","","4","","23","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Binary Models for Motor-Imagery Brain-Computer Interfaces: Sparse Random Projection and Binarized SVM","M. Hersche; L. Benini; A. Rahimi","Integrated Systems Laboratory, ETH Zurich, Switzerland; Integrated Systems Laboratory, ETH Zurich, Switzerland; Integrated Systems Laboratory, ETH Zurich, Switzerland",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","163","167","Successful motor imagery brain-computer (MIBCI) algorithms typically rely on a large number of features used in a classifier with real-valued weights that render them unsuitable for real-time execution on a resource-limited device. We propose a new method that randomly projects a large number of real-valued Riemannian covariance features to a binary space, where a linear SVM classifier can be learned with binary weights too. Flexibly increasing the dimension of binary embedding achieves almost the same accuracy (≤1.27% lower) compared to all models with float16 in 4-class and 3-class MI, yet delivering a more compact model with simpler operations to execute.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073968","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073968","EEG;motor imagery;embedding;sparse random projection;binarized SVM;Hamming distance.","Support vector machines;Electroencephalography;Feature extraction;Covariance matrices;Brain modeling;Kernel;Hamming distance","","2","","25","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Evolvable Hyperdimensional Computing: Unsupervised Regeneration of Associative Memory to Recover Faulty Components","M. Hersche; S. Sangalli; L. Benini; A. Rahimi","Integrated Systems Laboratory, ETH Zurich, Switzerland; Integrated Systems Laboratory, ETH Zurich, Switzerland; Integrated Systems Laboratory, ETH Zurich, Switzerland; Integrated Systems Laboratory, ETH Zurich, Switzerland",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","281","285","This paper proposes evolvable hyperdimensional (HD) computing to maintain high classification accuracy as permanent faults occur in emerging non-volatile memory fabrics. Our proposed HD architecture can detect, localize, and isolate faulty PCM blocks in discriminative classifiers, followed by unsupervised regeneration of new blocks to compensate accuracy loss. We demonstrate its application on a language recognition task: it is able to quickly relearn and fully recover the accuracy from 90.48% to 96.86% at fault rates as high as 42% by using solely 4. 2MB of text for regeneration. The new evolved model is still 285 more compact than state-of-the-art fastText.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073871","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073871","Evolvable hardware;HD computing;PCM.","Computer architecture;Phase change materials;Hamming distance;Task analysis;Training;Circuit faults;Computational modeling","","6","","17","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Low-Power HWAccelerator for AI Edge-Computing in Human Activity Recognition Systems","A. D. Vita; D. Pau; C. Parrella; L. D. Benedetto; A. Rubino; G. D. Licciardo","Department of Industrial Engineering, University of Salerno, Fisciano, SA, Italy; System Research and Applications, STMicroelectronics, Agrate Brianza, MI, Italy; Microcontrollers and Digital-IC, STMicroelectronics, Arzano, NA, Italy; Department of Industrial Engineering, University of Salerno, Fisciano, SA, Italy; Department of Industrial Engineering, University of Salerno, Fisciano, SA, Italy; Department of Industrial Engineering, University of Salerno, Fisciano, SA, Italy",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","291","295","In this paper, an energy efficient HW accelerator for AI edge-computing in Human Activity Recognition is proposed. The system processes samples from a tri-axial accelerometer and classifies the human activities by using a novel Hybrid Neural Network (HNN) topology, which has been designed to reduce the computational complexity of the system while preserving its accuracy. The HW design improves the characteristics of the HNN by means of an architecture that is aimed to reduce the allocated physical resources and the memory accesses. While accuracy measured on ad-hoc dataset is 97.5 %, measurements from synthesis with CMOS 65 nm standard cells report power consumption of 6.3 μW when the sensor output data rate is 25 Hz, normally used for HAR.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073913","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073913","artificial intelligence;edge computing;hardware;low power;human activity recognition","Neural networks;Computational modeling;Acceleration;Activity recognition;Accelerometers;Legged locomotion;Field programmable gate arrays","","18","","24","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"On-chip Few-shot Learning with Surrogate Gradient Descent on a Neuromorphic Processor","K. Stewart; G. Orchard; S. B. Shrestha; E. Neftci","Computer Science Department UC, Irvine, CA 92697-2625 USA, Irvine; Intel Labs, Intel Corporation, Santa Clara, California; Tamasek Laboratories @ NUS, National University of Singapore, Singapore; Cognitive Sciences Department and Computer Science Department UC, Irvine, CA 92697-2625 USA, Irvine",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","223","227","Recent work suggests that synaptic plasticity dynamics in biological models of neurons and neuromorphic hardware are compatible with gradient-based learning [1]. Gradient-based learning requires iterating several times over a dataset, which is both time-consuming and constrains the training samples to be independently and identically distributed. This is incompatible with learning systems that do not have boundaries between training and inference, such as in neuromorphic hardware. One approach to overcome these constraints is transfer learning, where a portion of the network is pre-trained and mapped into hardware and the remaining portion is trained online. Transfer learning has the advantage that pre-training can be accelerated offline if the task domain is known, and few samples of each class are sufficient for learning the target task at reasonable accuracies. Here, we demonstrate on-line surrogate gradient few-shot learning on Intel's Loihi neuromorphic research processor using features pre-trained with spike-based gradient backpropagation-through-time. Our experimental results show that the Loihi chip can learn gestures online using a small number of shots and achieve results that are comparable to the models simulated on a conventional processor.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073948","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073948","neuromorphic computing;spiking neural networks;on-chip learning;few-shot learning","Neurons;Neuromorphics;Task analysis;Training;Computational modeling;Biological neural networks;Hardware","","18","","19","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Live Demonstration: On-chip Few-shot Learning with Surrogate Gradient Descent on a Neuromorphic Processor","K. Stewart; G. Orchard; S. B. Shrestha; E. Neftci","Computer Science Department UC, Irvine, Irvine, CA, USA; Intel Labs Intel Corporation, Santa Clara, California; Tamasek Laboratories @ NUS, National University of Singapore, Singapore; Cognitive Sciences Department and Computer Science Department UC, Irvine, Irvine, CA, USA",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","128","128","This live demonstration will show real-time, embedded learning of gestures shown to a dynamics vision sensor in neuromorphic hardware. A multi-layer spiking neural network implemented in the Loihi neuromorphic processor partially trained on 11 classes of gestures will be able to learn new classes of gestures shown to the vision sensor by using a combination of transfer learning and local synaptic plasticity. Visitors will experience real-time learning of new classes of gestures they show to the vision sensor whose data is processed in real-time by the network on a connected neuromorphic chip.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073961","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073961","","Neuromorphics;Real-time systems;Vision sensors;System-on-chip;Neurons;Conferences;Computer science","","3","","3","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Neuromorphic Implementation of a Recurrent Neural Network for EMG Classification","Y. Ma; E. Donati; B. Chen; P. Ren; N. Zheng; G. Indiveri","Institute of Artificial Intelligence and Robotics, Xian Jiaotong University, Xian; Institute of Artificial Intelligence and Robotics, Xian Jiaotong University, Xian; Institute of Artificial Intelligence and Robotics, Xian Jiaotong University, Xian; Institute of Artificial Intelligence and Robotics, Xian Jiaotong University, Xian; Institute of Artificial Intelligence and Robotics, Xian Jiaotong University, Xian; Institute of Artificial Intelligence and Robotics, Xian Jiaotong University, Xian",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","69","73","Wearable sensor devices are disrupting healthcare technologies with a rapid increase of systems able to perform continuous monitoring of physiological data. These systems however typically produce large amounts of data that needs to be processed in real-time. Neuromorphic processors represent a promising class of devices that can be directly interfaced with the sensors to extract temporal data-streams in real-time with very low-power consumption. In this paper we present an application of such a neuromorphic approach for classifying electromyography (EMG) signals, that can be useful for designing compact wearable solutions for neuroprosthetic control. As the neuromorphic processor comprises configurable spiking neurons and adaptive synapses, we propose to use a spiking recurrent neural network (SRNN) for classifying the spatio-temporal data derived from the EMG signals. We performed a thorough investigation on the performance of the network implemented on the chip, by evaluating the classification performance of two hardware-friendly spike-based read-out models: a rate-based state distance model, and a spiking-time-dependent plasticity (STDP) learning model. The results were then compared with a classical machine learning approach based on the Support Vector Machine (SVM) method. Our results show how the classification accuracy of the state distance method is above 75%, which is even better than the SVM results; while the STDP learning rule only achieved 60% accuracy.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073810","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073810","","Neurons;Neuromorphics;Electromyography;Real-time systems;Support vector machines;Biological neural networks;Biological information theory","","12","","24","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"SpArNet: Sparse Asynchronous Neural Network execution for energy efficient inference","M. A. Khoei; A. Yousefzadeh; A. Pourtaherian; O. Moreira; J. Tapson","1 GrAI Matter Labs (GML), Paris, France; 2 GrAI Matter Labs (GML), Eindhoven, The Netherlands; 2 GrAI Matter Labs (GML), Eindhoven, The Netherlands; 2 GrAI Matter Labs (GML), Eindhoven, The Netherlands; 3 GrAI Matter Labs (GML), San-Jose, California, United States",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","256","260","Biological neurons are known to have sparse and asynchronous communications using spikes. Despite our incomplete understanding of processing strategies of the brain, its low energy consumption in fulfilling delicate tasks suggests the existence of energy efficient mechanisms. Inspired by these key factors, we introduce SpArNet, a bio-inspired quantization scheme to convert a pre-trained convolutional neural network to a spiking neural network, with the aim of minimizing the computational load for execution on neuromorphic processors. The proposed scheme has significant advantages over the reference CNN in a reduced number of synaptic operations, and can be used for frequent executions of inference tasks. The computational load of SpArNet is adjusted to the spatio-temporal dynamics of the the input data. We have tested the converted network on two applications (autonomous steering and hand gesture recognition), demonstrating a significant reduction on the number of required synaptic operations.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073827","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073827","","Neurons;Quantization (signal);Task analysis;Hardware;Biological neural networks;Encoding;Inference algorithms","","16","","29","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"A Real-Time Robot-Arm Surgical Guiding System Development by Image-Tracking","C. -H. Cheng","Feng Chia University, Taiwan",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","133","133","The endoscope is widely used for various diagnoses and treatments in Minimally Invasive Surgery (MIS), such as hysteroscopy, laparoscopy, and colonoscopy. However, the limited field of image of the endoscope is often the most problematic issue faced by surgeons and medical students, especially for those inexperienced physicians, which leads to difficulty during surgical operations. To reduce the difficulties of MIS with respect to endoscope function, the proposed identifying and locating techniques provide the angle and distance from the surgical instruments to the lesion. The in-time guiding information provides global positioning information by tracking the lesion position during surgery. The jointed with a robot-arm system can help an inexperienced surgeon with stable assistance for the long-time surgical operation. The whole system has been successfully validated by surgeons.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073805","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073805","","Surgery;Lesions;Endoscopes;Instruments;Robot kinematics","","1","","2","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"A Coarse-Grained Dual-Convolver Based CNN Accelerator with High Computing Resource Utilization","Y. Lu; Y. -L. Wu; J. -D. Huang","Institute of Electronics, National Chiao Tung University, Hsinchu, Taiwan; Institute of Electronics, National Chiao Tung University, Hsinchu, Taiwan; Institute of Electronics, National Chiao Tung University, Hsinchu, Taiwan",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","198","202","Deep learning technologies have been developed rapidly in recent years and have played an important role in our lives. Among them, convolutional neural network (CNN) performs well in many applications. The quality of result is generally getting better as the number of convolutional layers increases, which also increases the computational complexity. Hence, a highly resource-efficient accelerator is demanded. In this paper, we propose a new CNN accelerator that features a delay-chain-free input data aligner as well as a dual-convolver processing element (DCPE). Our architecture does not require delay chains with a large number of registers for input data alignment, which not only reduces the area and power but improves the overall resource utilization. In addition, a set of DCPEs shares the same input aligner to produce multiple output feature maps concurrently, which offers the desirable computing power and reduces the external memory traffic. An accelerator instance with 8 DCPEs (144 MACs) has been implemented using TSMC 40nm process. The internal logic only consumes 285K gates and the total internal memory size is merely 44KB. As running VGG-16, the average performance is 190GOPS (@750MHz), the resource (MAC) utilization reaches 8S.3%, and the energy efficiency is 481GOPS/W.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073835","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073835","convolutional neural network CNN;hardware accelerator;high resource utilization;low data bandwidth","Computer architecture;Convolvers;Kernel;Delays;Random access memory;Resource management","","4","","23","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Simulating Spiking Neural Networks with Timed Dataflow Graphs","L. Pan; F. Christophe; T. Mikkonen; Z. Li; S. S. Bhattacharyya","Dept.of ECE and UMIACS, University of Maryland, College Park, Maryland, USA; HAMK Tech, HAMK University of Applied Sciences, Hämeenlinna, Finland; Dept.of Computer Science, University of Helsinki, Helsinki, Finland; Dept.of Computer Science and Electrical Engineering, University of Missouri, Kansas City, Missouri, USA; Dept.of ECE and UMIACS, University of Maryland, College Park, Maryland, USA",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","64","68","This article presents a novel approach for simulating Spiking Neural Networks (SNNs) that is based on timed dataflow graphs. Whereas conventional SNN simulators compute changes in spiking neuron variables at each time step, the proposed simulation approach focuses on evaluating spike timings. This focus on evaluating when a dataflow actor (spiking neuron) reaches a new spike contributes to making spike evaluation an event-driven computation. The resulting event-driven simulation approach avoids unnecessary computations at time steps that lie between spiking events. This optimization is achieved while avoiding the large overheads associated with lookup tables that are incurred in existing event-driven approaches. Our results show identical spiking behavior compared to simulation using a conventional (time-based) simulator while providing significant improvement in execution time.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073928","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073928","Dataflow;model-based design;simulation;spiking neural networks.","Neurons;Computational modeling;Biological system modeling;Biological neural networks;Tools;Indexes;Integrated circuit modeling","","1","","17","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Neuromorphic Implementation of Spiking Relational Neural Network for Motor Control","J. Zhao; E. Donati; G. Indiveri","Institute of Neuroinformatics, University of Zurich and ETH Zurich, Zurich, Switzerland; Institute of Neuroinformatics, University of Zurich and ETH Zurich, Zurich, Switzerland; Institute of Neuroinformatics, University of Zurich and ETH Zurich, Zurich, Switzerland",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","89","93","Despite the rapid development of robotic control theory, hardware motor controllers still suffer from some disadvantages: they are computationally-intensive and rely on powerful computing systems which are usually implemented using bulky and power-hungry devices. On the other hand, biological motor control systems are power-efficient, light-weight and robust. Neuromorphic engineering sheds a light on how to uncover biological control features that could lead to the design of lower power and less bulky controllers. In this paper, we present a closed-loop motor controller implemented on mixed-signal analog-digital neuromorphic hardware using a spiking neural network. The network performs PI control by encoding target, feedback and error signals using population coding. It continuously calculates the error through the network, which relates the three variables by means of feed-forward inter-population synapses. This biologically plausible and fault-tolerant strategy is ideally suited for the use of neuromorphic hardware that comprises noisy silicon neurons. Here we show how to optimize the network structure to make it robust to both noisy inputs and device mismatch. We provide experimental results showing how the controller can reach 97.1% accuracy with 75.8 ms average latency.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073829","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073829","Spiking neural network;neuromorphic device;motor control;relational neural networks","Neurons;Sociology;Statistics;Neuromorphics;Biological information theory;Synapses;Biological neural networks","","14","","18","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Deep Neural Network Mapping and Performance Analysis on Tiled RRAM Architecture","X. Wang; Q. Wang; F. -H. Meng; S. H. Lee; W. D. Lu","Electrical Engineering and Computer Science, University of Michigan; Electrical Engineering and Computer Science, University of Michigan; Electrical Engineering and Computer Science, University of Michigan; Electrical Engineering and Computer Science, University of Michigan; Electrical Engineering and Computer Science, University of Michigan",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","141","144","Representative deep neural networks (DNNs) have been successfully mapped on an RRAM-based tiled in-memory computing (IMC) architecture. Effects of finite array size and quantized partial products (PPs) due to ADC precision constraints have been analyzed. Methods were developed to solve these challenges and preserve DNN accuracies and IMC performance gains in the tiled architecture. Popular models VGG-16, MobileNet, and RNN/LSTM have been successfully implemented and tested on ImageNet dataset and text classification tasks, respectively.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073942","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073942","RRAM;Deep Neural Network;In-Memory Computing;AI Accelerator","Quantization (signal);Computer architecture;Integrated circuit modeling;Neural networks;Virtual machine monitors;Task analysis;Load modeling","","5","","7","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"TentacleNet: A Pseudo-Ensemble Template for Accurate Binary Convolutional Neural Networks","L. Mocerino; A. Calimera","Politecnico di Torino, Torino, Italy; Politecnico di Torino, Torino, Italy",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","261","265","Binarization is an attractive strategy for implementing lightweight Deep Convolutional Neural Networks (CNNs). Despite the unquestionable savings offered, memory footprint above all, it may induce an excessive accuracy loss that prevents a widespread use. This work elaborates on this aspect introducing TentacleNet, a new template designed to improve the predictive performance of binarized CNNs via parallelization. Inspired by the ensemble learning theory, it consists of a compact topology that is end-to-end trainable and organized to minimize memory utilization. Experimental results collected over three realistic benchmarks show TentacleNet fills the gap left by classical binary models, ensuring substantial memory savings w.r.t. state-of-the-art binary ensemble methods.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073982","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073982","","Training;Computer architecture;Topology;Hardware;Task analysis;Image recognition;Boosting","","3","","32","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"EAST: Encoding-Aware Sparse Training for Deep Memory Compression of ConvNets","M. Grimaldi; V. Peluso; A. Calimera","Politecnico di Torino, Torino, Italy; Politecnico di Torino, Torino, Italy; Politecnico di Torino, Torino, Italy",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","233","237","The implementation of Deep Convolutional Neural Networks (ConvNets) on tiny end-nodes with limited non-volatile memory space calls for smart compression strategies capable of shrinking the footprint yet preserving predictive accuracy. There exist a number of strategies for this purpose, from those that play with the topology of the model or the arithmetic precision, e.g. pruning and quantization, to those that operate a model agnostic compression, e.g. weight encoding. The tighter the memory constraint, the higher the probability that these techniques alone cannot meet the requirement, hence more awareness and cooperation across different optimizations become mandatory. This work addresses the issue by introducing EAST, Encoding-Aware Sparse Training, a novel memory-constrained training procedure that leads quantized ConvNets towards deep memory compression. EAST implements an adaptive group pruning designed to maximize the compression rate of the weight encoding scheme (the LZ4 algorithm in this work). If compared to existing methods, EAST meets the memory constraint with lower sparsity, hence ensuring higher accuracy. Results conducted on a state-of-the-art ConvNet (ResNet-9) deployed on a low-power microcontroller (ARM Cortex-M4) validate the proposal.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073979","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073979","","Training;Encoding;Quantization (signal);Memory management;Standards;Optimization;Tensile stress","","2","","16","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Effect of Process Variations in Digital Pixel Circuits on the Accuracy of DNN based Smart Sensor","M. Lee; M. Mukherjee; P. Saha; M. F. Amir; T. Na; S. Mukhopadhyay","School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","296","300","The digital pixel based image sensors with 3D integrated and pixel-parallel read-out-integrated-circuits (ROIC) show potential for high resolution and high frame rate in many mission critical surveillance applications. However, fixed pattern noise (FPN) caused by process variations of ROIC aggravates the quality of image and further degrades the performance of deep neural network (DNN). This paper studies the effect of process variations in digital pixel circuits and resulting image noise on the accuracy of a DNN. We propose a digital pixel-DNN cross-layer simulation methodology for accurate training and evaluation of DNN under noise induced from process variations. The simulation results show that the process variation in the digital pixel creates distinct noise structure and should be accurately considered while training a DNN. We also present design space explorations using our cross-layer simulation.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073975","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073975","","Voltage control;Image sensors;Object detection;AWGN;Noise measurement;Mathematical model;Integrated circuit modeling","","6","","30","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Soft Error Mitigation for Deep Convolution Neural Network on FPGA Accelerators","W. Li; G. Ge; K. Guo; X. Chen; Q. Wei; Z. Gao; Y. Wang; H. Yang","Department of Electronic Engineering, BNRist, Tsinghua University, Beijing, China; Department of Electronic Engineering, BNRist, Tsinghua University, Beijing, China; Department of Electronic Engineering, BNRist, Tsinghua University, Beijing, China; State Key Laboratory of Computer Architecture, Institute of Computing Technology, CAS, Beijing, China; Department of Electronic Engineering, BNRist, Tsinghua University, Beijing, China; Tianjin International Engineering Institute, Tianjin University, Tianjin, China; Department of Electronic Engineering, BNRist, Tsinghua University, Beijing, China; Department of Electronic Engineering, BNRist, Tsinghua University, Beijing, China",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","1","5","Convolution neural networks (CNNs) have been widely used in many applications. Field-Programmable Gate Array (FPGA) based accelerator is an ideal solution for CNNs in embedded systems. However, the single event upset (SEU) effect in FPGA device may have a significant influence on the performance of CNNs. In this paper, we analyze the sensibility of CNNs to SEU and present a fault-tolerant design for CNN accelerators. First, we find that SEU in processing elements (PEs) has the worst effects on CNNs since it produces proportional errors and will not get refreshed. Furthermore, it is indicated that the large positive perturbation contributes almost all of the performance loss. Based on such observations, we propose an error detecting scheme to locate incorrect PEs and give an error masking method to achieve fault-tolerance. Experiments demonstrate that the proposed method achieves similar fault-tolerant performance with the triple modular redundancy (TMR) scheme while the overhead is much lower than it.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073925","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073925","","Table lookup;Adders;Field programmable gate arrays;Single event upsets;Neural networks;Fault tolerance","","16","","23","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"An End-to-End Deep Learning Approach for Epileptic Seizure Prediction","Y. Xu; J. Yang; S. Zhao; H. Wu; M. Sawan","CenBRAIN, School of Engineering, Westlake University, Hangzhou, Zhejiang, China; CenBRAIN, School of Engineering, Westlake University, Hangzhou, Zhejiang, China; CenBRAIN, School of Engineering, Westlake University, Hangzhou, Zhejiang, China; Department of Neurosurgery, Zhejiang University School of Medicine Second Affiliated Hospital, Hangzhou, Zhejiang, China; CenBRAIN, School of Engineering, Westlake University, Hangzhou, Zhejiang, China",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","266","270","An accurate seizure prediction system enables early warnings before seizure onset of epileptic patients. It is extremely important for drug-refractory patients. Conventional seizure prediction works usually rely on features extracted from Electroencephalography (EEG) recordings and classification algorithms such as regression or support vector machine (SVM) to locate the short time before seizure onset. However, such methods cannot achieve high-accuracy prediction due to information loss of the hand-crafted features and the limited classification ability of regression and SVM algorithms. We propose an end-to-end deep learning solution using a convolutional neural network (CNN) in this paper. One and two dimensional kernels are adopted in the early- and late-stage convolution and max-pooling layers, respectively. The proposed CNN model is evaluated on Kaggle intracranial and CHB-MIT scalp EEG datasets. Overall sensitivity, false prediction rate, and area under receiver operating characteristic curve reaches 93.5%, 0.063/h, 0.981 and 98.8%, 0.074/h, 0.988 on two datasets respectively. Comparison with state-of-the-art works indicates that the proposed model achieves exceeding prediction performance.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073988","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073988","epilepsy;seizure prediction;electroencephalography (EEG);convolutional neural network;deep learning;end-to-end;one dimensional kernel","Electroencephalography;Convolution;Kernel;Brain modeling;Dogs;Feature extraction;Two dimensional displays","","43","","39","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Implementation of a tunable spiking neuron for STDP with memristors in FDSOI 28nm","L. A. Camuñas-Mesa; B. Linares-Barranco; T. Serrano-Gotarredona","Instituto de Microelectrόnica de Sevilla (IMSE-CNM), CSIC and Universidad de Sevilla, Sevilla, Spain; Instituto de Microelectrόnica de Sevilla (IMSE-CNM), CSIC and Universidad de Sevilla, Sevilla, Spain; Instituto de Microelectrόnica de Sevilla (IMSE-CNM), CSIC and Universidad de Sevilla, Sevilla, Spain",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","94","98","Hybrid memristor-CMOS techniques have been recently proposed to build large-scale neural networks with learning capabilities. The intrinsic characteristics of memristors make them specially suited to implement synaptic connections between layers of spiking neurons, undergoing STDP learning (Spike-Timing-Dependent Plasticity) mechanisms when processing spikes with particular shapes. In a previous work, we proposed a tunable spiking neuron circuit which can generate spikes with controllable shape. In this work, the spike generator circuit has been implemented in FDSOI 28nm technology, and it has demonstrated its capability to produce spikes with pulse widths in the range between 8μs and 100ms.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073994","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073994","Spiking Neural Networks;Event-driven processing;STDP;Memristors","Neurons;Memristors;Generators;Shape;Voltage control;Neuromorphics;Biological neural networks","","4","","21","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Efficient Embedded Deep Neural-Network-based Object Detection Via Joint Quantization and Tiling","G. Plastiras; S. Siddiqui; C. Kyrkou; T. Theocharides",KIOS Research and Innovation Center of Excellence; KIOS Research and Innovation Center of Excellence; KIOS Research and Innovation Center of Excellence; KIOS Research and Innovation Center of Excellence,2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","6","10","Embedded visual AI is a growing trend in applications requiring low latency, real-time decision support, increased robustness and security. Visual object detection, a key task in visual data analytics, has enjoyed significant improvements in terms of capabilities and accuracy due to the emergence of Convolutional Neural Networks (CNNs). However, such complex paradigms require heavy computational resources that prevent their deployment on resource-constrained devices, and in particular, impose significant constraints in possible hardware accelerators geared towards such applications. In this work therefore, we investigate how a combination of techniques can lead to efficient visual AI pipelines for resource-constrained object detection. In particular we leverage an efficient search strategy based on a combination of pre-processing mechanisms, that reduce the processing demands of deep network as a counter measure for potential accuracy reduction caused by quantization. The proposed approach enables the detection of objects in higher resolution frames using quantized models, while maintaining the accuracy of full-precision CNN-based object detectors. We illustrate the impact on the accuracy and average processing time using quantization techniques and different tiling approaches on efficient object detection architectures; as a case study, we focus on Unmanned-Aerial- Vehicles (UAVs). Through the proposed methodology, hardware accelerator demands are thereby reduced, leading to both performance benefits and associated power savings.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073885","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073885","","Quantization (signal);Detectors;Object detection;Visualization;Image resolution;Real-time systems;Pipelines","","9","","32","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"A 35x10 Charge-Trap Synaptic Memory for 57xMatrix Recognition","E. -J. Park; J. -M. Choi; D. -W. Kwon; J. -J. Woo; K. -W. Kwon","College of Information and Communication Engineering, Sungkyunkwan University, Suwon, Republic of Korea; College of Information and Communication Engineering, Sungkyunkwan University, Suwon, Republic of Korea; College of Information and Communication Engineering, Sungkyunkwan University, Suwon, Republic of Korea; College of Information and Communication Engineering, Sungkyunkwan University, Suwon, Republic of Korea; College of Information and Communication Engineering, Sungkyunkwan University, Suwon, Republic of Korea",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","99","102","In this paper, we demonstrate the 35×10 neuromorphic system based on the charge-trap(CT) synaptic memories for learning and recognition of 5×7 dot matrix patterns. The CT memory can be linearly and symmetrically programmed by using regulated-step-pulse-programming(RSPP). We simulated CT memory in 180nm CMOS process technology with a behavioral model we have developed. The power dissipation of RSPP was significantly reduced than incremental-step-pulse-programming (ISPP). Also, we obtained 7 bits weight similar to ISPP. In neuromorphic system, we used the algorithm that updates not only when input is +1 but also when -1 to do not forget the previously learned data. The recognition rate is about 97% in 1 dot errors, and the recognition rate for all dot errors is about 90%.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073813","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073813","Charge-trap memory;synaptic device;incremental-step-pulse-programming (ISPP);regulated-step-pulse-programming (RSPP);neuromorphic system;dot matrix","Computer architecture;Erbium;Training;Microprocessors;Computed tomography;Neuromorphics;Generators","","1","","9","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Tunneling-based CMOS Floating Gate Synapse for Low Power Spike Timing Dependent Plasticity","M. Mastella; F. Toso; G. Sciortino; E. Prati; G. Ferrari","Dipartimento di elettronica, informazione e bioingegneria, I-20133 Milano, Italy; Dipartimento di elettronica, informazione e bioingegneria, I-20133 Milano, Italy; Dipartimento di elettronica, informazione e bioingegneria, I-20133 Milano, Italy; Istituto di Fotonica e Nanotecnologie, Consiglio Nazionale delle Ricerche, Piazza Leonardo da Vinci 32, Milano, Italy; Dipartimento di elettronica, informazione e bioingegneria, I-20133 Milano, Italy",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","213","217","We propose a CMOS architecture for spiking neural networks with permanent memory and online learning. It uses a three-transistors synapse with a floating node that stores the synaptic weight, programmed by using only Fowler-Nordheim tunneling current in the pA range for ultra-low power operation. A neuron with a conditioning circuit programs the floating gate synapse following the spike timing dependent plasticity rule. Simulations using a standard 150 nm CMOS process show the online learning capabilities of the architecture.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073965","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073965","VLSI;floating gate;STDP;spiking;synapse","Neurons;Synapses;Logic gates;Tunneling;Transistors;High-voltage techniques;Timing","","3","","27","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Fault-Tolerant-Driven Clustering for Large Scale Neuromorphic Computing Systems","Y. Wu; B. Ding; Q. Xu; S. Chen","School of Microelectronics, University of Science and Technology of China; School of Microelectronics, University of Science and Technology of China; School of Electronic Science and Applied Physics, Hefei University of Technology; School of Microelectronics, University of Science and Technology of China",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","238","242","Memristive crossbar-based neuromorphic computing systems (NCS) have been extensively investigated and applied to the neural networks due to the fast computation and low design cost. In most applications, neural networks are large and sparse, which violate the size limitations and high-density connections provided by the memristive crossbars. Besides, stuck-at-faults (SAFs) in the memristor devices significantly degrade the computing accuracy of NCS. In this paper, we propose a fault-driven clustering framework for NCS based on a set of unique size memristive crossbars, with consideration of both hardware cost and mapping success rate. First, in order to group the input neurons connected to different output neurons, we design a METIS-based clustering method by redefining the distance metric, to speed up the large-scale neural network partitioning and improve the fault tolerance of the memristive crossbar-based NCS, then map the synapses to a set of unique size crossbars. Second, a half transposition method is developed to address the extremely asymmetric clusters. The simulation results show that the proposed fault tolerance-aware clustering algorithm not only improves the mapping success rate and the hardware cost but also achieves speed-up. For example, for a large-scale neural network with four million synapses, the proposed framework can complete the algorithm in one hour.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073791","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073791","","Neurons;Fault tolerance;Fault tolerant systems;Neural networks;Memristors;Measurement;Synapses","","1","","10","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Energy-Efficient Accelerator Design with 3D-SRAM and Hierarchical Interconnection Architecture for Compact Sparse CNNs","C. -Y. Lo; P. -T. Huang; W. Hwang","Department of Electronics Engineering, National Chiao Tung University, Taiwan; International College of Semiconductor Technology, National Chiao Tung University, Taiwan; Department of Electronics Engineering, National Chiao Tung University, Taiwan",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","320","323","Deep learning applications are deployed to both resource and energy constrained edge devices via compact and sparse CNN models. However, sparsity, feature sizes and filter shapes are widely varying in deep networks resulting in inefficient resource utilization and data movement. In this paper, an energy-efficient accelerator is proposed for compact sparse CNNs by a flexible hierarchical on-chip interconnection architecture, 32 PE tiles and 3D-SRAM. 3D-SRAM are utilized as distributed memory for PE-tiles to hold intermediate data between layers for reducing the energy consumption of off-chip DRAM accesses. Based on distributed 3D-SRAM, output stationary dataflow is adopted without data movement of partial sums among PEs. Therefore, the 32 PE tiles are connected through a configurable ring-based unicast global network with micro-routers, which decreases implementation cost compared to a typical router for a mesh network. Each PE tile is implemented by an all-to-all local network to support widely varying sizes, shapes and non-zero activation computations of compact sparse CNNs. Overall, the proposed accelerator achieves 509.8 inference/sec, 1860.5 inference/J and 383.3 GOPS/W with MobileNetV2, and improves the energy efficiency by a factor of 1.43x over a dense architecture.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073944","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073944","","Random access memory;Convolution;Computer architecture;Indexes;System-on-chip;Decoding;Distributed databases","","6","","10","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Hardware Feasibility Analysis of Spatial Propagation Algorithms","C. -T. Lin; S. -Y. Chien",National Taiwan University; National Taiwan University,2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","324","324","Although convolutional neural networks (CNNs) have revolutionized many computer vision tasks in recent years, spatial propagation algorithm still plays an important role in many applications such as image matting, segmentation, depth estimation, and colorization. However, most of these methods focus on qualitative performance and result in expensive computation, which is not conducive to be deployed on mobile or edge devices. In this paper, we take the spatial propagation network (SPN), convolutional spatial propagation network (CSPN), and guided convolution as our analysis objects. We evaluate these methods from the hardware accelerating aspect and use depth completion as an example. In addition to quality comparison, we propose a hardware feasibility metric that analyzes each method in terms of hardware resources. With this metric, developers can easily decide a proper algorithm on a specific hardware platform. We apply it to an example and get a consistent result, successfully building the connection between algorithm and hardware design.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073960","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073960","","Hardware;Task analysis;Computer vision;Image edge detection;Measurement;Image segmentation;Buildings","","","","0","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Lifetime Enhancement for RRAM-based Computing-In-Memory Engine Considering Aging and Thermal Effects","S. Zhang; G. L. Zhang; B. Li; H. H. Li; U. Schlichtmann","1 Chair of Electronic Design Automation; 1 Chair of Electronic Design Automation; 1 Chair of Electronic Design Automation; Institute for AdvancedStudy, Technical University of Munich (TUM), Munich, Germany; 1 Chair of Electronic Design Automation",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","11","15","RRAM-based computing-in-memory engines provide a promising platform to accelerate deep neural networks. The programming process imposes high voltages onto the RRAM cells and thus degrades their valid conductance ranges from the fresh state, an effect called aging. Consequently, the expected conductances of RRAM cells corresponding to the weights after training may fall outside of the valid ranges, potentially leading to a significant accuracy degradation. In addition, an uneven temperature distribution due to different conductances accelerates the aging effect further. Moreover, the uneven temperatures can cause accuracy discrepancy between the tuning process and inference, thus reducing the lifetime of such accelerators even further. In this paper, we propose to counter aging and thermal effects by distributing aging stress and high-temperature RRAM cells evenly, during both software training and hardware mapping, to extend the lifetime of computing-in-memory engines. Experimental results demonstrate lifetime enhancement up to 453 times while maintaining the classification accuracy.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073995","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073995","","Aging;Tuning;Training;Software;Programming;Resistance;Neural networks","","28","","22","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Wearable DPM System with Intelligent Imager and GPU","L. Miyashita; M. Ishikawa","Department of Information Physics Computing, The University of Tokyo; Department of Information Physics Computing, The University of Tokyo",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","129","130","Dynamic Projection Mapping (DPM) can provide intelligent information visualization based on object recognition. In this paper, we propose a wearable DPM system using an intelligent imager and a GPU, and demonstrate DPM with 1,000fps high-speed target tracking and 60fps image rendering. The proposed system will show high-speed and adaptive projection as if the projection image was printed on a target.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073788","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073788","Dynamic projection mapping;Vision chip;High-speed image processing;Wearable device","Graphics processing units;Object recognition;Target tracking;Shape;Visualization;Sensors","","2","","4","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Real-Time SLAM Based on Image Stitching for Autonomous Navigation of UAVs in GNSS-Denied Regions","M. Rizk; A. Mroue; M. Farran; J. Charara","Department of Physics and Electronics, Lebanese University, Lebanon; Department of Computer and Communication Engineering, Lebanese International University, Lebanon; Department of Computer and Communication Engineering, Lebanese International University, Lebanon; Department of Physics and Electronics, Lebanese University, Lebanon",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","301","304","This paper introduces a novel visual Simultaneous Localization and Mapping (SLAM) system, which is based on image stitching technique. It is proposed to determine the position of unmanned aerial vehicles (UAVs) in GNSS-denied regions. Image stitching technique is adopted to overcome the limitations of current methods in terms of complexity and memory requirement. Also, the proposed method provides a solution to localize UAVs in unknown paths and to cope with modifications of landmarks. To evaluate the proposed method, several experiments have been conducted targeting datasets of images captured by UAVs in different environments. The obtained results demonstrate the effectiveness of the proposed method.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073793","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073793","UAV;SLAM;GNSS-free navigation;autonomous","Feature extraction;Simultaneous localization and mapping;Global navigation satellite system;Cameras;Visualization;Receivers","","13","","31","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"A Digital Multiplier-less Neuromorphic Model for Learning a Context-Dependent Task","H. Asgari; B. M. -N. Maybodi; R. Kreiser; Y. Sandamirskaya","Department of Electrical Engineering, Shahid Beheshti University Tehran, Iran; Department of Electrical Engineering, Shahid Beheshti University Tehran, Iran; Institute of Neuroinformatics, University of Zurich and ETH Zurich, Switzerland; Institute of Neuroinformatics, University of Zurich and ETH Zurich, Switzerland",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","123","127","Highly efficient performance-resources trade-off of the biological brain is a motivation for research on neuromorphic computing. Neuromorphic engineers develop event-based spiking neural networks (SNNs) in hardware. Learning in SNNs is a challenging topic of current research. Reinforcement learning (RL) is a particularly promising learning paradigm, important for developing autonomous agents. In this paper, we propose a digital multiplier-less hardware implementation of an SNN with RL capability. The network is able to learn stimulus-response associations in a context-dependent learning task. Validated in a robotic experiment, the proposed model replicates the behavior in animal experiments and the respective computational model.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073881","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073881","Neuromorphic engineering;spiking neural networks;reinforcement learning;context-dependent task","Neurons;Synapses;Task analysis;Hardware;Field programmable gate arrays;Neuromorphics;Integrated circuit modeling","","2","","22","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"An Architectural Study for Inference Coprocessor Core at the Edge in IoT Sensing","D. Watanabe; Y. Yano; S. Izumi; H. Kawaguchi; K. Takeuchi; T. Hiramoto; S. Iwai; M. Murakata; M. Yoshimoto","Graduate School of Science Technology and Innovation, Kobe University, Kobe, Japan; Graduate School of System Informatics, Kobe University, Kobe, Japan; Graduate School of System Informatics, Kobe University, Kobe, Japan; Graduate School of Science Technology and Innovation, Kobe University, Kobe, Japan; Institute of Industrial Science the University of Tokyo, Tokyo, Japan; Institute of Industrial Science the University of Tokyo, Tokyo, Japan; SALTYSTER, Shiojiri, Japan; Device&System Platform Development Center, Kawasaki, Japan; Graduate School of System Informatics, Kobe University, Kobe, Japan",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","305","309","In this paper, random forest (RF), convolutional neural network (CNN), and support vector machine (SVM) algorithms are evaluated in terms of accuracy and performance for one-dimensional time series data in the target application fields of wearable healthcare and factory automation, considering field programmable gate array (FPGA) and system-on-a-chip (SoC) implementations. The results show that the RF is an optimal learning/inference algorithm from the viewpoint of energy efficiency and that the CNN is effective for high-precision applications. For e,ample, in arrhythmia detection, the inference accuracies of RF and CNN are 94% and 97%, respectively. In contrast, RF is approximately 4 orders higher in energy efficiency. Ne,t, an architecture for the inference coprocessor core embedded at the edge sensor was proposed, which can efficiently implement the above RF and CNN inference algorithms. An inference-oriented data-path that accelerates CNN computation was proposed, allowing for a faster order of computation with approximately 1/8 power consumption. Additionally, a port-reconfigurable RAM that increases the memory bandwidth for RF and CNN processing was introduced, which doubles the energy efficiency for RF processing. As a result, in arrhythmia detection, heartbeat interval e,traction, and human activity classification (three wearable applications), the power consumption of the RF inference coprocessor was estimated to be 0.6 μW, 0.4 μW, and 0.4 μW, respectively, assuming a standard low-power 65-nm CMOS technology.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073992","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073992","Coprocessor;ioT;low power inference;machine learning;soC","Conferences;Machine learning;Coprocessors;Medical services;Heart beat;Manufacturing automation","","4","","8","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"A Real-Time Retinomorphic Simulator Using a Conductance-Based Discrete Neuronal Network","S. Baek; J. K. Eshraghian; W. Thio; Y. Sandamirskaya; H. H. C. Iu; W. D. Lu","College of Electrical and Computer Engineering, Chungbuk National University, Cheongju, South Korea; School of Electrical, Electronic and Computer Engineering, University of Michigan, Ann Arbor, MI, USA; School of Electrical, Electronic and Computer Engineering, University of Michigan, Ann Arbor, MI, USA; Institute of Neuroinformatics Neuroscience Center Zurich University and ETH Zurich, Switzerland; School of Electrical, Electronic and Computer Engineering, University of Western Australia, Crawley, WA, Australia; School of Electrical, Electronic and Computer Engineering, University of Michigan, Ann Arbor, MI, USA",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","79","83","We present an optimized conductance-based retina microcircuit simulator which transforms light stimuli into a series of graded and spiking action potentials through photo transduction. We use discrete retinal neuron blocks based on a collation of single-compartment models and morphologically realistic formulations, and successfully achieve a biologically real-time simulator. This is done by optimizing the numerical methods employed to solve the system of over 270 nonlinear ordinary differential equations and parameters. Our simulator includes some of the most recent advances in compartmental modeling to include five intrinsic ion currents of each cell whilst ensuring real-time performance, in attaining the ion-current and membrane responses of the photoreceptor rod and cone cells, the bipolar and amacrine cells, their laterally connected electrical and chemical synapses, and the output ganglion cell. It exhibits dynamical retinal behavior such as spike-frequency adaptation, rebound activation, fast-spiking, and subthreshold responsivity. Light stimuli incident at the photoreceptor rod and cone cells is modulated through the system of differential equations, enabling the user to probe the neuronal response at any point in the network. This is in contrast to many other retina encoding schemes which prefer to `black-box' the preceding stages to the spike train output. Our simulator is made available open source, with the hope that it will benefit neuroscientists and machine learning practitioners in better understanding the retina subcircuitries, how retina cells optimize the representation of visual information, and in generating large datasets of biologically accurate graded and spiking responses.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073963","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073963","biological;photoreceptors;retina;simulator;spiking neural network","Retina;Computer architecture;Biological system modeling;Microprocessors;Neurons;Computational modeling;Mathematical model","","8","","25","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"A Bio-Inspired Model of Sound Source Localization on Neuromorphic Hardware","T. Oess; M. Löhr; C. Jarvers; D. Schmid; H. Neumann","Institute for Neural Information Processing Ulm University, Ulm, Germany; Institute for Neural Information Processing Ulm University, Ulm, Germany; Institute for Neural Information Processing Ulm University, Ulm, Germany; Institute for Neural Information Processing Ulm University, Ulm, Germany; Institute for Neural Information Processing Ulm University, Ulm, Germany",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","103","107","Auditory sound source localization with only two ears is a computationally intensive problem. Nevertheless, some animals show impressive performance solving it. Neurons in the auditory system of these animals are specialized to exploit spatial information from binaural sound signals. A set of neurons located in the lateral superior olivary (LSO) complex responds to interaural level differences. Here, we present a spike-based sound source localization model inspired by neurons in the LSO that computes the level difference of incoming spike signals by integrating excitatory and inhibitory inputs for localizing sound sources. The model is implemented on the IBM TrueNorth neurosynaptic system to achieve real-time compute performance. We introduce system components, like spectro-temporal smoothing and weighted sum units and explain how they are implemented on the TrueNorth chip. Correct behavior for synthetic inputs is demonstrated. Finally, test scenarios with recorded natural sounds indicate that the system reliably computes the interaural level difference of perceived sound sources.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073935","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073935","","Computational modeling;Mathematical model;Reliability;Spectrogram;Neuromorphics","","3","","17","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Neuro-PULP: A Paradigm Shift Towards Fully Programmable Platforms for Neural Interfaces","P. D. Schiavone; D. Rossi; Y. Liu; S. Benatti; S. Luan; I. Williams; L. Benini; T. Constandinou","ETH Zurich, Switzerland; Imperial College London, UK; University of Bologna, Italy; Imperial College London, UK; University of Bologna, Italy; University of Bologna, Italy; Imperial College London, UK; University of Bologna, Italy",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","50","54","Designing systems with many recording channels is a major challenge in brain-machine interfaces. Power, bandwidth, and size requirements impose tight design constraints for implementing the required processing within an acceptable latency and battery life. Moreover, the variety of brain decoding algorithms require highly versatile systems that can be rapidly adapted to execute different tasks from experiment to experiment as for example microcontrollers (MCUs). However, state of the art MCUs lack of performance and consume too much power to be used as generic platforms for neural decoding applications. To overcome the aforementioned limitations, this paper presents an MCU-based system consisting of a 64-channel event-based neural interface and a Parallel Ultra-Low-Power (PULP) platform that acquires and processes the neural activity. The flexibility of the system (called Neuro-PULP) has been demonstrated through the deployment of two applications: one compressing raw data in streaming mode for wireless transmission, and one generating the cluster and time-stamp of detected spikes, leveraging a low-power event-mode. The event-based approach, coupled with the energy efficiency of the PULP architecture, leads to a more than 4x improvement in energy efficiency with respect to state of the art systems based on FPGAs, leading to the average power consumption of 114 μW/channel, yet retaining the flexibility of fully programmable processor-based architectures.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073920","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073920","","Sorting;Power demand;Performance evaluation;Signal processing algorithms;Bandwidth;Computer architecture;Clustering algorithms","","","","22","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Online Extreme Learning Machine Design for the Application of Federated Learning","Y. -T. Chen; Y. -C. Chuang; A. -Y. Wu","Graduate Institute of Electronics Engineering, National Taiwan University, Taipei, Taiwan; Graduate Institute of Electronics Engineering, National Taiwan University, Taipei, Taiwan; Graduate Institute of Electronics Engineering, National Taiwan University, Taipei, Taiwan",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","188","192","In this paper, we propose a federated extreme learning machine system (Fed-ELMS) to meet the demand for federated learning scenarios. In the scenario of federated learning, data is kept on edge devices to preserve the privacy of data, while metadata, such as model parameters, are exchanged between a centralized cloud server and edge devices. Despite non-independent and identically distributed (non-IID) and imbalanced data across edge devices, we show that Fed-ELMS can still achieve comparable performance with only 3.3% accuracy loss compared to a centralized ELM trained with IID and balanced data. (a) Moreover, by quantizing input weights and biases, parameters of a model and transmission power consumption between cloud and edge are dramatically reduced. Compared With conventional neural networks (NNs) with the same transmission cost, the proposed Fed-ELMS outperforms FederatedAveraging NN (Fed- NN) by 2.3% accuracy and the fine-tuning process is 7%-33% less time-consuming. Therefore, the proposed Fed-ELMS is a promising system for edge devices to support the future trend of federated learning.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073802","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073802","Federated learning;online sequential extreme learning machine","Servers;Computational modeling;Engines;Artificial neural networks;Metadata;Performance evaluation;Data privacy","","10","","10","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Exploiting Event Cameras for Spatio-Temporal Prediction of Fast-Changing Trajectories","M. Monforte; A. Arriandiaga; A. Glover; C. Bartolozzi","Università degli Studi di Genoa, Italy; Event-Driven Perception for Robotics, Istituto Italiano di Tecnologia, Italy; Event-Driven Perception for Robotics, Istituto Italiano di Tecnologia, Italy; Event-Driven Perception for Robotics, Istituto Italiano di Tecnologia, Italy",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","108","112","This paper investigates trajectory prediction for robotics, to improve the interaction of robots with moving targets, such as catching a bouncing ball. Unexpected, highly-non-linear trajectories cannot easily be predicted with regression-based fitting procedures, therefore we apply state of the art machine learning, specifically based on Long-Short Term Memory (LSTM) architectures. In addition, fast moving targets are better sensed using event cameras, which produce an asynchronous output triggered by spatial change, rather than at fixed temporal intervals as with traditional cameras. We investigate how LSTM models can be adapted for event camera data, and in particular look at the benefit of using asynchronously sampled data.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073855","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073855","","Cameras;Trajectory;Robot vision systems;Target tracking;Visualization","","4","","22","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Low Power In-Memory Implementation of Ternary Neural Networks with Resistive RAM-Based Synapse","A. Laborieux; M. Bocquet; T. Hirtzlin; J. . -O. Klein; L. H. Diez; E. Nowak; E. Vianello; J. . -M. Portal; D. Querlioz","Universit´e Paris-Saclay, CNRS, C2N, Palaiseau, France; IM2NP, Univ. Aix-Marseille et Toulon, CNRS, France; Universit´e Paris-Saclay, CNRS, C2N, Palaiseau, France; Universit´e Paris-Saclay, CNRS, C2N, Palaiseau, France; Universit´e Paris-Saclay, CNRS, C2N, Palaiseau, France; CEA, LETI, Grenoble, France; Universit´e Paris-Saclay, CNRS, C2N, Palaiseau, France; Universit´e Paris-Saclay, CNRS, C2N, Palaiseau, France; Universit´e Paris-Saclay, CNRS, C2N, Palaiseau, France",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","136","140","The design of systems implementing low precision neural networks with emerging memories such as resistive random access memory (RRAM) is a major lead for reducing the energy consumption of artificial intelligence (AI). Multiple works have for example proposed in-memory architectures to implement low power binarized neural networks. These simple neural networks, where synaptic weights and neuronal activations assume binary values, can indeed approach state-of-the-art performance on vision tasks. In this work, we revisit one of these architectures where synapses are implemented in a differential fashion to reduce bit errors, and synaptic weights are read using precharge sense amplifiers. Based on experimental measurements on a hybrid 130 nm CMOS/RRAM chip and on circuit simulation, we show that the same memory array architecture can be used to implement ternary weights instead of binary weights, and that this technique is particularly appropriate if the sense amplifier is operated in near-threshold regime. We also show based on neural network simulation on the CIFAR-10 image recognition task that going from binary to ternary neural networks significantly increases neural network performance. These results highlight that AI circuits function may sometimes be revisited when operated in low power regimes.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073877","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073877","","Biological neural networks;Immune system;Memory management;Task analysis;Circuit simulation;Integrated circuit modeling;Hardware","","4","","26","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Smart Logic-in-Memory Architecture For Ultra-Low Power Large Fan-In Operations","T. Zanotti; F. M. Puglisi; P. Pavan","Tommaso Zanotti, Francesco Maria Puglisi, Paolo Pavan DIEF, Università di Modena e Reggio Emilia, Via P. Vivarelli 10/1, Modena, Italy; Tommaso Zanotti, Francesco Maria Puglisi, Paolo Pavan DIEF, Università di Modena e Reggio Emilia, Via P. Vivarelli 10/1, Modena, Italy; Tommaso Zanotti, Francesco Maria Puglisi, Paolo Pavan DIEF, Università di Modena e Reggio Emilia, Via P. Vivarelli 10/1, Modena, Italy",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","31","35","The need for processing the continuously growing amount of data that is produced every day is promoting research for the development of energy-efficient non-von Neumann computing architectures. Over the last decade, resistive RAM (RRAM) devices together with material implication logic (IMPLY) were proposed as a promising solution for the development of low-power logic-in-memory (LIM) circuits. Still, the high design complexity and the low reliability of these circuits are hindering their practical realization. It is only recently that a new smart IMPLY architecture, named SIMPLY, was proposed and shown to drastically improve circuit reliability and energy efficiency of IMPLY-based LIM circuits. In this work, we introduce a new smart operation, called sFALSE, enabled by the SIMPLY architecture, and verify its feasibility using a physicsbased RRAM compact model calibrated on three different technologies. We highlight the significant advantage of the proposed solution vs. ordinary IMPLY architecture in terms of energy reduction, especially for large fan-in logic operations (e.g., n-bits NAND and EXOR).","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073870","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073870","SIMPLY;IMPLY;RRAM;Logic-In-Memory;Compact Model","Computer architecture;Resistance;Performance evaluation;Mathematical model;Degradation;Electrodes;Threshold voltage","","7","","38","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Live Demonstration: Video-to-Spike Conversion Using a Real-Time Retina Cell Network Simulator","S. Baek; J. K. Eshraghian; W. Thio; Y. Sandamirskaya; H. H. C. Iu; W. D. Lu",These authors contributed equally to the live demo; These authors contributed equally to the live demo; These authors contributed equally to the live demo; These authors contributed equally to the live demo; These authors contributed equally to the live demo; These authors contributed equally to the live demo,2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","131","131","Our live demonstration will present a discrete neuronal network simulator of the vertebrate retina, using a collation of prominent single-compartment outer segment neurons and morphologically accurate inner segment neurons. Cascaded models are scarce in literature due to computational intensity, but we successfully produce a biophysically accurate simulator that converts an input stream of pixels at 25-30 fps into a system of graded and spiking membrane potentials in real-time. We hope the simulator better facilitates an understanding of how retina cells represent visual information, and also provide an intuitive manner for neuroscientists to generate responses to video input for improved neural encoding schemes.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073790","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073790","","Retina;Real-time systems;Mathematical model;Computational modeling;Cameras;Numerical models;Biological system modeling","","3","","3","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"A SiPM-Based Directional Gamma-Ray Spectrometer With Embedded Machine Learning","L. Buonanno; D. D. Vita; A. Minerva; M. Carminati; C. Fiorini","Politecnico di Milano, Informazione e Bioingegneria (DEIB), Milano, Italy; Politecnico di Milano, Informazione e Bioingegneria (DEIB), Milano, Italy; Politecnico di Milano, Informazione e Bioingegneria (DEIB), Milano, Italy; Politecnico di Milano, Informazione e Bioingegneria (DEIB), Milano, Italy; Politecnico di Milano, Informazione e Bioingegneria (DEIB), Milano, Italy",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","168","172","A compact module based on arrays of solid-state SiPM detectors (up to 144), integrated front-end and a crystal with large scintillation efficiency (3” LaBr3:Ce) for detection of gamma rays is presented. In addition to state-of-the-art energy resolution (2.6% at 662 keV) and sub-centimeter spatial resolution in reconstruction of the photon interaction point, this portable unit enables the angular localization of gamma sources as a function of the reconstructed interaction point distribution. The latter task is performed by means of k-NN and decision tree classifiers. The implementation of the reconstruction algorithm in the micro-controller of the acquisition node allows for relaxation of constraints in data transmission and, in case of cooperative networks, distribution of computational complexity. The system architecture and design choices are here presented in detail, followed by preliminary experimental results obtained with a 16 channel front-end ASIC.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073914","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073914","Gamma spectroscopy;Machine Learning;Imaging;SiPM;Edge-Computing","Detectors;Crystals;Training;Photonics;Decision trees;Computer architecture;Heuristic algorithms","","5","","9","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Real-time Super Resolution CNN Accelerator with Constant Kernel Size Winograd Convolution","P. -W. Yen; Y. -S. Lin; C. -Y. Chang; S. -Y. Chien",National Taiwan University National Taiwan University; National Taiwan University National Taiwan University; National Taiwan University National Taiwan University; National Taiwan University National Taiwan University,2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","193","197","This paper presents a super-resolution CNN de-signed for real-time hardware processing and the associated hardware architecture. Previous networks typically contain numerous layers, various kernel sizes and deconvolution layers, making it hard for hardware implementation. In this paper, we present a CNN only consisting of 3×3 convolution, replacing the deconvolution by pixel shuffling. Such regularity of kernel size enables us to employ Winograd convolution to implement the whole network. The proposed architecture achieves output resolution of 1920×1080 (FHD) at 60 fps while working at a clock frequency of 200 MHz. It also outperforms other 12K-parameter networks in image quality.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073972","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073972","","Convolution;Image resolution;Computer architecture;Hardware;Computational modeling;Quantization (signal);Logic gates","","9","","13","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"XBAROPT - Enabling Ultra-Pipelined, Novel STT MRAM Based Processing-in-Memory DNN Accelerator","A. Anwar; A. Raychowdhury; R. Hatcher; T. Rakshit","Georgia Institute of Technology, Atlanta, GA, USA; Georgia Institute of Technology, Atlanta, GA, USA; Samsung Semiconductor Inc; Samsung Semiconductor Inc",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","36","40","An explosion in big data driven machine learning (ML) applications in conjunction with a severe slowdown of Moore's Law are prompting the search for alternative application-specific hardware fabrics. With its focus on bringing the compute inside memory bitcells, processing-in-memory (PIM) has been proposed to accelerate ML inference applications. In this paper, we present a modular, end-to-end simulation framework that is required to find a power-performance optimized solution for PIM based architectures for a given application. Our simulation framework encompasses multiple levels of hierarchies including device bitcell, array, memory hierarchy, dataflow, data re-use and algorithm-to-system mapping. Novel concepts at two levels of the hierarchy are introduced and evaluated: 1. Logic embeddable, high Ion/Ioff Magnetic Tunnel Junction (MTJ) bitcell and 2. Cycle accurate inter and intra layer pipelined operation for high performance and low power operations. Results are compared to pure digital custom ASIC implementation showing orders of magnitude improvements in power-performance on widely accepted MLPerf benchmarks.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073792","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073792","","Magnetic tunneling;Pipeline processing;Machine learning;Hardware;Transistors;Registers;Delays","","2","","15","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Fully-Integrated Spiking Neural Network Using SiOx-Based RRAM as Synaptic Device","A. REGEV; A. BRICALLI; G. PICCOLBONI; A. VALENTIAN; T. MESQUIDA; G. MOLAS; J. -F. NODIN","Weebit Nano, Hod Hasharon, Israel; CEA-Leti, Grenoble, France; Weebit Nano, Hod Hasharon, Israel; CEA-Leti, Grenoble, France; CEA-Leti, Grenoble, France; CEA-Leti, Grenoble, France; CEA-Leti, Grenoble, France",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","145","148","This paper presents, to the best of the authors' knowledge, the first complete integration of a Spiking Neural Network combining analog neurons and SiOx-based resistive memory (RRAM) synapses. The implemented topology is a perceptron, and the circuit is aimed at performing MNIST digits classification. An existing framework was adapted for off-line learning and weight quantization, and the network was later converted into its spiking equivalent. The test chip, fabricated in 130 nm CMOS, shows a classification accuracy of 82%, with a 180 pJ energy dissipation per spike.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073840","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073840","silicon oxide;resistive memories;spiking neural network;neuromorphic computing","Neurons;Synapses;Biological neural networks;Computer architecture;Training;Task analysis;Microprocessors","","6","","11","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Event-Based Attention and Tracking on Neuromorphic Hardware","A. Renner; M. Evanusa; G. Orchard; Y. Sandamirskaya","Institute of Neuroinformatics, UZH and ETH Zurich, Switzerland; University of Maryland, College Park, MD, USA; Intel Labs, San Francisco Bay Area, CA, USA; Institute of Neuroinformatics, UZH and ETH Zurich, Switzerland",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","132","132","We present a fully event-driven vision and processing system for selective attention and tracking implemented on Intel's neuromorphic research chip, Loihi, directly interfaced with an event-based Dynamic Vision Sensor, DAVIS. The attention mechanism is realized as a recurrent spiking neural network (SNN) that forms sustained activation-bump attractors. The network dynamics support object tracking when distractors are present and when the object slows down or stops.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073789","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073789","","Neuromorphics;Target tracking;Hardware;Vision sensors;Neurons;System-on-chip","","7","","4","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Layerwise Noise Maximisation to Train Low-Energy Deep Neural Networks","S. Henwood; F. Leduc-Primeau; Y. Savaria","Department of Electrical Engineering, ÉEcole Polytechnique de Montréal, Montréal (QC), Canada; Department of Electrical Engineering, ÉEcole Polytechnique de Montréal, Montréal (QC), Canada; Department of Electrical Engineering, ÉEcole Polytechnique de Montréal, Montréal (QC), Canada",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","271","275","Deep neural networks (DNNs) depend on the storage of a large number of parameters, which consumes an important portion of the energy used during inference. This paper considers the case where the energy usage of memory elements can be reduced at the cost of reduced reliability. A training algorithm is proposed to optimize the reliability of the storage separately for each layer of the network, while incurring a negligible complexity overhead compared to a conventional stochastic gradient descent training. For an exponential energy-reliability model, the proposed training approach can decrease the memory energy consumption of a DNN with binary parameters by 3.3× at isoaccuracy, compared to a reliable implementation.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073854","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073854","","Training;Circuit faults;Neural networks;Energy consumption;Reliability;Memory management;Sensitivity analysis","","7","","19","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Temperature Compensation Schemes for In-Memory Computing using Phase-Change Memory","I. Giannopoulos; M. L. Gallo; V. P. Jonnalagadda; E. Eleftheriou; A. Sebastian","IBM Research -Zurich, Rüschlikon, Switzerland; IBM Research -Zurich, Rüschlikon, Switzerland; IBM Research -Zurich, Rüschlikon, Switzerland; IBM Research -Zurich, Rüschlikon, Switzerland; IBM Research -Zurich, Rüschlikon, Switzerland",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","286","290","The explosive growth in data-centric artificial intelligence related applications necessitates exploration of non-von Neumann computing paradigms such as in-memory computing. The ability to perform certain computational tasks within the memory unit will reduce dramatically the time and energy that is spent into shuttling the data from the memory to the processing unit. However, the nanoscale resistive memory devices that are useful for these technologies suffer from non-ideal characteristics. In this work we deal with the computational precision loss due to the strong and inhomogeneous temperature dependence of resistive devices and in particular phase-change memory. We describe a temperature compensation method that applies to resistive crossbar arrays and its realization as a peripheral circuit. We derive array-level temperature compensation functions that are remarkably effective for projected phase-change memory devices. We simulate the system and experimentally validate its efficacy in the task of matrix-vector multiplications. The computational precision is found to be equivalent to an 8-bit multiplier at elevated temperatures.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9074003","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9074003","","Phase change materials;Temperature;Temperature measurement;Temperature dependence;Phase change memory;Performance evaluation;Programming","","5","","12","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"NeuronFlow: A Hybrid Neuromorphic – Dataflow Processor Architecture for AI Workloads","O. Moreira; A. Yousefzadeh; F. Chersi; A. Kapoor; R. . -J. Zwartenkot; P. Qiao; G. Cinserin; M. A. Khoei; M. Lindwer; J. Tapson","GrAI Matter Labs (GML) 2880 Zanker Rd, San Jose, CA, United States; GrAI Matter Labs (GML) 2880 Zanker Rd, San Jose, CA, United States; GrAI Matter Labs (GML) 2880 Zanker Rd, San Jose, CA, United States; GrAI Matter Labs (GML) 2880 Zanker Rd, San Jose, CA, United States; GrAI Matter Labs (GML) 2880 Zanker Rd, San Jose, CA, United States; GrAI Matter Labs (GML) 2880 Zanker Rd, San Jose, CA, United States; GrAI Matter Labs (GML) 2880 Zanker Rd, San Jose, CA, United States; GrAI Matter Labs (GML) 2880 Zanker Rd, San Jose, CA, United States; GrAI Matter Labs (GML) 2880 Zanker Rd, San Jose, CA, United States; GrAI Matter Labs (GML) 2880 Zanker Rd, San Jose, CA, United States",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","01","05","We present a novel computing architecture which combines the event-based and compute-in-network principles of neuromorphic computing with a traditional dataflow architecture. The result is a fine-grained dynamic dataflow system which avoids the coding issues intrinsic to spiking systems, and is suitable for both procedural workload and deep neural network (DNN) inference. The architecture is particularly suitable for computation of sparse CNNs and low-latency applications. We present results from GrAIOne, the first chip designed using the NeuronFlow architecture, which has 200 704 neurons implemented in a 28nm HPC + process.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073999","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073999","neuromorphic digital hardware;dataflow;event based neurol networks","Conferences;Circuits and systems","","13","","15","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Complex Neuron Dynamics on the IBM TrueNorth Neurosynaptic System","M. P. R. Löhr; C. Jarvers; H. Neumann","Inst. for Neural Information Processing, Ulm University, Ulm, Germany; Inst. for Neural Information Processing, Ulm University, Ulm, Germany; Inst. for Neural Information Processing, Ulm University, Ulm, Germany",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","113","117","Primate cortex is a layered computational system characterized by different cell clusterings and connectivities. Their details can be simplified by implementing two-dimensional sheets of visuo-topically arranged model columns defined as excitatory-inhibitory (E-I) pairs of single-voltage compartments (point-like entities). Such E-I pairs are driven by feedforward input, lateral recurrent interaction and modulating feedback from contextual signals. Here, we develop a principled modular approach to map the elemental computational processes of excitatory and inhibitory conductance-based neural elements onto spiking neuromorphic hardware. We focus on the braininspired IBM TrueNorth Neurosynaptic System to realize a realtime canonical columnar cortical model circuit that is also energy-efficient. The coding precision of the model is demonstrated in several experiments with populations of such model units.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073903","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073903","","Hardware;Computational modeling;Integrated circuit modeling;Axons;Brain modeling;Encoding","","2","","24","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Learning to Walk: Spike Based Reinforcement Learning for Hexapod Robot Central Pattern Generation","A. S. Lele; Y. Fang; J. Ting; A. Raychowdhury","School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","208","212","Learning to walk - i.e., learning locomotion under performance and energy constraints continues to be a challenge in legged robotics. Methods such as stochastic gradient, deep reinforcement learning (RL) have been explored for bipeds, quadrupeds and hexapods. These techniques are computationally intensive and often prohibitive for edge applications. These methods rely on complex sensors and pre-processing of data, which further increases energy and latency. Recent advances in spiking neural networks (SNNs) promise significant reduction in computing owing to the sparse firing of neuros and has been shown to integrate reinforcement learning mechanisms with biologically observed spike time dependent plasticity (STDP). However, training a legged robot to walk by learning the synchronization patterns of central pattern generators (CPG) in an SNN framework has not been shown. This can marry the efficiency of SNNs with synchronized locomotion of CPG based systems providing breakthrough end-to-end learning in mobile robotics. In this paper, we propose a reinforcement based stochastic weight update technique for training a spiking CPG. The whole system is implemented on a lightweight raspberry pi platform with integrated sensors, thus opening up exciting new possibilities.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073987","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073987","Central pattern generator;spiking neural Netwrks;Spike time dependent plasticity;Stochastic Reinforcement based STDP;robotic locomotion","Neurons;Legged locomotion;Robot sensing systems;Visualization;Fires","","24","","18","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Retinal Slip Estimation and Object Tracking with an Active Event Camera","Q. Zhu; J. Triesch; B. E. Shi","Department of Electrical and Computer Engineering, Hong Kong University of Science and Technology,Clear Water Bay, Kowloon, Hong Kong; Frankfurt Institute for Advanced Studies, Frankfurt am Main, Germany; Department of Electrical and Computer Engineering, Hong Kong University of Science and Technology,Clear Water Bay, Kowloon, Hong Kong",2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","59","63","This paper presents a retinal slip estimation algorithm and a novel tracking strategy for active event-based cameras. Event-based sensors have independent, asynchronous pixels that report local luminance change. Unlike conventional image sensors, the event cameras have a high dynamic range and high temporal resolution. To preserve these advantages, we propose an algorithm that enables estimates of the normal component of the optical flow to be updated as spikes come in, eschewing the accumulation of events within a fixed temporal window. We also propose a method for integrating these normal flow estimates to estimate the retinal slip between the camera and object. We demonstrate the advantages of this asynchronous estimator of the retinal slip using an active event camera simulator (AESIM), which we developed to enable simulation of the active control of an event sensor in a dynamic environment.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073922","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073922","Event-based sensor;Simulation;Tracking;Velocity estimation;Optical flow","Cameras;Sensors;Retina;Estimation;Image edge detection;Optical flow;Object tracking","","2","","18","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"[Front cover]","",,2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),"23 Apr 2020","2020","","","c1","c350","Presents the front cover or splash screen of the proceedings record.","","978-1-7281-4922-6","10.1109/AICAS48895.2020.9073956","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073956","","","","","","","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
